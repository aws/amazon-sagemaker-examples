{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and perform inference on ML Model packages from AWS Marketplace.\n",
    "\n",
    "There are two simple ways to try/deploy [ML model packages from AWS Marketplace](https://aws.amazon.com/marketplace/search/results?page=1&filters=FulfillmentOptionType%2CSageMaker::ResourceType&FulfillmentOptionType=SageMaker&SageMaker::ResourceType=ModelPackage), either using AWS console to deploy an ML model package (see [this blog](https://aws.amazon.com/blogs/machine-learning/adding-ai-to-your-applications-with-ready-to-use-models-from-aws-marketplace/)) or via code written typically in a Jupyter notebook. Many listings have a high-quality sample Jupyter notebooks provided by the seller itself, usually, these sample notebooks are linked to the AWS Marketplace listing (E.g. [Source Separation](https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we?qid=1579739476471&sr=0-1&ref_=srh_res_product_title)), If a sample notebook exists, try it out. \n",
    "\n",
    "If such a sample notebook does not exist and you want to deploy and try an ML model package via code written in python language, this generic notebook can guide you on how to deploy and perform inference on an ML model package from AWS Marketplace.\n",
    "\n",
    "\n",
    "> **Note**:If  you are facing technical issues while trying an ML model package from AWS Marketplace and need help, please open a support ticket or write to the team on aws-mp-bd-ml@amazon.com for additional assistance.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. Open this notebook from an Amazon SageMaker Notebook instance.\n",
    "1. Ensure that Amazon SageMaker notebook instance used  has  IAMExecutionRole with **AmazonSageMakerFullAccess**\n",
    "1. Your IAM role has these three permisions - **aws-marketplace:ViewSubscriptions**, **aws-marketplace:Unsubscribe**, **aws-marketplace:Subscribe** and you have authority to make AWS Marketplace subscriptions in the AWS account used.\n",
    "\n",
    "> **Note**: If you are viewing this notebook from a GitHub repository, then to try this notebook successfully, [create an Amazon SageMaker Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html) and then [access Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-access-ws.html) you just created. Next, upload this Jupyter notebook to your notebook instance. \n",
    "\n",
    "\n",
    "\n",
    "#### Additional Resources:\n",
    "**Background on Model Packages**:\n",
    "1. An ML model can be created from a Model Package, to know how, see [Use a Model Package to Create a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-model-pkg-model.html). \n",
    "2. An ML Model accepts data and generates predictions.\n",
    "3. To perform inference, you first need to deploy the ML Model. An ML model typically supports two types of predictions:\n",
    "    1. [Use Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to asynchronously generate predictions for multiple input data observations. \n",
    "    2. Send input data to Amazon SageMaker endpoint to synchronously generate predictions for individual data observations. For information, see [Deploy a Model on Amazon SageMaker Hosting Services](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)\n",
    "\n",
    "**Background on AWS Marketplace Model packages**:\n",
    "If you are new to Model packages from AWS Marketplace, here are some additional resources.\n",
    "* For a high level overview of how AWS Marketplace for Machine Learning see the [Using AWS Marketplace for machine learning workloads](https://aws.amazon.com/blogs/awsmarketplace/using-aws-marketplace-for-machine-learning-workloads/) blog post.\n",
    "* For a high level overview on Model packages from AWS Marketplace, see [this blog post](https://aws.amazon.com/blogs/aws/new-machine-learning-algorithms-and-model-packages-now-available-in-aws-marketplace/).\n",
    "* For an overview on how to deploy a Model package using AWS Console and using AWS CLI for performing inference, see the [Adding AI to your applications with ready-to-use models from AWS Marketplace](https://aws.amazon.com/blogs/machine-learning/adding-ai-to-your-applications-with-ready-to-use-models-from-aws-marketplace/) blog post. \n",
    "* For a Jupyter notebook of the sample solution for **Automating auto insurance claim processing workflow** outlined in [this re:Mars session](https://www.youtube.com/watch?v=GkKZt0s_ku0), see [amazon-sagemaker-examples/aws-marketplace](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/aws_marketplace/using_model_packages/auto_insurance) GitHub repository.\n",
    "* For a Jupyter notebook of the sample solution for **Improving workplace safety solution** outlined in [this re:Invent session](https://www.youtube.com/watch?v=iLOXaWpK6ag), see [amazon-sagemaker-examples/aws-marketplace](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/aws_marketplace/using_model_packages/improving_industrial_workplace_safety) GitHub repository.\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#Subscribe-to-the-model-package)\n",
    "   1. [Identify compatible instance-type](#A.-Identify-compatible-instance-type)\n",
    "   2. [Identify content-type](#B.-Identify-content_type)\n",
    "   3. [Specify model-package-arn](#C.-Specify-model-package-arn)\n",
    "2. [Create an Endpoint and perform real-time inference](#2.-Create-an-Endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an Endpoint](#A.-Create-an-Endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform Real-time inference](#C.-Perform-Real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform Batch inference](#3.-Perform-Batch-inference) \n",
    "   1. [Prepare input payload](#A.-Prepare-input-payload) \n",
    "   2. [Run a batch-transform job](#B.-Run-a-batch-transform-job)\n",
    "   3. [Visualize output](#C.-Visualize-output)\n",
    "4. [Delete the model](#4.-Delete-the-model)\n",
    "5. [Unsubscribe to the model package](#Unsubscribe-to-the-model-package)\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following boilerplate code includes all major libraries that you might need.\n",
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can deploy the model, your account needs to be subscribed to it. This section covers instructions for populating necessary parameters and for subscribing to the Model package, if the subscription does not already exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the Model Package listing page (E.g. [GluonCV YOLOv3 Object Detector](https://aws.amazon.com/marketplace/pp/prodview-5jlvp43tsn3ny?qid=1578429923058&ref_=srh_res_product_title&sr=0-1)) from AWS Marketplace that you wish to try/use.\n",
    "2. Read the **product overview** section and  **Highlights** section of the listing to understand the value proposition of the model package.\n",
    "3. View **usage information** and then **additional resources** sections. These sections will contain following things:\n",
    "    1. Input content-type\n",
    "    2. Sample input file (optional)\n",
    "    3. Sample Jupyter notebook\n",
    "    4. Output format\n",
    "    5. Any additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Identify compatible instance-type\n",
    "\n",
    "1. On the listing, Under **Pricing Information**, you will see **software pricing** for **real-time inference** as well as **batch-transform usage** for specific instance-types. \n",
    "\n",
    "> **Note**: Software pricing is in addition to regular SageMaker infrastructure charges.\n",
    "    \n",
    "2. In the pricing chart, you will also notice the **vendor recommended instance-type** . E.g [GluonCV YOLOv3 Object Detector](https://aws.amazon.com/marketplace/pp/prodview-5jlvp43tsn3ny?qid=1578429923058&ref_=srh_res_product_title&sr=0-1) has recommended real-time inference instance-type as \n",
    "**ml.m4.xlarge** and recommended batch transform inference as **ml.m4.xlarge**\n",
    "\n",
    "3. Specify the  recommended instance-types in the following cell and then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time_inference_instance_type=''\n",
    "batch_transform_inference_instance_type=''\n",
    "#real_time_inference_instance_type='ml.m4.xlarge'\n",
    "#batch_transform_inference_instance_type='ml.m4.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Identify content_type\n",
    "You need to specify input content-type and payload while performing inference on the model. In this sub-section you will identify input content type that is accepted by the model you wish to try. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sellers has provided content_type information via:\n",
    "1. a sample invoke_endpoint api/CLI call in the **usage instructions** section, of the listing. E.g [GluonCV YOLOv3 Object Detector](https://aws.amazon.com/marketplace/pp/prodview-5jlvp43tsn3ny?qid=1578429923058&sr=0-1&ref_=srh_res_product_title) has following AWS CLI snippet, with --content-type specified as **image/jpeg**.\n",
    ">```Bash\n",
    "aws sagemaker-runtime invoke-endpoint --endpoint-name your_endpoint_name --body fileb://img.jpg --content-type image/jpeg --custom-attributes '{\"threshold\": 0.2}' --accept json  >(cat) 1>/dev/null\n",
    "```\n",
    "\n",
    "2. plain-text information in the **usage instructions** section, of the listing. E.g. [Lyrics Generator (CPU)](https://aws.amazon.com/marketplace/pp/prodview-qqzh5iao6si4c?qid=1578429518061&sr=0-2&ref_=srh_res_product_title) has following snippet which indicates that **application/json** is the content-type. \n",
    "\n",
    ">```Javascript\n",
    "Input (application/json): Artist name and seed lyrics (start of song). \n",
    "Payload: {\"instances\": [{\"artist\":\"<singer>\", \"seed\": \"<seed_word>\"}]}\n",
    "```\n",
    "\n",
    "3. Sample notebook, linked under **usage instructions**/**additional information**/**support information** and the sample notebook might use AWS CLI/Boto3 or SDK to perform inference.\n",
    "    \n",
    "    1. E.g., [Vehicle Damage Inspection](https://aws.amazon.com/marketplace/pp/prodview-xhj66rbazm6oe?qid=1579723100840&sr=0-1&ref_=srh_res_product_title) has a link to a file under **Additional resources** section that containing **Vehicle-Damage-Inspection.ipynb**, a jupyter notebook that has following snippet with ContentType specified as **image/jpeg**.\n",
    "> ```Python\n",
    "invocation_api_handle.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='image/jpeg', ... \n",
    "```\n",
    "    2. [A Sample notebook from sagemaker-examples repo](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/auto_insurance/automating_auto_insurance_claim_processing.ipynb) uses Python SDK to perform inference, and the predictor class defined shows that content type is **image/jpeg**  \n",
    "> ```Python\n",
    "def damage_detection_predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session,content_type='image/jpeg')\n",
    "```\n",
    "\n",
    "Once you have identified the input content type, specify the same in following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_type=''\n",
    "#content_type='image/jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Specify model-package-arn\n",
    "A model-package-arn is a unique identifier for each ML model package from AWS Marketplace within a chosen region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "2. On the **Subscribe to this software** page (E.g. [here](https://aws.amazon.com/marketplace/ai/procurement?productId=d9949c88-fe3b-4a2d-923e-9458fe7e9f2c)), Review the **End user license agreement**, **support terms**, as well as **pricing information**.\n",
    "3. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA, pricing information as well as support terms.\n",
    "4. Next, **Continue to configuration** button becomes activated and when you click on the button, you will see that a **Product Arn** will appear. In the **Region** dropdown, Choose the region in which you have opened this notebook from, Copy the product ARN and replace it in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn=''\n",
    "#model_package_arn='arn:aws:sagemaker:us-east-1:865070037744:model-package/gluoncv-yolo3-darknet531547760-bdf604d6d9c12bf6194b6ae534a638b2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have identified necessary information to be able to create an endpoint for performing real-time inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an Endpoint and perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will stand up an Amazon SageMaker endpoint. Each endpoint must have a unique name which you can use for performing inference. \n",
    "\n",
    "Specify a short name you wish to use for naming endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=''\n",
    "#model_name='gluoncv-object-detector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)\n",
    "\n",
    "#Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**: A Machine Learning model accepts a payload and returns an inference. E.g. [Deep Vision vehicle recognition](https://aws.amazon.com/marketplace/pp/prodview-a7wgrolhu54ts?qid=1579728052169&sr=0-1&ref_=srh_res_product_title) accepts an image as a payload and returns an inference containing make,model, and year of the car. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you will prepare a payload to perform a prediction. This step varies from model to model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify a sample Input file you can use:\n",
    "1. Sometimes file is available in **additional resources** section of the listing. E.g. [Mphasis DeepInsights Document Classifier](https://aws.amazon.com/marketplace/pp/prodview-u5jlb2ba6xmaa?qid=1579793398686&sr=0-1&ref_=srh_res_product_title) has multiple sample files in an archieve.\n",
    "\n",
    "\n",
    "2. Sometimes file is available in a Github Repo link associated with the listing. E.g. [Source Separation](https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we?qid=1579739476471&sr=0-1&ref_=srh_res_product_title) has a sample file in the GitHUB repo. In which case, please copy the link to the raw data file.\n",
    "\n",
    "\n",
    "3. Sometimes a sample file is not available, however, clear instructions on how to prepare the payload are available. E.g. [Face Anonymizer (CPU)](https://aws.amazon.com/marketplace/pp/prodview-3olpixsfcqfq6?qid=1560287886810&sr=0-3&ref_=srh_res_product_title)), then you would need to manually identify an input file you can use. I identified that I can use an image shown on [this blog](https://aws-preview.aka.amazon.com/blogs/machine-learning/adding-ai-to-your-applications-with-ready-to-use-models-from-aws-marketplace/), and then manually prepare a payload for performing inference\n",
    "\n",
    "4. For models for which there is no sample file (E.g. [Demisto Phishing Email Classifier](https://aws.amazon.com/marketplace/pp/prodview-k5354ho27eyps)) but it accepts a simple input, jump to [Step B.2](#Step-B.2-Manually-prepare-data-(applicable-only-if-your-payload-is-not-ready-yet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the URL of the sample file you identified in the following cell to download the file for creating payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=''\n",
    "#url='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Vincent_van_Gogh_-_Self-Portrait_-_Google_Art_Project.jpg/512px-Vincent_van_Gogh_-_Self-Portrait_-_Google_Art_Project.jpg'\n",
    "#url='https://d1.awsstatic.com/webteam/architecture-icons/AWS-Architecture-Icons-Deck_For-Light-BG_20191031.pptx.6fcecd0cf65442a1ada0ce1674bc8bfc8de0cb1d.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, specify a file_name that you would like to save the file to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=''\n",
    "#file_name='input.json'\n",
    "#file_name='input.jpg'\n",
    "#file_name='file.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the file\n",
    "urllib.request.urlretrieve(url,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the file you just downloaded\n",
    "\n",
    "Based on the type of file used, uncomment, modify, and run appropriate code snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ZIP/Tar file\n",
    "If your input file was inside a zip file, uncomment appropriate line from following two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip $file_name\n",
    "#!tar -xvf $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the file_name variable with an appropriate file-path from the folder created by unzipping the archieve\n",
    "#file_name=''\n",
    "#file_name='images/AWS-Architecture-Icons-Deck_For-Light-BG_20191031.pptx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Image File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run the following line to view the image\n",
    "#Image(url= file_name, width=400, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Text/Json/CSV File\n",
    "If your input file is a text/json/csv file, view the file by un-commenting following line. If your file contains multiple payloads, consider keeping just one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head $file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View and play the video by uncommenting following two lines\n",
    "\n",
    "#from IPython.display import HTML\n",
    "#HTML('<iframe width=\"560\" height=\"315\" src=\"'+file_name+'?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment following two lines to view and play the audio\n",
    "\n",
    "#import IPython.display as ipd\n",
    "#ipd.Audio(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model's input **content-type** is one of the following and file_name variable is pointing to a file that can directly be sent to ML model, congratulations, you have prepared the payload, you can jump to Step [C. Perform Real-time inference](#C.-Perform-Real-time-inference):\n",
    "*  **wav/mp3** \n",
    "*  **application/pdf** \n",
    "*  **image/png** \n",
    "*  **image/jpeg**:\n",
    "*  **text/plain**\n",
    "*  **text/csv**\n",
    "*  **application/json** (Only if file_name variable is pointing to a JSON file that can directly be sent to ML model)\n",
    "\n",
    "If your content-type is any other, your model might need additional pre-processing, proceed to [Step B.1](#Step-B.1-Pre-process-the-data-(Optional-for-some-models)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step B.1 Pre-process the data (Optional for some models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models require preprocessing, others dont. If model you want to try/use requires additional pre-processing, Please refer to sample notebook or usage instructions for pre-processing required. This section contains some re-usable code that you might need to tweak as per your requirement. Uncomment, tweak and use following as required. Ensure that final payload is written to a variable with name 'payload'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some models require Base64 encoded data\n",
    "> [Background Noise Classifier (CPU)](https://aws.amazon.com/marketplace/pp/prodview-vpd6qdjm4d7u4?qid=1579792115621&sr=0-2&ref_=srh_res_product_title) requires payload to be in following format\n",
    "\n",
    "```javascript\n",
    "    Payload: {\"instances\": [{\"audio\": {\"b64\": \"BASE_64_ENCODED_WAV_FILE_CONTENTS\"}}]}\n",
    "```\n",
    "\n",
    "> [Neural Style Transfer](https://aws.amazon.com/marketplace/pp/prodview-g5i35lg4qmplu) requires payload to be in following format. You would need to tweak code appropriately to convert two images into base64 format for this model.\n",
    "    \n",
    "```javascript\n",
    "    {\n",
    "        \"content\": \"base64 characters of your content image\",\n",
    "        \"style\": \"base64 characters of your style image\",\n",
    "        \"iterations\": 2\n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a sample code that does Base64 encoding\n",
    "\n",
    "#file_read = open(file_name, 'rb').read() \n",
    "#base64_encoded_value = base64.b64encode(file_read).decode('utf-8')\n",
    "\n",
    "#payload=\"{\\\"style\\\":\\\"\"+str(style_image_base64_encoded_value)+\"\\\", \\\"iterations\\\": 2,\\\"content\\\":\\\"\"+str(base64_encoded_value)+\"\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some models require images in serialized format\n",
    "> E.g. [Mphasis DeepInsights Damage Prediction](https://aws.amazon.com/marketplace/pp/prodview-2f5br37zmuk2y?qid=1576781776298&sr=0-1&ref_=srh_res_product_title) requires the image to be re-sized to (300 x 300) and then JSON serialised before it can be fed to the model. To make it easy to do so, they also have provided snippet identical to following one in the sample jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "\n",
    "#image = Image.open(file_name).convert(mode = 'RGB')\n",
    "#resized_image = image.resize((300,300))\n",
    "\n",
    "#image_array = np.array(resized_image).tolist()\n",
    "#payload = json.dumps({'instances': [{'input_image': image_array}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, jump to [Step B.3](#Step-B.3-Write-payload-you-created-to-a-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step B.2 Manually prepare data (applicable only if your payload is not ready yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If sample notebook is not available but input format is simple, write code required for creating the input file. E.g. [Demisto Phishing Email Classifier](https://aws.amazon.com/marketplace/pp/prodview-k5354ho27eyps) does not have a sample file but sample notebook has some code that can be used for prepared payload.\n",
    "\n",
    "```Javascript\n",
    "email1 = \"<Email content shortened for brevity>\"\n",
    "email2 = \"<Email content shortened for brevity>\"\n",
    "emails = [email1, email2]\n",
    "json.dumps(emails)\n",
    "```\n",
    "\n",
    "Prepare appropriate payload and store the same in a variable called 'payload'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [Step B.3](#Step-B.3-Write-payload-you-created-to-a-file) to write your payload to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step B.3 Write payload you created to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that you have populated payload json/csv in a variable called 'payload', here is a sample generic code that writes the payload to a file you can un-comment and reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name='output_file'\n",
    "\n",
    "#file = open(file_name, \"w\") #Change w to wb if you intend to write bytes isntead of text.\n",
    "#file.write(payload)\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your payload is ready and is written to a file referenced by the file_name variable, you are ready to perform an inference. Proceed to Step [C. Perform Real-time inference](#C.-Perform-Real-time-inference).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform Real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify name and extension of the file you would like to store the inference output to. The output type varies from model to model and this information is usually available in the **Usage instructions**/**sample notebook** associated with the listing.\n",
    "\n",
    "For Example:\n",
    "* [Neural Style Transfer](https://aws.amazon.com/marketplace/pp/prodview-g5i35lg4qmplu) model's output type is image, so specify **.png**  as file extension.\n",
    "* [Source Separation](https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we?qid=1579807024600&sr=0-1&ref_=srh_res_product_title) model's output type is a zip file, so specify **.zip** as file extension. \n",
    "* [Mphasis DeepInsights Address Extraction](https://aws.amazon.com/marketplace/pp/prodview-z4wgslad4b27g?qid=1579802907920&sr=0-2&ref_=srh_res_product_title) model's output type is text/plain, so specify **.txt** as file extension.\n",
    "* Sample notebook provided by seller usually makes it evident what the output type is. If one doesnt exist, and instructions are unclear, try a few options, start with text - Many ML models return response in a simple textual format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time_inference_output_file_name=''\n",
    "#real_time_inference_output_file_name='output.json'\n",
    "#real_time_inference_output_file_name='output.zip'\n",
    "#real_time_inference_output_file_name='output.txt'\n",
    "#real_time_inference_output_file_name='output.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following AWS CLI command sends the **payload** and the **content-type** to the model hosted on the endpoint. \n",
    "> **Note on Custom Attributes**: Some models accept additional attributes such as [GluonCV YOLOv3 Object Detector](https://aws.amazon.com/marketplace/pp/prodview-5jlvp43tsn3ny?qid=1578429923058&ref_=srh_res_product_title&sr=0-1)\n",
    "    accepts a custom attribute called threshold as specified in following sample code snippet. \n",
    "> ```Bash\n",
    "aws sagemaker-runtime invoke-endpoint --endpoint-name your_endpoint_name --body fileb://img.jpg --content-type image/jpeg --custom-attributes '{\"threshold\": 0.2}' --accept json  >(cat) 1>/dev/null\n",
    "```\n",
    "Please modify the following AWS-CLI command appropriately if the model you wish to perform inference on requires any custom attribute, if not, execute following command to perform inference.\n",
    "\n",
    "Once inference has been performed, the output gets written to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $model_name \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    $real_time_inference_output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above invocation shows a snippet such as following, it means the command executed successfully. Otherwise, check whether input payload is in correct format.\n",
    "\n",
    "```Javascript\n",
    "{\n",
    "    \"ContentType\": \"<content_type>; charset=utf-8\",\n",
    "    \"InvokedProductionVariant\": \"<Variant>\"\n",
    "}\n",
    "```\n",
    "View the output available in file referenced by **real_time_inference_output_file_name** variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output is in **text**/**CSV**/**JSON** format, view the output file by uncommenting and running following command. Otherwise use an appropriate command (Please see reference commands from step [View the file you just downloaded](#View-the-file-you-just-downloaded)) for viewing the output OR open the output file directly from Jupyter console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f=open(real_time_inference_output_file_name, \"r\")\n",
    "#data=f.read()\n",
    "#print(data)\n",
    "#Sometimes output is a json, load it into a variable with json.loads(data) and then print the variable to see formatted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.RealTimePredictor(model_name, sagemaker_session,content_type)\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform Batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a batch transform job, we will use the same payload we used for performing real-time inference. file_name variable points to the payload.\n",
    "\n",
    "> **Note**: If you followed instructions closely, your input file contains a single payload. However, batch-transform can be used to perform a batch inference on multiple records at a time. To know more, see documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the file to S3\n",
    "transform_input = sagemaker_session.upload_data(file_name, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], file_name.split(\"/\")[-1])\n",
    "print(file_key)\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output is in **text**/**CSV**/**JSON** format, view the output file by uncommenting and running following command. Otherwise go to S3, download the file and open it using appropriate editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_bytes = response['Body'].read().decode('utf-8')\n",
    "print(response_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** - You need to write appropriate code here to clean-up any files you may have uploaded/created while trying out this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cleanup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if the AWS Marketplace subscription was created just for the experiment and you would like to unsubscribe to the product, here are the steps that can be followed.\n",
    "Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to un-subscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=lbr_tab_ml)\n",
    "2. Locate the listing that you would need to cancel subscription for, and then __Cancel Subscription__ can be clicked to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
