{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Tic-Tac-Toe with Reinforcement Learning\n",
    "**_Train with SageMaker RL and evaluate interactively within the notebook_**\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Setup](#Setup)\n",
    "1. [Code](#Code)\n",
    "  1. [Environment](#Environment)\n",
    "  1. [Preset](#Preset)\n",
    "  1. [Launcher](#Launcher)\n",
    "1. [Train](#Train)\n",
    "1. [Deploy](#Deploy)\n",
    "  1. [Inference](#Inference)\n",
    "1. [Play](#Play)\n",
    "1. [Wrap Up](#Wrap-Up)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Tic-tac-toe is one of the first games children learn to play and was one of the [first computer games ever](https://en.wikipedia.org/wiki/OXO).  Optimal play through exhaustive search is relatively straightforward, however, approaching with a reinforcement learning agent can be educational.\n",
    "\n",
    "This notebook shows how to train a reinforcement learning agent with SageMaker RL and then play locally and interactively within the notebook.  Unlike SageMaker local mode, this method does not require a docker container to run locally, instead using an endpoint and integration with a small Jupyter app.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by defining our S3 bucket and and IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the libraries we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from tic_tac_toe_game import TicTacToeGame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Code\n",
    "\n",
    "Our tic-tac-toe example requires 3 scripts in order to train our agent using SageMaker RL.  The scripts are placed in the `./src` directory which is sent to the container when the SageMaker training job is initiated.\n",
    "\n",
    "### Environment\n",
    "\n",
    "For our tic-tac-toe use case we'll create a custom Gym environment.  This means we'll specify a Python class which inherits from `gym.Env` and has two methods: `reset()` and `step()`.  These will provide the agent its state, actions, and rewards for learning.  In more detail:\n",
    "\n",
    "The `__init__()` method is called at the beginning of the SageMaker training job and:\n",
    "1. Starts the 3x3 tic-tac-toe board as a NumPy array of zeros\n",
    "1. Prepares the state space as a flattened version of the board (length 9)\n",
    "1. Defines a discrete action space with 9 possible options (one for each place on the board)\n",
    "\n",
    "The `reset()` method is called at the beginning of each episode and:\n",
    "1. Clears the 3x3 board (sets all values to 0)\n",
    "1. Does some minor record-keeping for tracking across tic-tac-toe games\n",
    "\n",
    "The `step()` method is called for each iteration in an episode and:\n",
    "1. Adjusts the board based on the action chosen by the agent based on the previous state\n",
    "1. Generates rewards based on performance\n",
    "1. Automatically chooses the move for the agent's opponent if needed\n",
    "\n",
    "Note:\n",
    "* The opponent has not been programmed for perfect play.  If we taught our agent against a perfect opponent, it would not generalize to scenarios where the rules of perfect play were not followed.\n",
    "* If our agent selects an occupied space, it is given a minor penalty (-0.1) and asked to choose again.  Although the state doesn't change across these steps (meaning the agent's network's prediction should stay the same), randomness in the agent should eventually result in different actions.  However, if the agent chooses an occupied space 10 times in a row, the game is forfeit.  Selecting an action only from available spaces would require more substantial modification than was desired for this example.\n",
    "* Other rewards only occur when a game is completed (+1 for win, 0 for draw, -1 for loss).\n",
    "* The board is saved as a NumPy array where a value of +1 represents our agent's moves (`X`s) and a value of -1 represents the opponent's moves (`O`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgym\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mgym\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m spaces\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mTicTacToeEnv\u001b[39;49;00m(gym.Env):\n",
      "\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, opponent=\u001b[33m'\u001b[39;49;00m\u001b[33mmoderate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "        \u001b[36mself\u001b[39;49;00m.opponent = opponent\n",
      "        \u001b[36mself\u001b[39;49;00m.episode = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.observation_space = spaces.Box(low=-\u001b[34m1\u001b[39;49;00m, high=\u001b[34m1\u001b[39;49;00m, shape=(\u001b[34m9\u001b[39;49;00m, ), dtype=np.int)\n",
      "        \u001b[36mself\u001b[39;49;00m.action_space = spaces.Discrete(\u001b[34m9\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mreset\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[36mself\u001b[39;49;00m.episode += \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.total_reward = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.occupied = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.board = np.zeros((\u001b[34m3\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m))\n",
      "        state = \u001b[36mself\u001b[39;49;00m.board.flatten()\n",
      "        \u001b[34mreturn\u001b[39;49;00m state\n",
      "\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mstep\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, action):\n",
      "\n",
      "        \u001b[37m# Convert action into board position\u001b[39;49;00m\n",
      "        row = action // \u001b[34m3\u001b[39;49;00m\n",
      "        col = action % \u001b[34m3\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# If agent picks an occupied space repeated end the game and give a penalty\u001b[39;49;00m\n",
      "        \u001b[37m# Otherwise, give a small penalty and try again\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board[row, col] != \u001b[34m0\u001b[39;49;00m:\n",
      "            \u001b[36mself\u001b[39;49;00m.occupied += \u001b[34m1\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.occupied > \u001b[34m10\u001b[39;49;00m:\n",
      "                reward = -\u001b[34m1\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.total_reward += reward\n",
      "                \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\n",
      "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[36mTrue\u001b[39;49;00m, {\u001b[33m'\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: reward}\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                reward = -\u001b[34m0.1\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.total_reward += reward\n",
      "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[36mFalse\u001b[39;49;00m, {\u001b[33m'\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: reward}\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[36mself\u001b[39;49;00m.occupied = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# Otherwise agent actions action updates the board and check for a win\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.board[row, col] = \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m check_win(\u001b[36mself\u001b[39;49;00m.board) == \u001b[34m1\u001b[39;49;00m:\n",
      "            reward = \u001b[34m1\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.total_reward += reward\n",
      "            \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[36mTrue\u001b[39;49;00m, {\u001b[33m'\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: reward}\n",
      "\n",
      "        \u001b[37m# Check if last move\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m.board != \u001b[34m0\u001b[39;49;00m).all():\n",
      "            reward = \u001b[34m0\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.total_reward += reward\n",
      "            \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[36mTrue\u001b[39;49;00m , {\u001b[33m'\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: reward}\n",
      "        \u001b[37m# If not then opponent moves\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[36mself\u001b[39;49;00m.move_opponent()\n",
      "            \u001b[34mif\u001b[39;49;00m check_win(\u001b[36mself\u001b[39;49;00m.board) == -\u001b[34m1\u001b[39;49;00m:\n",
      "                reward = -\u001b[34m1\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.total_reward += reward\n",
      "                \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\n",
      "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[36mTrue\u001b[39;49;00m, {\u001b[33m'\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: reward}\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), \u001b[34m0\u001b[39;49;00m, \u001b[36mFalse\u001b[39;49;00m, {\u001b[33m'\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34m0\u001b[39;49;00m}\n",
      "\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mmove_opponent\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.opponent == \u001b[33m'\u001b[39;49;00m\u001b[33mrandom\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            options = np.argwhere(\u001b[36mself\u001b[39;49;00m.board == \u001b[34m0\u001b[39;49;00m)\n",
      "            idx = np.random.randint(options.shape[\u001b[34m0\u001b[39;49;00m])\n",
      "            \u001b[36mself\u001b[39;49;00m.board[\u001b[36mtuple\u001b[39;49;00m(options[idx])] = -\u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.opponent == \u001b[33m'\u001b[39;49;00m\u001b[33mmoderate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            move = \u001b[36mNone\u001b[39;49;00m\n",
      "            options = np.argwhere(\u001b[36mself\u001b[39;49;00m.board == \u001b[34m0\u001b[39;49;00m)\n",
      "            \u001b[34mif\u001b[39;49;00m np.random.rand() < \u001b[34m0.1\u001b[39;49;00m:\n",
      "                idx = np.random.randint(options.shape[\u001b[34m0\u001b[39;49;00m])\n",
      "                \u001b[36mself\u001b[39;49;00m.board[\u001b[36mtuple\u001b[39;49;00m(options[idx])] = -\u001b[34m1\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                \u001b[37m# Check if there's a next move that could win\u001b[39;49;00m\n",
      "                \u001b[34mfor\u001b[39;49;00m o \u001b[35min\u001b[39;49;00m options:\n",
      "                    board = \u001b[36mself\u001b[39;49;00m.board.copy()\n",
      "                    board[\u001b[36mtuple\u001b[39;49;00m(o)] = -\u001b[34m1\u001b[39;49;00m\n",
      "                    \u001b[34mif\u001b[39;49;00m check_win(board) == -\u001b[34m1\u001b[39;49;00m:\n",
      "                        move = \u001b[36mtuple\u001b[39;49;00m(o)\n",
      "                        \u001b[34mbreak\u001b[39;49;00m\n",
      "                \u001b[37m# Otherwise check for a block\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m move:\n",
      "                    \u001b[34mfor\u001b[39;49;00m o \u001b[35min\u001b[39;49;00m options:    \n",
      "                        board = \u001b[36mself\u001b[39;49;00m.board.copy()\n",
      "                        board[\u001b[36mtuple\u001b[39;49;00m(o)] = \u001b[34m1\u001b[39;49;00m\n",
      "                        \u001b[34mif\u001b[39;49;00m check_win(board) == \u001b[34m1\u001b[39;49;00m:\n",
      "                            move = \u001b[36mtuple\u001b[39;49;00m(o)\n",
      "                            \u001b[34mbreak\u001b[39;49;00m\n",
      "                \u001b[37m# Otherwise, take a random option\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m move:\n",
      "                    idx = np.random.randint(options.shape[\u001b[34m0\u001b[39;49;00m])\n",
      "                    move = \u001b[36mtuple\u001b[39;49;00m(options[idx])\n",
      "                \u001b[36mself\u001b[39;49;00m.board[move] = -\u001b[34m1\u001b[39;49;00m\n",
      "\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msave_board\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, reward, path=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/output/data/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "        np.save(os.path.join(path, \u001b[33m'\u001b[39;49;00m\u001b[33mepisode_{}_reward_{}.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[36mself\u001b[39;49;00m.episode, reward)), \n",
      "                \u001b[36mself\u001b[39;49;00m.board)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcheck_win\u001b[39;49;00m(board):\n",
      "    v = board.sum(axis=\u001b[34m0\u001b[39;49;00m)\n",
      "    h = board.sum(axis=\u001b[34m1\u001b[39;49;00m)\n",
      "    dd = board[\u001b[34m0\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m] + board[\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m] + board[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m]\n",
      "    du = board[\u001b[34m2\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m] + board[\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m] + board[\u001b[34m0\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m]\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mmax\u001b[39;49;00m(v.max(), h.max()) == \u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m dd == \u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m du == \u001b[34m3\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\n",
      "    \u001b[34melif\u001b[39;49;00m \u001b[36mmin\u001b[39;49;00m(v.min(), h.min()) == -\u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m dd == -\u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m du == -\u001b[34m3\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m -\u001b[34m1\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m0\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/tic_tac_toe.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preset\n",
    "\n",
    "The preset file specifies Coach parameters used by our reinforcement learning agent.  For this problem we'll use a [Clipped PPO algorithm](https://nervanasystems.github.io/coach/components/agents/policy_optimization/cppo.html).  We have kept the preset file deliberately spartan, deferring to defaults for most parameters, in order to focus on just the key components.  Performance of our agent could likely be improved with increased tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.agents.clipped_ppo_agent\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ClippedPPOAgentParameters\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.base_parameters\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m VisualizationParameters, PresetValidationParameters\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.core_types\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TrainingSteps, EnvironmentEpisodes, EnvironmentSteps\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.environments.gym_environment\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m GymVectorEnvironment\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.graph_managers.basic_rl_graph_manager\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BasicRLGraphManager\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.graph_managers.graph_manager\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ScheduleParameters\r\n",
      "\r\n",
      "\u001b[37m####################\u001b[39;49;00m\r\n",
      "\u001b[37m# Graph Scheduling #\u001b[39;49;00m\r\n",
      "\u001b[37m####################\u001b[39;49;00m\r\n",
      "\r\n",
      "schedule_params = ScheduleParameters()\r\n",
      "schedule_params.improve_steps = TrainingSteps(\u001b[34m50000\u001b[39;49;00m)\r\n",
      "schedule_params.steps_between_evaluation_periods = EnvironmentSteps(\u001b[34m2000\u001b[39;49;00m)\r\n",
      "schedule_params.evaluation_steps = EnvironmentEpisodes(\u001b[34m5\u001b[39;49;00m)\r\n",
      "schedule_params.heatup_steps = EnvironmentSteps(\u001b[34m0\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[37m#########\u001b[39;49;00m\r\n",
      "\u001b[37m# Agent #\u001b[39;49;00m\r\n",
      "\u001b[37m#########\u001b[39;49;00m\r\n",
      "\r\n",
      "agent_params = ClippedPPOAgentParameters()\r\n",
      "\r\n",
      "\u001b[37m###############\u001b[39;49;00m\r\n",
      "\u001b[37m# Environment #\u001b[39;49;00m\r\n",
      "\u001b[37m###############\u001b[39;49;00m\r\n",
      "\r\n",
      "env_params = GymVectorEnvironment(level=\u001b[33m'\u001b[39;49;00m\u001b[33mtic_tac_toe:TicTacToeEnv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[37m########\u001b[39;49;00m\r\n",
      "\u001b[37m# Test #\u001b[39;49;00m\r\n",
      "\u001b[37m########\u001b[39;49;00m\r\n",
      "\r\n",
      "preset_validation_params = PresetValidationParameters()\r\n",
      "preset_validation_params.test = \u001b[36mTrue\u001b[39;49;00m\r\n",
      "\r\n",
      "graph_manager = BasicRLGraphManager(agent_params=agent_params, env_params=env_params,\r\n",
      "                                    schedule_params=schedule_params, vis_params=VisualizationParameters(),\r\n",
      "                                    preset_validation_params=preset_validation_params)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/preset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launcher\n",
    "\n",
    "The launcher is a script used by Amazon SageMaker to drive the training job on the SageMaker RL container.  We have kept it minimal, only specifying the name of the preset file to be used for the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_rl.coach_launcher\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SageMakerCoachPresetLauncher\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mMyLauncher\u001b[39;49;00m(SageMakerCoachPresetLauncher):\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mdefault_preset_name\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[33m\"\"\"This points to a .py file that configures everything about the RL job.\u001b[39;49;00m\r\n",
      "\u001b[33m        It can be overridden at runtime by specifying the RLCOACH_PRESET hyperparameter.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mpreset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    MyLauncher.train_main()\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/train-coach.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train\n",
    "\n",
    "Now, let's kick off the training job in Amazon SageMaker.  This call can include hyperparameters that overwrite values in `train-coach.py` or `preset.py`, but in our case, we've limited to defining:\n",
    "1. The location of our agent code `./src` and dependencies in `common`.\n",
    "1. Which RL and DL framework to use (SageMaker also supports [Ray RLlib](https://ray.readthedocs.io/en/latest/rllib.html) and Coach TensorFlow).\n",
    "1. The IAM role granted permissions to our data in S3 and ability to create SageMaker training jobs.\n",
    "1. Training job hardware specifications (in this case just 1 ml.m4.xlarge instance).\n",
    "1. Output path for our checkpoints and saved episodes.\n",
    "1. A single hyperparameter specifying that we would like our agent's network to be output (in this case as an ONNX model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 15:35:19 Starting - Starting the training job...\n",
      "2019-06-07 15:35:21 Starting - Launching requested ML instances.........\n",
      "2019-06-07 15:36:53 Starting - Preparing the instances for training......\n",
      "2019-06-07 15:38:10 Downloading - Downloading input data\n",
      "2019-06-07 15:38:10 Training - Downloading the training image..\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,105 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,109 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,123 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"save_model\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-345362745630/DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638/source/sourcedir.tar.gz\",\"module_name\":\"train-coach\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-coach.py\"}', 'SM_CURRENT_HOST': 'algo-1', 'SM_USER_ARGS': '[\"--save_model\",\"1\"]', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_USER_ENTRY_POINT': 'train-coach.py', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_NUM_GPUS': '0', 'SM_INPUT_DATA_CONFIG': '{}', 'SM_LOG_LEVEL': '20', 'SM_MODULE_NAME': 'train-coach', 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-345362745630/DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638/source/sourcedir.tar.gz', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_NUM_CPUS': '4', 'SM_HOSTS': '[\"algo-1\"]', 'SM_HP_SAVE_MODEL': '1', 'SM_CHANNELS': '[]', 'SM_HPS': '{\"save_model\":1}', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_estimator\":\"RLEstimator\"}', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_OUTPUT_DIR': '/opt/ml/output'}\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,236 sagemaker-containers INFO     Module train-coach does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,236 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,236 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:30,237 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train-coach\n",
      "  Running setup.py bdist_wheel for train-coach: started\n",
      "  Running setup.py bdist_wheel for train-coach: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gi1e0yd3/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built train-coach\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train-coach\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-coach-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.1.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:31,855 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-06-07 15:38:31,869 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"user_entry_point\": \"train-coach.py\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"log_level\": 20,\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_name\": \"train-coach\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-345362745630/DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638/source/sourcedir.tar.gz\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"hyperparameters\": {\n",
      "        \"save_model\": 1\n",
      "    },\n",
      "    \"input_data_config\": {},\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"job_name\": \"DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"current_host\": \"algo-1\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"save_model\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-345362745630/DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638/source/sourcedir.tar.gz\",\"module_name\":\"train-coach\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-coach.py\"}\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--save_model\",\"1\"]\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train-coach.py\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train-coach\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-west-2-345362745630/DEMO-rl-tic-tac-toe-2019-06-07-15-35-18-638/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_HP_SAVE_MODEL=1\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[31mSM_HPS={\"save_model\":1}\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train-coach --save_model 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m#033[93mWarning: failed to import the following packages - tensorflow#033[0m\u001b[0m\n",
      "\u001b[31mLoading preset preset from /opt/ml/code\u001b[0m\n",
      "\u001b[31m## Creating graph - name: BasicRLGraphManager\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\u001b[0m\n",
      "\u001b[31m## Creating agent - name: agent\u001b[0m\n",
      "\u001b[31mRequested devices [gpu(0)] not available. Default to CPU context.\u001b[0m\n",
      "\u001b[31mRequested devices [gpu(0)] not available. Default to CPU context.\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[31m## Starting to improve simple_rl_graph task index 0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1, Total reward=-1.1, Steps=5, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2, Total reward=-1, Steps=8, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3, Total reward=-1.2, Steps=13, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4, Total reward=-1.1, Steps=17, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5, Total reward=-0.2, Steps=24, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6, Total reward=-0.5, Steps=34, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=7, Total reward=-0.7, Steps=46, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=8, Total reward=-1.1, Steps=51, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=9, Total reward=0.1, Steps=64, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=10, Total reward=-1.6, Steps=74, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=11, Total reward=-1, Steps=77, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=12, Total reward=-2.1, Steps=93, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=13, Total reward=-1.2, Steps=99, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=14, Total reward=-1, Steps=103, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=15, Total reward=-1.2, Steps=109, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=16, Total reward=-0.2, Steps=116, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=17, Total reward=-1.2, Steps=121, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=18, Total reward=-1.2, Steps=126, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=19, Total reward=-2.1, Steps=142, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=20, Total reward=-0.6, Steps=153, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=21, Total reward=-1.5, Steps=162, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=22, Total reward=-1, Steps=165, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=23, Total reward=-2.4, Steps=184, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=24, Total reward=-1, Steps=188, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=25, Total reward=-1, Steps=191, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=26, Total reward=-1, Steps=194, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=27, Total reward=0.7, Steps=201, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=28, Total reward=-1.1, Steps=205, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=29, Total reward=-2.0, Steps=219, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=30, Total reward=-1.3, Steps=226, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=31, Total reward=-1.1, Steps=230, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=32, Total reward=0.7, Steps=238, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=33, Total reward=-1.1, Steps=242, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=34, Total reward=-1.2, Steps=247, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=35, Total reward=-0.6, Steps=258, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=36, Total reward=-1, Steps=261, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=37, Total reward=-1.5, Steps=269, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=38, Total reward=-1, Steps=272, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=39, Total reward=-1, Steps=276, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=40, Total reward=-1, Steps=280, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=41, Total reward=-1.1, Steps=285, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=42, Total reward=-1.1, Steps=290, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=43, Total reward=-1.6, Steps=300, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=44, Total reward=-1.1, Steps=304, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=45, Total reward=-1, Steps=307, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=46, Total reward=-1.2, Steps=312, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=47, Total reward=-2.0, Steps=327, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=48, Total reward=-1, Steps=330, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=49, Total reward=-1.1, Steps=334, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=50, Total reward=0.9, Steps=339, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=51, Total reward=-1, Steps=343, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=52, Total reward=-1.2, Steps=349, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=53, Total reward=-1.4, Steps=357, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=54, Total reward=-1, Steps=361, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=55, Total reward=-1.1, Steps=365, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=56, Total reward=-1, Steps=368, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=57, Total reward=-1.1, Steps=372, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=58, Total reward=-1.7, Steps=394, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=59, Total reward=-1.5, Steps=403, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=60, Total reward=0.1, Steps=417, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=61, Total reward=-1.1, Steps=421, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=62, Total reward=-1.2, Steps=427, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=63, Total reward=-2.0, Steps=442, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=64, Total reward=-0.6, Steps=453, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=65, Total reward=-1.4, Steps=460, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=66, Total reward=-2.1, Steps=476, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=67, Total reward=-1.2, Steps=482, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=68, Total reward=-1, Steps=485, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=69, Total reward=-1, Steps=488, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=70, Total reward=-1.2, Steps=493, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=71, Total reward=-1.1, Steps=497, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=72, Total reward=-2.2, Steps=514, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=73, Total reward=-1, Steps=517, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=74, Total reward=-2.0, Steps=532, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=75, Total reward=-2.1, Steps=548, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=76, Total reward=-2.2, Steps=565, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=77, Total reward=-0.2, Steps=572, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=78, Total reward=-2.6, Steps=593, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=79, Total reward=-1.4, Steps=600, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=80, Total reward=-2.0, Steps=614, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=81, Total reward=-1, Steps=617, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=82, Total reward=-1.2, Steps=623, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=83, Total reward=-0.6, Steps=634, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=84, Total reward=-1, Steps=637, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=85, Total reward=-2.0, Steps=652, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=86, Total reward=-0.1, Steps=658, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=87, Total reward=-1.1, Steps=662, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=88, Total reward=-1.2, Steps=668, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=89, Total reward=-1, Steps=671, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=90, Total reward=0.6, Steps=679, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=91, Total reward=-1.1, Steps=683, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=92, Total reward=-1.2, Steps=688, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=93, Total reward=-1, Steps=692, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=94, Total reward=-1.2, Steps=698, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=95, Total reward=-1, Steps=701, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=96, Total reward=-1.1, Steps=705, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=97, Total reward=-1, Steps=708, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=98, Total reward=-1.4, Steps=715, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=99, Total reward=-1.2, Steps=721, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=100, Total reward=-0.7, Steps=733, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=101, Total reward=-0.7, Steps=745, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=102, Total reward=-0.4, Steps=754, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=103, Total reward=-1.1, Steps=758, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=104, Total reward=-1.2, Steps=764, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=105, Total reward=-1.6, Steps=774, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=106, Total reward=-1.1, Steps=778, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=107, Total reward=-0.6, Steps=789, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=108, Total reward=-0.2, Steps=796, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=109, Total reward=0.8, Steps=802, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=110, Total reward=-0.9, Steps=816, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=111, Total reward=-1.2, Steps=821, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=112, Total reward=-0.5, Steps=831, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=113, Total reward=-0.9, Steps=845, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=114, Total reward=-1.5, Steps=854, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=115, Total reward=-1.1, Steps=858, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=116, Total reward=-2.4, Steps=877, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=117, Total reward=-2.2, Steps=894, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=118, Total reward=-1, Steps=897, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=119, Total reward=-1, Steps=900, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=120, Total reward=-1.7, Steps=910, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=121, Total reward=-1.3, Steps=916, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=122, Total reward=-0.7, Steps=928, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=123, Total reward=-2.4, Steps=947, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=124, Total reward=-1.2, Steps=953, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=125, Total reward=-1.2, Steps=970, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=126, Total reward=-1.9, Steps=983, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=127, Total reward=-1, Steps=986, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=128, Total reward=-1.4, Steps=994, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=129, Total reward=-1.7, Steps=1004, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=130, Total reward=-0.1, Steps=1010, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=131, Total reward=0.6, Steps=1018, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=132, Total reward=-1.2, Steps=1023, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=133, Total reward=-2.5, Steps=1043, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=134, Total reward=0.6, Steps=1051, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=135, Total reward=-0.1, Steps=1057, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=136, Total reward=-1, Steps=1060, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=137, Total reward=-1, Steps=1063, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=138, Total reward=-1, Steps=1066, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=139, Total reward=-1, Steps=1069, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=140, Total reward=-1.1, Steps=1073, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=141, Total reward=-1, Steps=1076, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=142, Total reward=-1.3, Steps=1083, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=143, Total reward=-1.2, Steps=1089, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=144, Total reward=-1.1, Steps=1093, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=145, Total reward=-1.5, Steps=1102, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=146, Total reward=-0.2, Steps=1109, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=147, Total reward=-1.2, Steps=1115, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=148, Total reward=1, Steps=1119, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=149, Total reward=0.4, Steps=1129, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=150, Total reward=-0.1, Steps=1135, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=151, Total reward=-1.2, Steps=1140, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=152, Total reward=-1, Steps=1143, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=153, Total reward=-1.1, Steps=1147, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=154, Total reward=0.9, Steps=1152, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=155, Total reward=-1.4, Steps=1160, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=156, Total reward=-1.2, Steps=1165, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=157, Total reward=-1.3, Steps=1171, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=158, Total reward=-1.2, Steps=1176, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=159, Total reward=-1, Steps=1180, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=160, Total reward=-1.1, Steps=1184, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=161, Total reward=-0.8, Steps=1197, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=162, Total reward=-1, Steps=1200, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=163, Total reward=-1, Steps=1203, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=164, Total reward=-1, Steps=1206, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=165, Total reward=-1.3, Steps=1213, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=166, Total reward=-1, Steps=1216, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=167, Total reward=-1, Steps=1219, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=168, Total reward=-1, Steps=1223, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=169, Total reward=-1, Steps=1226, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=170, Total reward=-1, Steps=1229, Training iteration=0\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/0_Step-1230.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/0_Step-1230.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=171, Total reward=0.8, Steps=1235, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=172, Total reward=-1.1, Steps=1239, Training iteration=0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=173, Total reward=-1, Steps=1242, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=174, Total reward=-0.6, Steps=1253, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=175, Total reward=-1, Steps=1257, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=176, Total reward=-2.1, Steps=1272, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=177, Total reward=-0.4, Steps=1281, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=178, Total reward=-1, Steps=1284, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=179, Total reward=-1, Steps=1287, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=180, Total reward=-2.1, Steps=1303, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=181, Total reward=-1, Steps=1306, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=182, Total reward=-1.8, Steps=1318, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=183, Total reward=-0.4, Steps=1327, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=184, Total reward=-1.1, Steps=1332, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=185, Total reward=-1, Steps=1335, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=186, Total reward=-0.4, Steps=1344, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=187, Total reward=-1.2, Steps=1350, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=188, Total reward=-1.4, Steps=1357, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=189, Total reward=-1.6, Steps=1367, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=190, Total reward=0.9, Steps=1372, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=191, Total reward=-2.4, Steps=1391, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=192, Total reward=-1, Steps=1394, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=193, Total reward=-1.1, Steps=1410, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=194, Total reward=-0.2, Steps=1427, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=195, Total reward=-1.1, Steps=1431, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=196, Total reward=0.4, Steps=1441, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=197, Total reward=-0.1, Steps=1447, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=198, Total reward=-1, Steps=1450, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=199, Total reward=-1.1, Steps=1454, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=200, Total reward=-1, Steps=1457, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=201, Total reward=-2.5, Steps=1476, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=202, Total reward=-1.2, Steps=1481, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=203, Total reward=0.8, Steps=1488, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=204, Total reward=-1, Steps=1491, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=205, Total reward=-1.2, Steps=1496, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=206, Total reward=-1.5, Steps=1505, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=207, Total reward=-1.1, Steps=1509, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=208, Total reward=-1, Steps=1512, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=209, Total reward=-1.3, Steps=1519, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=210, Total reward=-0.4, Steps=1528, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=211, Total reward=-1, Steps=1531, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=212, Total reward=-2.0, Steps=1545, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=213, Total reward=-2.0, Steps=1559, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=214, Total reward=-0.5, Steps=1569, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=215, Total reward=0.7, Steps=1576, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=216, Total reward=-2.3, Steps=1594, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=217, Total reward=-1.1, Steps=1598, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=218, Total reward=-0.3, Steps=1606, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=219, Total reward=-1, Steps=1609, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=220, Total reward=0.4, Steps=1619, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=221, Total reward=-1.3, Steps=1626, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=222, Total reward=-1.2, Steps=1632, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=223, Total reward=-1.1, Steps=1637, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=224, Total reward=-1.1, Steps=1642, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=225, Total reward=-0.7, Steps=1654, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=226, Total reward=-1.4, Steps=1661, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=227, Total reward=-1.1, Steps=1665, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=228, Total reward=-1.3, Steps=1683, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=229, Total reward=1, Steps=1687, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=230, Total reward=-1.1, Steps=1691, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=231, Total reward=-0.9, Steps=1705, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=232, Total reward=-1.3, Steps=1711, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=233, Total reward=-1.3, Steps=1718, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=234, Total reward=0.4, Steps=1729, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=235, Total reward=-0.7, Steps=1741, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=236, Total reward=-1.1, Steps=1745, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=237, Total reward=-1, Steps=1748, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=238, Total reward=-1, Steps=1751, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=239, Total reward=-1.0, Steps=1766, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=240, Total reward=-1.4, Steps=1774, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=241, Total reward=-0.4, Steps=1783, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=242, Total reward=-1.4, Steps=1790, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=243, Total reward=-2.2, Steps=1807, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=244, Total reward=-1, Steps=1810, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=245, Total reward=-1, Steps=1814, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=246, Total reward=-1.1, Steps=1818, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=247, Total reward=-1.1, Steps=1822, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=248, Total reward=-1.5, Steps=1831, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=249, Total reward=-1.1, Steps=1835, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=250, Total reward=0.7, Steps=1842, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=251, Total reward=-0.6, Steps=1853, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=252, Total reward=-1.4, Steps=1860, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=253, Total reward=-1.8, Steps=1872, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=254, Total reward=-1.5, Steps=1881, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=255, Total reward=-2.4, Steps=1900, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=256, Total reward=-1.1, Steps=1904, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=257, Total reward=-1.3, Steps=1910, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=258, Total reward=-1, Steps=1913, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=259, Total reward=-1.3, Steps=1920, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=260, Total reward=-2.3, Steps=1938, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=261, Total reward=-1, Steps=1942, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=262, Total reward=0.7, Steps=1949, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=263, Total reward=-1.1, Steps=1953, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=264, Total reward=0.6, Steps=1961, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=265, Total reward=-1.4, Steps=1969, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=266, Total reward=-1.1, Steps=1974, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=267, Total reward=-1.1, Steps=1978, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=268, Total reward=-0.4, Steps=1987, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=269, Total reward=-1.2, Steps=1992, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=270, Total reward=-1.1, Steps=1996, Training iteration=0\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=270, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=270, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=270, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=270, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=270, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=271, Total reward=-1, Steps=2003, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=272, Total reward=-1, Steps=2006, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=273, Total reward=-0.6, Steps=2017, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=274, Total reward=-0.1, Steps=2023, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=275, Total reward=-0.4, Steps=2032, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=276, Total reward=-1.2, Steps=2038, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=277, Total reward=-1, Steps=2041, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=278, Total reward=-1.2, Steps=2046, Training iteration=0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=279, Total reward=-1.4, Steps=2053, Training iteration=0\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/rl_coach/architectures/mxnet_components/heads/head.py:95: UserWarning: Parameter clippedppolossdiscrete0_kl_coefficient is not used by any computation. Is this intended?\n",
      "  outputs = super(HeadLoss, self).forward(*args)\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=1.7821788787841797e-05, KL divergence=[0.], Entropy=[-0.02197164], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0026009369175881147, KL divergence=[0.], Entropy=[-0.02197002], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.005531562492251396, KL divergence=[0.], Entropy=[-0.02196376], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008843415416777134, KL divergence=[0.], Entropy=[-0.02194564], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012144815176725388, KL divergence=[0.], Entropy=[-0.02192666], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01525056641548872, KL divergence=[0.], Entropy=[-0.02190159], training epoch=5, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.016231467947363853, KL divergence=[0.], Entropy=[-0.0218709], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01799607463181019, KL divergence=[0.], Entropy=[-0.02186245], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018739134073257446, KL divergence=[0.], Entropy=[-0.02184578], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01849059946835041, KL divergence=[0.], Entropy=[-0.02183821], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/1_Step-2053.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/1_Step-2053.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=280, Total reward=-1.3, Steps=2060, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=281, Total reward=-0.8, Steps=2073, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=282, Total reward=-1, Steps=2076, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=283, Total reward=-1.1, Steps=2080, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=284, Total reward=-1, Steps=2083, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=285, Total reward=-1.3, Steps=2090, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=286, Total reward=-1.1, Steps=2094, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=287, Total reward=-1, Steps=2097, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=288, Total reward=-1.1, Steps=2101, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=289, Total reward=-1, Steps=2104, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=290, Total reward=0.5, Steps=2114, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=291, Total reward=-1.9, Steps=2127, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=292, Total reward=-1.3, Steps=2134, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=293, Total reward=0.6, Steps=2142, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=294, Total reward=-2.5, Steps=2162, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=295, Total reward=-1.2, Steps=2168, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=296, Total reward=-0.6, Steps=2179, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=297, Total reward=-1.4, Steps=2187, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=298, Total reward=-2.1, Steps=2203, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=299, Total reward=-1.2, Steps=2209, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=300, Total reward=-1, Steps=2212, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=301, Total reward=-0.2, Steps=2219, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=302, Total reward=-1, Steps=2222, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=303, Total reward=-1.1, Steps=2226, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=304, Total reward=0.8, Steps=2232, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=305, Total reward=-1, Steps=2235, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=306, Total reward=-1, Steps=2239, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=307, Total reward=-1.2, Steps=2256, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=308, Total reward=-2.3, Steps=2274, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=309, Total reward=-0.6, Steps=2285, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=310, Total reward=-0.5, Steps=2295, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=311, Total reward=-1.1, Steps=2299, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=312, Total reward=-1.2, Steps=2304, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=313, Total reward=-1, Steps=2308, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=314, Total reward=-0.7, Steps=2320, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=315, Total reward=-1, Steps=2323, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=316, Total reward=-1.1, Steps=2327, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=317, Total reward=-1.1, Steps=2331, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=318, Total reward=-1, Steps=2334, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=319, Total reward=-1.2, Steps=2340, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=320, Total reward=-1.3, Steps=2347, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=321, Total reward=-1, Steps=2351, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=322, Total reward=-0.4, Steps=2360, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=323, Total reward=-1.1, Steps=2364, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=324, Total reward=-1.5, Steps=2373, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=325, Total reward=0.0, Steps=2388, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=326, Total reward=-2.8, Steps=2411, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=327, Total reward=-1, Steps=2414, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=328, Total reward=-1.5, Steps=2423, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=329, Total reward=-1, Steps=2426, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=330, Total reward=-1.5, Steps=2435, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=331, Total reward=-1.2, Steps=2441, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=332, Total reward=-2.0, Steps=2455, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=333, Total reward=-1.2, Steps=2461, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=334, Total reward=-0.3, Steps=2469, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=335, Total reward=-1.0, Steps=2484, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=336, Total reward=-1, Steps=2487, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=337, Total reward=-1, Steps=2490, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=338, Total reward=-1.7, Steps=2501, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=339, Total reward=-1, Steps=2504, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=340, Total reward=-1.4, Steps=2512, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=341, Total reward=-2.4, Steps=2531, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=342, Total reward=-0.9, Steps=2545, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=343, Total reward=-2.4, Steps=2564, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=344, Total reward=-1, Steps=2568, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=345, Total reward=-1.1, Steps=2572, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=346, Total reward=-1, Steps=2575, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=347, Total reward=-1.3, Steps=2581, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=348, Total reward=-1.1, Steps=2585, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=349, Total reward=-1, Steps=2588, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=350, Total reward=-1.1, Steps=2604, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=351, Total reward=-2.1, Steps=2620, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=352, Total reward=-1.4, Steps=2628, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=353, Total reward=-2.1, Steps=2642, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=354, Total reward=-1.2, Steps=2647, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=355, Total reward=-1.1, Steps=2651, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=356, Total reward=-1.1, Steps=2656, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=357, Total reward=-1.2, Steps=2662, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=358, Total reward=-1.1, Steps=2666, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=359, Total reward=-1.5, Steps=2675, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=360, Total reward=-2.1, Steps=2691, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=361, Total reward=-1.3, Steps=2698, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=362, Total reward=-1.2, Steps=2704, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=363, Total reward=-1.2, Steps=2709, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=364, Total reward=0.7, Steps=2716, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=365, Total reward=-2.2, Steps=2733, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=366, Total reward=-1.2, Steps=2739, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=367, Total reward=-2.3, Steps=2757, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=368, Total reward=-1.4, Steps=2765, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=369, Total reward=-1.7, Steps=2776, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=370, Total reward=-1, Steps=2779, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=371, Total reward=-1.1, Steps=2783, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=372, Total reward=-2.3, Steps=2801, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=373, Total reward=-1.2, Steps=2806, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=374, Total reward=-1, Steps=2810, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=375, Total reward=-1, Steps=2813, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=376, Total reward=-1.2, Steps=2830, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=377, Total reward=-0.7, Steps=2842, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=378, Total reward=-1.7, Steps=2853, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=379, Total reward=-1, Steps=2856, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=380, Total reward=-1, Steps=2859, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=381, Total reward=-2.0, Steps=2874, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=382, Total reward=-1.3, Steps=2881, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=383, Total reward=-1.2, Steps=2886, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=384, Total reward=-1.1, Steps=2902, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=385, Total reward=-1.5, Steps=2911, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=386, Total reward=-0.1, Steps=2917, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=387, Total reward=-1, Steps=2920, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=388, Total reward=-0.8, Steps=2933, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=389, Total reward=-1, Steps=2936, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=390, Total reward=-1.4, Steps=2944, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=391, Total reward=-1, Steps=2948, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=392, Total reward=-1.4, Steps=2956, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=393, Total reward=-1.1, Steps=2961, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=394, Total reward=-1.5, Steps=2970, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=395, Total reward=-0.2, Steps=2977, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=396, Total reward=-1.9, Steps=2990, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=397, Total reward=-1.6, Steps=3011, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=398, Total reward=-1, Steps=3014, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=399, Total reward=0.5, Steps=3023, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=400, Total reward=-1, Steps=3026, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=401, Total reward=-1.1, Steps=3030, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=402, Total reward=-1, Steps=3034, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=403, Total reward=-1.1, Steps=3038, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=404, Total reward=-1.1, Steps=3042, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=405, Total reward=-1.9, Steps=3055, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=406, Total reward=-1.3, Steps=3061, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=407, Total reward=-1.1, Steps=3065, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=408, Total reward=-1, Steps=3068, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=409, Total reward=-1.1, Steps=3073, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=410, Total reward=-2.1, Steps=3089, Training iteration=1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-06-07 15:39:01 Training - Training image download completed. Training in progress.\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=411, Total reward=-1.3, Steps=3095, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=412, Total reward=-1, Steps=3099, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=413, Total reward=-1.1, Steps=3103, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=414, Total reward=-0.7, Steps=3115, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=415, Total reward=-1, Steps=3118, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=416, Total reward=-0.6, Steps=3129, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=417, Total reward=-1.4, Steps=3136, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=418, Total reward=-1.1, Steps=3140, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=419, Total reward=-1.7, Steps=3151, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=420, Total reward=-1.2, Steps=3157, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=421, Total reward=-2.3, Steps=3175, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=422, Total reward=-1.1, Steps=3180, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=423, Total reward=-0.6, Steps=3191, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=424, Total reward=-1.3, Steps=3197, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=425, Total reward=-1.4, Steps=3204, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=426, Total reward=-2.3, Steps=3222, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=427, Total reward=-1, Steps=3225, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=428, Total reward=-0.2, Steps=3232, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=429, Total reward=-1, Steps=3235, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=430, Total reward=-1.4, Steps=3243, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=431, Total reward=-1.1, Steps=3248, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=432, Total reward=-1.5, Steps=3256, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=433, Total reward=-1.6, Steps=3266, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=434, Total reward=0.9, Steps=3270, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=435, Total reward=-1, Steps=3273, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=436, Total reward=-1, Steps=3276, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=437, Total reward=-1.4, Steps=3284, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=438, Total reward=-1.2, Steps=3290, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=439, Total reward=-1, Steps=3294, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=440, Total reward=-1.5, Steps=3303, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=441, Total reward=-1, Steps=3306, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=442, Total reward=-1.1, Steps=3310, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=443, Total reward=-1, Steps=3313, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=444, Total reward=-1.5, Steps=3322, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=445, Total reward=-1.0, Steps=3337, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=446, Total reward=-1.4, Steps=3344, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=447, Total reward=-1.4, Steps=3352, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=448, Total reward=-1, Steps=3355, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=449, Total reward=-1, Steps=3359, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=450, Total reward=-2.5, Steps=3379, Training iteration=1\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/2_Step-3382.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/2_Step-3382.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=451, Total reward=0.5, Steps=3388, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=452, Total reward=0.3, Steps=3400, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=453, Total reward=-1.3, Steps=3407, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=454, Total reward=-0.4, Steps=3416, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=455, Total reward=-1, Steps=3419, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=456, Total reward=-1.8, Steps=3431, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=457, Total reward=-1.0, Steps=3446, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=458, Total reward=-1.1, Steps=3450, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=459, Total reward=-0.3, Steps=3458, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=460, Total reward=-1, Steps=3461, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=461, Total reward=-1.2, Steps=3466, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=462, Total reward=-1.1, Steps=3470, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=463, Total reward=0.8, Steps=3476, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=464, Total reward=-1.3, Steps=3483, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=465, Total reward=-1, Steps=3486, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=466, Total reward=0.5, Steps=3495, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=467, Total reward=-1.3, Steps=3502, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=468, Total reward=-1.3, Steps=3509, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=469, Total reward=-1.1, Steps=3525, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=470, Total reward=-1, Steps=3528, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=471, Total reward=0.8, Steps=3534, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=472, Total reward=-1.1, Steps=3538, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=473, Total reward=-1, Steps=3541, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=474, Total reward=-2.3, Steps=3559, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=475, Total reward=-1.2, Steps=3564, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=476, Total reward=-1, Steps=3567, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=477, Total reward=0.7, Steps=3574, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=478, Total reward=-1.5, Steps=3582, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=479, Total reward=-2.2, Steps=3599, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=480, Total reward=-0.1, Steps=3605, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=481, Total reward=-2.2, Steps=3622, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=482, Total reward=-0.7, Steps=3634, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=483, Total reward=-0.5, Steps=3644, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=484, Total reward=-0.9, Steps=3658, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=485, Total reward=-1, Steps=3661, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=486, Total reward=-1.5, Steps=3670, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=487, Total reward=-0.3, Steps=3678, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=488, Total reward=-1.1, Steps=3682, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=489, Total reward=-0.2, Steps=3689, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=490, Total reward=-1, Steps=3692, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=491, Total reward=-0.5, Steps=3702, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=492, Total reward=-1.4, Steps=3709, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=493, Total reward=-1.4, Steps=3716, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=494, Total reward=-1.2, Steps=3721, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=495, Total reward=-1.3, Steps=3728, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=496, Total reward=-1.1, Steps=3733, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=497, Total reward=-1.2, Steps=3738, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=498, Total reward=1, Steps=3742, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=499, Total reward=-1.2, Steps=3747, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=500, Total reward=-1, Steps=3750, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=501, Total reward=0.7, Steps=3757, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=502, Total reward=-2.4, Steps=3776, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=503, Total reward=-1, Steps=3779, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=504, Total reward=-1, Steps=3783, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=505, Total reward=-1.1, Steps=3787, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=506, Total reward=-1, Steps=3790, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=507, Total reward=-0.8, Steps=3803, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=508, Total reward=-1, Steps=3806, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=509, Total reward=-1.4, Steps=3813, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=510, Total reward=-1.4, Steps=3820, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=511, Total reward=-1.3, Steps=3827, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=512, Total reward=-1, Steps=3830, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=513, Total reward=-1, Steps=3833, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=514, Total reward=-2.0, Steps=3848, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=515, Total reward=-1.1, Steps=3852, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=516, Total reward=-0.6, Steps=3863, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=517, Total reward=1, Steps=3867, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=518, Total reward=-1.0, Steps=3882, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=519, Total reward=-1.1, Steps=3886, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=520, Total reward=-1.1, Steps=3890, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=521, Total reward=-1.2, Steps=3895, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=522, Total reward=-1, Steps=3898, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=523, Total reward=0.7, Steps=3905, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=524, Total reward=-1, Steps=3908, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=525, Total reward=0.4, Steps=3919, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=526, Total reward=-1.1, Steps=3923, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=527, Total reward=-1, Steps=3927, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=528, Total reward=-1.6, Steps=3937, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=529, Total reward=-1.1, Steps=3942, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=530, Total reward=-1.4, Steps=3949, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=531, Total reward=-1.1, Steps=3953, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=532, Total reward=-1, Steps=3957, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=533, Total reward=-1.1, Steps=3961, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=534, Total reward=-1.4, Steps=3969, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=535, Total reward=-1.1, Steps=3974, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=536, Total reward=-1.1, Steps=3978, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=537, Total reward=-1, Steps=3981, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=538, Total reward=-1.1, Steps=3985, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=539, Total reward=-1.1, Steps=3990, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=540, Total reward=-1.5, Steps=3999, Training iteration=1\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=540, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=540, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=540, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=540, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=540, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=541, Total reward=0.2, Steps=4012, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=542, Total reward=-2.9, Steps=4036, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=543, Total reward=-1, Steps=4039, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=544, Total reward=-1, Steps=4042, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=545, Total reward=-1.0, Steps=4057, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=546, Total reward=-2.6, Steps=4078, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=547, Total reward=-1.1, Steps=4094, Training iteration=1\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=548, Total reward=0.2, Steps=4107, Training iteration=1\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.005810832604765892, KL divergence=[0.], Entropy=[-0.02184707], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.00197370583191514, KL divergence=[0.], Entropy=[-0.02182061], training epoch=1, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.006139806006103754, KL divergence=[0.], Entropy=[-0.02179379], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009154296480119228, KL divergence=[0.], Entropy=[-0.02176896], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.010454955510795116, KL divergence=[0.], Entropy=[-0.02176537], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011527474038302898, KL divergence=[0.], Entropy=[-0.02174321], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011554984375834465, KL divergence=[0.], Entropy=[-0.02171823], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011834641918540001, KL divergence=[0.], Entropy=[-0.0217067], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012181682512164116, KL divergence=[0.], Entropy=[-0.02170207], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012776585295796394, KL divergence=[0.], Entropy=[-0.02170704], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/3_Step-4107.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/3_Step-4107.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=549, Total reward=-1.8, Steps=4119, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=550, Total reward=-1, Steps=4122, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=551, Total reward=-1.2, Steps=4127, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=552, Total reward=-1.3, Steps=4145, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=553, Total reward=-1.8, Steps=4157, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=554, Total reward=-2.4, Steps=4176, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=555, Total reward=-1, Steps=4179, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=556, Total reward=-2.0, Steps=4194, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=557, Total reward=-0.7, Steps=4206, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=558, Total reward=-1.7, Steps=4217, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=559, Total reward=-1.8, Steps=4229, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=560, Total reward=-1.1, Steps=4233, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=561, Total reward=-1, Steps=4237, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=562, Total reward=-1.1, Steps=4241, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=563, Total reward=0.1, Steps=4255, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=564, Total reward=-2.8, Steps=4278, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=565, Total reward=-1.1, Steps=4282, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=566, Total reward=-0.3, Steps=4290, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=567, Total reward=-1.2, Steps=4296, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=568, Total reward=-1, Steps=4299, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=569, Total reward=-1.1, Steps=4303, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=570, Total reward=-0.6, Steps=4314, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=571, Total reward=-1.1, Steps=4318, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=572, Total reward=-0.8, Steps=4331, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=573, Total reward=-0.2, Steps=4338, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=574, Total reward=-1, Steps=4342, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=575, Total reward=-1, Steps=4345, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=576, Total reward=-1.8, Steps=4356, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=577, Total reward=-1.5, Steps=4365, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=578, Total reward=-1.3, Steps=4372, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=579, Total reward=-1.8, Steps=4384, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=580, Total reward=-0.7, Steps=4396, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=581, Total reward=-1, Steps=4399, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=582, Total reward=-1, Steps=4402, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=583, Total reward=-0.3, Steps=4410, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=584, Total reward=-0.7, Steps=4422, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=585, Total reward=-1, Steps=4425, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=586, Total reward=0.9, Steps=4430, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=587, Total reward=-1.2, Steps=4435, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=588, Total reward=-0.9, Steps=4449, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=589, Total reward=-2.3, Steps=4467, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=590, Total reward=-1, Steps=4470, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=591, Total reward=-1.4, Steps=4478, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=592, Total reward=-1.1, Steps=4482, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=593, Total reward=-1, Steps=4485, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=594, Total reward=-1, Steps=4488, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=595, Total reward=-0.9, Steps=4502, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=596, Total reward=-1.4, Steps=4510, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=597, Total reward=-1.2, Steps=4516, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=598, Total reward=-1, Steps=4520, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=599, Total reward=-1.2, Steps=4525, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=600, Total reward=-1, Steps=4529, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=601, Total reward=-2.4, Steps=4548, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=602, Total reward=-2.1, Steps=4564, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=603, Total reward=-1.1, Steps=4568, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=604, Total reward=-1.1, Steps=4572, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=605, Total reward=-1, Steps=4575, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=606, Total reward=-1.1, Steps=4579, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=607, Total reward=-1.4, Steps=4586, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=608, Total reward=-0.3, Steps=4594, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=609, Total reward=-1.3, Steps=4600, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=610, Total reward=-1.0, Steps=4615, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=611, Total reward=-1.5, Steps=4624, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=612, Total reward=-0.2, Steps=4631, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=613, Total reward=-1.1, Steps=4636, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=614, Total reward=-1, Steps=4639, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=615, Total reward=-1.0, Steps=4654, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=616, Total reward=-1.3, Steps=4661, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=617, Total reward=-0.7, Steps=4673, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=618, Total reward=-1, Steps=4677, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=619, Total reward=-1.0, Steps=4692, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=620, Total reward=0.2, Steps=4704, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=621, Total reward=-0.3, Steps=4712, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=622, Total reward=-1.1, Steps=4716, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=623, Total reward=-0.4, Steps=4725, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=624, Total reward=-1.7, Steps=4736, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=625, Total reward=-1.1, Steps=4740, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=626, Total reward=-1, Steps=4743, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=627, Total reward=-0.1, Steps=4749, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=628, Total reward=-0.9, Steps=4763, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=629, Total reward=-1.1, Steps=4767, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=630, Total reward=-0.1, Steps=4773, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=631, Total reward=-0.4, Steps=4782, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=632, Total reward=-1, Steps=4786, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=633, Total reward=-1.1, Steps=4790, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=634, Total reward=-1.1, Steps=4794, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=635, Total reward=-1.5, Steps=4802, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=636, Total reward=-1.8, Steps=4825, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=637, Total reward=-1, Steps=4828, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=638, Total reward=-0.4, Steps=4837, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=639, Total reward=-2.7, Steps=4859, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=640, Total reward=-2.1, Steps=4875, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=641, Total reward=-1.2, Steps=4881, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=642, Total reward=-0.6, Steps=4892, Training iteration=2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=643, Total reward=-1, Steps=4895, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=644, Total reward=-2.5, Steps=4915, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=645, Total reward=-0.6, Steps=4926, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=646, Total reward=-0.1, Steps=4932, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=647, Total reward=-2.3, Steps=4950, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=648, Total reward=-1.3, Steps=4956, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=649, Total reward=-1, Steps=4959, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=650, Total reward=-2.2, Steps=4976, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=651, Total reward=-0.7, Steps=4988, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=652, Total reward=-1, Steps=4991, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=653, Total reward=-1.1, Steps=4995, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=654, Total reward=-1.3, Steps=5001, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=655, Total reward=-0.7, Steps=5013, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=656, Total reward=-0.8, Steps=5026, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=657, Total reward=0.6, Steps=5035, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=658, Total reward=-1.2, Steps=5040, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=659, Total reward=-1, Steps=5043, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=660, Total reward=-1.1, Steps=5047, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=661, Total reward=-1, Steps=5050, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=662, Total reward=-2.0, Steps=5064, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=663, Total reward=-1, Steps=5067, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=664, Total reward=-1.4, Steps=5075, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=665, Total reward=-2.2, Steps=5092, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=666, Total reward=-1.1, Steps=5096, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=667, Total reward=-1.1, Steps=5100, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=668, Total reward=-2.8, Steps=5123, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=669, Total reward=-1.4, Steps=5131, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=670, Total reward=1, Steps=5135, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=671, Total reward=-1, Steps=5138, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=672, Total reward=-1.3, Steps=5145, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=673, Total reward=-1.2, Steps=5150, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=674, Total reward=-0.6, Steps=5161, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=675, Total reward=-1.2, Steps=5166, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=676, Total reward=-2.1, Steps=5182, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=677, Total reward=-1, Steps=5185, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=678, Total reward=-0.8, Steps=5198, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=679, Total reward=-2.3, Steps=5216, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=680, Total reward=-1, Steps=5219, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=681, Total reward=-1.1, Steps=5235, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=682, Total reward=-2.0, Steps=5250, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=683, Total reward=-1, Steps=5253, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=684, Total reward=-0.3, Steps=5261, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=685, Total reward=-1, Steps=5264, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=686, Total reward=-1.3, Steps=5270, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=687, Total reward=0.3, Steps=5282, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=688, Total reward=-1.1, Steps=5286, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=689, Total reward=-1, Steps=5289, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=690, Total reward=-1.1, Steps=5293, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=691, Total reward=-1.1, Steps=5297, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=692, Total reward=-1, Steps=5300, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=693, Total reward=-0.3, Steps=5308, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=694, Total reward=-1.6, Steps=5318, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=695, Total reward=-1.4, Steps=5325, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=696, Total reward=-1, Steps=5328, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=697, Total reward=-2.3, Steps=5346, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=698, Total reward=1, Steps=5349, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=699, Total reward=-1, Steps=5353, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=700, Total reward=-1.2, Steps=5370, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=701, Total reward=-1.1, Steps=5374, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=702, Total reward=-0.2, Steps=5381, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=703, Total reward=-1, Steps=5384, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=704, Total reward=-1.1, Steps=5389, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=705, Total reward=-1.1, Steps=5393, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=706, Total reward=-1.1, Steps=5398, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=707, Total reward=-1.3, Steps=5405, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=708, Total reward=-1.0, Steps=5420, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=709, Total reward=-1.1, Steps=5424, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=710, Total reward=-1, Steps=5427, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=711, Total reward=-1.1, Steps=5431, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=712, Total reward=-1.5, Steps=5440, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=713, Total reward=0.8, Steps=5446, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=714, Total reward=-1.1, Steps=5450, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=715, Total reward=-1, Steps=5454, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=716, Total reward=-1, Steps=5457, Training iteration=2\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/4_Step-5457.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/4_Step-5457.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=717, Total reward=-1.2, Steps=5462, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=718, Total reward=-1, Steps=5465, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=719, Total reward=-2.3, Steps=5483, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=720, Total reward=-1.2, Steps=5488, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=721, Total reward=-1.2, Steps=5494, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=722, Total reward=-1, Steps=5498, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=723, Total reward=0.5, Steps=5507, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=724, Total reward=-0.8, Steps=5520, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=725, Total reward=-0.6, Steps=5531, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=726, Total reward=-1, Steps=5534, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=727, Total reward=-1.2, Steps=5539, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=728, Total reward=-0.6, Steps=5550, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=729, Total reward=-1.2, Steps=5567, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=730, Total reward=-1.9, Steps=5580, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=731, Total reward=-1, Steps=5583, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=732, Total reward=-1.3, Steps=5589, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=733, Total reward=-1.6, Steps=5599, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=734, Total reward=0.4, Steps=5610, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=735, Total reward=-0.5, Steps=5620, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=736, Total reward=1, Steps=5623, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=737, Total reward=-0.9, Steps=5637, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=738, Total reward=-0.3, Steps=5645, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=739, Total reward=-1.9, Steps=5658, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=740, Total reward=-0.2, Steps=5665, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=741, Total reward=-1.0, Steps=5680, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=742, Total reward=-2.1, Steps=5696, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=743, Total reward=-1, Steps=5700, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=744, Total reward=-1, Steps=5703, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=745, Total reward=-1, Steps=5706, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=746, Total reward=-1, Steps=5709, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=747, Total reward=-0.3, Steps=5717, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=748, Total reward=-0.6, Steps=5728, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=749, Total reward=-1, Steps=5732, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=750, Total reward=1, Steps=5736, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=751, Total reward=-2.3, Steps=5754, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=752, Total reward=-1, Steps=5757, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=753, Total reward=-0.5, Steps=5767, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=754, Total reward=0.2, Steps=5779, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=755, Total reward=-1.4, Steps=5787, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=756, Total reward=-1, Steps=5790, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=757, Total reward=-1.3, Steps=5796, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=758, Total reward=-0.2, Steps=5803, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=759, Total reward=-1.1, Steps=5808, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=760, Total reward=-1, Steps=5812, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=761, Total reward=-1, Steps=5816, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=762, Total reward=-0.5, Steps=5826, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=763, Total reward=-0.4, Steps=5835, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=764, Total reward=-2.1, Steps=5851, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=765, Total reward=-1.1, Steps=5855, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=766, Total reward=-2.1, Steps=5871, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=767, Total reward=0.6, Steps=5880, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=768, Total reward=-1, Steps=5883, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=769, Total reward=-1, Steps=5886, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=770, Total reward=-0.6, Steps=5897, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=771, Total reward=-3.2, Steps=5924, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=772, Total reward=-2.4, Steps=5943, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=773, Total reward=0.7, Steps=5951, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=774, Total reward=-0.3, Steps=5959, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=775, Total reward=-2.0, Steps=5974, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=776, Total reward=-1.5, Steps=5983, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=777, Total reward=-1, Steps=5986, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=778, Total reward=-1.1, Steps=5991, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=779, Total reward=-1.2, Steps=5996, Training iteration=2\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=779, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=779, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=779, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=779, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=779, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=780, Total reward=-0.7, Steps=6012, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=781, Total reward=-1.1, Steps=6016, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=782, Total reward=-1.1, Steps=6020, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=783, Total reward=-1, Steps=6023, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=784, Total reward=-1.7, Steps=6034, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=785, Total reward=-1.3, Steps=6040, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=786, Total reward=-1.2, Steps=6045, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=787, Total reward=-1.2, Steps=6050, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=788, Total reward=-0.3, Steps=6058, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=789, Total reward=-1.2, Steps=6063, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=790, Total reward=1, Steps=6066, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=791, Total reward=-1.1, Steps=6070, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=792, Total reward=-1, Steps=6073, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=793, Total reward=-1.3, Steps=6080, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=794, Total reward=-3.1, Steps=6106, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=795, Total reward=-0.4, Steps=6115, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=796, Total reward=-1.2, Steps=6120, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=797, Total reward=-0.9, Steps=6134, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=798, Total reward=-0.7, Steps=6146, Training iteration=2\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=799, Total reward=-0.7, Steps=6158, Training iteration=2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=0.006649320479482412, KL divergence=[0.], Entropy=[-0.02166798], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.00990191288292408, KL divergence=[0.], Entropy=[-0.02168251], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014921552501618862, KL divergence=[0.], Entropy=[-0.02163666], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014410367235541344, KL divergence=[0.], Entropy=[-0.02162141], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012273123487830162, KL divergence=[0.], Entropy=[-0.02161769], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01582665555179119, KL divergence=[0.], Entropy=[-0.02159612], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011142424307763577, KL divergence=[0.], Entropy=[-0.02159632], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009891637600958347, KL divergence=[0.], Entropy=[-0.02158305], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.022662952542304993, KL divergence=[0.], Entropy=[-0.02157267], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020108932629227638, KL divergence=[0.], Entropy=[-0.02156515], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/5_Step-6158.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/5_Step-6158.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=800, Total reward=-1.4, Steps=6166, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=801, Total reward=-0.8, Steps=6179, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=802, Total reward=-1.1, Steps=6183, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=803, Total reward=-1.1, Steps=6188, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=804, Total reward=-2.0, Steps=6202, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=805, Total reward=-1.5, Steps=6211, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=806, Total reward=-1, Steps=6214, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=807, Total reward=-0.1, Steps=6220, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=808, Total reward=-1.2, Steps=6226, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=809, Total reward=-1, Steps=6229, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=810, Total reward=-2.0, Steps=6244, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=811, Total reward=-1.3, Steps=6251, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=812, Total reward=-2.0, Steps=6266, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=813, Total reward=0.6, Steps=6274, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=814, Total reward=-1.2, Steps=6279, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=815, Total reward=-1.6, Steps=6289, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=816, Total reward=-1, Steps=6292, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=817, Total reward=-1, Steps=6296, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=818, Total reward=-1, Steps=6299, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=819, Total reward=-1.3, Steps=6306, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=820, Total reward=-1.5, Steps=6314, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=821, Total reward=-1.3, Steps=6320, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=822, Total reward=-0.3, Steps=6328, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=823, Total reward=-0.5, Steps=6338, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=824, Total reward=-1.1, Steps=6342, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=825, Total reward=-1.3, Steps=6349, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=826, Total reward=-1, Steps=6353, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=827, Total reward=-0.7, Steps=6365, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=828, Total reward=-1.2, Steps=6370, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=829, Total reward=-1.8, Steps=6382, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=830, Total reward=-1.4, Steps=6390, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=831, Total reward=-1, Steps=6393, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=832, Total reward=-1.3, Steps=6399, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=833, Total reward=-1.2, Steps=6405, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=834, Total reward=-0.7, Steps=6417, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=835, Total reward=-2.3, Steps=6435, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=836, Total reward=0.9, Steps=6439, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=837, Total reward=-1, Steps=6442, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=838, Total reward=-1.1, Steps=6446, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=839, Total reward=-1.1, Steps=6450, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=840, Total reward=-1.7, Steps=6461, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=841, Total reward=-0.4, Steps=6470, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=842, Total reward=-0.7, Steps=6482, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=843, Total reward=-1.6, Steps=6492, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=844, Total reward=-1.4, Steps=6511, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=845, Total reward=-1.4, Steps=6518, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=846, Total reward=-1, Steps=6521, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=847, Total reward=-2.0, Steps=6536, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=848, Total reward=-1.1, Steps=6540, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=849, Total reward=0.4, Steps=6550, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=850, Total reward=0.2, Steps=6563, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=851, Total reward=-0.2, Steps=6570, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=852, Total reward=-1, Steps=6573, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=853, Total reward=-1, Steps=6576, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=854, Total reward=-1.1, Steps=6580, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=855, Total reward=-1.2, Steps=6585, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=856, Total reward=-1.0, Steps=6600, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=857, Total reward=1, Steps=6604, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=858, Total reward=-1.0, Steps=6619, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=859, Total reward=-0.8, Steps=6632, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=860, Total reward=-1.2, Steps=6637, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=861, Total reward=-1.1, Steps=6641, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=862, Total reward=-1.1, Steps=6646, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=863, Total reward=-0.2, Steps=6653, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=864, Total reward=-1, Steps=6657, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=865, Total reward=-0.6, Steps=6668, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=866, Total reward=-1.0, Steps=6683, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=867, Total reward=-1.2, Steps=6688, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=868, Total reward=-1, Steps=6691, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=869, Total reward=-1.1, Steps=6695, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=870, Total reward=-2.2, Steps=6712, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=871, Total reward=-2.1, Steps=6728, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=872, Total reward=-1.2, Steps=6745, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=873, Total reward=-1, Steps=6749, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=874, Total reward=-0.4, Steps=6758, Training iteration=3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=875, Total reward=-1.4, Steps=6765, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=876, Total reward=-1.1, Steps=6769, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=877, Total reward=-0.4, Steps=6778, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=878, Total reward=-1.1, Steps=6783, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=879, Total reward=-1, Steps=6786, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=880, Total reward=-1.3, Steps=6793, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=881, Total reward=-1.8, Steps=6816, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=882, Total reward=-1.1, Steps=6820, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=883, Total reward=-0.8, Steps=6833, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=884, Total reward=-1.1, Steps=6837, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=885, Total reward=-1.1, Steps=6841, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=886, Total reward=-1, Steps=6844, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=887, Total reward=-1.8, Steps=6856, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=888, Total reward=-0.6, Steps=6867, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=889, Total reward=-1.1, Steps=6872, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=890, Total reward=-1, Steps=6875, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=891, Total reward=-0.1, Steps=6881, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=892, Total reward=-0.8, Steps=6894, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=893, Total reward=-1.3, Steps=6900, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=894, Total reward=-2.2, Steps=6917, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=895, Total reward=-0.8, Steps=6930, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=896, Total reward=-0.2, Steps=6937, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=897, Total reward=-0.6, Steps=6948, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=898, Total reward=-1.6, Steps=6958, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=899, Total reward=-0.3, Steps=6966, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=900, Total reward=-1.4, Steps=6974, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=901, Total reward=-0.6, Steps=6985, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=902, Total reward=-1.3, Steps=6991, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=903, Total reward=-1, Steps=6994, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=904, Total reward=-1.5, Steps=7014, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=905, Total reward=-1.5, Steps=7023, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=906, Total reward=-0.7, Steps=7035, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=907, Total reward=-1.0, Steps=7050, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=908, Total reward=-0.3, Steps=7058, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=909, Total reward=-1, Steps=7061, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=910, Total reward=-1.5, Steps=7070, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=911, Total reward=-1, Steps=7073, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=912, Total reward=-1.3, Steps=7080, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=913, Total reward=-1, Steps=7083, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=914, Total reward=-0.1, Steps=7089, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=915, Total reward=-1.4, Steps=7097, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=916, Total reward=-1.3, Steps=7104, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=917, Total reward=-0.5, Steps=7114, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=918, Total reward=-1.4, Steps=7121, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=919, Total reward=-1.3, Steps=7127, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=920, Total reward=1, Steps=7131, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=921, Total reward=-1.3, Steps=7137, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=922, Total reward=0.9, Steps=7142, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=923, Total reward=-1, Steps=7145, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=924, Total reward=-1, Steps=7148, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=925, Total reward=-1.5, Steps=7157, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=926, Total reward=-1.4, Steps=7165, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=927, Total reward=-1.1, Steps=7169, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=928, Total reward=-1, Steps=7172, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=929, Total reward=-1, Steps=7175, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=930, Total reward=-1, Steps=7178, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=931, Total reward=-1.5, Steps=7186, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=932, Total reward=-1.2, Steps=7191, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=933, Total reward=-1.1, Steps=7195, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=934, Total reward=-2.4, Steps=7214, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=935, Total reward=-1.3, Steps=7220, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=936, Total reward=-1.1, Steps=7224, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=937, Total reward=-1, Steps=7228, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=938, Total reward=-0.7, Steps=7240, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=939, Total reward=-0.8, Steps=7253, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=940, Total reward=-2.7, Steps=7275, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=941, Total reward=-1, Steps=7279, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=942, Total reward=-1, Steps=7282, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=943, Total reward=1, Steps=7286, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=944, Total reward=-1, Steps=7289, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=945, Total reward=-1.1, Steps=7293, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=946, Total reward=-1.2, Steps=7310, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=947, Total reward=-1, Steps=7313, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=948, Total reward=-1.4, Steps=7332, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=949, Total reward=0.5, Steps=7342, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=950, Total reward=-2.3, Steps=7360, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=951, Total reward=-1.2, Steps=7365, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=952, Total reward=-1, Steps=7368, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=953, Total reward=-1.2, Steps=7373, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=954, Total reward=-1.2, Steps=7378, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=955, Total reward=-1.1, Steps=7383, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=956, Total reward=-1.1, Steps=7387, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=957, Total reward=-1.1, Steps=7391, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=958, Total reward=-1.2, Steps=7396, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=959, Total reward=-1.3, Steps=7414, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=960, Total reward=-0.5, Steps=7424, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=961, Total reward=-1.1, Steps=7428, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=962, Total reward=-1, Steps=7431, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=963, Total reward=-2.1, Steps=7447, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=964, Total reward=-1, Steps=7450, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=965, Total reward=-1.4, Steps=7458, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=966, Total reward=0.8, Steps=7465, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=967, Total reward=-0.7, Steps=7477, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=968, Total reward=-1, Steps=7481, Training iteration=3\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/6_Step-7481.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/6_Step-7481.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=969, Total reward=-1.7, Steps=7491, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=970, Total reward=-0.3, Steps=7499, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=971, Total reward=-1, Steps=7502, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=972, Total reward=-0.7, Steps=7514, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=973, Total reward=-1.1, Steps=7518, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=974, Total reward=-2.0, Steps=7533, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=975, Total reward=-1, Steps=7536, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=976, Total reward=-1.2, Steps=7542, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=977, Total reward=-1.2, Steps=7547, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=978, Total reward=-1.2, Steps=7552, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=979, Total reward=0.5, Steps=7562, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=980, Total reward=-1.1, Steps=7566, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=981, Total reward=-1, Steps=7569, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=982, Total reward=-1, Steps=7572, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=983, Total reward=-1, Steps=7575, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=984, Total reward=-1.1, Steps=7580, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=985, Total reward=-1.5, Steps=7589, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=986, Total reward=0.7, Steps=7596, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=987, Total reward=-1.1, Steps=7601, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=988, Total reward=-1, Steps=7604, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=989, Total reward=-1, Steps=7607, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=990, Total reward=-1, Steps=7610, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=991, Total reward=-0.2, Steps=7627, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=992, Total reward=-0.6, Steps=7638, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=993, Total reward=-1.1, Steps=7643, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=994, Total reward=-1.1, Steps=7648, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=995, Total reward=-1, Steps=7651, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=996, Total reward=-1.2, Steps=7657, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=997, Total reward=-1, Steps=7660, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=998, Total reward=-1, Steps=7663, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=999, Total reward=-1.1, Steps=7667, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1000, Total reward=-1, Steps=7671, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1001, Total reward=-1, Steps=7674, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1002, Total reward=-1.1, Steps=7678, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1003, Total reward=-0.6, Steps=7689, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1004, Total reward=-1, Steps=7692, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1005, Total reward=-2.2, Steps=7709, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1006, Total reward=-1.0, Steps=7724, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1007, Total reward=-1.1, Steps=7729, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1008, Total reward=-1.1, Steps=7734, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1009, Total reward=-1, Steps=7738, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1010, Total reward=-1.3, Steps=7744, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1011, Total reward=-1.6, Steps=7754, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1012, Total reward=-2.4, Steps=7773, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1013, Total reward=-1.4, Steps=7781, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1014, Total reward=0.0, Steps=7796, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1015, Total reward=-1.6, Steps=7817, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1016, Total reward=-1.3, Steps=7824, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1017, Total reward=-1.2, Steps=7829, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1018, Total reward=-1.1, Steps=7833, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1019, Total reward=-1, Steps=7837, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1020, Total reward=-1.5, Steps=7846, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1021, Total reward=-1.5, Steps=7855, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1022, Total reward=-2.2, Steps=7872, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1023, Total reward=-1.1, Steps=7876, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1024, Total reward=-0.2, Steps=7883, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1025, Total reward=-0.2, Steps=7890, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1026, Total reward=-1, Steps=7893, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1027, Total reward=-1.4, Steps=7900, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1028, Total reward=-1.9, Steps=7913, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1029, Total reward=-0.6, Steps=7924, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1030, Total reward=-1, Steps=7927, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1031, Total reward=-1, Steps=7930, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1032, Total reward=-1.7, Steps=7941, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1033, Total reward=1, Steps=7944, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1034, Total reward=-1.1, Steps=7949, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1035, Total reward=-2.4, Steps=7968, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1036, Total reward=-0.2, Steps=7975, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1037, Total reward=-1.2, Steps=7980, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1038, Total reward=-1.2, Steps=7985, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1039, Total reward=-1.1, Steps=7989, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-1.6, Steps=7999, Training iteration=3\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1041, Total reward=-0.7, Steps=8012, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1042, Total reward=-0.4, Steps=8021, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1043, Total reward=-1.2, Steps=8027, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1044, Total reward=0.0, Steps=8042, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1045, Total reward=-1.3, Steps=8049, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1046, Total reward=-1, Steps=8052, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1047, Total reward=-2.1, Steps=8067, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1048, Total reward=-1.1, Steps=8071, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1049, Total reward=-0.2, Steps=8078, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1050, Total reward=-0.2, Steps=8085, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1051, Total reward=-1.1, Steps=8101, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1052, Total reward=-1, Steps=8104, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-1.2, Steps=8110, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1054, Total reward=-1.3, Steps=8116, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1055, Total reward=-1.7, Steps=8127, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1056, Total reward=0.7, Steps=8135, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1057, Total reward=-1.2, Steps=8140, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1058, Total reward=1, Steps=8144, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1059, Total reward=-1, Steps=8147, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1060, Total reward=-1, Steps=8150, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1061, Total reward=-1.4, Steps=8157, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1062, Total reward=-1.1, Steps=8161, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1063, Total reward=0.9, Steps=8166, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1064, Total reward=-1.5, Steps=8175, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1065, Total reward=1, Steps=8179, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1066, Total reward=-1.4, Steps=8186, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1067, Total reward=-1, Steps=8189, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1068, Total reward=-1, Steps=8192, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1069, Total reward=-1.1, Steps=8196, Training iteration=3\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1070, Total reward=-2.0, Steps=8210, Training iteration=3\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0003831207286566496, KL divergence=[0.], Entropy=[-0.02155969], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.005053576547652483, KL divergence=[0.], Entropy=[-0.02152624], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009275374002754688, KL divergence=[0.], Entropy=[-0.02151155], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.010340950451791286, KL divergence=[0.], Entropy=[-0.02149218], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01153421588242054, KL divergence=[0.], Entropy=[-0.02147098], training epoch=4, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.012167873792350292, KL divergence=[0.], Entropy=[-0.02146081], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013184120878577232, KL divergence=[0.], Entropy=[-0.02146401], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013755375519394875, KL divergence=[0.], Entropy=[-0.02143923], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013607991859316826, KL divergence=[0.], Entropy=[-0.02142605], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014061628840863705, KL divergence=[0.], Entropy=[-0.02141408], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/7_Step-8210.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/7_Step-8210.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1071, Total reward=-0.7, Steps=8222, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1072, Total reward=-1.1, Steps=8226, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1073, Total reward=-1.2, Steps=8232, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1074, Total reward=-0.2, Steps=8239, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1075, Total reward=0, Steps=8244, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1076, Total reward=-2.2, Steps=8261, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1077, Total reward=-1.2, Steps=8266, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1078, Total reward=-1.2, Steps=8272, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1079, Total reward=-1.2, Steps=8278, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1080, Total reward=0.8, Steps=8283, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1081, Total reward=-2.2, Steps=8300, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1082, Total reward=-1.1, Steps=8304, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1083, Total reward=-1.4, Steps=8312, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1084, Total reward=-1, Steps=8315, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1085, Total reward=-1.1, Steps=8320, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1086, Total reward=-1, Steps=8323, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1087, Total reward=-1.1, Steps=8327, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1088, Total reward=-0.8, Steps=8340, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1089, Total reward=-1.0, Steps=8355, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1090, Total reward=-0.5, Steps=8365, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1091, Total reward=-0.1, Steps=8371, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1092, Total reward=-1.2, Steps=8376, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1093, Total reward=-1, Steps=8379, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1094, Total reward=-1, Steps=8382, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1095, Total reward=-1.1, Steps=8387, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1096, Total reward=-1, Steps=8390, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1097, Total reward=-1, Steps=8393, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1098, Total reward=-2.2, Steps=8410, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1099, Total reward=-1.1, Steps=8414, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1100, Total reward=-1.2, Steps=8420, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1101, Total reward=-0.6, Steps=8431, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1102, Total reward=-2.1, Steps=8447, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1103, Total reward=-1, Steps=8450, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1104, Total reward=-0.4, Steps=8459, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1105, Total reward=-1.2, Steps=8464, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1106, Total reward=-2.1, Steps=8480, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1107, Total reward=-1, Steps=8483, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1108, Total reward=-1.2, Steps=8489, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1109, Total reward=-1.1, Steps=8494, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1110, Total reward=-1, Steps=8497, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1111, Total reward=-1.2, Steps=8503, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1112, Total reward=-1, Steps=8506, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1113, Total reward=-1.0, Steps=8521, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1114, Total reward=-1.3, Steps=8539, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1115, Total reward=-1.2, Steps=8544, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1116, Total reward=-0.6, Steps=8555, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1117, Total reward=-1, Steps=8558, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1118, Total reward=-0.5, Steps=8578, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1119, Total reward=-1.6, Steps=8588, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1120, Total reward=0.4, Steps=8598, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1121, Total reward=-1.1, Steps=8614, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1122, Total reward=-0.6, Steps=8625, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1123, Total reward=-1.1, Steps=8629, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1124, Total reward=-1.1, Steps=8633, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1125, Total reward=0.5, Steps=8643, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1126, Total reward=-1.1, Steps=8647, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1127, Total reward=-2.0, Steps=8661, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1128, Total reward=-1.1, Steps=8677, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1129, Total reward=-0.4, Steps=8686, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1130, Total reward=-0.2, Steps=8693, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1131, Total reward=-1, Steps=8696, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1132, Total reward=-1.2, Steps=8702, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1133, Total reward=-1.2, Steps=8708, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1134, Total reward=-1, Steps=8712, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1135, Total reward=1, Steps=8716, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1136, Total reward=0.4, Steps=8727, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1137, Total reward=-1.2, Steps=8732, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1138, Total reward=-1, Steps=8735, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1139, Total reward=0.8, Steps=8741, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1140, Total reward=-1.2, Steps=8746, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1141, Total reward=-1.1, Steps=8750, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1142, Total reward=-1.1, Steps=8754, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1143, Total reward=-1.4, Steps=8762, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1144, Total reward=-1.5, Steps=8782, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1145, Total reward=-1, Steps=8785, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1146, Total reward=-1.8, Steps=8796, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1147, Total reward=-2.0, Steps=8810, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1148, Total reward=-1.1, Steps=8814, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1149, Total reward=-1.4, Steps=8821, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1150, Total reward=-1.1, Steps=8825, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1151, Total reward=-0.6, Steps=8836, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1152, Total reward=-1.4, Steps=8844, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1153, Total reward=-0.9, Steps=8858, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1154, Total reward=-1, Steps=8861, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1155, Total reward=-1.1, Steps=8877, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1156, Total reward=-1, Steps=8880, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1157, Total reward=-1.0, Steps=8895, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1158, Total reward=-1, Steps=8898, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1159, Total reward=-1, Steps=8901, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1160, Total reward=-1, Steps=8904, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1161, Total reward=-1.0, Steps=8919, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1162, Total reward=-3.1, Steps=8945, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1163, Total reward=-1, Steps=8948, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1164, Total reward=-1, Steps=8951, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1165, Total reward=-1.3, Steps=8958, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1166, Total reward=-1.1, Steps=8962, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1167, Total reward=0, Steps=8967, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1168, Total reward=-1, Steps=8970, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1169, Total reward=-1.1, Steps=8974, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1170, Total reward=-1, Steps=8977, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1171, Total reward=-1.3, Steps=8983, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1172, Total reward=-1.2, Steps=8989, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1173, Total reward=-0.7, Steps=9001, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1174, Total reward=-1.3, Steps=9007, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1175, Total reward=-2.2, Steps=9024, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1176, Total reward=-1.2, Steps=9029, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1177, Total reward=-1.4, Steps=9036, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1178, Total reward=-1, Steps=9039, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1179, Total reward=-0.8, Steps=9052, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1180, Total reward=-2.1, Steps=9068, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1181, Total reward=-1.5, Steps=9077, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1182, Total reward=-1.3, Steps=9084, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1183, Total reward=0.4, Steps=9094, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1184, Total reward=-2.0, Steps=9109, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1185, Total reward=-0.4, Steps=9118, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1186, Total reward=-1.4, Steps=9126, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-2.0, Steps=9140, Training iteration=4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1188, Total reward=-1.4, Steps=9147, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1189, Total reward=-1.1, Steps=9163, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1190, Total reward=-1.5, Steps=9171, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1191, Total reward=-1.2, Steps=9177, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1192, Total reward=-2.0, Steps=9192, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1193, Total reward=-0.2, Steps=9199, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1194, Total reward=-0.8, Steps=9212, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1195, Total reward=-2.0, Steps=9226, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1196, Total reward=-1.2, Steps=9231, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1197, Total reward=-0.8, Steps=9244, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1198, Total reward=0.4, Steps=9255, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1199, Total reward=-1, Steps=9258, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1200, Total reward=-0.9, Steps=9272, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1201, Total reward=-1.0, Steps=9287, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1202, Total reward=-1.1, Steps=9291, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1203, Total reward=-1, Steps=9295, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1204, Total reward=-0.5, Steps=9305, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1205, Total reward=-1.2, Steps=9310, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1206, Total reward=-1.1, Steps=9314, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1207, Total reward=0.7, Steps=9321, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1208, Total reward=-1.1, Steps=9325, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1209, Total reward=-1, Steps=9328, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1210, Total reward=-1.2, Steps=9334, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1211, Total reward=-0.4, Steps=9343, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1212, Total reward=-1.4, Steps=9350, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1213, Total reward=-1.1, Steps=9355, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1214, Total reward=-1.1, Steps=9371, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1215, Total reward=0.2, Steps=9384, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1216, Total reward=-1.2, Steps=9401, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1217, Total reward=-1, Steps=9404, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1218, Total reward=-2.0, Steps=9419, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1219, Total reward=-1.4, Steps=9427, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1220, Total reward=-1.3, Steps=9433, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1221, Total reward=-1.2, Steps=9450, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1222, Total reward=-0.2, Steps=9457, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1223, Total reward=-1, Steps=9460, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1224, Total reward=-1.1, Steps=9464, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1225, Total reward=-0.6, Steps=9475, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1226, Total reward=-1.1, Steps=9479, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1227, Total reward=-1, Steps=9482, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1228, Total reward=-1.1, Steps=9486, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1229, Total reward=-2.1, Steps=9502, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1230, Total reward=-2.6, Steps=9523, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1231, Total reward=-2.0, Steps=9537, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1232, Total reward=-2.8, Steps=9560, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1233, Total reward=-2.1, Steps=9576, Training iteration=4\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/8_Step-9576.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/8_Step-9576.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1234, Total reward=-1.2, Steps=9581, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1235, Total reward=-1, Steps=9584, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1236, Total reward=-1, Steps=9587, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1237, Total reward=-0.2, Steps=9594, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1238, Total reward=-1.3, Steps=9600, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1239, Total reward=-1.1, Steps=9604, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1240, Total reward=-1, Steps=9607, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1241, Total reward=-1.2, Steps=9612, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1242, Total reward=-1.2, Steps=9617, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1243, Total reward=-2.2, Steps=9634, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1244, Total reward=0.9, Steps=9639, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1245, Total reward=-1, Steps=9642, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1246, Total reward=-2.3, Steps=9660, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1247, Total reward=-1.3, Steps=9666, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1248, Total reward=-1, Steps=9670, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1249, Total reward=-1, Steps=9673, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1250, Total reward=-2.0, Steps=9687, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1251, Total reward=-1, Steps=9691, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1252, Total reward=-2.0, Steps=9705, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1253, Total reward=-1.8, Steps=9717, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1254, Total reward=-1, Steps=9720, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1255, Total reward=-1.1, Steps=9724, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1256, Total reward=-1, Steps=9727, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1257, Total reward=-1, Steps=9730, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1258, Total reward=-1, Steps=9733, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1259, Total reward=-1.3, Steps=9739, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1260, Total reward=-1.3, Steps=9746, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1261, Total reward=-1.1, Steps=9750, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1262, Total reward=-0.3, Steps=9758, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1263, Total reward=-1.6, Steps=9767, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1264, Total reward=-0.5, Steps=9777, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1265, Total reward=-2.3, Steps=9795, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1266, Total reward=-1, Steps=9798, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1267, Total reward=-0.9, Steps=9812, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1268, Total reward=-1.1, Steps=9816, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1269, Total reward=-0.1, Steps=9832, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1270, Total reward=-1.1, Steps=9836, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1271, Total reward=-1.3, Steps=9843, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1272, Total reward=-1.3, Steps=9849, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1273, Total reward=0.6, Steps=9857, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1274, Total reward=-1.0, Steps=9872, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1275, Total reward=-1.1, Steps=9877, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1276, Total reward=-1.5, Steps=9886, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1277, Total reward=-1.1, Steps=9890, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1278, Total reward=-1, Steps=9893, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1279, Total reward=-0.2, Steps=9900, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1280, Total reward=-2.0, Steps=9915, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1281, Total reward=-1, Steps=9918, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1282, Total reward=-1.0, Steps=9933, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1283, Total reward=0.7, Steps=9940, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1284, Total reward=-1, Steps=9943, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1285, Total reward=-0.6, Steps=9954, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1286, Total reward=-1, Steps=9957, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1287, Total reward=0.3, Steps=9968, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1288, Total reward=-2.2, Steps=9985, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1289, Total reward=-1, Steps=9988, Training iteration=4\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1289, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1289, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1289, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1289, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1289, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1290, Total reward=-0.2, Steps=10007, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1291, Total reward=-1.4, Steps=10014, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1292, Total reward=-1.1, Steps=10018, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1293, Total reward=-1.1, Steps=10023, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1294, Total reward=-0.2, Steps=10030, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1295, Total reward=-1, Steps=10034, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1296, Total reward=-1.1, Steps=10038, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1297, Total reward=-1, Steps=10042, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1298, Total reward=-1.2, Steps=10047, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1299, Total reward=-0.6, Steps=10058, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1300, Total reward=-1.1, Steps=10062, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1301, Total reward=-1.1, Steps=10066, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1302, Total reward=-1.5, Steps=10075, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1303, Total reward=-1, Steps=10078, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1304, Total reward=-1, Steps=10081, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1305, Total reward=-1.2, Steps=10086, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1306, Total reward=-0.3, Steps=10094, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1307, Total reward=-1.1, Steps=10098, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1308, Total reward=-2.0, Steps=10112, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1309, Total reward=-1.3, Steps=10119, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1310, Total reward=-0.6, Steps=10130, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1311, Total reward=-1.1, Steps=10135, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1312, Total reward=-0.6, Steps=10146, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1313, Total reward=-1.1, Steps=10150, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1314, Total reward=-1, Steps=10153, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1315, Total reward=-2.3, Steps=10171, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1316, Total reward=-1, Steps=10174, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1317, Total reward=-2.0, Steps=10189, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1318, Total reward=-2.6, Steps=10210, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1319, Total reward=-1.2, Steps=10215, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1320, Total reward=-1, Steps=10218, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1321, Total reward=-1.4, Steps=10226, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-2.0, Steps=10241, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1323, Total reward=-1, Steps=10244, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1324, Total reward=-1, Steps=10247, Training iteration=4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1325, Total reward=-1.3, Steps=10265, Training iteration=4\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0006367256282828748, KL divergence=[0.], Entropy=[-0.02134812], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008425856940448284, KL divergence=[0.], Entropy=[-0.02128936], training epoch=1, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.01481508556753397, KL divergence=[0.], Entropy=[-0.021208], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01102064736187458, KL divergence=[0.], Entropy=[-0.02123042], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020161183550953865, KL divergence=[0.], Entropy=[-0.02118429], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016819478943943977, KL divergence=[0.], Entropy=[-0.02117538], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009511539712548256, KL divergence=[0.], Entropy=[-0.02116999], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018424885347485542, KL divergence=[0.], Entropy=[-0.02116523], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019215207546949387, KL divergence=[0.], Entropy=[-0.02118155], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019352544099092484, KL divergence=[0.], Entropy=[-0.02115048], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/9_Step-10265.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/9_Step-10265.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1326, Total reward=-1.5, Steps=10273, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1327, Total reward=0.4, Steps=10283, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1328, Total reward=-0.9, Steps=10297, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1329, Total reward=-1.2, Steps=10314, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1330, Total reward=-1.1, Steps=10318, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1331, Total reward=-0.9, Steps=10332, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1332, Total reward=-1, Steps=10336, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1333, Total reward=1, Steps=10339, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1334, Total reward=-2.3, Steps=10356, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1335, Total reward=-0.3, Steps=10374, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1336, Total reward=-2.2, Steps=10391, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1337, Total reward=-1, Steps=10394, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1338, Total reward=-1.2, Steps=10400, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1339, Total reward=-1.1, Steps=10404, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1340, Total reward=-0.5, Steps=10414, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1341, Total reward=-1.2, Steps=10420, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1342, Total reward=-1.2, Steps=10426, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1343, Total reward=-1, Steps=10429, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1344, Total reward=-2.1, Steps=10444, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1345, Total reward=-1.3, Steps=10451, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1346, Total reward=-1.1, Steps=10455, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1347, Total reward=0.6, Steps=10463, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1348, Total reward=-1.1, Steps=10467, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1349, Total reward=-1.2, Steps=10472, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1350, Total reward=-2.8, Steps=10495, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1351, Total reward=-1.3, Steps=10501, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1352, Total reward=-1, Steps=10504, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1353, Total reward=-2.7, Steps=10526, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1354, Total reward=-1.2, Steps=10531, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1355, Total reward=1, Steps=10535, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1356, Total reward=-0.5, Steps=10545, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1357, Total reward=-1.2, Steps=10562, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1358, Total reward=0, Steps=10567, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1359, Total reward=-1, Steps=10571, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1360, Total reward=-1.1, Steps=10576, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1361, Total reward=-1.1, Steps=10580, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1362, Total reward=-1.1, Steps=10585, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1363, Total reward=-1.5, Steps=10593, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1364, Total reward=-2.5, Steps=10613, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1365, Total reward=0.6, Steps=10621, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1366, Total reward=-1, Steps=10624, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1367, Total reward=0.8, Steps=10630, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1368, Total reward=1, Steps=10634, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1369, Total reward=-1.2, Steps=10639, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1370, Total reward=-1.2, Steps=10644, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1371, Total reward=-1.7, Steps=10655, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1372, Total reward=-1.2, Steps=10660, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1373, Total reward=-1.5, Steps=10669, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1374, Total reward=-1, Steps=10672, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1375, Total reward=-1, Steps=10675, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1376, Total reward=1, Steps=10679, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1377, Total reward=-1, Steps=10682, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1378, Total reward=-1.4, Steps=10701, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1379, Total reward=-1, Steps=10704, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1380, Total reward=-0.4, Steps=10713, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1381, Total reward=-1, Steps=10716, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1382, Total reward=-1, Steps=10720, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1383, Total reward=-1.3, Steps=10738, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1384, Total reward=0.5, Steps=10747, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1385, Total reward=0.6, Steps=10755, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1386, Total reward=-2.1, Steps=10771, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1387, Total reward=-1.3, Steps=10778, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1388, Total reward=-1.4, Steps=10786, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1389, Total reward=-2.9, Steps=10810, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1390, Total reward=-2.1, Steps=10826, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1391, Total reward=-1, Steps=10829, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1392, Total reward=-1.1, Steps=10833, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1393, Total reward=-1.3, Steps=10840, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1394, Total reward=0.9, Steps=10845, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1395, Total reward=-1.0, Steps=10860, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1396, Total reward=-1.1, Steps=10864, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1397, Total reward=-1, Steps=10867, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1398, Total reward=-1.2, Steps=10872, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1399, Total reward=-0.7, Steps=10884, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1400, Total reward=-1.5, Steps=10893, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1401, Total reward=-1.1, Steps=10897, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1402, Total reward=-1.3, Steps=10903, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1403, Total reward=-1.2, Steps=10908, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1404, Total reward=-1.8, Steps=10920, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1405, Total reward=-1.4, Steps=10927, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1406, Total reward=-1, Steps=10930, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1407, Total reward=-1, Steps=10933, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1408, Total reward=-1.3, Steps=10951, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1409, Total reward=-0.2, Steps=10958, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1410, Total reward=-1, Steps=10962, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1411, Total reward=0.9, Steps=10967, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1412, Total reward=-1.4, Steps=10974, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1413, Total reward=-1.2, Steps=10979, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1414, Total reward=-1.0, Steps=10994, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1415, Total reward=-1.2, Steps=11000, Training iteration=5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1416, Total reward=-0.3, Steps=11018, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1417, Total reward=-1.1, Steps=11022, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1418, Total reward=-1.3, Steps=11028, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1419, Total reward=-1.5, Steps=11037, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1420, Total reward=-1.3, Steps=11043, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1421, Total reward=-1.2, Steps=11048, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1422, Total reward=-1.1, Steps=11053, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1423, Total reward=-0.2, Steps=11060, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1424, Total reward=-1.0, Steps=11075, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1425, Total reward=-1.2, Steps=11080, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1426, Total reward=0.9, Steps=11085, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1427, Total reward=-1, Steps=11088, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1428, Total reward=0.7, Steps=11096, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1429, Total reward=-2.4, Steps=11115, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1430, Total reward=-1.5, Steps=11124, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1431, Total reward=-0.9, Steps=11138, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1432, Total reward=-1.4, Steps=11145, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1433, Total reward=-0.6, Steps=11156, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1434, Total reward=-1.3, Steps=11163, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1435, Total reward=-1.1, Steps=11167, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1436, Total reward=-1, Steps=11170, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1437, Total reward=-1.2, Steps=11176, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1438, Total reward=-0.1, Steps=11182, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1439, Total reward=-2.3, Steps=11200, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1440, Total reward=-0.8, Steps=11213, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1441, Total reward=-1.1, Steps=11217, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1442, Total reward=-2.2, Steps=11234, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1443, Total reward=-1, Steps=11237, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1444, Total reward=-1.2, Steps=11242, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1445, Total reward=-1, Steps=11245, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1446, Total reward=-1.2, Steps=11250, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1447, Total reward=-2.1, Steps=11266, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1448, Total reward=-2.2, Steps=11283, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1449, Total reward=-0.2, Steps=11290, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1450, Total reward=-1.1, Steps=11295, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1451, Total reward=-1.2, Steps=11300, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1452, Total reward=-1.2, Steps=11305, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1453, Total reward=-1, Steps=11308, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1454, Total reward=-1, Steps=11311, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1455, Total reward=-0.5, Steps=11321, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1456, Total reward=-1.2, Steps=11326, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1457, Total reward=-2.3, Steps=11344, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1458, Total reward=-2.2, Steps=11361, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-2.1, Steps=11377, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1460, Total reward=-2.0, Steps=11391, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1461, Total reward=-1.1, Steps=11407, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1462, Total reward=-1.1, Steps=11411, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1463, Total reward=-1, Steps=11414, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1464, Total reward=-1.1, Steps=11418, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1465, Total reward=0.7, Steps=11424, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1466, Total reward=-1.1, Steps=11429, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1467, Total reward=-0.9, Steps=11443, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1468, Total reward=-1, Steps=11447, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1469, Total reward=-1, Steps=11450, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1470, Total reward=-1.1, Steps=11454, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1471, Total reward=-1, Steps=11458, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1472, Total reward=-3.0, Steps=11483, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1473, Total reward=-1.2, Steps=11489, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1474, Total reward=-2.7, Steps=11511, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1475, Total reward=-1, Steps=11514, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1476, Total reward=-2.1, Steps=11530, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1477, Total reward=-0.4, Steps=11539, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1478, Total reward=-1.3, Steps=11545, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1479, Total reward=-1, Steps=11548, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1480, Total reward=-1.3, Steps=11566, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1481, Total reward=-2.1, Steps=11582, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1482, Total reward=0.1, Steps=11595, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1483, Total reward=-0.5, Steps=11605, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1484, Total reward=-2.1, Steps=11620, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1485, Total reward=-1, Steps=11623, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1486, Total reward=-2.2, Steps=11639, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1487, Total reward=-1.4, Steps=11647, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1488, Total reward=-1.3, Steps=11665, Training iteration=5\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/10_Step-11665.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/10_Step-11665.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1489, Total reward=-1.1, Steps=11669, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1490, Total reward=-1.5, Steps=11678, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1491, Total reward=-2.1, Steps=11694, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1492, Total reward=-1, Steps=11697, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1493, Total reward=-1, Steps=11700, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1494, Total reward=-1, Steps=11703, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1495, Total reward=-1.2, Steps=11708, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1496, Total reward=-1.2, Steps=11714, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1497, Total reward=0.4, Steps=11725, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1498, Total reward=-0.2, Steps=11742, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1499, Total reward=-1.9, Steps=11755, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1500, Total reward=-2.2, Steps=11772, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1501, Total reward=0, Steps=11777, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1502, Total reward=-2.0, Steps=11791, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1503, Total reward=-1.1, Steps=11795, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1504, Total reward=-2.0, Steps=11810, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1505, Total reward=-1.1, Steps=11814, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1506, Total reward=-2.1, Steps=11830, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1507, Total reward=-0.7, Steps=11842, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1508, Total reward=-1.1, Steps=11846, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1509, Total reward=-1.2, Steps=11851, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1510, Total reward=-2.0, Steps=11866, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1511, Total reward=-2.1, Steps=11882, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1512, Total reward=-0.1, Steps=11888, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1513, Total reward=-2.0, Steps=11902, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1514, Total reward=-1.1, Steps=11906, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1515, Total reward=-1.1, Steps=11910, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1516, Total reward=-2.1, Steps=11925, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1517, Total reward=-1, Steps=11928, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1518, Total reward=-1.2, Steps=11933, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1519, Total reward=-2.7, Steps=11955, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1520, Total reward=-1.1, Steps=11959, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1521, Total reward=-1.1, Steps=11963, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1522, Total reward=-1.1, Steps=11979, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1523, Total reward=-1, Steps=11982, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1524, Total reward=-0.7, Steps=11994, Training iteration=5\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1524, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1524, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1524, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1524, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1524, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1525, Total reward=-1.2, Steps=12005, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1526, Total reward=-0.4, Steps=12014, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1527, Total reward=-1.1, Steps=12018, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1528, Total reward=-1, Steps=12021, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1529, Total reward=-1.1, Steps=12026, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1530, Total reward=-1, Steps=12029, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1531, Total reward=-1.2, Steps=12035, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1532, Total reward=-2.4, Steps=12054, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1533, Total reward=-1, Steps=12057, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1534, Total reward=-1, Steps=12060, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1535, Total reward=-1.2, Steps=12066, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1536, Total reward=-1.4, Steps=12073, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1537, Total reward=-1, Steps=12076, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1538, Total reward=-1.3, Steps=12082, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1539, Total reward=-1, Steps=12085, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1540, Total reward=0.7, Steps=12093, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1541, Total reward=-1, Steps=12096, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1542, Total reward=-1.1, Steps=12100, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1543, Total reward=-1.1, Steps=12104, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1544, Total reward=-1.2, Steps=12110, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1545, Total reward=-0.4, Steps=12119, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1546, Total reward=-0.3, Steps=12127, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1547, Total reward=-2.1, Steps=12143, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1548, Total reward=-1.2, Steps=12148, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1549, Total reward=-1.9, Steps=12161, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1550, Total reward=-1, Steps=12164, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1551, Total reward=-1, Steps=12167, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1552, Total reward=-0.5, Steps=12177, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1553, Total reward=-1.4, Steps=12185, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1554, Total reward=-1.2, Steps=12202, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1555, Total reward=-1.1, Steps=12206, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1556, Total reward=-2.1, Steps=12221, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1557, Total reward=-1.2, Steps=12226, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1558, Total reward=-1.1, Steps=12231, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1559, Total reward=-1.1, Steps=12235, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1560, Total reward=-0.5, Steps=12245, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1561, Total reward=-1.5, Steps=12253, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1562, Total reward=-0.1, Steps=12259, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1563, Total reward=-1.3, Steps=12266, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1564, Total reward=-0.5, Steps=12276, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1565, Total reward=-2.2, Steps=12293, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1566, Total reward=-1, Steps=12296, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1567, Total reward=-1.6, Steps=12306, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1568, Total reward=-0.1, Steps=12312, Training iteration=5\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1569, Total reward=-1.1, Steps=12316, Training iteration=5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.00402833940461278, KL divergence=[0.], Entropy=[-0.02125546], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012601017951965332, KL divergence=[0.], Entropy=[-0.02131982], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01281595416367054, KL divergence=[0.], Entropy=[-0.02131479], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019701676443219185, KL divergence=[0.], Entropy=[-0.02129945], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019200138747692108, KL divergence=[0.], Entropy=[-0.02126358], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020444797351956367, KL divergence=[0.], Entropy=[-0.02125837], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018390145152807236, KL divergence=[0.], Entropy=[-0.02122474], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.025945810601115227, KL divergence=[0.], Entropy=[-0.02125698], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.023676123470067978, KL divergence=[0.], Entropy=[-0.02122284], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014483713544905186, KL divergence=[0.], Entropy=[-0.021217], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/11_Step-12316.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/11_Step-12316.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1570, Total reward=-1.4, Steps=12323, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1571, Total reward=0.8, Steps=12329, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1572, Total reward=-0.2, Steps=12336, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1573, Total reward=-1, Steps=12339, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1574, Total reward=-1.2, Steps=12344, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1575, Total reward=-1, Steps=12347, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1576, Total reward=-1, Steps=12350, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1577, Total reward=-1.4, Steps=12358, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1578, Total reward=-1.1, Steps=12362, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1579, Total reward=-1, Steps=12366, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1580, Total reward=-0.5, Steps=12376, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1581, Total reward=-1, Steps=12379, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1582, Total reward=-1, Steps=12382, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1583, Total reward=-0.2, Steps=12398, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1584, Total reward=-1, Steps=12402, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1585, Total reward=-1.1, Steps=12406, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1586, Total reward=-1.3, Steps=12412, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1587, Total reward=-1.1, Steps=12416, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1588, Total reward=-1.3, Steps=12423, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1589, Total reward=-1, Steps=12427, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1590, Total reward=-1.1, Steps=12431, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1591, Total reward=-2.0, Steps=12445, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1592, Total reward=-1.2, Steps=12450, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1593, Total reward=-1.2, Steps=12455, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1594, Total reward=-0.8, Steps=12468, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1595, Total reward=-1.6, Steps=12478, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1596, Total reward=-0.5, Steps=12488, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1597, Total reward=-1.4, Steps=12495, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1598, Total reward=0.8, Steps=12501, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1599, Total reward=0.0, Steps=12515, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1600, Total reward=-1.2, Steps=12521, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1601, Total reward=-1.1, Steps=12525, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1602, Total reward=-1, Steps=12528, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1603, Total reward=-0.3, Steps=12536, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1604, Total reward=-1.2, Steps=12542, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1605, Total reward=-1.6, Steps=12552, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1606, Total reward=-1, Steps=12555, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1607, Total reward=-1, Steps=12558, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1608, Total reward=-1.6, Steps=12568, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1609, Total reward=-0.3, Steps=12576, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1610, Total reward=-1.3, Steps=12582, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1611, Total reward=-0.4, Steps=12591, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1612, Total reward=-2.3, Steps=12608, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1613, Total reward=-1.2, Steps=12614, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1614, Total reward=-1.1, Steps=12618, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1615, Total reward=-1.7, Steps=12629, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1616, Total reward=-1.3, Steps=12635, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1617, Total reward=-0.9, Steps=12649, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1618, Total reward=-0.9, Steps=12663, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1619, Total reward=-1.3, Steps=12681, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1620, Total reward=-1.7, Steps=12692, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1621, Total reward=-0.2, Steps=12699, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1622, Total reward=-2.2, Steps=12716, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1623, Total reward=-1.4, Steps=12724, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1624, Total reward=0.4, Steps=12734, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1625, Total reward=-2.1, Steps=12749, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1626, Total reward=0.4, Steps=12760, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1627, Total reward=-1, Steps=12763, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1628, Total reward=-1, Steps=12766, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1629, Total reward=-1.2, Steps=12772, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1630, Total reward=-0.4, Steps=12781, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1631, Total reward=-1.3, Steps=12788, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1632, Total reward=1, Steps=12792, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1633, Total reward=-0.1, Steps=12798, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1634, Total reward=-1, Steps=12801, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1635, Total reward=-1, Steps=12805, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1636, Total reward=-1.1, Steps=12809, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1637, Total reward=-1.1, Steps=12813, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1638, Total reward=-2.4, Steps=12832, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1639, Total reward=-1.1, Steps=12837, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1640, Total reward=-1.1, Steps=12841, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1641, Total reward=-2.0, Steps=12855, Training iteration=6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1642, Total reward=-1.1, Steps=12859, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1643, Total reward=-0.4, Steps=12868, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1644, Total reward=-1.3, Steps=12875, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1645, Total reward=-1.8, Steps=12887, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1646, Total reward=-2.0, Steps=12902, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1647, Total reward=-1.4, Steps=12910, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1648, Total reward=0.9, Steps=12915, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1649, Total reward=-0.6, Steps=12926, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1650, Total reward=-1.2, Steps=12931, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1651, Total reward=-1, Steps=12934, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1652, Total reward=-1.1, Steps=12938, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1653, Total reward=-2.5, Steps=12958, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1654, Total reward=-1.1, Steps=12962, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1655, Total reward=-1, Steps=12965, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1656, Total reward=-1, Steps=12968, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1657, Total reward=-1.5, Steps=12977, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1658, Total reward=-1.3, Steps=12984, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1659, Total reward=-1.2, Steps=12989, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1660, Total reward=-1.1, Steps=12993, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1661, Total reward=-1.2, Steps=12999, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1662, Total reward=-1.1, Steps=13003, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1663, Total reward=-1, Steps=13006, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1664, Total reward=-1.1, Steps=13022, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1665, Total reward=0.3, Steps=13033, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1666, Total reward=0.5, Steps=13042, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1667, Total reward=-1.4, Steps=13049, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1668, Total reward=-0.7, Steps=13061, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1669, Total reward=-1.2, Steps=13067, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1670, Total reward=-0.4, Steps=13076, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1671, Total reward=-2.3, Steps=13094, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1672, Total reward=-1.3, Steps=13101, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1673, Total reward=-1.3, Steps=13108, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1674, Total reward=-1, Steps=13111, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1675, Total reward=-1, Steps=13115, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1676, Total reward=-1, Steps=13118, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1677, Total reward=-0.6, Steps=13129, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1678, Total reward=-1.1, Steps=13133, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1679, Total reward=0.8, Steps=13139, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1680, Total reward=-2.1, Steps=13154, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1681, Total reward=-1, Steps=13157, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1682, Total reward=-2.1, Steps=13173, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1683, Total reward=-1.2, Steps=13178, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1684, Total reward=-0.7, Steps=13190, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1685, Total reward=-1.4, Steps=13197, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1686, Total reward=-1.6, Steps=13207, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1687, Total reward=-1.1, Steps=13211, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1688, Total reward=-1.1, Steps=13215, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1689, Total reward=-1.1, Steps=13219, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1690, Total reward=0.7, Steps=13227, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1691, Total reward=-0.5, Steps=13237, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1692, Total reward=-2.0, Steps=13252, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1693, Total reward=-1, Steps=13255, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1694, Total reward=-0.2, Steps=13262, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1695, Total reward=-1.2, Steps=13267, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1696, Total reward=-1.1, Steps=13271, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1697, Total reward=0.9, Steps=13276, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1698, Total reward=-0.8, Steps=13289, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1699, Total reward=-1, Steps=13292, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1700, Total reward=-1, Steps=13295, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1701, Total reward=-1.1, Steps=13299, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1702, Total reward=-1, Steps=13302, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1703, Total reward=-0.9, Steps=13316, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1704, Total reward=-1.1, Steps=13320, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1705, Total reward=-1.1, Steps=13324, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1706, Total reward=-2.1, Steps=13340, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1707, Total reward=-1.3, Steps=13346, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1708, Total reward=-1.1, Steps=13351, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1709, Total reward=-1.1, Steps=13356, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1710, Total reward=1, Steps=13360, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1711, Total reward=-1.3, Steps=13378, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1712, Total reward=-1.2, Steps=13383, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1713, Total reward=-1.1, Steps=13387, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1714, Total reward=-0.3, Steps=13395, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1715, Total reward=-1.2, Steps=13412, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1716, Total reward=-0.5, Steps=13422, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1717, Total reward=1, Steps=13426, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1718, Total reward=-2.3, Steps=13444, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1719, Total reward=-1, Steps=13447, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1720, Total reward=-1.3, Steps=13453, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1721, Total reward=-1.1, Steps=13457, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1722, Total reward=-1.1, Steps=13461, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1723, Total reward=-1.1, Steps=13466, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1724, Total reward=-2.3, Steps=13484, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1725, Total reward=-0.4, Steps=13493, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1726, Total reward=-1, Steps=13496, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1727, Total reward=-1.1, Steps=13500, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1728, Total reward=-1.1, Steps=13516, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1729, Total reward=-1, Steps=13519, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1730, Total reward=-1.1, Steps=13523, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1731, Total reward=-1.1, Steps=13527, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1732, Total reward=-0.6, Steps=13538, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1733, Total reward=-1.5, Steps=13546, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1734, Total reward=-2.7, Steps=13568, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1735, Total reward=-1.1, Steps=13572, Training iteration=6\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/12_Step-13575.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/12_Step-13575.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1736, Total reward=-1.3, Steps=13578, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1737, Total reward=-1, Steps=13581, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1738, Total reward=-1.3, Steps=13588, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1739, Total reward=-2.4, Steps=13607, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1740, Total reward=-2.0, Steps=13621, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1741, Total reward=-1.1, Steps=13625, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1742, Total reward=-2.1, Steps=13641, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1743, Total reward=-1, Steps=13644, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1744, Total reward=-1.1, Steps=13648, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1745, Total reward=-1.2, Steps=13653, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1746, Total reward=-1, Steps=13657, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1747, Total reward=-1.1, Steps=13661, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1748, Total reward=-2.9, Steps=13685, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1749, Total reward=-1.5, Steps=13694, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1750, Total reward=-0.8, Steps=13707, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1751, Total reward=-1.1, Steps=13711, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1752, Total reward=-1.1, Steps=13715, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1753, Total reward=-2.0, Steps=13729, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1754, Total reward=-1.3, Steps=13736, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1755, Total reward=-2.4, Steps=13754, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1756, Total reward=0.3, Steps=13765, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1757, Total reward=-1.3, Steps=13783, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1758, Total reward=-2.1, Steps=13799, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1759, Total reward=-2.1, Steps=13815, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1760, Total reward=-1, Steps=13819, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1761, Total reward=-1, Steps=13822, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1762, Total reward=-0.5, Steps=13832, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1763, Total reward=-1.2, Steps=13837, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1764, Total reward=-1, Steps=13840, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1765, Total reward=-1.4, Steps=13848, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1766, Total reward=-1, Steps=13851, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1767, Total reward=-1, Steps=13854, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1768, Total reward=-3.1, Steps=13880, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1769, Total reward=-1.6, Steps=13890, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1770, Total reward=-0.7, Steps=13902, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1771, Total reward=-1, Steps=13905, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1772, Total reward=-1.1, Steps=13909, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1773, Total reward=-1.6, Steps=13919, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1774, Total reward=-0.8, Steps=13932, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1775, Total reward=-1.1, Steps=13936, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1776, Total reward=-2.2, Steps=13953, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1777, Total reward=-1.4, Steps=13960, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1778, Total reward=-1.7, Steps=13971, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1779, Total reward=0.7, Steps=13979, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1780, Total reward=-1, Steps=13982, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1781, Total reward=-1.3, Steps=13989, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1782, Total reward=-1, Steps=13992, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1783, Total reward=0.6, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1783, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1783, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1783, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1783, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=1783, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1784, Total reward=-0.5, Steps=14019, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1785, Total reward=0.5, Steps=14029, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1786, Total reward=-0.6, Steps=14040, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1787, Total reward=-1.4, Steps=14047, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1788, Total reward=-1, Steps=14050, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1789, Total reward=-1, Steps=14053, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1790, Total reward=-1.4, Steps=14061, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1791, Total reward=-1, Steps=14064, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1792, Total reward=-1.4, Steps=14071, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1793, Total reward=-0.7, Steps=14083, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1794, Total reward=-1.3, Steps=14090, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1795, Total reward=-1.4, Steps=14098, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1796, Total reward=-1, Steps=14102, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1797, Total reward=0.9, Steps=14107, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1798, Total reward=-0.1, Steps=14113, Training iteration=6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1799, Total reward=-1.4, Steps=14120, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1800, Total reward=-0.4, Steps=14129, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1801, Total reward=-1, Steps=14132, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1802, Total reward=-0.5, Steps=14142, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1803, Total reward=-1.1, Steps=14146, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1804, Total reward=-1.8, Steps=14158, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1805, Total reward=-0.3, Steps=14166, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1806, Total reward=-1, Steps=14169, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1807, Total reward=-1, Steps=14172, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1808, Total reward=-2.7, Steps=14194, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1809, Total reward=-0.4, Steps=14203, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1810, Total reward=-1.8, Steps=14214, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1811, Total reward=-1.4, Steps=14222, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1812, Total reward=-1.1, Steps=14226, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1813, Total reward=-1.1, Steps=14231, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1814, Total reward=-1.1, Steps=14235, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1815, Total reward=-1, Steps=14239, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1816, Total reward=-0.8, Steps=14252, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1817, Total reward=-1.1, Steps=14268, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1818, Total reward=-0.4, Steps=14277, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1819, Total reward=-1.1, Steps=14281, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1820, Total reward=-1.1, Steps=14286, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1821, Total reward=-0.1, Steps=14292, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1822, Total reward=-1.2, Steps=14298, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1823, Total reward=-2.1, Steps=14314, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1824, Total reward=-1, Steps=14317, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1825, Total reward=-1, Steps=14320, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1826, Total reward=-1, Steps=14323, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1827, Total reward=-1, Steps=14326, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1828, Total reward=0.7, Steps=14333, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1829, Total reward=-0.9, Steps=14347, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1830, Total reward=-0.4, Steps=14356, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1831, Total reward=-1, Steps=14359, Training iteration=6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1832, Total reward=-1.6, Steps=14369, Training iteration=6\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0018813707865774632, KL divergence=[0.], Entropy=[-0.02118023], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014430725947022438, KL divergence=[0.], Entropy=[-0.02129638], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017433753237128258, KL divergence=[0.], Entropy=[-0.02130047], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01854597218334675, KL divergence=[0.], Entropy=[-0.02125906], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020196158438920975, KL divergence=[0.], Entropy=[-0.02126084], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.02082543447613716, KL divergence=[0.], Entropy=[-0.02125615], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.02051069214940071, KL divergence=[0.], Entropy=[-0.02120474], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020878847688436508, KL divergence=[0.], Entropy=[-0.0211989], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020667141303420067, KL divergence=[0.], Entropy=[-0.02121631], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020675789564847946, KL divergence=[0.], Entropy=[-0.02120005], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/13_Step-14369.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/13_Step-14369.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1833, Total reward=0.9, Steps=14373, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1834, Total reward=-1.1, Steps=14389, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1835, Total reward=-1.2, Steps=14394, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1836, Total reward=-1.2, Steps=14399, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1837, Total reward=-1.1, Steps=14403, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1838, Total reward=-1, Steps=14406, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1839, Total reward=-0.9, Steps=14420, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1840, Total reward=-2.3, Steps=14438, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1841, Total reward=-2.4, Steps=14457, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1842, Total reward=-1.3, Steps=14464, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1843, Total reward=-2.4, Steps=14483, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1844, Total reward=0.2, Steps=14496, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1845, Total reward=-0.6, Steps=14507, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1846, Total reward=-1.2, Steps=14513, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1847, Total reward=-0.2, Steps=14529, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1848, Total reward=-1.2, Steps=14535, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1849, Total reward=-1, Steps=14538, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1850, Total reward=-1.1, Steps=14542, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1851, Total reward=-0.7, Steps=14554, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1852, Total reward=-2.4, Steps=14573, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1853, Total reward=-0.6, Steps=14584, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1854, Total reward=-1, Steps=14587, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1855, Total reward=-1, Steps=14591, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1856, Total reward=-1, Steps=14595, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1857, Total reward=-1.4, Steps=14602, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1858, Total reward=0.8, Steps=14608, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1859, Total reward=-1, Steps=14612, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1860, Total reward=-1.2, Steps=14618, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1861, Total reward=0.5, Steps=14627, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1862, Total reward=-1.1, Steps=14631, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1863, Total reward=-2.5, Steps=14651, Training iteration=7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1864, Total reward=-2.0, Steps=14666, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1865, Total reward=-1, Steps=14669, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1866, Total reward=1, Steps=14673, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1867, Total reward=-2.2, Steps=14690, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1868, Total reward=-1.1, Steps=14694, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1869, Total reward=-1.3, Steps=14700, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1870, Total reward=-1.2, Steps=14706, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1871, Total reward=-2.1, Steps=14722, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1872, Total reward=-1, Steps=14725, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1873, Total reward=-1.0, Steps=14740, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1874, Total reward=-2.2, Steps=14756, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1875, Total reward=-1, Steps=14760, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1876, Total reward=-0.9, Steps=14774, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1877, Total reward=-0.2, Steps=14781, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1878, Total reward=-1.4, Steps=14789, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1879, Total reward=-0.9, Steps=14803, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1880, Total reward=-2.1, Steps=14819, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1881, Total reward=-1.3, Steps=14825, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1882, Total reward=-1.5, Steps=14845, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1883, Total reward=-1.5, Steps=14865, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1884, Total reward=-1.1, Steps=14870, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1885, Total reward=-2.0, Steps=14884, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1886, Total reward=-1.5, Steps=14893, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1887, Total reward=-1.2, Steps=14898, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1888, Total reward=-1, Steps=14901, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1889, Total reward=-1.1, Steps=14905, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1890, Total reward=-0.6, Steps=14916, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1891, Total reward=-1.3, Steps=14922, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1892, Total reward=-2.4, Steps=14941, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1893, Total reward=-1, Steps=14945, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1894, Total reward=-1.1, Steps=14961, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1895, Total reward=-1, Steps=14964, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1896, Total reward=-2.1, Steps=14980, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1897, Total reward=0.1, Steps=14994, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1898, Total reward=0.6, Steps=15002, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1899, Total reward=-2.4, Steps=15021, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1900, Total reward=-1, Steps=15024, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1901, Total reward=-0.8, Steps=15037, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1902, Total reward=-1.1, Steps=15042, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1903, Total reward=-1.1, Steps=15046, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1904, Total reward=-1.2, Steps=15051, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1905, Total reward=-1.2, Steps=15057, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1906, Total reward=-0.5, Steps=15067, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1907, Total reward=-1.1, Steps=15071, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1908, Total reward=-1.2, Steps=15077, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1909, Total reward=-1.7, Steps=15087, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1910, Total reward=-0.4, Steps=15096, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1911, Total reward=-1, Steps=15100, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1912, Total reward=-2.2, Steps=15117, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1913, Total reward=0.5, Steps=15126, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1914, Total reward=-1.1, Steps=15131, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1915, Total reward=-1.2, Steps=15137, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1916, Total reward=-1, Steps=15140, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1917, Total reward=-1.6, Steps=15150, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1918, Total reward=-1.2, Steps=15167, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1919, Total reward=-1.2, Steps=15172, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1920, Total reward=-1.2, Steps=15189, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1921, Total reward=-1.2, Steps=15195, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1922, Total reward=-1.2, Steps=15200, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1923, Total reward=0, Steps=15205, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1924, Total reward=-1.2, Steps=15211, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1925, Total reward=-1, Steps=15214, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1926, Total reward=0.2, Steps=15227, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1927, Total reward=-1.3, Steps=15233, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1928, Total reward=-0.6, Steps=15244, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1929, Total reward=-1.1, Steps=15249, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1930, Total reward=-1.1, Steps=15253, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1931, Total reward=-1.1, Steps=15269, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1932, Total reward=-1.1, Steps=15274, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1933, Total reward=-0.1, Steps=15280, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1934, Total reward=-1, Steps=15283, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1935, Total reward=0.5, Steps=15292, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1936, Total reward=-1.2, Steps=15297, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1937, Total reward=-1.6, Steps=15306, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1938, Total reward=-0.2, Steps=15313, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1939, Total reward=-1.2, Steps=15318, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1940, Total reward=-1.8, Steps=15341, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1941, Total reward=-2.3, Steps=15359, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1942, Total reward=0.7, Steps=15366, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1943, Total reward=-0.1, Steps=15372, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1944, Total reward=-1.1, Steps=15377, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1945, Total reward=-1.2, Steps=15382, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1946, Total reward=-1.1, Steps=15386, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1947, Total reward=-1.5, Steps=15406, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1948, Total reward=-2.2, Steps=15423, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1949, Total reward=-1.2, Steps=15428, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1950, Total reward=-0.3, Steps=15446, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1951, Total reward=-1, Steps=15449, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1952, Total reward=-0.1, Steps=15455, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1953, Total reward=0, Steps=15460, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1954, Total reward=-1.1, Steps=15464, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1955, Total reward=-0.7, Steps=15476, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1956, Total reward=-2.4, Steps=15495, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1957, Total reward=-1, Steps=15498, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1958, Total reward=-1.5, Steps=15507, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1959, Total reward=0.8, Steps=15513, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1960, Total reward=0, Steps=15518, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1961, Total reward=-1.1, Steps=15522, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1962, Total reward=-0.2, Steps=15529, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1963, Total reward=-1.2, Steps=15534, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1964, Total reward=-1.5, Steps=15543, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1965, Total reward=-0.4, Steps=15552, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1966, Total reward=-2.2, Steps=15569, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1967, Total reward=-0.5, Steps=15579, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1968, Total reward=-1.1, Steps=15595, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1969, Total reward=-1.1, Steps=15599, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1970, Total reward=-1.1, Steps=15603, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1971, Total reward=-0.2, Steps=15620, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1972, Total reward=-0.3, Steps=15628, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1973, Total reward=-1.1, Steps=15632, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1974, Total reward=-1.9, Steps=15645, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1975, Total reward=-0.3, Steps=15653, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1976, Total reward=-1.4, Steps=15660, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1977, Total reward=-0.3, Steps=15668, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1978, Total reward=1, Steps=15673, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1979, Total reward=-1, Steps=15676, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1980, Total reward=-2.0, Steps=15691, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1981, Total reward=-1.1, Steps=15695, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1982, Total reward=-1.1, Steps=15699, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1983, Total reward=-2.1, Steps=15715, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1984, Total reward=-0.8, Steps=15728, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1985, Total reward=-2.2, Steps=15745, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1986, Total reward=-0.3, Steps=15753, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1987, Total reward=-1.1, Steps=15758, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1988, Total reward=-2.0, Steps=15773, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1989, Total reward=-0.5, Steps=15783, Training iteration=7\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/14_Step-15783.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/14_Step-15783.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1990, Total reward=-1, Steps=15786, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1991, Total reward=-1, Steps=15789, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1992, Total reward=-2.0, Steps=15804, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1993, Total reward=-0.3, Steps=15812, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1994, Total reward=-0.7, Steps=15824, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1995, Total reward=-1.2, Steps=15829, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1996, Total reward=0.8, Steps=15835, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1997, Total reward=-1, Steps=15838, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1998, Total reward=-1.1, Steps=15842, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=1999, Total reward=-1, Steps=15845, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2000, Total reward=-1.2, Steps=15851, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2001, Total reward=-1.1, Steps=15855, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2002, Total reward=0.8, Steps=15861, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2003, Total reward=-1.9, Steps=15874, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2004, Total reward=-1, Steps=15878, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2005, Total reward=0.7, Steps=15884, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2006, Total reward=-0.5, Steps=15894, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2007, Total reward=-1.2, Steps=15899, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2008, Total reward=-2.9, Steps=15923, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2009, Total reward=-0.2, Steps=15930, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2010, Total reward=-1.1, Steps=15935, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2011, Total reward=-1.1, Steps=15940, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2012, Total reward=-1.1, Steps=15945, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2013, Total reward=-2.2, Steps=15961, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2014, Total reward=-1, Steps=15964, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2015, Total reward=0.6, Steps=15972, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2016, Total reward=1, Steps=15976, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2017, Total reward=0.5, Steps=15985, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2018, Total reward=-1.1, Steps=15990, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2019, Total reward=-1.3, Steps=15996, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-1, Steps=15999, Training iteration=7\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2021, Total reward=-1, Steps=16003, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2022, Total reward=-0.9, Steps=16017, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2023, Total reward=-1.2, Steps=16023, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2024, Total reward=-1.4, Steps=16031, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2025, Total reward=-1.4, Steps=16039, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2026, Total reward=-1.2, Steps=16045, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2027, Total reward=-3.2, Steps=16072, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2028, Total reward=-1.1, Steps=16076, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2029, Total reward=-1.1, Steps=16080, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2030, Total reward=-1.1, Steps=16084, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2031, Total reward=-1.1, Steps=16088, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2032, Total reward=-1, Steps=16091, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2033, Total reward=-0.7, Steps=16103, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2034, Total reward=-1.1, Steps=16108, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2035, Total reward=-0.5, Steps=16118, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2036, Total reward=-1, Steps=16121, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2037, Total reward=-1, Steps=16124, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2038, Total reward=-1.3, Steps=16130, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2039, Total reward=-1.1, Steps=16134, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2040, Total reward=-2.0, Steps=16148, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2041, Total reward=-0.1, Steps=16154, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2042, Total reward=-2.2, Steps=16171, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2043, Total reward=-1.1, Steps=16175, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2044, Total reward=-0.7, Steps=16187, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2045, Total reward=-1.3, Steps=16194, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2046, Total reward=-2.3, Steps=16212, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2047, Total reward=-1, Steps=16215, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2048, Total reward=0.8, Steps=16220, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2049, Total reward=-1.7, Steps=16231, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2050, Total reward=-1.1, Steps=16235, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2051, Total reward=-1, Steps=16239, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2052, Total reward=-1.5, Steps=16248, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2053, Total reward=-1.1, Steps=16252, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2054, Total reward=-1.4, Steps=16260, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2055, Total reward=-0.2, Steps=16267, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2056, Total reward=-1.2, Steps=16273, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2057, Total reward=-1.6, Steps=16283, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2058, Total reward=-1.1, Steps=16288, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2059, Total reward=-1.2, Steps=16293, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2060, Total reward=-1.7, Steps=16304, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2061, Total reward=-1.2, Steps=16310, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2062, Total reward=-1.3, Steps=16316, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2063, Total reward=-1.1, Steps=16321, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2064, Total reward=-1, Steps=16324, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2065, Total reward=-1.1, Steps=16328, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2066, Total reward=-1.1, Steps=16333, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2067, Total reward=-1.1, Steps=16349, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2068, Total reward=-3.2, Steps=16376, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2069, Total reward=-1.1, Steps=16380, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2070, Total reward=-1.1, Steps=16384, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2071, Total reward=-1.5, Steps=16393, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2072, Total reward=-0.5, Steps=16403, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2073, Total reward=-1.1, Steps=16407, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2074, Total reward=-1.2, Steps=16413, Training iteration=7\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2075, Total reward=-1.2, Steps=16419, Training iteration=7\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=8.428964065387845e-05, KL divergence=[0.], Entropy=[-0.02122672], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012462040409445763, KL divergence=[0.], Entropy=[-0.02119283], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014807076193392277, KL divergence=[0.], Entropy=[-0.02115221], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016691673547029495, KL divergence=[0.], Entropy=[-0.02118642], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016734182834625244, KL divergence=[0.], Entropy=[-0.0211658], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016716327518224716, KL divergence=[0.], Entropy=[-0.02116036], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017313579097390175, KL divergence=[0.], Entropy=[-0.02114856], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018437590450048447, KL divergence=[0.], Entropy=[-0.02116134], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017905324697494507, KL divergence=[0.], Entropy=[-0.02116234], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018173981457948685, KL divergence=[0.], Entropy=[-0.02112307], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/15_Step-16419.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/15_Step-16419.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2076, Total reward=-1, Steps=16422, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2077, Total reward=-1, Steps=16425, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2078, Total reward=-1, Steps=16428, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2079, Total reward=-1, Steps=16431, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2080, Total reward=-1, Steps=16434, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2081, Total reward=-2.0, Steps=16448, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2082, Total reward=-1, Steps=16451, Training iteration=8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2083, Total reward=-1.1, Steps=16455, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2084, Total reward=-1.3, Steps=16461, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2085, Total reward=-1.1, Steps=16465, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2086, Total reward=-1, Steps=16468, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2087, Total reward=-0.3, Steps=16476, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2088, Total reward=-1, Steps=16479, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2089, Total reward=-2.5, Steps=16499, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2090, Total reward=-1.2, Steps=16504, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2091, Total reward=-1, Steps=16508, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2092, Total reward=-0.5, Steps=16518, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2093, Total reward=-1, Steps=16521, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2094, Total reward=-1.2, Steps=16526, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2095, Total reward=-1.2, Steps=16543, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2096, Total reward=-0.5, Steps=16553, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2097, Total reward=-1.8, Steps=16565, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2098, Total reward=-1, Steps=16568, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2099, Total reward=-0.7, Steps=16580, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2100, Total reward=-0.9, Steps=16594, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2101, Total reward=-1.3, Steps=16600, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2102, Total reward=-1.1, Steps=16604, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2103, Total reward=-1.1, Steps=16608, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2104, Total reward=-2.0, Steps=16623, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2105, Total reward=-1, Steps=16626, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2106, Total reward=-1.7, Steps=16637, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2107, Total reward=-2.3, Steps=16655, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2108, Total reward=-1.3, Steps=16661, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2109, Total reward=-1.1, Steps=16665, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2110, Total reward=-1.2, Steps=16671, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2111, Total reward=-1.3, Steps=16677, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2112, Total reward=-0.3, Steps=16685, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2113, Total reward=-1.2, Steps=16702, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2114, Total reward=-1, Steps=16705, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2115, Total reward=-1.2, Steps=16711, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2116, Total reward=-0.9, Steps=16725, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2117, Total reward=-1.6, Steps=16734, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2118, Total reward=-1, Steps=16737, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2119, Total reward=-0.7, Steps=16749, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2120, Total reward=0.9, Steps=16753, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2121, Total reward=-1.1, Steps=16758, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2122, Total reward=-0.9, Steps=16772, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2123, Total reward=-1, Steps=16775, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2124, Total reward=-1, Steps=16778, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2125, Total reward=-3.0, Steps=16803, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2126, Total reward=-1.2, Steps=16808, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2127, Total reward=-0.5, Steps=16818, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2128, Total reward=0.8, Steps=16824, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2129, Total reward=-1.1, Steps=16840, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2130, Total reward=-1, Steps=16843, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2131, Total reward=0.5, Steps=16853, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2132, Total reward=-1, Steps=16856, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2133, Total reward=-0.2, Steps=16873, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2134, Total reward=-2.7, Steps=16895, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2135, Total reward=-1, Steps=16898, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2136, Total reward=-1, Steps=16901, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2137, Total reward=-1.6, Steps=16910, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2138, Total reward=-1.3, Steps=16917, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2139, Total reward=-2.8, Steps=16940, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2140, Total reward=-1, Steps=16943, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2141, Total reward=-2.3, Steps=16961, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2142, Total reward=0.3, Steps=16973, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2143, Total reward=-2.4, Steps=16992, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2144, Total reward=-2.1, Steps=17007, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2145, Total reward=-0.3, Steps=17015, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2146, Total reward=0.6, Steps=17023, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2147, Total reward=-0.5, Steps=17033, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2148, Total reward=-1.3, Steps=17039, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2149, Total reward=-1.1, Steps=17055, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2150, Total reward=-2.2, Steps=17071, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2151, Total reward=-1.7, Steps=17082, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2152, Total reward=-1, Steps=17086, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2153, Total reward=-1, Steps=17090, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2154, Total reward=-1, Steps=17093, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2155, Total reward=-2.1, Steps=17109, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2156, Total reward=-1.1, Steps=17113, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2157, Total reward=-1.1, Steps=17118, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2158, Total reward=0.8, Steps=17124, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2159, Total reward=-1.4, Steps=17132, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2160, Total reward=-0.8, Steps=17145, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2161, Total reward=0.6, Steps=17153, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2162, Total reward=-1.1, Steps=17157, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2163, Total reward=-1, Steps=17160, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2164, Total reward=-0.1, Steps=17166, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2165, Total reward=-1.2, Steps=17172, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2166, Total reward=-1.1, Steps=17177, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2167, Total reward=-1, Steps=17180, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2168, Total reward=-1.4, Steps=17188, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2169, Total reward=-1.3, Steps=17194, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2170, Total reward=-0.6, Steps=17205, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2171, Total reward=-2.2, Steps=17222, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2172, Total reward=-1.5, Steps=17231, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2173, Total reward=-0.1, Steps=17237, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2174, Total reward=-1, Steps=17240, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2175, Total reward=-0.8, Steps=17253, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2176, Total reward=-1, Steps=17256, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2177, Total reward=-1, Steps=17259, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2178, Total reward=-1, Steps=17262, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2179, Total reward=-1, Steps=17265, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2180, Total reward=-1.1, Steps=17270, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2181, Total reward=-1.3, Steps=17277, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2182, Total reward=-1, Steps=17280, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2183, Total reward=-0.9, Steps=17294, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2184, Total reward=-0.7, Steps=17306, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2185, Total reward=-1.6, Steps=17316, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2186, Total reward=0.6, Steps=17323, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2187, Total reward=-0.2, Steps=17330, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2188, Total reward=-0.6, Steps=17341, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2189, Total reward=-0.7, Steps=17353, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2190, Total reward=-1.1, Steps=17357, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2191, Total reward=-0.4, Steps=17366, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2192, Total reward=-0.2, Steps=17373, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2193, Total reward=-1, Steps=17376, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2194, Total reward=-2.5, Steps=17396, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2195, Total reward=1, Steps=17399, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2196, Total reward=-1.7, Steps=17410, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2197, Total reward=-1.1, Steps=17415, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2198, Total reward=-1.6, Steps=17425, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2199, Total reward=-1, Steps=17429, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2200, Total reward=-1.3, Steps=17435, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2201, Total reward=-1.1, Steps=17439, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2202, Total reward=-1.2, Steps=17444, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2203, Total reward=-1.1, Steps=17448, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2204, Total reward=-1, Steps=17451, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2205, Total reward=-1, Steps=17454, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2206, Total reward=-0.4, Steps=17463, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2207, Total reward=-1.1, Steps=17467, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2208, Total reward=0.3, Steps=17479, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2209, Total reward=-1.5, Steps=17488, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2210, Total reward=-1.3, Steps=17506, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2211, Total reward=-1.8, Steps=17518, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2212, Total reward=-1.7, Steps=17529, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2213, Total reward=-0.4, Steps=17538, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2214, Total reward=-1.2, Steps=17555, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2215, Total reward=-1.9, Steps=17568, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2216, Total reward=-1, Steps=17572, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2217, Total reward=-1.0, Steps=17587, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2218, Total reward=-1.1, Steps=17591, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2219, Total reward=-0.5, Steps=17601, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2220, Total reward=-1.2, Steps=17607, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2221, Total reward=-1.1, Steps=17611, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2222, Total reward=-0.7, Steps=17623, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2223, Total reward=-1.1, Steps=17627, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2224, Total reward=-1, Steps=17631, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2225, Total reward=-1, Steps=17634, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2226, Total reward=-1, Steps=17637, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2227, Total reward=0.7, Steps=17644, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2228, Total reward=-1.1, Steps=17648, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2229, Total reward=-1.1, Steps=17653, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2230, Total reward=-0.5, Steps=17663, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2231, Total reward=-1, Steps=17666, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2232, Total reward=-2.0, Steps=17681, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2233, Total reward=-1.1, Steps=17685, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2234, Total reward=0.4, Steps=17695, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2235, Total reward=-0.8, Steps=17708, Training iteration=8\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/16_Step-17708.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/16_Step-17708.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2236, Total reward=-0.8, Steps=17721, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2237, Total reward=-1, Steps=17725, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2238, Total reward=-1, Steps=17728, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2239, Total reward=-1, Steps=17732, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2240, Total reward=-1.5, Steps=17741, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2241, Total reward=-1.2, Steps=17746, Training iteration=8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2242, Total reward=-1.5, Steps=17766, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2243, Total reward=-1, Steps=17769, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2244, Total reward=-0.8, Steps=17782, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2245, Total reward=-2.0, Steps=17797, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2246, Total reward=0.9, Steps=17802, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2247, Total reward=-1.1, Steps=17806, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2248, Total reward=-2.3, Steps=17824, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2249, Total reward=-1, Steps=17827, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2250, Total reward=-0.2, Steps=17834, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2251, Total reward=0.9, Steps=17839, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2252, Total reward=-2.5, Steps=17859, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2253, Total reward=-0.4, Steps=17868, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2254, Total reward=-1.6, Steps=17878, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2255, Total reward=-1.4, Steps=17886, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2256, Total reward=-2.0, Steps=17900, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2257, Total reward=-0.6, Steps=17921, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2258, Total reward=1, Steps=17925, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2259, Total reward=-1.5, Steps=17934, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2260, Total reward=-2.7, Steps=17956, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2261, Total reward=-0.5, Steps=17966, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2262, Total reward=-1.2, Steps=17971, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2263, Total reward=-1.3, Steps=17978, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-2.0, Steps=17992, Training iteration=8\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-2.0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-2.0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-2.0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-2.0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-2.0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2265, Total reward=-1.4, Steps=18007, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2266, Total reward=-1.2, Steps=18012, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2267, Total reward=-1.2, Steps=18017, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2268, Total reward=-0.9, Steps=18031, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2269, Total reward=-1.1, Steps=18035, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2270, Total reward=0.5, Steps=18045, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2271, Total reward=-0.7, Steps=18057, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2272, Total reward=-1, Steps=18060, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2273, Total reward=-1.8, Steps=18072, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2274, Total reward=-2.1, Steps=18088, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2275, Total reward=-1.2, Steps=18093, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2276, Total reward=-1.4, Steps=18101, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2277, Total reward=-1, Steps=18104, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2278, Total reward=-1.0, Steps=18119, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2279, Total reward=-1, Steps=18122, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2280, Total reward=-1, Steps=18125, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2281, Total reward=-0.3, Steps=18133, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2282, Total reward=-1, Steps=18136, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2283, Total reward=-1.1, Steps=18141, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2284, Total reward=-1.2, Steps=18146, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2285, Total reward=-0.1, Steps=18152, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2286, Total reward=-1.5, Steps=18161, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2287, Total reward=-2.1, Steps=18177, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2288, Total reward=-1, Steps=18180, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2289, Total reward=-1.1, Steps=18184, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2290, Total reward=-1, Steps=18188, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2291, Total reward=-0.1, Steps=18194, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2292, Total reward=-1.1, Steps=18198, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2293, Total reward=-2.4, Steps=18217, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2294, Total reward=-1.3, Steps=18224, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2295, Total reward=-1.4, Steps=18243, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2296, Total reward=-1.5, Steps=18251, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2297, Total reward=-1.3, Steps=18257, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2298, Total reward=-1, Steps=18260, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2299, Total reward=-1.7, Steps=18271, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2300, Total reward=-1.2, Steps=18277, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2301, Total reward=1, Steps=18281, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2302, Total reward=-1, Steps=18284, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2303, Total reward=1, Steps=18288, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2304, Total reward=-2.0, Steps=18303, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2305, Total reward=-1.1, Steps=18307, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2306, Total reward=-2.0, Steps=18321, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2307, Total reward=-1.1, Steps=18326, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2308, Total reward=-1.0, Steps=18341, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2309, Total reward=-1.1, Steps=18357, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2310, Total reward=-0.6, Steps=18368, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2311, Total reward=0.5, Steps=18377, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2312, Total reward=-0.6, Steps=18388, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2313, Total reward=-1.4, Steps=18396, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2314, Total reward=-0.5, Steps=18406, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2315, Total reward=-2.3, Steps=18424, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2316, Total reward=-0.1, Steps=18440, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2317, Total reward=-2.1, Steps=18456, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2318, Total reward=-1.2, Steps=18461, Training iteration=8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2319, Total reward=0.8, Steps=18468, Training iteration=8\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.003718781750649214, KL divergence=[0.], Entropy=[-0.02111867], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0056871031410992146, KL divergence=[0.], Entropy=[-0.02115889], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008067398332059383, KL divergence=[0.], Entropy=[-0.02108684], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01407089177519083, KL divergence=[0.], Entropy=[-0.02109203], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009431201964616776, KL divergence=[0.], Entropy=[-0.02110822], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015244852751493454, KL divergence=[0.], Entropy=[-0.02111425], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.021118810400366783, KL divergence=[0.], Entropy=[-0.02107618], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014167401939630508, KL divergence=[0.], Entropy=[-0.02108196], training epoch=7, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.013172081671655178, KL divergence=[0.], Entropy=[-0.02112224], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018213534727692604, KL divergence=[0.], Entropy=[-0.02110823], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/17_Step-18468.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/17_Step-18468.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2320, Total reward=-1.7, Steps=18479, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2321, Total reward=-0.4, Steps=18488, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2322, Total reward=-1.2, Steps=18493, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2323, Total reward=-1, Steps=18497, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2324, Total reward=-1.6, Steps=18507, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2325, Total reward=-1.1, Steps=18512, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2326, Total reward=-1.1, Steps=18516, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2327, Total reward=-1.2, Steps=18521, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2328, Total reward=-2.6, Steps=18542, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2329, Total reward=-1.1, Steps=18546, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2330, Total reward=-2.9, Steps=18570, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2331, Total reward=1, Steps=18574, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2332, Total reward=-1.2, Steps=18579, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2333, Total reward=-1.4, Steps=18586, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2334, Total reward=-2.3, Steps=18604, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2335, Total reward=-0.4, Steps=18613, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2336, Total reward=-1.5, Steps=18633, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2337, Total reward=0.9, Steps=18638, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2338, Total reward=-1.2, Steps=18655, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2339, Total reward=0, Steps=18660, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2340, Total reward=-1.1, Steps=18665, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2341, Total reward=-1, Steps=18669, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2342, Total reward=-1.6, Steps=18679, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2343, Total reward=-2.3, Steps=18697, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2344, Total reward=-1.1, Steps=18702, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2345, Total reward=-2.3, Steps=18720, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2346, Total reward=-0.4, Steps=18729, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2347, Total reward=-0.8, Steps=18742, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2348, Total reward=-1.1, Steps=18746, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2349, Total reward=-1.2, Steps=18752, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2350, Total reward=-1.1, Steps=18757, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2351, Total reward=-1.1, Steps=18761, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2352, Total reward=-1, Steps=18764, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2353, Total reward=-1.3, Steps=18770, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2354, Total reward=0.6, Steps=18777, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2355, Total reward=-1.1, Steps=18793, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2356, Total reward=-1.7, Steps=18804, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2357, Total reward=0.6, Steps=18812, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2358, Total reward=-1.2, Steps=18818, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2359, Total reward=-1.2, Steps=18823, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2360, Total reward=-1, Steps=18826, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2361, Total reward=-1, Steps=18829, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2362, Total reward=-1, Steps=18832, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2363, Total reward=-1, Steps=18836, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2364, Total reward=-1.3, Steps=18854, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2365, Total reward=-1.2, Steps=18859, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2366, Total reward=-0.1, Steps=18865, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2367, Total reward=-1.2, Steps=18882, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2368, Total reward=-1, Steps=18885, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2369, Total reward=-1.1, Steps=18889, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2370, Total reward=-1.2, Steps=18894, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2371, Total reward=-0.2, Steps=18901, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2372, Total reward=-1, Steps=18905, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2373, Total reward=-1.2, Steps=18911, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2374, Total reward=-0.6, Steps=18922, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2375, Total reward=0.9, Steps=18927, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2376, Total reward=0.8, Steps=18933, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2377, Total reward=-1.3, Steps=18940, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2378, Total reward=-1.2, Steps=18945, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2379, Total reward=-1.1, Steps=18949, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2380, Total reward=-1, Steps=18952, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2381, Total reward=-1.1, Steps=18956, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2382, Total reward=-1, Steps=18959, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2383, Total reward=-0.5, Steps=18969, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2384, Total reward=-1.4, Steps=18988, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2385, Total reward=-1.1, Steps=18992, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2386, Total reward=-1.4, Steps=19000, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2387, Total reward=-1.1, Steps=19004, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2388, Total reward=-2.0, Steps=19019, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2389, Total reward=0.4, Steps=19029, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2390, Total reward=-1.2, Steps=19035, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2391, Total reward=-1.1, Steps=19040, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2392, Total reward=-1.2, Steps=19045, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2393, Total reward=-1.2, Steps=19051, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2394, Total reward=-1.0, Steps=19066, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2395, Total reward=-1.3, Steps=19072, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2396, Total reward=-1.9, Steps=19085, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2397, Total reward=-1.1, Steps=19090, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2398, Total reward=-1, Steps=19093, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2399, Total reward=-1.3, Steps=19099, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2400, Total reward=-1, Steps=19102, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2401, Total reward=-1, Steps=19105, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2402, Total reward=-0.6, Steps=19116, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2403, Total reward=-1.3, Steps=19123, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2404, Total reward=-2.2, Steps=19140, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2405, Total reward=-1, Steps=19144, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2406, Total reward=-1.2, Steps=19150, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2407, Total reward=-0.8, Steps=19163, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2408, Total reward=-1.1, Steps=19168, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2409, Total reward=-0.9, Steps=19182, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2410, Total reward=-1.1, Steps=19187, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2411, Total reward=-1.1, Steps=19192, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2412, Total reward=-1, Steps=19195, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2413, Total reward=-0.7, Steps=19207, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2414, Total reward=-2.4, Steps=19226, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2415, Total reward=-1.1, Steps=19230, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2416, Total reward=-2.6, Steps=19251, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2417, Total reward=-2.1, Steps=19267, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2418, Total reward=-0.3, Steps=19275, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2419, Total reward=-1.2, Steps=19280, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2420, Total reward=-1.1, Steps=19296, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2421, Total reward=-1.1, Steps=19300, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2422, Total reward=-0.9, Steps=19314, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2423, Total reward=-0.3, Steps=19322, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2424, Total reward=-2.3, Steps=19340, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2425, Total reward=-1.2, Steps=19345, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2426, Total reward=-1.5, Steps=19354, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2427, Total reward=-1.4, Steps=19361, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2428, Total reward=-1.1, Steps=19365, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2429, Total reward=1, Steps=19368, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2430, Total reward=0.8, Steps=19373, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2431, Total reward=1, Steps=19377, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2432, Total reward=-1.2, Steps=19394, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2433, Total reward=-0.3, Steps=19412, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2434, Total reward=-0.1, Steps=19428, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2435, Total reward=-0.5, Steps=19438, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2436, Total reward=-1.2, Steps=19443, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2437, Total reward=-1.2, Steps=19449, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2438, Total reward=-1.2, Steps=19455, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2439, Total reward=-2.1, Steps=19471, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2440, Total reward=-2.1, Steps=19487, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2441, Total reward=-1.1, Steps=19492, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2442, Total reward=-1.1, Steps=19496, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2443, Total reward=-1, Steps=19499, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2444, Total reward=-1.3, Steps=19506, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2445, Total reward=-1.2, Steps=19512, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2446, Total reward=-1.2, Steps=19517, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2447, Total reward=-1.2, Steps=19523, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2448, Total reward=-1.1, Steps=19527, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2449, Total reward=-1, Steps=19530, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2450, Total reward=-1.5, Steps=19538, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2451, Total reward=-1.2, Steps=19544, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2452, Total reward=-1, Steps=19547, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2453, Total reward=-1.3, Steps=19553, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2454, Total reward=-1, Steps=19556, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2455, Total reward=-1.1, Steps=19560, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2456, Total reward=-2.7, Steps=19582, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2457, Total reward=-2.5, Steps=19602, Training iteration=9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2458, Total reward=-0.7, Steps=19614, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2459, Total reward=-1.1, Steps=19618, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2460, Total reward=-0.6, Steps=19629, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2461, Total reward=-1.3, Steps=19635, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2462, Total reward=-1.1, Steps=19640, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2463, Total reward=-1.2, Steps=19645, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2464, Total reward=0.3, Steps=19656, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2465, Total reward=-1, Steps=19659, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2466, Total reward=-1.2, Steps=19664, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2467, Total reward=-2.1, Steps=19680, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2468, Total reward=-0.3, Steps=19688, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2469, Total reward=0.6, Steps=19696, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2470, Total reward=-2.0, Steps=19711, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2471, Total reward=-1, Steps=19714, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2472, Total reward=-1.3, Steps=19720, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2473, Total reward=0.7, Steps=19728, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2474, Total reward=-2.5, Steps=19748, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2475, Total reward=-1, Steps=19751, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2476, Total reward=-1, Steps=19754, Training iteration=9\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/18_Step-19754.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/18_Step-19754.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2477, Total reward=-1, Steps=19757, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2478, Total reward=-1.1, Steps=19761, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2479, Total reward=-1.2, Steps=19778, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2480, Total reward=-2.3, Steps=19795, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2481, Total reward=-1.1, Steps=19800, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2482, Total reward=-1.1, Steps=19805, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2483, Total reward=-1.2, Steps=19810, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2484, Total reward=-1, Steps=19813, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2485, Total reward=-0.5, Steps=19823, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2486, Total reward=-1, Steps=19826, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2487, Total reward=-1, Steps=19829, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2488, Total reward=-0.7, Steps=19841, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2489, Total reward=-1.2, Steps=19847, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2490, Total reward=-2.2, Steps=19864, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2491, Total reward=-0.7, Steps=19886, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2492, Total reward=-2.0, Steps=19901, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2493, Total reward=-1, Steps=19904, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2494, Total reward=-1.6, Steps=19914, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2495, Total reward=-1, Steps=19917, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2496, Total reward=-0.1, Steps=19923, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2497, Total reward=-0.1, Steps=19939, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2498, Total reward=-1.1, Steps=19943, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2499, Total reward=-1.1, Steps=19948, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2500, Total reward=-1.1, Steps=19952, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2501, Total reward=-1, Steps=19955, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2502, Total reward=-0.3, Steps=19963, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2503, Total reward=-1.3, Steps=19970, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2504, Total reward=0.6, Steps=19978, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2505, Total reward=-1.3, Steps=19984, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2506, Total reward=-1, Steps=19987, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2507, Total reward=0.8, Steps=19993, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-0.1, Steps=19999, Training iteration=9\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-1, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-2.0, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-2.0, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-2.0, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-2.0, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2509, Total reward=-1.1, Steps=20004, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2510, Total reward=-1, Steps=20007, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2511, Total reward=1, Steps=20011, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2512, Total reward=-2.1, Steps=20027, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2513, Total reward=-1, Steps=20030, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2514, Total reward=-1.2, Steps=20035, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2515, Total reward=1, Steps=20039, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2516, Total reward=-0.2, Steps=20046, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2517, Total reward=-2.5, Steps=20066, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2518, Total reward=-1.1, Steps=20070, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2519, Total reward=-1.1, Steps=20074, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2520, Total reward=-0.8, Steps=20087, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2521, Total reward=-2.1, Steps=20102, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2522, Total reward=-1, Steps=20105, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2523, Total reward=-1.2, Steps=20111, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2524, Total reward=0.6, Steps=20120, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2525, Total reward=-1.1, Steps=20124, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2526, Total reward=0.9, Steps=20129, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2527, Total reward=-1.2, Steps=20135, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2528, Total reward=-2.1, Steps=20151, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2529, Total reward=-1, Steps=20154, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2530, Total reward=0.9, Steps=20158, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2531, Total reward=-1, Steps=20161, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2532, Total reward=-1, Steps=20164, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2533, Total reward=-1.3, Steps=20171, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2534, Total reward=-1, Steps=20174, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2535, Total reward=-1.3, Steps=20180, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2536, Total reward=-1.1, Steps=20184, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2537, Total reward=-1, Steps=20187, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2538, Total reward=0.7, Steps=20194, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2539, Total reward=-1.5, Steps=20202, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2540, Total reward=-1, Steps=20205, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2541, Total reward=-1.8, Steps=20217, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2542, Total reward=-1.2, Steps=20222, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2543, Total reward=-0.3, Steps=20230, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2544, Total reward=-0.3, Steps=20238, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2545, Total reward=-1, Steps=20242, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2546, Total reward=-1.2, Steps=20247, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2547, Total reward=-1.0, Steps=20262, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2548, Total reward=-1.5, Steps=20270, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2549, Total reward=-1, Steps=20273, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2550, Total reward=-1.1, Steps=20277, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2551, Total reward=-1.1, Steps=20281, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2552, Total reward=0.8, Steps=20288, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2553, Total reward=-1, Steps=20292, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2554, Total reward=-1.3, Steps=20299, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2555, Total reward=-1.2, Steps=20305, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2556, Total reward=-2.3, Steps=20323, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2557, Total reward=-2.2, Steps=20340, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2558, Total reward=-1.1, Steps=20344, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2559, Total reward=-1.5, Steps=20353, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2560, Total reward=-1.7, Steps=20375, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2561, Total reward=-1, Steps=20379, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2562, Total reward=-1, Steps=20382, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2563, Total reward=-1, Steps=20385, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2564, Total reward=-2.0, Steps=20400, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2565, Total reward=-1, Steps=20403, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2566, Total reward=-1.3, Steps=20410, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2567, Total reward=0.9, Steps=20415, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2568, Total reward=-1, Steps=20418, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2569, Total reward=-1.2, Steps=20423, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2570, Total reward=-1.3, Steps=20429, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2571, Total reward=-1.6, Steps=20439, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2572, Total reward=-1.2, Steps=20445, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2573, Total reward=-1.0, Steps=20460, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2574, Total reward=-1, Steps=20464, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2575, Total reward=-1, Steps=20467, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2576, Total reward=-1, Steps=20470, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2577, Total reward=-1.5, Steps=20479, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2578, Total reward=-0.5, Steps=20489, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2579, Total reward=-1, Steps=20493, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2580, Total reward=-2.4, Steps=20512, Training iteration=9\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2581, Total reward=0.2, Steps=20525, Training iteration=9\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.009081214666366577, KL divergence=[0.], Entropy=[-0.02114021], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.003860078053548932, KL divergence=[0.], Entropy=[-0.02113751], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.006760840769857168, KL divergence=[0.], Entropy=[-0.02113964], training epoch=2, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.008461217395961285, KL divergence=[0.], Entropy=[-0.02112949], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009390773251652718, KL divergence=[0.], Entropy=[-0.02114019], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009794431738555431, KL divergence=[0.], Entropy=[-0.02109722], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009543782100081444, KL divergence=[0.], Entropy=[-0.02112355], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009771621786057949, KL divergence=[0.], Entropy=[-0.02112409], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.010077225975692272, KL divergence=[0.], Entropy=[-0.02110557], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01098724827170372, KL divergence=[0.], Entropy=[-0.02112223], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/19_Step-20525.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/19_Step-20525.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2582, Total reward=-1, Steps=20528, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2583, Total reward=-1.0, Steps=20543, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2584, Total reward=-0.5, Steps=20553, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2585, Total reward=-1, Steps=20556, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2586, Total reward=-1.3, Steps=20562, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2587, Total reward=-1.0, Steps=20577, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2588, Total reward=-1.5, Steps=20586, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2589, Total reward=-1.1, Steps=20590, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2590, Total reward=-1.2, Steps=20596, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2591, Total reward=-1, Steps=20599, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2592, Total reward=-1.2, Steps=20616, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2593, Total reward=-1, Steps=20619, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2594, Total reward=-0.4, Steps=20628, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2595, Total reward=-1.0, Steps=20643, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2596, Total reward=-1.2, Steps=20648, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2597, Total reward=-1.2, Steps=20654, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2598, Total reward=-1, Steps=20657, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2599, Total reward=-0.7, Steps=20669, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2600, Total reward=0.8, Steps=20675, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2601, Total reward=-0.1, Steps=20681, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2602, Total reward=-0.2, Steps=20688, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2603, Total reward=-1.1, Steps=20693, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2604, Total reward=-1, Steps=20696, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2605, Total reward=-1.1, Steps=20700, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2606, Total reward=-1.1, Steps=20704, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2607, Total reward=-1, Steps=20707, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2608, Total reward=-0.6, Steps=20718, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2609, Total reward=-2.5, Steps=20738, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2610, Total reward=-1.3, Steps=20745, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2611, Total reward=0.7, Steps=20752, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2612, Total reward=-1.1, Steps=20756, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2613, Total reward=-1.3, Steps=20763, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2614, Total reward=-1.2, Steps=20768, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2615, Total reward=-1, Steps=20771, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2616, Total reward=-1.1, Steps=20776, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2617, Total reward=-1.1, Steps=20780, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2618, Total reward=0.6, Steps=20789, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2619, Total reward=-2.2, Steps=20805, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2620, Total reward=-1.1, Steps=20809, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2621, Total reward=-1, Steps=20813, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2622, Total reward=-1.3, Steps=20820, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2623, Total reward=-1.3, Steps=20827, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2624, Total reward=-0.5, Steps=20837, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2625, Total reward=-1, Steps=20840, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2626, Total reward=-1.2, Steps=20857, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2627, Total reward=-1.0, Steps=20872, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2628, Total reward=-1.2, Steps=20878, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2629, Total reward=-1, Steps=20881, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2630, Total reward=-1.1, Steps=20886, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2631, Total reward=-0.5, Steps=20896, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2632, Total reward=-1, Steps=20899, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2633, Total reward=-1.1, Steps=20903, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2634, Total reward=-1.1, Steps=20907, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2635, Total reward=-0.9, Steps=20921, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2636, Total reward=-1.2, Steps=20926, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2637, Total reward=-1.1, Steps=20930, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2638, Total reward=-1.1, Steps=20935, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2639, Total reward=-1.2, Steps=20940, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2640, Total reward=-1, Steps=20943, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2641, Total reward=-0.3, Steps=20951, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2642, Total reward=-1, Steps=20955, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2643, Total reward=-0.9, Steps=20969, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2644, Total reward=-1.2, Steps=20975, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2645, Total reward=-0.7, Steps=20987, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2646, Total reward=-1, Steps=20990, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2647, Total reward=-0.3, Steps=20998, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2648, Total reward=0.6, Steps=21007, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2649, Total reward=-1.1, Steps=21011, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2650, Total reward=-2.3, Steps=21028, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2651, Total reward=-1.2, Steps=21034, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2652, Total reward=-1.0, Steps=21049, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2653, Total reward=-1, Steps=21052, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2654, Total reward=-2.2, Steps=21069, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2655, Total reward=1, Steps=21072, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2656, Total reward=-2.1, Steps=21088, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2657, Total reward=-1.4, Steps=21096, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2658, Total reward=-1.1, Steps=21101, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2659, Total reward=-1.5, Steps=21110, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2660, Total reward=-1, Steps=21113, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2661, Total reward=-1.5, Steps=21122, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2662, Total reward=-1.1, Steps=21126, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2663, Total reward=-1.2, Steps=21132, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2664, Total reward=-1.1, Steps=21136, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2665, Total reward=-1, Steps=21140, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2666, Total reward=-0.5, Steps=21150, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2667, Total reward=-1.1, Steps=21155, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2668, Total reward=-1, Steps=21158, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2669, Total reward=-1.2, Steps=21164, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2670, Total reward=0.9, Steps=21169, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2671, Total reward=-1.2, Steps=21174, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2672, Total reward=-1.1, Steps=21178, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2673, Total reward=-1, Steps=21182, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2674, Total reward=0.9, Steps=21187, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2675, Total reward=-0.7, Steps=21199, Training iteration=10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2676, Total reward=0.9, Steps=21204, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2677, Total reward=-1, Steps=21207, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2678, Total reward=-1.1, Steps=21211, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2679, Total reward=0.9, Steps=21216, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2680, Total reward=-1.1, Steps=21220, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2681, Total reward=-1.1, Steps=21225, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2682, Total reward=-1.1, Steps=21229, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2683, Total reward=-1.3, Steps=21235, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2684, Total reward=-1.3, Steps=21253, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2685, Total reward=-2.2, Steps=21270, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2686, Total reward=-1.4, Steps=21278, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2687, Total reward=-1, Steps=21281, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2688, Total reward=-1.1, Steps=21285, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2689, Total reward=-1.2, Steps=21290, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2690, Total reward=-2.7, Steps=21312, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2691, Total reward=0.9, Steps=21318, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2692, Total reward=-1, Steps=21321, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2693, Total reward=-1.8, Steps=21332, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2694, Total reward=-1.5, Steps=21341, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2695, Total reward=-1, Steps=21344, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2696, Total reward=-1, Steps=21347, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2697, Total reward=-1.2, Steps=21352, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2698, Total reward=-1.2, Steps=21357, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2699, Total reward=-2.0, Steps=21372, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2700, Total reward=-2.1, Steps=21388, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2701, Total reward=0.2, Steps=21400, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2702, Total reward=-0.1, Steps=21406, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2703, Total reward=-1.1, Steps=21411, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2704, Total reward=-1.2, Steps=21416, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2705, Total reward=-0.6, Steps=21427, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2706, Total reward=-2.1, Steps=21443, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2707, Total reward=-2.4, Steps=21462, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2708, Total reward=-1.3, Steps=21468, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2709, Total reward=-1.1, Steps=21473, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2710, Total reward=-1.1, Steps=21477, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2711, Total reward=-1.6, Steps=21487, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2712, Total reward=-1, Steps=21491, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2713, Total reward=-0.7, Steps=21503, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2714, Total reward=-1, Steps=21506, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2715, Total reward=-1.1, Steps=21510, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2716, Total reward=-1, Steps=21513, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2717, Total reward=-1.1, Steps=21517, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2718, Total reward=-2.2, Steps=21534, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2719, Total reward=-1, Steps=21537, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2720, Total reward=-1.2, Steps=21542, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2721, Total reward=-0.6, Steps=21553, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2722, Total reward=-1, Steps=21556, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2723, Total reward=-1.5, Steps=21565, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2724, Total reward=0.7, Steps=21572, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2725, Total reward=-1, Steps=21575, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2726, Total reward=-2.5, Steps=21595, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2727, Total reward=-1, Steps=21598, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2728, Total reward=-2.0, Steps=21612, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2729, Total reward=-1.1, Steps=21616, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2730, Total reward=-1.5, Steps=21625, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2731, Total reward=-0.2, Steps=21642, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2732, Total reward=-1.2, Steps=21648, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2733, Total reward=-0.3, Steps=21656, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2734, Total reward=-1.2, Steps=21662, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2735, Total reward=-1.1, Steps=21666, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2736, Total reward=-1.1, Steps=21670, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2737, Total reward=-1.5, Steps=21679, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2738, Total reward=-1, Steps=21682, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2739, Total reward=-2.0, Steps=21697, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2740, Total reward=-1.1, Steps=21702, Training iteration=10\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/20_Step-21702.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/20_Step-21702.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2741, Total reward=-1.1, Steps=21706, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2742, Total reward=-1.4, Steps=21714, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2743, Total reward=-1.1, Steps=21719, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2744, Total reward=-1.4, Steps=21727, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2745, Total reward=0.5, Steps=21736, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2746, Total reward=-1.5, Steps=21744, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2747, Total reward=0.9, Steps=21749, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2748, Total reward=-1, Steps=21753, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2749, Total reward=-1.2, Steps=21758, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2750, Total reward=-2.0, Steps=21773, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2751, Total reward=-1.8, Steps=21784, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2752, Total reward=-2.1, Steps=21799, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2753, Total reward=-1.6, Steps=21809, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2754, Total reward=-0.6, Steps=21820, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2755, Total reward=-1, Steps=21823, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2756, Total reward=-1, Steps=21826, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2757, Total reward=-1.6, Steps=21835, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2758, Total reward=-1, Steps=21838, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2759, Total reward=-1.1, Steps=21842, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2760, Total reward=-1.8, Steps=21854, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2761, Total reward=-1.1, Steps=21858, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2762, Total reward=-1.2, Steps=21863, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2763, Total reward=-1.2, Steps=21868, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2764, Total reward=-1.3, Steps=21874, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2765, Total reward=-1.3, Steps=21880, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2766, Total reward=-1.4, Steps=21887, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2767, Total reward=-1.2, Steps=21892, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2768, Total reward=-1, Steps=21895, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2769, Total reward=-1, Steps=21898, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2770, Total reward=-0.4, Steps=21907, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2771, Total reward=-0.3, Steps=21915, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2772, Total reward=-2.5, Steps=21935, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2773, Total reward=-1.3, Steps=21942, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2774, Total reward=-2.1, Steps=21958, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2775, Total reward=-0.9, Steps=21972, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2776, Total reward=-1.1, Steps=21976, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2777, Total reward=-1, Steps=21979, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2778, Total reward=-1.2, Steps=21984, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2779, Total reward=-1.3, Steps=21990, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2780, Total reward=-0.5, Steps=22000, Training iteration=10\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2780, Total reward=-2.0, Steps=22000, Training iteration=10\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2780, Total reward=-1, Steps=22000, Training iteration=10\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2780, Total reward=-2.0, Steps=22000, Training iteration=10\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2780, Total reward=-2.0, Steps=22000, Training iteration=10\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2780, Total reward=-1, Steps=22000, Training iteration=10\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2781, Total reward=-1.1, Steps=22004, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2782, Total reward=-1.2, Steps=22009, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2783, Total reward=-1, Steps=22012, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2784, Total reward=-1.2, Steps=22017, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2785, Total reward=-0.7, Steps=22029, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2786, Total reward=-1.3, Steps=22036, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2787, Total reward=-1, Steps=22039, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2788, Total reward=-1.1, Steps=22044, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2789, Total reward=1, Steps=22048, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2790, Total reward=-2.4, Steps=22067, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2791, Total reward=-1.3, Steps=22074, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2792, Total reward=-1, Steps=22078, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2793, Total reward=0.9, Steps=22082, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2794, Total reward=-1.2, Steps=22099, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2795, Total reward=-1.1, Steps=22103, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2796, Total reward=-1, Steps=22106, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2797, Total reward=-1, Steps=22110, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2798, Total reward=-0.2, Steps=22117, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2799, Total reward=-2.5, Steps=22137, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2800, Total reward=-1.2, Steps=22142, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2801, Total reward=-1.2, Steps=22147, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2802, Total reward=-0.4, Steps=22156, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2803, Total reward=-1.7, Steps=22167, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2804, Total reward=0.8, Steps=22172, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2805, Total reward=-1.5, Steps=22192, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2806, Total reward=-1.7, Steps=22203, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2807, Total reward=-1, Steps=22206, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2808, Total reward=-0.4, Steps=22225, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2809, Total reward=-1.7, Steps=22236, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2810, Total reward=-1, Steps=22239, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2811, Total reward=-1.3, Steps=22246, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2812, Total reward=-2.0, Steps=22260, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2813, Total reward=-0.2, Steps=22267, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2814, Total reward=-1.2, Steps=22273, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2815, Total reward=-1.1, Steps=22278, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2816, Total reward=-0.4, Steps=22287, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2817, Total reward=1, Steps=22291, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2818, Total reward=-0.2, Steps=22308, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2819, Total reward=-1.1, Steps=22312, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2820, Total reward=-1, Steps=22316, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2821, Total reward=-1, Steps=22319, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2822, Total reward=-0.1, Steps=22325, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2823, Total reward=-1, Steps=22328, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2824, Total reward=-2.4, Steps=22346, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2825, Total reward=-0.5, Steps=22356, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2826, Total reward=-0.3, Steps=22364, Training iteration=10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2827, Total reward=-0.8, Steps=22377, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2828, Total reward=0.3, Steps=22389, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2829, Total reward=-1.5, Steps=22398, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2830, Total reward=0.1, Steps=22411, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2831, Total reward=-1.1, Steps=22416, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2832, Total reward=-2.4, Steps=22435, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2833, Total reward=-1.4, Steps=22442, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2834, Total reward=0.1, Steps=22455, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2835, Total reward=-0.3, Steps=22463, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2836, Total reward=-2.7, Steps=22485, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2837, Total reward=-2.4, Steps=22504, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2838, Total reward=-0.3, Steps=22512, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2839, Total reward=-2.0, Steps=22527, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2840, Total reward=-1.9, Steps=22539, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2841, Total reward=0.4, Steps=22549, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2842, Total reward=0.9, Steps=22554, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2843, Total reward=-0.2, Steps=22571, Training iteration=10\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2844, Total reward=-1, Steps=22574, Training iteration=10\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0007073840824887156, KL divergence=[0.], Entropy=[-0.02110638], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.009328764863312244, KL divergence=[0.], Entropy=[-0.02114724], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012782953679561615, KL divergence=[0.], Entropy=[-0.02112512], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014887487515807152, KL divergence=[0.], Entropy=[-0.02106267], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015901196748018265, KL divergence=[0.], Entropy=[-0.02103506], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017096716910600662, KL divergence=[0.], Entropy=[-0.02102412], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017404474318027496, KL divergence=[0.], Entropy=[-0.02101911], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017033947631716728, KL divergence=[0.], Entropy=[-0.02097383], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017347009852528572, KL divergence=[0.], Entropy=[-0.02096894], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017061544582247734, KL divergence=[0.], Entropy=[-0.02098619], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/21_Step-22574.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/21_Step-22574.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2845, Total reward=-1.4, Steps=22582, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2846, Total reward=-1.2, Steps=22588, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2847, Total reward=-1.4, Steps=22595, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2848, Total reward=0.9, Steps=22600, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2849, Total reward=-1.7, Steps=22611, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2850, Total reward=-1, Steps=22614, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2851, Total reward=0.8, Steps=22620, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2852, Total reward=-0.3, Steps=22638, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2853, Total reward=-1.1, Steps=22643, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2854, Total reward=-2.0, Steps=22658, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2855, Total reward=-2.1, Steps=22674, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2856, Total reward=-1.4, Steps=22693, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2857, Total reward=-2.0, Steps=22707, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2858, Total reward=-1.3, Steps=22714, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2859, Total reward=-1.4, Steps=22733, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2860, Total reward=-1.1, Steps=22738, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2861, Total reward=1, Steps=22742, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2862, Total reward=-1.5, Steps=22751, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2863, Total reward=-1.2, Steps=22757, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2864, Total reward=-1, Steps=22760, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2865, Total reward=-2.9, Steps=22784, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2866, Total reward=-2.3, Steps=22802, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2867, Total reward=-2.0, Steps=22817, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2868, Total reward=-1, Steps=22820, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2869, Total reward=-0.9, Steps=22834, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2870, Total reward=-1, Steps=22837, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2871, Total reward=-1.1, Steps=22841, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2872, Total reward=-1.8, Steps=22853, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2873, Total reward=-2.1, Steps=22869, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2874, Total reward=-1.5, Steps=22889, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2875, Total reward=0.2, Steps=22901, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2876, Total reward=-0.1, Steps=22907, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2877, Total reward=-1.0, Steps=22922, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2878, Total reward=-0.9, Steps=22936, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2879, Total reward=-1.5, Steps=22944, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2880, Total reward=-1.2, Steps=22949, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2881, Total reward=0.1, Steps=22962, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2882, Total reward=-1, Steps=22966, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2883, Total reward=-1, Steps=22969, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2884, Total reward=-2.5, Steps=22989, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2885, Total reward=-1.6, Steps=22999, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2886, Total reward=-1.1, Steps=23003, Training iteration=11\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2887, Total reward=-1.4, Steps=23011, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2888, Total reward=-1.1, Steps=23015, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2889, Total reward=-1.1, Steps=23019, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2890, Total reward=-1.3, Steps=23025, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2891, Total reward=-2.4, Steps=23044, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2892, Total reward=0.5, Steps=23053, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2893, Total reward=-1, Steps=23057, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2894, Total reward=0.0, Steps=23072, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2895, Total reward=0.5, Steps=23081, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2896, Total reward=-1.3, Steps=23087, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2897, Total reward=-1.4, Steps=23106, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2898, Total reward=-2.0, Steps=23121, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2899, Total reward=-1.4, Steps=23128, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2900, Total reward=-2.0, Steps=23142, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2901, Total reward=-1, Steps=23145, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2902, Total reward=-2.1, Steps=23161, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2903, Total reward=0.9, Steps=23166, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2904, Total reward=-2.0, Steps=23180, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2905, Total reward=-1.2, Steps=23185, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2906, Total reward=-1.6, Steps=23195, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2907, Total reward=0.5, Steps=23204, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2908, Total reward=-1.1, Steps=23220, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2909, Total reward=-0.3, Steps=23228, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2910, Total reward=-1.0, Steps=23243, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2911, Total reward=-2.0, Steps=23258, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2912, Total reward=-1.2, Steps=23263, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2913, Total reward=-0.9, Steps=23277, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2914, Total reward=-1.4, Steps=23284, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2915, Total reward=-1.2, Steps=23289, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2916, Total reward=-1.2, Steps=23295, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2917, Total reward=-1.2, Steps=23300, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2918, Total reward=-1.2, Steps=23305, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2919, Total reward=-2.0, Steps=23320, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2920, Total reward=-1, Steps=23323, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2921, Total reward=-1.2, Steps=23329, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2922, Total reward=0.5, Steps=23338, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2923, Total reward=-1, Steps=23342, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2924, Total reward=-0.8, Steps=23355, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2925, Total reward=-2.5, Steps=23375, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2926, Total reward=-1.1, Steps=23391, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2927, Total reward=-2.5, Steps=23411, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2928, Total reward=-1, Steps=23415, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2929, Total reward=-1, Steps=23418, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2930, Total reward=-1.4, Steps=23425, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2931, Total reward=-1.3, Steps=23431, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2932, Total reward=-2.5, Steps=23451, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2933, Total reward=-1.2, Steps=23456, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2934, Total reward=-1.5, Steps=23464, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2935, Total reward=-3.0, Steps=23489, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2936, Total reward=-1, Steps=23492, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2937, Total reward=-1.1, Steps=23497, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2938, Total reward=0.2, Steps=23510, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2939, Total reward=-1.3, Steps=23517, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2940, Total reward=-1.4, Steps=23524, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2941, Total reward=-1, Steps=23527, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2942, Total reward=-2.2, Steps=23543, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2943, Total reward=0.4, Steps=23554, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2944, Total reward=-1, Steps=23557, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2945, Total reward=-0.7, Steps=23569, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2946, Total reward=0.9, Steps=23573, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2947, Total reward=0.6, Steps=23581, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2948, Total reward=-1, Steps=23585, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2949, Total reward=-1, Steps=23588, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2950, Total reward=-1.3, Steps=23594, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2951, Total reward=-1, Steps=23598, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2952, Total reward=-1, Steps=23601, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2953, Total reward=-1, Steps=23605, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2954, Total reward=-1.2, Steps=23610, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2955, Total reward=-1.4, Steps=23618, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2956, Total reward=-1.2, Steps=23635, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2957, Total reward=-0.8, Steps=23648, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2958, Total reward=-0.5, Steps=23658, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2959, Total reward=-1.1, Steps=23662, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2960, Total reward=-1.0, Steps=23677, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2961, Total reward=-1.1, Steps=23693, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2962, Total reward=-0.7, Steps=23705, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2963, Total reward=-1, Steps=23708, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2964, Total reward=-1.3, Steps=23714, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2965, Total reward=-1.1, Steps=23718, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2966, Total reward=-2.4, Steps=23737, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2967, Total reward=-1.4, Steps=23744, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2968, Total reward=-0.5, Steps=23754, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2969, Total reward=-1.3, Steps=23760, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2970, Total reward=-1.5, Steps=23769, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2971, Total reward=-0.1, Steps=23775, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2972, Total reward=-1, Steps=23778, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2973, Total reward=0.6, Steps=23787, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2974, Total reward=-1.6, Steps=23797, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2975, Total reward=-2.1, Steps=23813, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2976, Total reward=-1.1, Steps=23817, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2977, Total reward=-1.1, Steps=23822, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2978, Total reward=0, Steps=23827, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2979, Total reward=-1.5, Steps=23835, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2980, Total reward=-1, Steps=23838, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2981, Total reward=-1.2, Steps=23843, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2982, Total reward=-1, Steps=23847, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2983, Total reward=-1, Steps=23850, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2984, Total reward=-2.2, Steps=23867, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2985, Total reward=-2.0, Steps=23880, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2986, Total reward=-2.0, Steps=23895, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2987, Total reward=0.7, Steps=23903, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2988, Total reward=-0.1, Steps=23909, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2989, Total reward=-0.2, Steps=23916, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2990, Total reward=-2.9, Steps=23940, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2991, Total reward=-1.2, Steps=23945, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2992, Total reward=-1, Steps=23948, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2993, Total reward=-1.1, Steps=23952, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2994, Total reward=-2.2, Steps=23969, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2995, Total reward=-1.1, Steps=23973, Training iteration=11\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/22_Step-23973.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/22_Step-23973.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2996, Total reward=-1.2, Steps=23978, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2997, Total reward=-0.8, Steps=23991, Training iteration=11\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2997, Total reward=-2.0, Steps=24000, Training iteration=11\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2997, Total reward=-1, Steps=24000, Training iteration=11\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2997, Total reward=-2.0, Steps=24000, Training iteration=11\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2997, Total reward=-2.0, Steps=24000, Training iteration=11\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=2997, Total reward=-2.0, Steps=24000, Training iteration=11\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2998, Total reward=-1.1, Steps=24004, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=2999, Total reward=-0.1, Steps=24010, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3000, Total reward=-1, Steps=24013, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3001, Total reward=0.0, Steps=24028, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3002, Total reward=-0.8, Steps=24041, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3003, Total reward=-1.2, Steps=24058, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3004, Total reward=-0.5, Steps=24068, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3005, Total reward=-1.2, Steps=24074, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3006, Total reward=-0.7, Steps=24086, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3007, Total reward=-0.4, Steps=24095, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3008, Total reward=-1.1, Steps=24099, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3009, Total reward=-0.3, Steps=24107, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3010, Total reward=-1.2, Steps=24112, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3011, Total reward=-2.0, Steps=24127, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3012, Total reward=-1.1, Steps=24131, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3013, Total reward=-1.5, Steps=24140, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3014, Total reward=-2.2, Steps=24157, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3015, Total reward=-1.3, Steps=24163, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3016, Total reward=-2.2, Steps=24180, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3017, Total reward=-1.3, Steps=24186, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3018, Total reward=-1.2, Steps=24191, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3019, Total reward=-1, Steps=24194, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3020, Total reward=-1.2, Steps=24199, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3021, Total reward=-1, Steps=24202, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3022, Total reward=-1.4, Steps=24210, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3023, Total reward=-1, Steps=24213, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3024, Total reward=-1.5, Steps=24222, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3025, Total reward=-1, Steps=24226, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3026, Total reward=-1.1, Steps=24231, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3027, Total reward=0.4, Steps=24241, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3028, Total reward=-2.2, Steps=24258, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3029, Total reward=0.6, Steps=24266, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3030, Total reward=-1.1, Steps=24270, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3031, Total reward=-1.0, Steps=24285, Training iteration=11\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3032, Total reward=-0.3, Steps=24293, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3033, Total reward=-1.1, Steps=24297, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3034, Total reward=-2.0, Steps=24312, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3035, Total reward=-1, Steps=24315, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3036, Total reward=0.6, Steps=24323, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3037, Total reward=-1.1, Steps=24327, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3038, Total reward=-1.0, Steps=24342, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3039, Total reward=-2.2, Steps=24358, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3040, Total reward=-1.3, Steps=24364, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3041, Total reward=-1.1, Steps=24368, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3042, Total reward=-1.2, Steps=24374, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3043, Total reward=-1.2, Steps=24380, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3044, Total reward=-1.1, Steps=24384, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3045, Total reward=-1, Steps=24387, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3046, Total reward=-2.5, Steps=24407, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3047, Total reward=-1.7, Steps=24418, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3048, Total reward=-1, Steps=24421, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3049, Total reward=-1.3, Steps=24428, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3050, Total reward=-1, Steps=24431, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3051, Total reward=-1, Steps=24435, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3052, Total reward=-1, Steps=24438, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3053, Total reward=-1, Steps=24441, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3054, Total reward=-1.6, Steps=24451, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3055, Total reward=-1.7, Steps=24473, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3056, Total reward=-0.5, Steps=24483, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3057, Total reward=0.9, Steps=24488, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3058, Total reward=-1, Steps=24491, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3059, Total reward=-0.1, Steps=24497, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3060, Total reward=-1, Steps=24500, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3061, Total reward=-2.3, Steps=24518, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3062, Total reward=0.8, Steps=24525, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3063, Total reward=-2.5, Steps=24545, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3064, Total reward=-2.4, Steps=24563, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3065, Total reward=-0.7, Steps=24575, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3066, Total reward=-1.1, Steps=24580, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3067, Total reward=-1.1, Steps=24596, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3068, Total reward=-1.5, Steps=24605, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3069, Total reward=-1.5, Steps=24613, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3070, Total reward=-1, Steps=24617, Training iteration=11\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3071, Total reward=-1.1, Steps=24633, Training iteration=11\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0005620410665869713, KL divergence=[0.], Entropy=[-0.02096652], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008137394674122334, KL divergence=[0.], Entropy=[-0.0209586], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011063477024435997, KL divergence=[0.], Entropy=[-0.02095787], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014230075292289257, KL divergence=[0.], Entropy=[-0.02093408], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014375200495123863, KL divergence=[0.], Entropy=[-0.02095405], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015207278542220592, KL divergence=[0.], Entropy=[-0.0209006], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014625164680182934, KL divergence=[0.], Entropy=[-0.02088882], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015825407579541206, KL divergence=[0.], Entropy=[-0.02085392], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015716221183538437, KL divergence=[0.], Entropy=[-0.02082419], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015374355018138885, KL divergence=[0.], Entropy=[-0.02084252], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/23_Step-24633.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/23_Step-24633.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3072, Total reward=-1.1, Steps=24637, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3073, Total reward=-2.4, Steps=24656, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3074, Total reward=-2.3, Steps=24674, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3075, Total reward=-1.1, Steps=24678, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3076, Total reward=-1.1, Steps=24682, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3077, Total reward=-1.1, Steps=24686, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3078, Total reward=-1.1, Steps=24690, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3079, Total reward=-2.0, Steps=24704, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3080, Total reward=0.8, Steps=24710, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3081, Total reward=-0.1, Steps=24716, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3082, Total reward=-0.6, Steps=24727, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3083, Total reward=-1.3, Steps=24733, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3084, Total reward=-1.1, Steps=24737, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3085, Total reward=-0.9, Steps=24751, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3086, Total reward=-1, Steps=24754, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3087, Total reward=-0.8, Steps=24767, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3088, Total reward=-0.1, Steps=24773, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3089, Total reward=-1.2, Steps=24778, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3090, Total reward=-1.2, Steps=24784, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3091, Total reward=-1.6, Steps=24793, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3092, Total reward=-2.5, Steps=24813, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3093, Total reward=-1, Steps=24816, Training iteration=12\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3094, Total reward=-1.3, Steps=24823, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3095, Total reward=-2.5, Steps=24843, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3096, Total reward=-1.1, Steps=24847, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3097, Total reward=-1.4, Steps=24854, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3098, Total reward=-2.9, Steps=24878, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3099, Total reward=-0.8, Steps=24891, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3100, Total reward=-0.3, Steps=24899, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3101, Total reward=-1.1, Steps=24904, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3102, Total reward=-2.0, Steps=24918, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3103, Total reward=-0.2, Steps=24925, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3104, Total reward=-1.2, Steps=24931, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3105, Total reward=-1, Steps=24934, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3106, Total reward=-1.3, Steps=24941, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3107, Total reward=-1, Steps=24944, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3108, Total reward=-0.3, Steps=24952, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3109, Total reward=-1.3, Steps=24959, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3110, Total reward=0.6, Steps=24967, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3111, Total reward=-0.4, Steps=24976, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3112, Total reward=-2.1, Steps=24992, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3113, Total reward=-1.1, Steps=24996, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3114, Total reward=-1.2, Steps=25001, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3115, Total reward=-1.3, Steps=25007, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3116, Total reward=-0.7, Steps=25019, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3117, Total reward=0.1, Steps=25032, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3118, Total reward=-1, Steps=25035, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3119, Total reward=-0.6, Steps=25046, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3120, Total reward=-1.7, Steps=25056, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3121, Total reward=-1.2, Steps=25061, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3122, Total reward=-0.4, Steps=25070, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3123, Total reward=-2.4, Steps=25088, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3124, Total reward=-1.1, Steps=25092, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3125, Total reward=-1.1, Steps=25096, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3126, Total reward=-1.2, Steps=25101, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3127, Total reward=-1, Steps=25105, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3128, Total reward=-1, Steps=25108, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3129, Total reward=-0.3, Steps=25116, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3130, Total reward=-0.4, Steps=25125, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3131, Total reward=-1.1, Steps=25129, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3132, Total reward=0.9, Steps=25134, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3133, Total reward=-1.3, Steps=25141, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3134, Total reward=-0.9, Steps=25155, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3135, Total reward=-1.3, Steps=25161, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3136, Total reward=-2.2, Steps=25178, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3137, Total reward=-0.5, Steps=25188, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3138, Total reward=-2.0, Steps=25202, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3139, Total reward=-1.0, Steps=25217, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3140, Total reward=0.7, Steps=25225, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3141, Total reward=1, Steps=25228, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3142, Total reward=-1, Steps=25232, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3143, Total reward=-1.3, Steps=25239, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3144, Total reward=-1.1, Steps=25243, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3145, Total reward=-1.3, Steps=25250, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3146, Total reward=-1, Steps=25253, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3147, Total reward=-1.3, Steps=25259, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3148, Total reward=-2.1, Steps=25275, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3149, Total reward=-1.2, Steps=25280, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3150, Total reward=-1.2, Steps=25297, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3151, Total reward=-2.0, Steps=25312, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3152, Total reward=-1.2, Steps=25317, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3153, Total reward=-1, Steps=25321, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3154, Total reward=-1.1, Steps=25326, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3155, Total reward=-2.0, Steps=25341, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3156, Total reward=-1.2, Steps=25346, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3157, Total reward=-2.1, Steps=25362, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3158, Total reward=-1.8, Steps=25374, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3159, Total reward=-1, Steps=25377, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3160, Total reward=-1.7, Steps=25388, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3161, Total reward=-2.2, Steps=25405, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3162, Total reward=-2.1, Steps=25421, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3163, Total reward=-2.0, Steps=25436, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3164, Total reward=-2.0, Steps=25450, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3165, Total reward=0.9, Steps=25455, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3166, Total reward=-1, Steps=25458, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3167, Total reward=-1.2, Steps=25464, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3168, Total reward=-0.6, Steps=25475, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3169, Total reward=-0.8, Steps=25488, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3170, Total reward=-1.6, Steps=25498, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3171, Total reward=-0.4, Steps=25507, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3172, Total reward=-1.1, Steps=25511, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3173, Total reward=-1.2, Steps=25517, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3174, Total reward=-0.5, Steps=25527, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3175, Total reward=-1, Steps=25530, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3176, Total reward=0.8, Steps=25536, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3177, Total reward=-1, Steps=25540, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3178, Total reward=0.7, Steps=25546, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3179, Total reward=-1, Steps=25550, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3180, Total reward=-1.2, Steps=25555, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3181, Total reward=-2.1, Steps=25571, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3182, Total reward=-1.1, Steps=25575, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3183, Total reward=0.9, Steps=25580, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3184, Total reward=-2.8, Steps=25603, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3185, Total reward=-1.5, Steps=25612, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3186, Total reward=-2.0, Steps=25626, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3187, Total reward=-1, Steps=25629, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3188, Total reward=-0.7, Steps=25641, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3189, Total reward=-2.7, Steps=25663, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3190, Total reward=-1.2, Steps=25668, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3191, Total reward=-2.2, Steps=25685, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3192, Total reward=0.8, Steps=25691, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3193, Total reward=-1, Steps=25694, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3194, Total reward=-1, Steps=25697, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3195, Total reward=-1.1, Steps=25713, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3196, Total reward=-1, Steps=25716, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3197, Total reward=-1.8, Steps=25728, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3198, Total reward=-1, Steps=25731, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3199, Total reward=-0.4, Steps=25740, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3200, Total reward=-1.1, Steps=25744, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3201, Total reward=-1.1, Steps=25749, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3202, Total reward=-1, Steps=25752, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3203, Total reward=-2.5, Steps=25772, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3204, Total reward=-2.2, Steps=25799, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3205, Total reward=-1.1, Steps=25803, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3206, Total reward=-1.8, Steps=25815, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3207, Total reward=1, Steps=25818, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3208, Total reward=-1.3, Steps=25824, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3209, Total reward=0.9, Steps=25829, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3210, Total reward=-1.1, Steps=25834, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3211, Total reward=-2.7, Steps=25856, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3212, Total reward=-1, Steps=25859, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3213, Total reward=-0.2, Steps=25866, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3214, Total reward=-2.6, Steps=25887, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3215, Total reward=-2.2, Steps=25904, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3216, Total reward=-0.7, Steps=25916, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3217, Total reward=-1, Steps=25919, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3218, Total reward=-2.6, Steps=25940, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3219, Total reward=-1, Steps=25944, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3220, Total reward=-1, Steps=25947, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3221, Total reward=-1.5, Steps=25956, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3222, Total reward=-1, Steps=25959, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3223, Total reward=-1, Steps=25962, Training iteration=12\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/24_Step-25962.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/24_Step-25962.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3224, Total reward=1, Steps=25966, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3225, Total reward=-1.2, Steps=25971, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3226, Total reward=-1.2, Steps=25976, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3227, Total reward=-1.6, Steps=25997, Training iteration=12\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3227, Total reward=1, Steps=26000, Training iteration=12\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3227, Total reward=-2.0, Steps=26000, Training iteration=12\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3227, Total reward=-2.0, Steps=26000, Training iteration=12\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3227, Total reward=1, Steps=26000, Training iteration=12\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3227, Total reward=-2.0, Steps=26000, Training iteration=12\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -0.8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3228, Total reward=-1.2, Steps=26005, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3229, Total reward=-1.3, Steps=26012, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3230, Total reward=-1.1, Steps=26016, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3231, Total reward=-1.0, Steps=26031, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3232, Total reward=-1.4, Steps=26039, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3233, Total reward=-1.2, Steps=26045, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3234, Total reward=-1.1, Steps=26049, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3235, Total reward=-2.0, Steps=26063, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3236, Total reward=-1.1, Steps=26067, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3237, Total reward=-1.1, Steps=26071, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3238, Total reward=-1.6, Steps=26081, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3239, Total reward=-1.2, Steps=26086, Training iteration=12\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3240, Total reward=-1.1, Steps=26090, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3241, Total reward=-1, Steps=26093, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3242, Total reward=-1.5, Steps=26101, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3243, Total reward=-1.1, Steps=26105, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3244, Total reward=-1.0, Steps=26120, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3245, Total reward=-1.1, Steps=26124, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3246, Total reward=-1, Steps=26127, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3247, Total reward=-1.9, Steps=26140, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3248, Total reward=-2.5, Steps=26160, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3249, Total reward=-1.4, Steps=26167, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3250, Total reward=-1.1, Steps=26172, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3251, Total reward=-3.0, Steps=26197, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3252, Total reward=-1.1, Steps=26202, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3253, Total reward=-1, Steps=26206, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3254, Total reward=-1, Steps=26209, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3255, Total reward=-1, Steps=26212, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3256, Total reward=0.1, Steps=26226, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3257, Total reward=-2.6, Steps=26247, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3258, Total reward=-0.3, Steps=26255, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3259, Total reward=-1.3, Steps=26262, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3260, Total reward=-0.7, Steps=26274, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3261, Total reward=-1.1, Steps=26278, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3262, Total reward=0.3, Steps=26290, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3263, Total reward=-1, Steps=26293, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3264, Total reward=-0.9, Steps=26307, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3265, Total reward=0.9, Steps=26312, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3266, Total reward=-2.5, Steps=26332, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3267, Total reward=-1.3, Steps=26338, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3268, Total reward=-1.1, Steps=26342, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3269, Total reward=-1.3, Steps=26348, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3270, Total reward=-1.3, Steps=26366, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3271, Total reward=-2.1, Steps=26381, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3272, Total reward=-2.1, Steps=26397, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3273, Total reward=-1.4, Steps=26405, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3274, Total reward=-2.2, Steps=26422, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3275, Total reward=-0.7, Steps=26434, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3276, Total reward=0.4, Steps=26445, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3277, Total reward=-1.1, Steps=26449, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3278, Total reward=-2.2, Steps=26466, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3279, Total reward=-1.2, Steps=26471, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3280, Total reward=-1.1, Steps=26475, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3281, Total reward=-1.6, Steps=26485, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3282, Total reward=1, Steps=26489, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3283, Total reward=-1, Steps=26492, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3284, Total reward=-1.8, Steps=26504, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3285, Total reward=0.3, Steps=26516, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3286, Total reward=-1, Steps=26519, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3287, Total reward=1, Steps=26523, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3288, Total reward=-1.1, Steps=26527, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3289, Total reward=-2.6, Steps=26548, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3290, Total reward=-1.1, Steps=26552, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3291, Total reward=-2.4, Steps=26571, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3292, Total reward=-2.7, Steps=26593, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3293, Total reward=0.8, Steps=26599, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3294, Total reward=-1, Steps=26602, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3295, Total reward=-1.2, Steps=26607, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3296, Total reward=-1.1, Steps=26611, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3297, Total reward=-1, Steps=26614, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3298, Total reward=-1, Steps=26617, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3299, Total reward=-1.2, Steps=26623, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3300, Total reward=-1.2, Steps=26628, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3301, Total reward=-1, Steps=26631, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3302, Total reward=0.9, Steps=26636, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3303, Total reward=-1.3, Steps=26642, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3304, Total reward=-1, Steps=26645, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3305, Total reward=-1.4, Steps=26653, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3306, Total reward=-0.4, Steps=26662, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3307, Total reward=-0.5, Steps=26672, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3308, Total reward=-1.4, Steps=26680, Training iteration=12\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3309, Total reward=-1.2, Steps=26685, Training iteration=12\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.001607583835721016, KL divergence=[0.], Entropy=[-0.02075207], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013761866837739944, KL divergence=[0.], Entropy=[-0.02078112], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015538625419139862, KL divergence=[0.], Entropy=[-0.0207043], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01813487522304058, KL divergence=[0.], Entropy=[-0.020694], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01863344945013523, KL divergence=[0.], Entropy=[-0.02067463], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0186835415661335, KL divergence=[0.], Entropy=[-0.02065061], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019219420850276947, KL divergence=[0.], Entropy=[-0.02061775], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01823102869093418, KL divergence=[0.], Entropy=[-0.02058594], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019507665187120438, KL divergence=[0.], Entropy=[-0.02057587], training epoch=8, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.017740141600370407, KL divergence=[0.], Entropy=[-0.02055498], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/25_Step-26685.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/25_Step-26685.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3310, Total reward=-1.1, Steps=26689, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3311, Total reward=-1.1, Steps=26694, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3312, Total reward=-1.4, Steps=26702, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3313, Total reward=-1, Steps=26706, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3314, Total reward=-2.8, Steps=26729, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3315, Total reward=-1.1, Steps=26733, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3316, Total reward=-0.7, Steps=26745, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3317, Total reward=-1.2, Steps=26750, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3318, Total reward=-0.5, Steps=26760, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3319, Total reward=1, Steps=26764, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3320, Total reward=0.8, Steps=26769, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3321, Total reward=0.6, Steps=26778, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3322, Total reward=-1.1, Steps=26783, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3323, Total reward=-2.3, Steps=26801, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3324, Total reward=-1, Steps=26804, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3325, Total reward=-1.3, Steps=26810, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3326, Total reward=-0.3, Steps=26818, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3327, Total reward=-1, Steps=26822, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3328, Total reward=-1.3, Steps=26829, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3329, Total reward=-1.1, Steps=26834, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3330, Total reward=-1.5, Steps=26843, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3331, Total reward=0.5, Steps=26853, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3332, Total reward=-1.1, Steps=26857, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3333, Total reward=-2.1, Steps=26872, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3334, Total reward=-1.1, Steps=26877, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3335, Total reward=-1.2, Steps=26883, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3336, Total reward=-1, Steps=26886, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3337, Total reward=-2.8, Steps=26909, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3338, Total reward=-1.2, Steps=26915, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3339, Total reward=-1.3, Steps=26921, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3340, Total reward=-1.4, Steps=26928, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3341, Total reward=-1, Steps=26932, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3342, Total reward=-0.7, Steps=26944, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3343, Total reward=-2.0, Steps=26959, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3344, Total reward=-0.1, Steps=26965, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3345, Total reward=-1.1, Steps=26970, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3346, Total reward=0.2, Steps=26983, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3347, Total reward=-1.1, Steps=26999, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3348, Total reward=-1.1, Steps=27003, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3349, Total reward=-1.1, Steps=27007, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3350, Total reward=-2.5, Steps=27027, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3351, Total reward=-1.2, Steps=27032, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3352, Total reward=-2.4, Steps=27051, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3353, Total reward=-1.6, Steps=27061, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3354, Total reward=-0.7, Steps=27073, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3355, Total reward=-1, Steps=27076, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3356, Total reward=-1.1, Steps=27080, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3357, Total reward=-0.6, Steps=27091, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3358, Total reward=-1, Steps=27094, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3359, Total reward=-2.5, Steps=27114, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3360, Total reward=-1.1, Steps=27118, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3361, Total reward=-2.6, Steps=27139, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3362, Total reward=-1, Steps=27143, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3363, Total reward=0.6, Steps=27151, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3364, Total reward=-0.6, Steps=27162, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3365, Total reward=0.9, Steps=27166, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3366, Total reward=-1, Steps=27169, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3367, Total reward=-2.2, Steps=27186, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3368, Total reward=-1.1, Steps=27191, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3369, Total reward=-1.2, Steps=27197, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3370, Total reward=-1.6, Steps=27207, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3371, Total reward=-1.2, Steps=27212, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3372, Total reward=-1, Steps=27215, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3373, Total reward=-1, Steps=27218, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3374, Total reward=-0.6, Steps=27229, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3375, Total reward=-0.5, Steps=27239, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3376, Total reward=-2.3, Steps=27257, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3377, Total reward=-1, Steps=27260, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3378, Total reward=-1.6, Steps=27270, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3379, Total reward=-2.0, Steps=27285, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3380, Total reward=-1, Steps=27288, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3381, Total reward=-0.8, Steps=27301, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3382, Total reward=-1, Steps=27304, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3383, Total reward=-1.3, Steps=27310, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3384, Total reward=-2.1, Steps=27326, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3385, Total reward=-1.2, Steps=27331, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3386, Total reward=-1.3, Steps=27337, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3387, Total reward=-0.7, Steps=27349, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3388, Total reward=-1, Steps=27352, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3389, Total reward=-1.3, Steps=27359, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3390, Total reward=-1.4, Steps=27367, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3391, Total reward=-1.4, Steps=27374, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3392, Total reward=-1, Steps=27377, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3393, Total reward=-2.3, Steps=27395, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3394, Total reward=0.1, Steps=27408, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3395, Total reward=0.3, Steps=27419, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3396, Total reward=-1, Steps=27422, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3397, Total reward=0.5, Steps=27431, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3398, Total reward=-1, Steps=27434, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3399, Total reward=-1, Steps=27437, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3400, Total reward=-0.3, Steps=27445, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3401, Total reward=-1.5, Steps=27465, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3402, Total reward=-1.2, Steps=27482, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3403, Total reward=-0.5, Steps=27492, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3404, Total reward=-1.1, Steps=27496, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3405, Total reward=-1, Steps=27499, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3406, Total reward=-0.5, Steps=27509, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3407, Total reward=-0.9, Steps=27523, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3408, Total reward=0.8, Steps=27529, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3409, Total reward=-2.4, Steps=27548, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3410, Total reward=-1.2, Steps=27553, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3411, Total reward=-2.0, Steps=27568, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3412, Total reward=-0.9, Steps=27582, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3413, Total reward=-1, Steps=27585, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3414, Total reward=-1.7, Steps=27596, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3415, Total reward=-1, Steps=27599, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3416, Total reward=-1.1, Steps=27615, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3417, Total reward=-1.2, Steps=27620, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3418, Total reward=-1.1, Steps=27646, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3419, Total reward=-1, Steps=27649, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3420, Total reward=-0.9, Steps=27663, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3421, Total reward=-1.2, Steps=27669, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3422, Total reward=0.6, Steps=27677, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3423, Total reward=0.8, Steps=27683, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3424, Total reward=-1.3, Steps=27689, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3425, Total reward=-0.9, Steps=27703, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3426, Total reward=-1.5, Steps=27712, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3427, Total reward=-1.1, Steps=27716, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3428, Total reward=-0.2, Steps=27723, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3429, Total reward=-2.1, Steps=27739, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3430, Total reward=-0.8, Steps=27752, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3431, Total reward=-1.2, Steps=27758, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3432, Total reward=-1, Steps=27761, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3433, Total reward=-0.4, Steps=27770, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3434, Total reward=-1, Steps=27773, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3435, Total reward=-1, Steps=27776, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3436, Total reward=-1, Steps=27779, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3437, Total reward=-1.3, Steps=27785, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3438, Total reward=-1, Steps=27788, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3439, Total reward=-1.2, Steps=27794, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3440, Total reward=-2.2, Steps=27811, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3441, Total reward=-1.1, Steps=27815, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3442, Total reward=-1.6, Steps=27824, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3443, Total reward=-2.1, Steps=27840, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3444, Total reward=-1.5, Steps=27849, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3445, Total reward=-1, Steps=27853, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3446, Total reward=-1.4, Steps=27861, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3447, Total reward=-1, Steps=27864, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3448, Total reward=-0.6, Steps=27875, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3449, Total reward=0.8, Steps=27881, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3450, Total reward=-1, Steps=27884, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3451, Total reward=0.8, Steps=27890, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3452, Total reward=-1.3, Steps=27896, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3453, Total reward=-1.2, Steps=27901, Training iteration=13\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3454, Total reward=-1, Steps=27904, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3455, Total reward=-0.3, Steps=27912, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3456, Total reward=-2.2, Steps=27929, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3457, Total reward=-1, Steps=27933, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3458, Total reward=-2.0, Steps=27947, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3459, Total reward=-1.4, Steps=27955, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3460, Total reward=-1.1, Steps=27959, Training iteration=13\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/26_Step-27959.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/26_Step-27959.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3461, Total reward=-1.0, Steps=27974, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3462, Total reward=-1.2, Steps=27979, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3463, Total reward=-1.3, Steps=27985, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3464, Total reward=-1.2, Steps=27991, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3465, Total reward=1, Steps=27995, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3466, Total reward=-1.1, Steps=27999, Training iteration=13\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3466, Total reward=-2.0, Steps=28000, Training iteration=13\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3466, Total reward=-2.0, Steps=28000, Training iteration=13\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3466, Total reward=-2.0, Steps=28000, Training iteration=13\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3466, Total reward=-2.0, Steps=28000, Training iteration=13\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3466, Total reward=-2.0, Steps=28000, Training iteration=13\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3467, Total reward=-1.4, Steps=28007, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3468, Total reward=-1.2, Steps=28012, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3469, Total reward=-1, Steps=28015, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3470, Total reward=-2.1, Steps=28031, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3471, Total reward=-1.1, Steps=28035, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3472, Total reward=-1, Steps=28038, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3473, Total reward=-1.4, Steps=28046, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3474, Total reward=-0.1, Steps=28052, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3475, Total reward=-2.0, Steps=28067, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3476, Total reward=-1.3, Steps=28073, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3477, Total reward=-2.1, Steps=28089, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3478, Total reward=-2.1, Steps=28105, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3479, Total reward=0.5, Steps=28114, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3480, Total reward=-1.3, Steps=28132, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3481, Total reward=-1.4, Steps=28139, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3482, Total reward=-1.1, Steps=28144, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3483, Total reward=-1, Steps=28147, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3484, Total reward=-1.4, Steps=28154, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3485, Total reward=-1, Steps=28157, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3486, Total reward=-1.1, Steps=28162, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3487, Total reward=-1.5, Steps=28170, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3488, Total reward=-2.1, Steps=28186, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3489, Total reward=-1, Steps=28189, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3490, Total reward=-1, Steps=28192, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3491, Total reward=-0.6, Steps=28203, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3492, Total reward=-1, Steps=28206, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3493, Total reward=-0.9, Steps=28220, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3494, Total reward=-2.3, Steps=28238, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3495, Total reward=-0.3, Steps=28255, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3496, Total reward=-1, Steps=28258, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3497, Total reward=-1.4, Steps=28266, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3498, Total reward=-1.2, Steps=28271, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3499, Total reward=-1.3, Steps=28277, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3500, Total reward=-0.5, Steps=28287, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3501, Total reward=-1.4, Steps=28295, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3502, Total reward=-1, Steps=28299, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3503, Total reward=1, Steps=28303, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3504, Total reward=-1, Steps=28307, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3505, Total reward=-1.7, Steps=28318, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3506, Total reward=-1, Steps=28321, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3507, Total reward=-1.1, Steps=28325, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3508, Total reward=-1, Steps=28328, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3509, Total reward=-2.3, Steps=28346, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3510, Total reward=0.9, Steps=28351, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3511, Total reward=0.1, Steps=28365, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3512, Total reward=-2.6, Steps=28386, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3513, Total reward=-1, Steps=28389, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3514, Total reward=0.9, Steps=28394, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3515, Total reward=0.5, Steps=28403, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3516, Total reward=-0.5, Steps=28413, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3517, Total reward=-1.1, Steps=28417, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3518, Total reward=0.8, Steps=28423, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3519, Total reward=-1.6, Steps=28433, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3520, Total reward=-2.0, Steps=28447, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3521, Total reward=-1.2, Steps=28453, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3522, Total reward=-1.3, Steps=28459, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3523, Total reward=-2.4, Steps=28477, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3524, Total reward=-1.3, Steps=28483, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3525, Total reward=0.8, Steps=28489, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3526, Total reward=-1.1, Steps=28494, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3527, Total reward=-1.0, Steps=28509, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3528, Total reward=-1.3, Steps=28516, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3529, Total reward=-1.4, Steps=28535, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3530, Total reward=-1.2, Steps=28540, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3531, Total reward=-1.1, Steps=28545, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3532, Total reward=-1, Steps=28548, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3533, Total reward=-0.8, Steps=28561, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3534, Total reward=-1.1, Steps=28565, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3535, Total reward=-1, Steps=28568, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3536, Total reward=-1.2, Steps=28574, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3537, Total reward=0.8, Steps=28581, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3538, Total reward=-1.0, Steps=28596, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3539, Total reward=-1, Steps=28599, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3540, Total reward=-1.2, Steps=28604, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3541, Total reward=-2.1, Steps=28620, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3542, Total reward=-1, Steps=28623, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3543, Total reward=-0.3, Steps=28631, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3544, Total reward=-1.3, Steps=28637, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3545, Total reward=-0.8, Steps=28650, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3546, Total reward=-1.1, Steps=28655, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3547, Total reward=-1, Steps=28659, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3548, Total reward=-0.5, Steps=28669, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3549, Total reward=-1, Steps=28672, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3550, Total reward=-1, Steps=28675, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3551, Total reward=-0.3, Steps=28693, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3552, Total reward=-1.1, Steps=28697, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3553, Total reward=-1.2, Steps=28702, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3554, Total reward=1, Steps=28706, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3555, Total reward=-1, Steps=28709, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3556, Total reward=-1.4, Steps=28717, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3557, Total reward=-0.2, Steps=28724, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3558, Total reward=-1.3, Steps=28731, Training iteration=13\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3559, Total reward=-1.9, Steps=28744, Training iteration=13\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0034518924076110125, KL divergence=[0.], Entropy=[-0.02061506], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013039701618254185, KL divergence=[0.], Entropy=[-0.02071681], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01590883918106556, KL divergence=[0.], Entropy=[-0.02069024], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017009135335683823, KL divergence=[0.], Entropy=[-0.02065527], training epoch=3, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.017668835818767548, KL divergence=[0.], Entropy=[-0.02066642], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01636495441198349, KL divergence=[0.], Entropy=[-0.02060301], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017108911648392677, KL divergence=[0.], Entropy=[-0.02063004], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01837288774549961, KL divergence=[0.], Entropy=[-0.02065354], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01626228541135788, KL divergence=[0.], Entropy=[-0.02060197], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01825937069952488, KL divergence=[0.], Entropy=[-0.02062425], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/27_Step-28744.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/27_Step-28744.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3560, Total reward=-1.6, Steps=28754, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3561, Total reward=-1.2, Steps=28759, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3562, Total reward=-1, Steps=28762, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3563, Total reward=-1.5, Steps=28771, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3564, Total reward=1, Steps=28775, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3565, Total reward=-1, Steps=28778, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3566, Total reward=-0.2, Steps=28785, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3567, Total reward=-1.2, Steps=28791, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3568, Total reward=-1.7, Steps=28802, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3569, Total reward=0.9, Steps=28807, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3570, Total reward=0.8, Steps=28813, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3571, Total reward=-1.1, Steps=28817, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3572, Total reward=-2.3, Steps=28835, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3573, Total reward=-1, Steps=28838, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3574, Total reward=0.2, Steps=28850, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3575, Total reward=-1, Steps=28854, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3576, Total reward=-1, Steps=28857, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3577, Total reward=-1, Steps=28860, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3578, Total reward=-1, Steps=28863, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3579, Total reward=-1.4, Steps=28870, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3580, Total reward=-0.3, Steps=28878, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3581, Total reward=-1.2, Steps=28883, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3582, Total reward=-1, Steps=28886, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3583, Total reward=-2.1, Steps=28902, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3584, Total reward=-1, Steps=28906, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3585, Total reward=-0.7, Steps=28918, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3586, Total reward=-1, Steps=28921, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3587, Total reward=-1, Steps=28925, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3588, Total reward=-2.1, Steps=28940, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3589, Total reward=-1, Steps=28943, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3590, Total reward=-1.2, Steps=28948, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3591, Total reward=-1, Steps=28951, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3592, Total reward=-1, Steps=28954, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3593, Total reward=-1.3, Steps=28960, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3594, Total reward=-2.2, Steps=28976, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3595, Total reward=-1.3, Steps=28982, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3596, Total reward=0.8, Steps=28988, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3597, Total reward=-1, Steps=28991, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3598, Total reward=-0.2, Steps=28998, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3599, Total reward=-1.8, Steps=29010, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3600, Total reward=-1.2, Steps=29015, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3601, Total reward=1, Steps=29019, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3602, Total reward=-1, Steps=29022, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3603, Total reward=0.6, Steps=29031, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3604, Total reward=-1.1, Steps=29035, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3605, Total reward=0.7, Steps=29042, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3606, Total reward=-1.6, Steps=29052, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3607, Total reward=-0.6, Steps=29063, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3608, Total reward=-0.5, Steps=29073, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3609, Total reward=-1, Steps=29076, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3610, Total reward=-1.1, Steps=29080, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3611, Total reward=-0.3, Steps=29088, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3612, Total reward=-0.7, Steps=29100, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3613, Total reward=0.9, Steps=29105, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3614, Total reward=-1.1, Steps=29109, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3615, Total reward=-0.3, Steps=29117, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3616, Total reward=-1.2, Steps=29122, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3617, Total reward=-0.6, Steps=29133, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3618, Total reward=-2.4, Steps=29152, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3619, Total reward=-2.2, Steps=29169, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3620, Total reward=-1.1, Steps=29173, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3621, Total reward=-1.4, Steps=29181, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3622, Total reward=-0.7, Steps=29193, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3623, Total reward=0.8, Steps=29199, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3624, Total reward=-2.4, Steps=29218, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3625, Total reward=-0.7, Steps=29230, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3626, Total reward=-1.2, Steps=29247, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3627, Total reward=-1.0, Steps=29262, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3628, Total reward=-1.3, Steps=29268, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3629, Total reward=-0.7, Steps=29280, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3630, Total reward=-1.4, Steps=29288, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3631, Total reward=-0.4, Steps=29297, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3632, Total reward=-1, Steps=29300, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3633, Total reward=-1.5, Steps=29309, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3634, Total reward=-2.1, Steps=29324, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3635, Total reward=-1.1, Steps=29328, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3636, Total reward=-0.5, Steps=29338, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3637, Total reward=-1.4, Steps=29345, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3638, Total reward=-1.1, Steps=29349, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3639, Total reward=-2.0, Steps=29363, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3640, Total reward=-1.4, Steps=29370, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3641, Total reward=-1.1, Steps=29374, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3642, Total reward=-1.1, Steps=29379, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3643, Total reward=-2.8, Steps=29402, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3644, Total reward=-1, Steps=29405, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3645, Total reward=-2.6, Steps=29426, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3646, Total reward=-1, Steps=29429, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3647, Total reward=-0.6, Steps=29440, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3648, Total reward=-1, Steps=29443, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3649, Total reward=-1.1, Steps=29447, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3650, Total reward=-1, Steps=29450, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3651, Total reward=0.8, Steps=29457, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3652, Total reward=-0.6, Steps=29468, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3653, Total reward=-1.5, Steps=29477, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3654, Total reward=-1.5, Steps=29497, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3655, Total reward=-1.3, Steps=29504, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3656, Total reward=-0.7, Steps=29516, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3657, Total reward=-1.2, Steps=29521, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3658, Total reward=-1.2, Steps=29538, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3659, Total reward=-1.1, Steps=29543, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3660, Total reward=-1.2, Steps=29549, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3661, Total reward=0.6, Steps=29557, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3662, Total reward=-1.1, Steps=29561, Training iteration=14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3663, Total reward=-1.3, Steps=29567, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3664, Total reward=-1.1, Steps=29571, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3665, Total reward=-1, Steps=29574, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3666, Total reward=1, Steps=29578, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3667, Total reward=-2.2, Steps=29595, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3668, Total reward=-2.3, Steps=29613, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3669, Total reward=-1.0, Steps=29628, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3670, Total reward=0.1, Steps=29641, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3671, Total reward=-2.2, Steps=29658, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3672, Total reward=-1, Steps=29662, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3673, Total reward=-1.1, Steps=29666, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3674, Total reward=-1.2, Steps=29671, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3675, Total reward=-1, Steps=29674, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3676, Total reward=-1.0, Steps=29689, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3677, Total reward=-1, Steps=29692, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3678, Total reward=-1.2, Steps=29697, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3679, Total reward=-0.4, Steps=29706, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3680, Total reward=0.9, Steps=29711, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3681, Total reward=0.3, Steps=29723, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3682, Total reward=-1.8, Steps=29735, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3683, Total reward=-1.1, Steps=29739, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3684, Total reward=-1.1, Steps=29743, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3685, Total reward=-2.2, Steps=29760, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3686, Total reward=-1.1, Steps=29764, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3687, Total reward=-0.6, Steps=29775, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3688, Total reward=-1.2, Steps=29781, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3689, Total reward=-1.1, Steps=29785, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3690, Total reward=-1, Steps=29788, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3691, Total reward=-1, Steps=29791, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3692, Total reward=-1.3, Steps=29798, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3693, Total reward=-1.5, Steps=29807, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3694, Total reward=-0.6, Steps=29818, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3695, Total reward=-1.8, Steps=29830, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3696, Total reward=-2.0, Steps=29844, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3697, Total reward=0.4, Steps=29854, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3698, Total reward=-1.5, Steps=29863, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3699, Total reward=-0.5, Steps=29873, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3700, Total reward=-2.0, Steps=29888, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3701, Total reward=-1, Steps=29891, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3702, Total reward=-1.0, Steps=29906, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3703, Total reward=0.6, Steps=29914, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3704, Total reward=-2.2, Steps=29931, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3705, Total reward=-1.2, Steps=29937, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3706, Total reward=-2.0, Steps=29951, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3707, Total reward=-1.1, Steps=29956, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3708, Total reward=-1, Steps=29959, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3709, Total reward=-1, Steps=29962, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3710, Total reward=-1.1, Steps=29966, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3711, Total reward=-1, Steps=29969, Training iteration=14\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/28_Step-29969.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/28_Step-29969.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3712, Total reward=-1, Steps=29972, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3713, Total reward=-1.2, Steps=29977, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3714, Total reward=-1.7, Steps=29999, Training iteration=14\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3714, Total reward=-2.0, Steps=30000, Training iteration=14\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3714, Total reward=-2.0, Steps=30000, Training iteration=14\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3714, Total reward=-2.0, Steps=30000, Training iteration=14\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3714, Total reward=1, Steps=30000, Training iteration=14\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3714, Total reward=-2.0, Steps=30000, Training iteration=14\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3715, Total reward=-1.2, Steps=30006, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3716, Total reward=-1.1, Steps=30010, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3717, Total reward=-1.1, Steps=30014, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3718, Total reward=-0.8, Steps=30027, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3719, Total reward=-1.3, Steps=30033, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3720, Total reward=1, Steps=30037, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3721, Total reward=1, Steps=30041, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3722, Total reward=-1.0, Steps=30056, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3723, Total reward=-1.4, Steps=30063, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3724, Total reward=-1.1, Steps=30067, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3725, Total reward=-1.1, Steps=30072, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3726, Total reward=-2.1, Steps=30088, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3727, Total reward=-1, Steps=30091, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3728, Total reward=-1.2, Steps=30096, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3729, Total reward=-0.8, Steps=30109, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3730, Total reward=-0.4, Steps=30118, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3731, Total reward=-1.1, Steps=30122, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3732, Total reward=-1.2, Steps=30127, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3733, Total reward=-1, Steps=30130, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3734, Total reward=-1.1, Steps=30134, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3735, Total reward=-0.5, Steps=30144, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3736, Total reward=-1, Steps=30147, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3737, Total reward=-1.2, Steps=30153, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3738, Total reward=-1, Steps=30156, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3739, Total reward=-1.1, Steps=30160, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3740, Total reward=-1, Steps=30163, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3741, Total reward=-1.2, Steps=30168, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3742, Total reward=0.8, Steps=30174, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3743, Total reward=0.4, Steps=30184, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3744, Total reward=-1, Steps=30187, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3745, Total reward=-0.4, Steps=30196, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3746, Total reward=0.6, Steps=30203, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3747, Total reward=-0.2, Steps=30210, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3748, Total reward=-0.4, Steps=30219, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3749, Total reward=-2.5, Steps=30239, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3750, Total reward=-1, Steps=30242, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3751, Total reward=-1.1, Steps=30247, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3752, Total reward=-1.3, Steps=30254, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3753, Total reward=-2.2, Steps=30271, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3754, Total reward=-1, Steps=30274, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3755, Total reward=-1, Steps=30277, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3756, Total reward=-0.4, Steps=30286, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3757, Total reward=-1.3, Steps=30292, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3758, Total reward=-2.7, Steps=30314, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3759, Total reward=-2.4, Steps=30333, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3760, Total reward=-1, Steps=30336, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3761, Total reward=0.6, Steps=30344, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3762, Total reward=-1.3, Steps=30350, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3763, Total reward=-2.4, Steps=30369, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3764, Total reward=0.5, Steps=30378, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3765, Total reward=-1.2, Steps=30383, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3766, Total reward=-1.1, Steps=30388, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3767, Total reward=-1.1, Steps=30392, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3768, Total reward=-1.1, Steps=30396, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3769, Total reward=-0.3, Steps=30404, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3770, Total reward=-1.1, Steps=30409, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3771, Total reward=-1.2, Steps=30414, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3772, Total reward=-1, Steps=30418, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3773, Total reward=-1.1, Steps=30422, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3774, Total reward=-1.2, Steps=30427, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3775, Total reward=1, Steps=30431, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3776, Total reward=-1, Steps=30434, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3777, Total reward=-2.2, Steps=30451, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3778, Total reward=-1.1, Steps=30456, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3779, Total reward=-0.3, Steps=30464, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3780, Total reward=-1.3, Steps=30471, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3781, Total reward=-2.4, Steps=30490, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3782, Total reward=-1.3, Steps=30508, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3783, Total reward=-1.3, Steps=30515, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3784, Total reward=0.9, Steps=30520, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3785, Total reward=-1.1, Steps=30524, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3786, Total reward=-1.2, Steps=30530, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3787, Total reward=-2.2, Steps=30547, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3788, Total reward=-2.4, Steps=30566, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3789, Total reward=0.1, Steps=30580, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3790, Total reward=-0.1, Steps=30586, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3791, Total reward=-0.4, Steps=30595, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3792, Total reward=-1.1, Steps=30599, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3793, Total reward=0.5, Steps=30608, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3794, Total reward=1, Steps=30612, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3795, Total reward=-0.3, Steps=30620, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3796, Total reward=-0.8, Steps=30633, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3797, Total reward=-2.2, Steps=30650, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3798, Total reward=-1, Steps=30653, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3799, Total reward=-1.3, Steps=30660, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3800, Total reward=-1, Steps=30663, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3801, Total reward=-0.6, Steps=30674, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3802, Total reward=0.8, Steps=30680, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3803, Total reward=0.9, Steps=30685, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3804, Total reward=0.9, Steps=30690, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3805, Total reward=0.7, Steps=30696, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3806, Total reward=-1.2, Steps=30701, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3807, Total reward=-0.8, Steps=30714, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3808, Total reward=-1.0, Steps=30729, Training iteration=14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3809, Total reward=-1.1, Steps=30733, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3810, Total reward=-1, Steps=30736, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3811, Total reward=-1.3, Steps=30743, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3812, Total reward=-1.2, Steps=30748, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3813, Total reward=-2.2, Steps=30764, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3814, Total reward=0.4, Steps=30775, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3815, Total reward=-1, Steps=30778, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3816, Total reward=-1.3, Steps=30785, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3817, Total reward=-1, Steps=30788, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3818, Total reward=-1, Steps=30791, Training iteration=14\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3819, Total reward=-0.4, Steps=30800, Training iteration=14\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0023537292145192623, KL divergence=[0.], Entropy=[-0.02059299], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.00766226788982749, KL divergence=[0.], Entropy=[-0.02047198], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01040820125490427, KL divergence=[0.], Entropy=[-0.02041346], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012666494585573673, KL divergence=[0.], Entropy=[-0.02038054], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012587069533765316, KL divergence=[0.], Entropy=[-0.02037365], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014433901757001877, KL divergence=[0.], Entropy=[-0.02037093], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014240377582609653, KL divergence=[0.], Entropy=[-0.02034112], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014464244246482849, KL divergence=[0.], Entropy=[-0.02037393], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01427001878619194, KL divergence=[0.], Entropy=[-0.02035481], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014053380116820335, KL divergence=[0.], Entropy=[-0.02031736], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/29_Step-30800.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/29_Step-30800.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3820, Total reward=0.8, Steps=30806, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3821, Total reward=-1.2, Steps=30811, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3822, Total reward=-1.0, Steps=30826, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3823, Total reward=-1.3, Steps=30832, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3824, Total reward=-1.2, Steps=30838, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3825, Total reward=-0.2, Steps=30845, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3826, Total reward=-1.2, Steps=30850, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3827, Total reward=-1.6, Steps=30860, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3828, Total reward=-1.1, Steps=30876, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3829, Total reward=-0.9, Steps=30890, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3830, Total reward=-1.1, Steps=30894, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3831, Total reward=-0.2, Steps=30901, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3832, Total reward=-1.7, Steps=30912, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3833, Total reward=-1.4, Steps=30919, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3834, Total reward=-1, Steps=30922, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3835, Total reward=-1.1, Steps=30926, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3836, Total reward=-1.2, Steps=30932, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3837, Total reward=0.0, Steps=30946, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3838, Total reward=-1.2, Steps=30951, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3839, Total reward=-1.3, Steps=30957, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3840, Total reward=-1.3, Steps=30964, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3841, Total reward=-0.3, Steps=30972, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3842, Total reward=-1.3, Steps=30979, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3843, Total reward=-1.4, Steps=30987, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3844, Total reward=-2.1, Steps=31002, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3845, Total reward=-2.1, Steps=31018, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3846, Total reward=-0.2, Steps=31025, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3847, Total reward=-2.2, Steps=31042, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3848, Total reward=-0.5, Steps=31052, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3849, Total reward=-1, Steps=31056, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3850, Total reward=-2.4, Steps=31075, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3851, Total reward=-1.0, Steps=31090, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3852, Total reward=-1.2, Steps=31095, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3853, Total reward=0.1, Steps=31109, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3854, Total reward=-1.8, Steps=31121, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3855, Total reward=-2.4, Steps=31140, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3856, Total reward=-0.6, Steps=31151, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3857, Total reward=-1, Steps=31154, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3858, Total reward=-1, Steps=31157, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3859, Total reward=-1, Steps=31161, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3860, Total reward=-1.2, Steps=31166, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3861, Total reward=-2.1, Steps=31182, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3862, Total reward=-2.4, Steps=31201, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3863, Total reward=-1, Steps=31204, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3864, Total reward=-0.7, Steps=31216, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3865, Total reward=-1, Steps=31219, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3866, Total reward=-1.3, Steps=31226, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3867, Total reward=-1.4, Steps=31233, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3868, Total reward=0.9, Steps=31237, Training iteration=15\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3869, Total reward=-1.4, Steps=31245, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3870, Total reward=-1.1, Steps=31250, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3871, Total reward=-2.0, Steps=31264, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3872, Total reward=-1.1, Steps=31280, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3873, Total reward=-1.3, Steps=31286, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3874, Total reward=-1.4, Steps=31293, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3875, Total reward=-2.3, Steps=31311, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3876, Total reward=-2.6, Steps=31332, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3877, Total reward=-2.3, Steps=31350, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3878, Total reward=-1.2, Steps=31355, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3879, Total reward=-1.2, Steps=31360, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3880, Total reward=-1.8, Steps=31372, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3881, Total reward=-1.1, Steps=31376, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3882, Total reward=-1.2, Steps=31382, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3883, Total reward=-1.2, Steps=31387, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3884, Total reward=-0.4, Steps=31396, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3885, Total reward=-1.1, Steps=31400, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3886, Total reward=-2.9, Steps=31424, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3887, Total reward=-1.8, Steps=31447, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3888, Total reward=-1.3, Steps=31465, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3889, Total reward=-2.0, Steps=31480, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3890, Total reward=-1.3, Steps=31486, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3891, Total reward=-0.2, Steps=31493, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3892, Total reward=-1.3, Steps=31499, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3893, Total reward=-1.1, Steps=31503, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3894, Total reward=-2.3, Steps=31521, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3895, Total reward=-0.5, Steps=31531, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3896, Total reward=-1.3, Steps=31538, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3897, Total reward=-1.0, Steps=31553, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3898, Total reward=-2.0, Steps=31567, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3899, Total reward=-2.1, Steps=31582, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3900, Total reward=1, Steps=31585, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3901, Total reward=-1.1, Steps=31589, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3902, Total reward=-2.2, Steps=31606, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3903, Total reward=-1, Steps=31609, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3904, Total reward=-0.1, Steps=31615, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3905, Total reward=-0.4, Steps=31624, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3906, Total reward=-1.1, Steps=31629, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3907, Total reward=-1.1, Steps=31633, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3908, Total reward=-1.1, Steps=31649, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3909, Total reward=-1.1, Steps=31654, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3910, Total reward=-1, Steps=31657, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3911, Total reward=-1.3, Steps=31663, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3912, Total reward=-1.0, Steps=31678, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3913, Total reward=-1, Steps=31682, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3914, Total reward=-2.3, Steps=31699, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3915, Total reward=-2.3, Steps=31717, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3916, Total reward=-2.2, Steps=31734, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3917, Total reward=-1.1, Steps=31738, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3918, Total reward=-0.8, Steps=31751, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3919, Total reward=-1.1, Steps=31755, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3920, Total reward=0.9, Steps=31760, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3921, Total reward=-1.1, Steps=31764, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3922, Total reward=-1, Steps=31767, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3923, Total reward=0.8, Steps=31773, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3924, Total reward=-0.1, Steps=31779, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3925, Total reward=-2.1, Steps=31794, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3926, Total reward=-1.2, Steps=31800, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3927, Total reward=-0.4, Steps=31809, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3928, Total reward=-1, Steps=31812, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3929, Total reward=-1.1, Steps=31816, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3930, Total reward=-1, Steps=31819, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3931, Total reward=-0.2, Steps=31826, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3932, Total reward=-1, Steps=31829, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3933, Total reward=-1, Steps=31832, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3934, Total reward=0.9, Steps=31838, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3935, Total reward=0.9, Steps=31842, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3936, Total reward=0.4, Steps=31852, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3937, Total reward=-1.1, Steps=31856, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3938, Total reward=-1.4, Steps=31864, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3939, Total reward=-1, Steps=31868, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3940, Total reward=-1.1, Steps=31872, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3941, Total reward=-2.7, Steps=31894, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3942, Total reward=0.9, Steps=31899, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3943, Total reward=-2.1, Steps=31915, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3944, Total reward=-1, Steps=31919, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3945, Total reward=-1, Steps=31922, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3946, Total reward=1, Steps=31925, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3947, Total reward=-0.2, Steps=31932, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3948, Total reward=-0.5, Steps=31942, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3949, Total reward=-1.8, Steps=31954, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3950, Total reward=-1.2, Steps=31960, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3951, Total reward=-1.1, Steps=31964, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3952, Total reward=-0.8, Steps=31977, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3953, Total reward=-1, Steps=31980, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3954, Total reward=-1.1, Steps=31984, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3955, Total reward=-0.7, Steps=31996, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3956, Total reward=-1.1, Steps=32000, Training iteration=15\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3956, Total reward=-2.0, Steps=32000, Training iteration=15\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3956, Total reward=-2.0, Steps=32000, Training iteration=15\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3956, Total reward=-2.0, Steps=32000, Training iteration=15\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3956, Total reward=-2.0, Steps=32000, Training iteration=15\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=3956, Total reward=-2.0, Steps=32000, Training iteration=15\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3957, Total reward=-2.3, Steps=32018, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3958, Total reward=-1, Steps=32021, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3959, Total reward=-1, Steps=32024, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3960, Total reward=-1.2, Steps=32030, Training iteration=15\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/30_Step-32030.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/30_Step-32030.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3961, Total reward=-3.0, Steps=32055, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3962, Total reward=-2.3, Steps=32073, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3963, Total reward=-1.4, Steps=32081, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3964, Total reward=-1.1, Steps=32086, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3965, Total reward=-1.6, Steps=32096, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3966, Total reward=-1.4, Steps=32103, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3967, Total reward=-2.2, Steps=32119, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3968, Total reward=-0.9, Steps=32133, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3969, Total reward=-2.0, Steps=32147, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3970, Total reward=0.6, Steps=32155, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3971, Total reward=-1.7, Steps=32166, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3972, Total reward=0.9, Steps=32171, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3973, Total reward=-0.1, Steps=32177, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3974, Total reward=0.8, Steps=32183, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3975, Total reward=-1, Steps=32186, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3976, Total reward=-0.6, Steps=32197, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3977, Total reward=-1.1, Steps=32201, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3978, Total reward=0.9, Steps=32206, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3979, Total reward=-2.2, Steps=32223, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3980, Total reward=-2.0, Steps=32237, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3981, Total reward=-1.3, Steps=32244, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3982, Total reward=-1, Steps=32247, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3983, Total reward=-1.2, Steps=32252, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3984, Total reward=-0.2, Steps=32259, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3985, Total reward=-0.3, Steps=32267, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3986, Total reward=-1.1, Steps=32271, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3987, Total reward=-0.6, Steps=32282, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3988, Total reward=1, Steps=32286, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3989, Total reward=-1, Steps=32289, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3990, Total reward=-1.1, Steps=32294, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3991, Total reward=-1.5, Steps=32302, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3992, Total reward=-2.3, Steps=32320, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3993, Total reward=-1, Steps=32323, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3994, Total reward=-1, Steps=32326, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3995, Total reward=-0.2, Steps=32333, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3996, Total reward=-2.2, Steps=32350, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3997, Total reward=-1.9, Steps=32362, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3998, Total reward=0.6, Steps=32370, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=3999, Total reward=-1.6, Steps=32391, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4000, Total reward=0.8, Steps=32398, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4001, Total reward=-1.1, Steps=32402, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4002, Total reward=-1, Steps=32405, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4003, Total reward=-1.5, Steps=32413, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4004, Total reward=-1.5, Steps=32422, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4005, Total reward=0.7, Steps=32429, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4006, Total reward=-1, Steps=32432, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4007, Total reward=0.7, Steps=32439, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4008, Total reward=0.3, Steps=32450, Training iteration=15\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4009, Total reward=-1.3, Steps=32457, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4010, Total reward=-2.3, Steps=32475, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4011, Total reward=-1.2, Steps=32480, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4012, Total reward=-0.9, Steps=32494, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4013, Total reward=0.9, Steps=32498, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4014, Total reward=-2.2, Steps=32515, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4015, Total reward=-0.5, Steps=32525, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4016, Total reward=-1.2, Steps=32530, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4017, Total reward=0.6, Steps=32538, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4018, Total reward=-1, Steps=32541, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4019, Total reward=-1.3, Steps=32547, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4020, Total reward=-1.6, Steps=32557, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4021, Total reward=-1.1, Steps=32561, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4022, Total reward=-1, Steps=32564, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4023, Total reward=-1, Steps=32567, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4024, Total reward=0.6, Steps=32575, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4025, Total reward=-1.1, Steps=32579, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4026, Total reward=-1, Steps=32582, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4027, Total reward=-1, Steps=32585, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4028, Total reward=-1.2, Steps=32590, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4029, Total reward=-1.2, Steps=32596, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4030, Total reward=-2.2, Steps=32613, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4031, Total reward=-1.0, Steps=32628, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4032, Total reward=-1.3, Steps=32634, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4033, Total reward=-1.3, Steps=32640, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4034, Total reward=-1, Steps=32643, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4035, Total reward=-1.9, Steps=32656, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4036, Total reward=-1.1, Steps=32660, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4037, Total reward=-2.3, Steps=32678, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4038, Total reward=0.2, Steps=32691, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4039, Total reward=-0.6, Steps=32702, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4040, Total reward=-1.1, Steps=32706, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4041, Total reward=-1.2, Steps=32711, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4042, Total reward=-1.2, Steps=32716, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4043, Total reward=-2.0, Steps=32731, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4044, Total reward=-1.2, Steps=32736, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4045, Total reward=-2.0, Steps=32750, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4046, Total reward=-1.1, Steps=32754, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4047, Total reward=-1.1, Steps=32758, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4048, Total reward=-1, Steps=32761, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4049, Total reward=-1.2, Steps=32766, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4050, Total reward=-2.0, Steps=32780, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4051, Total reward=1, Steps=32783, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4052, Total reward=-1.1, Steps=32787, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4053, Total reward=-1.4, Steps=32806, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4054, Total reward=-1.3, Steps=32812, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4055, Total reward=-0.7, Steps=32824, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4056, Total reward=-1.2, Steps=32830, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4057, Total reward=-1.4, Steps=32837, Training iteration=15\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4058, Total reward=-2.5, Steps=32857, Training iteration=15\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.002165024634450674, KL divergence=[0.], Entropy=[-0.02037142], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011493678204715252, KL divergence=[0.], Entropy=[-0.02044515], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015516184270381927, KL divergence=[0.], Entropy=[-0.02041255], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017023518681526184, KL divergence=[0.], Entropy=[-0.02041008], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018112363293766975, KL divergence=[0.], Entropy=[-0.02035443], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018103204667568207, KL divergence=[0.], Entropy=[-0.02032498], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019544702023267746, KL divergence=[0.], Entropy=[-0.02033416], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017832398414611816, KL divergence=[0.], Entropy=[-0.02025782], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018547963351011276, KL divergence=[0.], Entropy=[-0.02027565], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018599707633256912, KL divergence=[0.], Entropy=[-0.0202661], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/31_Step-32857.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/31_Step-32857.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4059, Total reward=-1, Steps=32860, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4060, Total reward=-1, Steps=32863, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4061, Total reward=-1.2, Steps=32868, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4062, Total reward=-1.7, Steps=32879, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4063, Total reward=-0.5, Steps=32889, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4064, Total reward=-1, Steps=32892, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4065, Total reward=-1.1, Steps=32896, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4066, Total reward=-1.2, Steps=32901, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4067, Total reward=-1.1, Steps=32905, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4068, Total reward=-0.2, Steps=32912, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4069, Total reward=-2.4, Steps=32931, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4070, Total reward=-2.4, Steps=32950, Training iteration=16\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4071, Total reward=0.9, Steps=32955, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4072, Total reward=-0.4, Steps=32964, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4073, Total reward=-1.3, Steps=32970, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4074, Total reward=-2.5, Steps=32990, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4075, Total reward=-0.3, Steps=32998, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4076, Total reward=-1.3, Steps=33005, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4077, Total reward=-1, Steps=33008, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4078, Total reward=-0.6, Steps=33019, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4079, Total reward=-1.4, Steps=33026, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4080, Total reward=-1.1, Steps=33030, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4081, Total reward=0.8, Steps=33036, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4082, Total reward=-1.2, Steps=33042, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4083, Total reward=-2.6, Steps=33062, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4084, Total reward=-1.3, Steps=33068, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4085, Total reward=0.5, Steps=33077, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4086, Total reward=-1.2, Steps=33083, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4087, Total reward=0.7, Steps=33089, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4088, Total reward=-0.2, Steps=33096, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4089, Total reward=-1.2, Steps=33101, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4090, Total reward=-0.1, Steps=33107, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4091, Total reward=-0.7, Steps=33119, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4092, Total reward=-1.2, Steps=33124, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4093, Total reward=-1, Steps=33127, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4094, Total reward=-1.3, Steps=33133, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4095, Total reward=-2.2, Steps=33150, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4096, Total reward=0.8, Steps=33156, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4097, Total reward=-0.9, Steps=33170, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4098, Total reward=-0.8, Steps=33183, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4099, Total reward=-1.6, Steps=33193, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4100, Total reward=-2.0, Steps=33207, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4101, Total reward=-0.4, Steps=33216, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4102, Total reward=1, Steps=33220, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4103, Total reward=-1, Steps=33223, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4104, Total reward=-1, Steps=33226, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4105, Total reward=0.4, Steps=33235, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4106, Total reward=-0.5, Steps=33245, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4107, Total reward=-1, Steps=33248, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4108, Total reward=-0.2, Steps=33255, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4109, Total reward=0.9, Steps=33260, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4110, Total reward=0.6, Steps=33268, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4111, Total reward=-1.3, Steps=33274, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4112, Total reward=0.4, Steps=33284, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4113, Total reward=-0.8, Steps=33297, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4114, Total reward=-1.2, Steps=33314, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4115, Total reward=-0.7, Steps=33326, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4116, Total reward=-1, Steps=33330, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4117, Total reward=-1.7, Steps=33340, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4118, Total reward=0.8, Steps=33346, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4119, Total reward=-2.5, Steps=33366, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4120, Total reward=-1, Steps=33369, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4121, Total reward=-2.5, Steps=33389, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4122, Total reward=-1.4, Steps=33396, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4123, Total reward=-1.3, Steps=33402, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4124, Total reward=-1.7, Steps=33413, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4125, Total reward=-0.7, Steps=33425, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4126, Total reward=-1.1, Steps=33429, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4127, Total reward=-1.2, Steps=33434, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4128, Total reward=-2.4, Steps=33453, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4129, Total reward=-1.3, Steps=33459, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4130, Total reward=-2.6, Steps=33480, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4131, Total reward=-1.5, Steps=33489, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4132, Total reward=-0.7, Steps=33501, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4133, Total reward=-0.9, Steps=33515, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4134, Total reward=-1.1, Steps=33520, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4135, Total reward=0.5, Steps=33529, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4136, Total reward=-1.1, Steps=33533, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4137, Total reward=-1, Steps=33536, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4138, Total reward=-0.6, Steps=33547, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4139, Total reward=-0.7, Steps=33559, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4140, Total reward=-1.3, Steps=33566, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4141, Total reward=-1.5, Steps=33574, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4142, Total reward=-1.5, Steps=33582, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4143, Total reward=0.3, Steps=33593, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4144, Total reward=-1, Steps=33596, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4145, Total reward=-1.2, Steps=33601, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4146, Total reward=-1, Steps=33604, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4147, Total reward=-1.5, Steps=33613, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4148, Total reward=-2.6, Steps=33634, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4149, Total reward=-1.4, Steps=33641, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4150, Total reward=-1, Steps=33644, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4151, Total reward=-1.2, Steps=33649, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4152, Total reward=0.6, Steps=33658, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4153, Total reward=-2.2, Steps=33675, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4154, Total reward=-0.1, Steps=33681, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4155, Total reward=0.9, Steps=33686, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4156, Total reward=-1, Steps=33689, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4157, Total reward=-0.4, Steps=33698, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4158, Total reward=-1, Steps=33701, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4159, Total reward=-1.3, Steps=33707, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4160, Total reward=-1.6, Steps=33717, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4161, Total reward=-2.0, Steps=33732, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4162, Total reward=-1.2, Steps=33737, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4163, Total reward=-1.9, Steps=33749, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4164, Total reward=-1.3, Steps=33756, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4165, Total reward=-1, Steps=33759, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4166, Total reward=-0.2, Steps=33766, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4167, Total reward=-1.3, Steps=33784, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4168, Total reward=-1, Steps=33787, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4169, Total reward=-1.2, Steps=33792, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4170, Total reward=-1.1, Steps=33796, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4171, Total reward=-2.3, Steps=33814, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4172, Total reward=-1, Steps=33817, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4173, Total reward=-2.1, Steps=33833, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4174, Total reward=-1, Steps=33836, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4175, Total reward=-1, Steps=33839, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4176, Total reward=-0.3, Steps=33847, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4177, Total reward=-1, Steps=33851, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4178, Total reward=-2.6, Steps=33872, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4179, Total reward=-0.3, Steps=33880, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4180, Total reward=-1.2, Steps=33885, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4181, Total reward=-1, Steps=33888, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4182, Total reward=-1.3, Steps=33894, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4183, Total reward=-1, Steps=33897, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4184, Total reward=-1.1, Steps=33901, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4185, Total reward=-1.3, Steps=33908, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4186, Total reward=-1.2, Steps=33914, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4187, Total reward=-1.1, Steps=33918, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4188, Total reward=-0.5, Steps=33928, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4189, Total reward=-2.2, Steps=33945, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4190, Total reward=-0.2, Steps=33952, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4191, Total reward=-1.1, Steps=33957, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4192, Total reward=-1.0, Steps=33972, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4193, Total reward=-1.2, Steps=33977, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4194, Total reward=-0.7, Steps=33989, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4195, Total reward=0.8, Steps=33995, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4196, Total reward=-1.1, Steps=33999, Training iteration=16\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4196, Total reward=-2.0, Steps=34000, Training iteration=16\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4196, Total reward=-2.0, Steps=34000, Training iteration=16\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4196, Total reward=-2.0, Steps=34000, Training iteration=16\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4196, Total reward=-2.0, Steps=34000, Training iteration=16\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4196, Total reward=-2.0, Steps=34000, Training iteration=16\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4197, Total reward=-2.0, Steps=34014, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4198, Total reward=-1.1, Steps=34019, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4199, Total reward=-1.0, Steps=34034, Training iteration=16\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/32_Step-34034.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/32_Step-34034.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4200, Total reward=-1, Steps=34037, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4201, Total reward=-1, Steps=34040, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4202, Total reward=-1.1, Steps=34044, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4203, Total reward=-1.7, Steps=34055, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4204, Total reward=-2.6, Steps=34076, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4205, Total reward=-1.2, Steps=34081, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4206, Total reward=-0.4, Steps=34090, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4207, Total reward=-0.3, Steps=34098, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4208, Total reward=-1.1, Steps=34102, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4209, Total reward=-1.2, Steps=34107, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4210, Total reward=-1.1, Steps=34111, Training iteration=16\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4211, Total reward=-1.1, Steps=34115, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4212, Total reward=-1.2, Steps=34120, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4213, Total reward=-1, Steps=34123, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4214, Total reward=-2.1, Steps=34139, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4215, Total reward=-1.8, Steps=34151, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4216, Total reward=-1.4, Steps=34159, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4217, Total reward=-2.4, Steps=34178, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4218, Total reward=-1, Steps=34181, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4219, Total reward=-1.2, Steps=34186, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4220, Total reward=-1.1, Steps=34190, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4221, Total reward=0.4, Steps=34200, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4222, Total reward=0.9, Steps=34205, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4223, Total reward=-2.0, Steps=34219, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4224, Total reward=-0.6, Steps=34230, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4225, Total reward=-2.2, Steps=34247, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4226, Total reward=-1.7, Steps=34258, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4227, Total reward=-1.1, Steps=34262, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4228, Total reward=-1, Steps=34265, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4229, Total reward=-1, Steps=34268, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4230, Total reward=-1.1, Steps=34272, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4231, Total reward=-2.6, Steps=34293, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4232, Total reward=-0.7, Steps=34305, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4233, Total reward=-1.3, Steps=34311, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4234, Total reward=-1.1, Steps=34315, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4235, Total reward=0.6, Steps=34323, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4236, Total reward=1, Steps=34326, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4237, Total reward=-1.0, Steps=34341, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4238, Total reward=-2.2, Steps=34358, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4239, Total reward=-1.1, Steps=34362, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4240, Total reward=-1.4, Steps=34381, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4241, Total reward=-1, Steps=34385, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4242, Total reward=0.9, Steps=34390, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4243, Total reward=-1.1, Steps=34395, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4244, Total reward=-1.3, Steps=34402, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4245, Total reward=-0.1, Steps=34408, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4246, Total reward=-1.1, Steps=34412, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4247, Total reward=-2.1, Steps=34428, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4248, Total reward=-1.7, Steps=34439, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4249, Total reward=-2.1, Steps=34454, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4250, Total reward=-1.5, Steps=34462, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4251, Total reward=0.8, Steps=34468, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4252, Total reward=0.6, Steps=34476, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4253, Total reward=-2.3, Steps=34494, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4254, Total reward=-2.0, Steps=34508, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4255, Total reward=-2.4, Steps=34527, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4256, Total reward=-0.7, Steps=34539, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4257, Total reward=-0.3, Steps=34547, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4258, Total reward=-1.1, Steps=34563, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4259, Total reward=-0.6, Steps=34574, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4260, Total reward=-1.5, Steps=34582, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4261, Total reward=-1.3, Steps=34589, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4262, Total reward=-2.3, Steps=34607, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4263, Total reward=-1.1, Steps=34611, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4264, Total reward=-1, Steps=34614, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4265, Total reward=1, Steps=34618, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4266, Total reward=-2.2, Steps=34635, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4267, Total reward=-1.2, Steps=34640, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4268, Total reward=0.8, Steps=34646, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4269, Total reward=-2.1, Steps=34662, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4270, Total reward=-1, Steps=34665, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4271, Total reward=0.8, Steps=34671, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4272, Total reward=0.6, Steps=34680, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4273, Total reward=-0.7, Steps=34692, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4274, Total reward=-1.3, Steps=34699, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4275, Total reward=-1, Steps=34702, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4276, Total reward=-0.4, Steps=34711, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4277, Total reward=-1, Steps=34714, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4278, Total reward=0.3, Steps=34725, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4279, Total reward=-1, Steps=34728, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4280, Total reward=-2.1, Steps=34743, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4281, Total reward=-1, Steps=34746, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4282, Total reward=-0.3, Steps=34754, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4283, Total reward=-1.1, Steps=34758, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4284, Total reward=-0.7, Steps=34770, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4285, Total reward=1, Steps=34774, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4286, Total reward=-0.7, Steps=34786, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4287, Total reward=-1.2, Steps=34792, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4288, Total reward=-0.6, Steps=34803, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4289, Total reward=-2.4, Steps=34822, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4290, Total reward=-0.5, Steps=34832, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4291, Total reward=0.6, Steps=34840, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4292, Total reward=-1.1, Steps=34844, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4293, Total reward=-1.1, Steps=34848, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4294, Total reward=-1.8, Steps=34860, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4295, Total reward=-2.0, Steps=34874, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4296, Total reward=-1.4, Steps=34881, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4297, Total reward=-1, Steps=34885, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4298, Total reward=1, Steps=34889, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4299, Total reward=-1.3, Steps=34896, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4300, Total reward=-1, Steps=34900, Training iteration=16\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4301, Total reward=-0.5, Steps=34910, Training iteration=16\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0018650148995220661, KL divergence=[0.], Entropy=[-0.02029571], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.007990717887878418, KL divergence=[0.], Entropy=[-0.0205045], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013515233062207699, KL divergence=[0.], Entropy=[-0.0205215], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0144474096596241, KL divergence=[0.], Entropy=[-0.02044145], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014528149738907814, KL divergence=[0.], Entropy=[-0.02044617], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014546837657690048, KL divergence=[0.], Entropy=[-0.02045679], training epoch=5, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.014726868830621243, KL divergence=[0.], Entropy=[-0.02040864], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014971758238971233, KL divergence=[0.], Entropy=[-0.02042085], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014140975661575794, KL divergence=[0.], Entropy=[-0.0203804], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014284862205386162, KL divergence=[0.], Entropy=[-0.02037345], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/33_Step-34910.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/33_Step-34910.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4302, Total reward=0.3, Steps=34922, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4303, Total reward=-1.2, Steps=34927, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4304, Total reward=0.8, Steps=34933, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4305, Total reward=-1, Steps=34936, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4306, Total reward=-1, Steps=34939, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4307, Total reward=0.7, Steps=34946, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4308, Total reward=-2.2, Steps=34963, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4309, Total reward=-2.0, Steps=34977, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4310, Total reward=-1.3, Steps=34984, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4311, Total reward=-1.0, Steps=34999, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4312, Total reward=-1.3, Steps=35005, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4313, Total reward=-0.7, Steps=35017, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4314, Total reward=-2.5, Steps=35037, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4315, Total reward=-1.4, Steps=35056, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4316, Total reward=-2.4, Steps=35075, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4317, Total reward=-1, Steps=35078, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4318, Total reward=-1.3, Steps=35084, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4319, Total reward=-1.2, Steps=35089, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4320, Total reward=-0.5, Steps=35099, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4321, Total reward=-1.5, Steps=35107, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4322, Total reward=-1.3, Steps=35113, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4323, Total reward=-2.0, Steps=35127, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4324, Total reward=-1, Steps=35130, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4325, Total reward=-1.1, Steps=35135, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4326, Total reward=-2.6, Steps=35156, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4327, Total reward=-1.6, Steps=35166, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4328, Total reward=-2.1, Steps=35182, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4329, Total reward=-1.1, Steps=35187, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4330, Total reward=-1, Steps=35190, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4331, Total reward=-1.4, Steps=35198, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4332, Total reward=-1.3, Steps=35204, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4333, Total reward=-1.5, Steps=35212, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4334, Total reward=-1.2, Steps=35217, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4335, Total reward=-0.5, Steps=35227, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4336, Total reward=-0.7, Steps=35239, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4337, Total reward=-1.2, Steps=35245, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4338, Total reward=-0.6, Steps=35256, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4339, Total reward=-2.0, Steps=35270, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4340, Total reward=-1.1, Steps=35274, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4341, Total reward=0.6, Steps=35281, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4342, Total reward=-1.1, Steps=35286, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4343, Total reward=-1.1, Steps=35302, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4344, Total reward=-1, Steps=35305, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4345, Total reward=-1.6, Steps=35315, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4346, Total reward=-1, Steps=35319, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4347, Total reward=-1, Steps=35322, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4348, Total reward=-1.1, Steps=35326, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4349, Total reward=-1.1, Steps=35331, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4350, Total reward=-1, Steps=35334, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4351, Total reward=-1.2, Steps=35339, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4352, Total reward=-2.0, Steps=35353, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4353, Total reward=-1.3, Steps=35359, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4354, Total reward=-1.1, Steps=35363, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4355, Total reward=-0.9, Steps=35377, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4356, Total reward=-1.3, Steps=35383, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4357, Total reward=-1.2, Steps=35388, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4358, Total reward=-1.1, Steps=35392, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4359, Total reward=-2.1, Steps=35408, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4360, Total reward=-2.2, Steps=35424, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4361, Total reward=1, Steps=35428, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4362, Total reward=-1.2, Steps=35434, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4363, Total reward=0.6, Steps=35443, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4364, Total reward=-1, Steps=35446, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4365, Total reward=-1.2, Steps=35451, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4366, Total reward=-1.4, Steps=35458, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4367, Total reward=-1.4, Steps=35465, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4368, Total reward=-1.1, Steps=35469, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4369, Total reward=-1.5, Steps=35478, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4370, Total reward=-1.6, Steps=35488, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4371, Total reward=-1.1, Steps=35492, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4372, Total reward=-1.5, Steps=35501, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4373, Total reward=-1, Steps=35504, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4374, Total reward=-0.4, Steps=35513, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4375, Total reward=-1.2, Steps=35519, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4376, Total reward=-1, Steps=35522, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4377, Total reward=-1, Steps=35525, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4378, Total reward=-2.3, Steps=35543, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4379, Total reward=-1.3, Steps=35549, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4380, Total reward=0.6, Steps=35558, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4381, Total reward=-1.2, Steps=35563, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4382, Total reward=-0.2, Steps=35570, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4383, Total reward=-0.4, Steps=35579, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4384, Total reward=-2.3, Steps=35597, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4385, Total reward=-1.1, Steps=35601, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4386, Total reward=-0.1, Steps=35617, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4387, Total reward=-1.7, Steps=35628, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4388, Total reward=-1.1, Steps=35632, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4389, Total reward=0.6, Steps=35640, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4390, Total reward=-1.5, Steps=35649, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4391, Total reward=-1.2, Steps=35654, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4392, Total reward=-1.2, Steps=35659, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4393, Total reward=-1.1, Steps=35663, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4394, Total reward=-1.4, Steps=35671, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4395, Total reward=-1, Steps=35675, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4396, Total reward=-0.2, Steps=35682, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4397, Total reward=-0.8, Steps=35695, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4398, Total reward=0.7, Steps=35702, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4399, Total reward=-2.1, Steps=35718, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4400, Total reward=-1.1, Steps=35722, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4401, Total reward=-0.6, Steps=35733, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4402, Total reward=-1.1, Steps=35737, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4403, Total reward=0.8, Steps=35743, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4404, Total reward=-1, Steps=35746, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4405, Total reward=-1.5, Steps=35754, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4406, Total reward=-0.4, Steps=35763, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4407, Total reward=-1.2, Steps=35769, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4408, Total reward=-3.5, Steps=35799, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4409, Total reward=-0.4, Steps=35808, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4410, Total reward=-2.0, Steps=35823, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4411, Total reward=-1.7, Steps=35833, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4412, Total reward=-1.1, Steps=35838, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4413, Total reward=-0.6, Steps=35849, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4414, Total reward=-1.3, Steps=35855, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4415, Total reward=-1.1, Steps=35860, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4416, Total reward=-1.5, Steps=35869, Training iteration=17\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4417, Total reward=-1.1, Steps=35873, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4418, Total reward=0.8, Steps=35879, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4419, Total reward=-1.1, Steps=35883, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4420, Total reward=-1, Steps=35886, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4421, Total reward=-1, Steps=35889, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4422, Total reward=-1, Steps=35892, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4423, Total reward=-1, Steps=35896, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4424, Total reward=-1.7, Steps=35906, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4425, Total reward=-1.1, Steps=35911, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4426, Total reward=0.8, Steps=35917, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4427, Total reward=-1, Steps=35920, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4428, Total reward=-1.2, Steps=35926, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4429, Total reward=-1, Steps=35929, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4430, Total reward=-1.1, Steps=35934, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4431, Total reward=0.6, Steps=35942, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4432, Total reward=-2.1, Steps=35957, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4433, Total reward=-2.1, Steps=35973, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4434, Total reward=-2.1, Steps=35989, Training iteration=17\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4434, Total reward=-2.0, Steps=36000, Training iteration=17\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4434, Total reward=-1, Steps=36000, Training iteration=17\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4434, Total reward=-2.0, Steps=36000, Training iteration=17\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4434, Total reward=-2.0, Steps=36000, Training iteration=17\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4434, Total reward=-2.0, Steps=36000, Training iteration=17\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4435, Total reward=-1.1, Steps=36004, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4436, Total reward=-1.1, Steps=36008, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4437, Total reward=-2.2, Steps=36025, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4438, Total reward=-1, Steps=36028, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4439, Total reward=-1.1, Steps=36032, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4440, Total reward=-2.2, Steps=36048, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4441, Total reward=-0.5, Steps=36058, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4442, Total reward=-0.4, Steps=36067, Training iteration=17\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/34_Step-36067.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/34_Step-36067.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4443, Total reward=-1.4, Steps=36074, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4444, Total reward=-1, Steps=36077, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4445, Total reward=-0.5, Steps=36087, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4446, Total reward=-2.0, Steps=36101, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4447, Total reward=0.9, Steps=36106, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4448, Total reward=-0.9, Steps=36120, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4449, Total reward=0.9, Steps=36124, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4450, Total reward=-1.2, Steps=36130, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4451, Total reward=-1.1, Steps=36134, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4452, Total reward=-2.3, Steps=36152, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4453, Total reward=0.3, Steps=36164, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4454, Total reward=-0.7, Steps=36176, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4455, Total reward=-1, Steps=36179, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4456, Total reward=-1, Steps=36182, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4457, Total reward=-1.3, Steps=36189, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4458, Total reward=-1.3, Steps=36195, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4459, Total reward=-1.4, Steps=36203, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4460, Total reward=-1, Steps=36206, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4461, Total reward=-1.5, Steps=36215, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4462, Total reward=-2.6, Steps=36236, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4463, Total reward=0.5, Steps=36246, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4464, Total reward=-1, Steps=36250, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4465, Total reward=-0.4, Steps=36259, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4466, Total reward=-1, Steps=36262, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4467, Total reward=-1.2, Steps=36268, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4468, Total reward=-1, Steps=36271, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4469, Total reward=-2.2, Steps=36288, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4470, Total reward=-1.3, Steps=36294, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4471, Total reward=-1, Steps=36297, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4472, Total reward=0.6, Steps=36306, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4473, Total reward=-1.1, Steps=36311, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4474, Total reward=0.7, Steps=36319, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4475, Total reward=-1.2, Steps=36324, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4476, Total reward=-0.2, Steps=36331, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4477, Total reward=0.9, Steps=36336, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4478, Total reward=-1.3, Steps=36343, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4479, Total reward=-1.1, Steps=36347, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4480, Total reward=-1.2, Steps=36352, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4481, Total reward=-1.8, Steps=36364, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4482, Total reward=-1, Steps=36367, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4483, Total reward=-1, Steps=36370, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4484, Total reward=-0.1, Steps=36376, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4485, Total reward=-1.1, Steps=36380, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4486, Total reward=-1.2, Steps=36385, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4487, Total reward=-1.3, Steps=36392, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4488, Total reward=-1.3, Steps=36398, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4489, Total reward=-0.9, Steps=36412, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4490, Total reward=-1, Steps=36415, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4491, Total reward=1, Steps=36419, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4492, Total reward=-1, Steps=36422, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4493, Total reward=-1.5, Steps=36430, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4494, Total reward=-0.3, Steps=36438, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4495, Total reward=-1.6, Steps=36448, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4496, Total reward=-2.3, Steps=36466, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4497, Total reward=-1.2, Steps=36471, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4498, Total reward=0.7, Steps=36479, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4499, Total reward=-1.6, Steps=36489, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4500, Total reward=-1, Steps=36492, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4501, Total reward=0.9, Steps=36496, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4502, Total reward=-0.2, Steps=36503, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4503, Total reward=-0.8, Steps=36516, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4504, Total reward=-1.2, Steps=36522, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4505, Total reward=-2.0, Steps=36536, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4506, Total reward=-2.1, Steps=36552, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4507, Total reward=-1.0, Steps=36567, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4508, Total reward=-2.3, Steps=36585, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4509, Total reward=-2.3, Steps=36603, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4510, Total reward=-2.0, Steps=36617, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4511, Total reward=-1.1, Steps=36621, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4512, Total reward=-1, Steps=36624, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4513, Total reward=-0.5, Steps=36634, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4514, Total reward=-2.0, Steps=36649, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4515, Total reward=-1.7, Steps=36660, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4516, Total reward=-0.1, Steps=36666, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4517, Total reward=-0.8, Steps=36679, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4518, Total reward=-1, Steps=36682, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4519, Total reward=-1.6, Steps=36692, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4520, Total reward=-2.4, Steps=36711, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4521, Total reward=-0.4, Steps=36720, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4522, Total reward=-3.3, Steps=36748, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4523, Total reward=-1.1, Steps=36753, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4524, Total reward=-1, Steps=36756, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4525, Total reward=-1.2, Steps=36761, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4526, Total reward=-1, Steps=36765, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4527, Total reward=-0.4, Steps=36774, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4528, Total reward=-1.1, Steps=36779, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4529, Total reward=-1.0, Steps=36794, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4530, Total reward=-1.2, Steps=36800, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4531, Total reward=0.1, Steps=36814, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4532, Total reward=-1, Steps=36817, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4533, Total reward=-1, Steps=36820, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4534, Total reward=-1.8, Steps=36832, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4535, Total reward=-0.1, Steps=36838, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4536, Total reward=-1.7, Steps=36848, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4537, Total reward=-1.2, Steps=36854, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4538, Total reward=0.9, Steps=36859, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4539, Total reward=1, Steps=36863, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4540, Total reward=-1.1, Steps=36867, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4541, Total reward=-2.0, Steps=36880, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4542, Total reward=0.9, Steps=36885, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4543, Total reward=-1, Steps=36889, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4544, Total reward=-2.6, Steps=36910, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4545, Total reward=-1.2, Steps=36915, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4546, Total reward=-2.6, Steps=36936, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4547, Total reward=-1, Steps=36939, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4548, Total reward=-1, Steps=36942, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4549, Total reward=0.4, Steps=36952, Training iteration=17\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4550, Total reward=-1.9, Steps=36965, Training iteration=17\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.0012222720542922616, KL divergence=[0.], Entropy=[-0.02048531], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.006166974548250437, KL divergence=[0.], Entropy=[-0.02049991], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016840631142258644, KL divergence=[0.], Entropy=[-0.02049147], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0134761743247509, KL divergence=[0.], Entropy=[-0.02042898], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008649528957903385, KL divergence=[0.], Entropy=[-0.02045467], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008873945102095604, KL divergence=[0.], Entropy=[-0.02041368], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014790860936045647, KL divergence=[0.], Entropy=[-0.02038978], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016373151913285255, KL divergence=[0.], Entropy=[-0.02037221], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016992464661598206, KL divergence=[0.], Entropy=[-0.02039733], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012641813606023788, KL divergence=[0.], Entropy=[-0.02039075], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/35_Step-36965.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/35_Step-36965.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4551, Total reward=-1, Steps=36968, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4552, Total reward=-1.1, Steps=36972, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4553, Total reward=-0.4, Steps=36981, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4554, Total reward=-1.2, Steps=36986, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4555, Total reward=-2.0, Steps=37001, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4556, Total reward=-1.3, Steps=37019, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4557, Total reward=-1.2, Steps=37025, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4558, Total reward=-2.0, Steps=37038, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4559, Total reward=-1.6, Steps=37048, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4560, Total reward=-1.4, Steps=37055, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4561, Total reward=-1.1, Steps=37059, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4562, Total reward=0.2, Steps=37071, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4563, Total reward=-1, Steps=37074, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4564, Total reward=-1, Steps=37077, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4565, Total reward=-1, Steps=37080, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4566, Total reward=-1, Steps=37083, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4567, Total reward=-0.2, Steps=37090, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4568, Total reward=-1, Steps=37093, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4569, Total reward=-1.1, Steps=37097, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4570, Total reward=-1.6, Steps=37106, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4571, Total reward=-2.0, Steps=37119, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4572, Total reward=-0.2, Steps=37126, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4573, Total reward=-1, Steps=37129, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4574, Total reward=0.8, Steps=37135, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4575, Total reward=-1, Steps=37138, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4576, Total reward=-0.8, Steps=37151, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4577, Total reward=-1, Steps=37154, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4578, Total reward=-1.6, Steps=37163, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4579, Total reward=-1, Steps=37166, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4580, Total reward=0.6, Steps=37174, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4581, Total reward=-0.2, Steps=37181, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4582, Total reward=-0.9, Steps=37195, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4583, Total reward=-1, Steps=37198, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4584, Total reward=-2.9, Steps=37222, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4585, Total reward=-1.5, Steps=37231, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4586, Total reward=-1.4, Steps=37239, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4587, Total reward=-1.6, Steps=37248, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4588, Total reward=-2.2, Steps=37264, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4589, Total reward=-0.9, Steps=37278, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4590, Total reward=-1.3, Steps=37284, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4591, Total reward=-1, Steps=37287, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4592, Total reward=-2.4, Steps=37306, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4593, Total reward=-1.1, Steps=37322, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4594, Total reward=-1.1, Steps=37326, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4595, Total reward=-1.3, Steps=37333, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4596, Total reward=-0.7, Steps=37345, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4597, Total reward=-1.1, Steps=37349, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4598, Total reward=-1.6, Steps=37370, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4599, Total reward=-1, Steps=37373, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4600, Total reward=0.8, Steps=37380, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4601, Total reward=0.8, Steps=37386, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4602, Total reward=0.8, Steps=37392, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4603, Total reward=-1.2, Steps=37397, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4604, Total reward=-1, Steps=37401, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4605, Total reward=-0.6, Steps=37412, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4606, Total reward=-1.3, Steps=37419, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4607, Total reward=0.8, Steps=37425, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4608, Total reward=-1.5, Steps=37434, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4609, Total reward=-1.1, Steps=37438, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4610, Total reward=-1.1, Steps=37454, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4611, Total reward=-1.7, Steps=37465, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4612, Total reward=-2.5, Steps=37485, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4613, Total reward=-0.3, Steps=37493, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4614, Total reward=-1.5, Steps=37501, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4615, Total reward=-1.6, Steps=37511, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4616, Total reward=-1, Steps=37515, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4617, Total reward=-0.5, Steps=37525, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4618, Total reward=-1.2, Steps=37530, Training iteration=18\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4619, Total reward=-1.8, Steps=37553, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4620, Total reward=-2.5, Steps=37573, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4621, Total reward=-1.2, Steps=37578, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4622, Total reward=-1.6, Steps=37587, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4623, Total reward=-1.3, Steps=37593, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4624, Total reward=-0.6, Steps=37604, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4625, Total reward=-2.1, Steps=37619, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4626, Total reward=-1.2, Steps=37624, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4627, Total reward=-1.3, Steps=37630, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4628, Total reward=-1, Steps=37634, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4629, Total reward=-1.1, Steps=37638, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4630, Total reward=-1.3, Steps=37644, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4631, Total reward=-1.4, Steps=37663, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4632, Total reward=-1.1, Steps=37668, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4633, Total reward=-0.1, Steps=37674, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4634, Total reward=-1.4, Steps=37681, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4635, Total reward=-1.4, Steps=37688, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4636, Total reward=-1.7, Steps=37710, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4637, Total reward=-0.1, Steps=37716, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4638, Total reward=-1, Steps=37719, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4639, Total reward=-1.3, Steps=37725, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4640, Total reward=-1.1, Steps=37741, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4641, Total reward=0.8, Steps=37747, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4642, Total reward=-1, Steps=37750, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4643, Total reward=-1.2, Steps=37755, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4644, Total reward=-1, Steps=37758, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4645, Total reward=0, Steps=37763, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4646, Total reward=-1, Steps=37767, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4647, Total reward=0.7, Steps=37774, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4648, Total reward=-1.4, Steps=37782, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4649, Total reward=-1.3, Steps=37789, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4650, Total reward=-2.4, Steps=37807, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4651, Total reward=-1.3, Steps=37814, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4652, Total reward=-2.6, Steps=37835, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4653, Total reward=-2.2, Steps=37852, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4654, Total reward=0.5, Steps=37861, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4655, Total reward=-1.1, Steps=37866, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4656, Total reward=-1.5, Steps=37875, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4657, Total reward=-1.1, Steps=37879, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4658, Total reward=-2.3, Steps=37897, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4659, Total reward=0.8, Steps=37903, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4660, Total reward=-1, Steps=37906, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4661, Total reward=-1.1, Steps=37910, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4662, Total reward=-1, Steps=37913, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4663, Total reward=-0.8, Steps=37926, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4664, Total reward=-1, Steps=37929, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4665, Total reward=1, Steps=37933, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4666, Total reward=-1.1, Steps=37937, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4667, Total reward=-2.8, Steps=37960, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4668, Total reward=-2.9, Steps=37984, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4669, Total reward=-1.2, Steps=37989, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4670, Total reward=-1.1, Steps=37993, Training iteration=18\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4670, Total reward=-2.0, Steps=38000, Training iteration=18\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4670, Total reward=-2.0, Steps=38000, Training iteration=18\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4670, Total reward=-2.0, Steps=38000, Training iteration=18\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4670, Total reward=-1, Steps=38000, Training iteration=18\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4670, Total reward=-2.0, Steps=38000, Training iteration=18\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4671, Total reward=-1.3, Steps=38007, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4672, Total reward=-1.1, Steps=38012, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4673, Total reward=-0.5, Steps=38022, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4674, Total reward=-1, Steps=38025, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4675, Total reward=-0.9, Steps=38039, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4676, Total reward=-1, Steps=38042, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4677, Total reward=-1, Steps=38045, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4678, Total reward=-1.0, Steps=38060, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4679, Total reward=-1.4, Steps=38068, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4680, Total reward=-1, Steps=38071, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4681, Total reward=-1.1, Steps=38075, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4682, Total reward=-2.3, Steps=38093, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4683, Total reward=-2.4, Steps=38110, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4684, Total reward=-1.4, Steps=38118, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4685, Total reward=0.5, Steps=38127, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4686, Total reward=-1, Steps=38131, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4687, Total reward=0.8, Steps=38137, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4688, Total reward=0.9, Steps=38142, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4689, Total reward=-1.1, Steps=38146, Training iteration=18\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/36_Step-38147.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/36_Step-38147.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4690, Total reward=-2.0, Steps=38161, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4691, Total reward=0, Steps=38166, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4692, Total reward=-1.0, Steps=38181, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4693, Total reward=-1, Steps=38184, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4694, Total reward=-1.3, Steps=38190, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4695, Total reward=-1.1, Steps=38194, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4696, Total reward=-1, Steps=38197, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4697, Total reward=0.9, Steps=38202, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4698, Total reward=-1.1, Steps=38206, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4699, Total reward=-1.1, Steps=38210, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4700, Total reward=-1.2, Steps=38216, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4701, Total reward=1, Steps=38220, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4702, Total reward=-1.1, Steps=38225, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4703, Total reward=-2.0, Steps=38239, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4704, Total reward=-1.2, Steps=38245, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4705, Total reward=-1, Steps=38248, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4706, Total reward=-1, Steps=38251, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4707, Total reward=-0.2, Steps=38258, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4708, Total reward=-1.4, Steps=38266, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4709, Total reward=-1, Steps=38269, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4710, Total reward=-1.4, Steps=38276, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4711, Total reward=-1, Steps=38280, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4712, Total reward=-1.1, Steps=38284, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4713, Total reward=-1.1, Steps=38289, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4714, Total reward=-1.2, Steps=38295, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4715, Total reward=-1.1, Steps=38299, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4716, Total reward=-1.4, Steps=38306, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4717, Total reward=-1.3, Steps=38312, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4718, Total reward=0.9, Steps=38317, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4719, Total reward=-2.0, Steps=38332, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4720, Total reward=0, Steps=38337, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4721, Total reward=-2.1, Steps=38353, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4722, Total reward=-0.5, Steps=38363, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4723, Total reward=-1.0, Steps=38378, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4724, Total reward=-2.2, Steps=38395, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4725, Total reward=-0.7, Steps=38407, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4726, Total reward=-1.1, Steps=38411, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4727, Total reward=-2.2, Steps=38428, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4728, Total reward=-1.2, Steps=38433, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4729, Total reward=-1.1, Steps=38437, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4730, Total reward=0.4, Steps=38447, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4731, Total reward=-1.2, Steps=38453, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4732, Total reward=-1, Steps=38456, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4733, Total reward=-1, Steps=38459, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4734, Total reward=-1, Steps=38462, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4735, Total reward=-1, Steps=38465, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4736, Total reward=-1, Steps=38468, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4737, Total reward=-1.3, Steps=38474, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4738, Total reward=-0.4, Steps=38483, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4739, Total reward=0, Steps=38488, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4740, Total reward=-0.1, Steps=38494, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4741, Total reward=-1, Steps=38497, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4742, Total reward=-1.3, Steps=38504, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4743, Total reward=-1.4, Steps=38511, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4744, Total reward=-0.3, Steps=38519, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4745, Total reward=-0.5, Steps=38529, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4746, Total reward=-1, Steps=38532, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4747, Total reward=-1.3, Steps=38539, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4748, Total reward=-1.3, Steps=38546, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4749, Total reward=-0.8, Steps=38559, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4750, Total reward=0.9, Steps=38564, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4751, Total reward=-1.3, Steps=38570, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4752, Total reward=-2.2, Steps=38587, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4753, Total reward=-1.2, Steps=38593, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4754, Total reward=-1.4, Steps=38601, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4755, Total reward=0.7, Steps=38608, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4756, Total reward=0.3, Steps=38619, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4757, Total reward=-1, Steps=38622, Training iteration=18\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4758, Total reward=-1.3, Steps=38628, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4759, Total reward=-0.5, Steps=38638, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4760, Total reward=-1.4, Steps=38645, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4761, Total reward=1, Steps=38649, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4762, Total reward=-1.1, Steps=38653, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4763, Total reward=-1.0, Steps=38668, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4764, Total reward=-1, Steps=38671, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4765, Total reward=-0.7, Steps=38683, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4766, Total reward=0.8, Steps=38689, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4767, Total reward=-1.8, Steps=38701, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4768, Total reward=0.2, Steps=38713, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4769, Total reward=-2.3, Steps=38731, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4770, Total reward=-1.1, Steps=38736, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4771, Total reward=0.9, Steps=38741, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4772, Total reward=-1.1, Steps=38745, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4773, Total reward=-1.4, Steps=38764, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4774, Total reward=-0.9, Steps=38778, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4775, Total reward=-2.3, Steps=38796, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4776, Total reward=-0.2, Steps=38803, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4777, Total reward=-1.3, Steps=38809, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4778, Total reward=-0.7, Steps=38831, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4779, Total reward=-0.5, Steps=38841, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4780, Total reward=0.9, Steps=38846, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4781, Total reward=-2.7, Steps=38868, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4782, Total reward=0.4, Steps=38879, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4783, Total reward=-1.8, Steps=38891, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4784, Total reward=-1.1, Steps=38896, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4785, Total reward=-1.3, Steps=38902, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4786, Total reward=-1.9, Steps=38915, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4787, Total reward=-0.7, Steps=38927, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4788, Total reward=-1.2, Steps=38932, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4789, Total reward=-1.4, Steps=38940, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4790, Total reward=-2.6, Steps=38961, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4791, Total reward=-0.1, Steps=38967, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4792, Total reward=-2.5, Steps=38986, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4793, Total reward=-1.1, Steps=38990, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4794, Total reward=-1.1, Steps=38994, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4795, Total reward=-1.4, Steps=39001, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4796, Total reward=-1, Steps=39004, Training iteration=18\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4797, Total reward=-2.4, Steps=39023, Training iteration=18\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.00013157643843442202, KL divergence=[0.], Entropy=[-0.02037926], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.00911259651184082, KL divergence=[0.], Entropy=[-0.02023038], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011675461195409298, KL divergence=[0.], Entropy=[-0.02017807], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013383057899773121, KL divergence=[0.], Entropy=[-0.02017258], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013386273756623268, KL divergence=[0.], Entropy=[-0.02011586], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01486284751445055, KL divergence=[0.], Entropy=[-0.02011438], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01343454234302044, KL divergence=[0.], Entropy=[-0.02005456], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014924583956599236, KL divergence=[0.], Entropy=[-0.02008212], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01456773653626442, KL divergence=[0.], Entropy=[-0.02009107], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015014640055596828, KL divergence=[0.], Entropy=[-0.02005645], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/37_Step-39023.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/37_Step-39023.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4798, Total reward=-1.1, Steps=39027, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4799, Total reward=-1.7, Steps=39038, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4800, Total reward=-2.1, Steps=39054, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4801, Total reward=0.2, Steps=39066, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4802, Total reward=1, Steps=39069, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4803, Total reward=-1.2, Steps=39075, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4804, Total reward=-0.9, Steps=39089, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4805, Total reward=-1.2, Steps=39094, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4806, Total reward=0.7, Steps=39101, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4807, Total reward=-1.4, Steps=39120, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4808, Total reward=0.9, Steps=39124, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4809, Total reward=-1, Steps=39127, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4810, Total reward=-1.6, Steps=39148, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4811, Total reward=-1.2, Steps=39154, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4812, Total reward=-1, Steps=39157, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4813, Total reward=0.7, Steps=39164, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4814, Total reward=-2.2, Steps=39181, Training iteration=19\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4815, Total reward=-1.4, Steps=39188, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4816, Total reward=-2.4, Steps=39207, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4817, Total reward=-1.1, Steps=39211, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4818, Total reward=-1.7, Steps=39222, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4819, Total reward=-0.3, Steps=39230, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4820, Total reward=-1.1, Steps=39234, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4821, Total reward=-1.9, Steps=39247, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4822, Total reward=-2.2, Steps=39263, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4823, Total reward=-1.2, Steps=39268, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4824, Total reward=-2.7, Steps=39290, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4825, Total reward=-1, Steps=39293, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4826, Total reward=-2.2, Steps=39310, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4827, Total reward=0.9, Steps=39315, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4828, Total reward=-2.2, Steps=39332, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4829, Total reward=-1.1, Steps=39336, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4830, Total reward=-1.1, Steps=39340, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4831, Total reward=-2.1, Steps=39356, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4832, Total reward=-0.3, Steps=39364, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4833, Total reward=-1.7, Steps=39375, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4834, Total reward=-1, Steps=39378, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4835, Total reward=-1.1, Steps=39382, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4836, Total reward=-0.1, Steps=39388, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4837, Total reward=-1, Steps=39391, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4838, Total reward=-1.1, Steps=39396, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4839, Total reward=-1.3, Steps=39403, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4840, Total reward=-1.5, Steps=39411, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4841, Total reward=-1, Steps=39414, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4842, Total reward=0.7, Steps=39421, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4843, Total reward=-2.0, Steps=39436, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4844, Total reward=-1, Steps=39439, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4845, Total reward=-1.3, Steps=39445, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4846, Total reward=-1, Steps=39448, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4847, Total reward=-1.2, Steps=39454, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4848, Total reward=-1.1, Steps=39470, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4849, Total reward=-1.4, Steps=39477, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4850, Total reward=-1, Steps=39481, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4851, Total reward=-2.3, Steps=39499, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4852, Total reward=-1.3, Steps=39506, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4853, Total reward=-1, Steps=39510, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4854, Total reward=-1.2, Steps=39516, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4855, Total reward=-0.4, Steps=39525, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4856, Total reward=-1.2, Steps=39530, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4857, Total reward=-1.2, Steps=39535, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4858, Total reward=-2.0, Steps=39549, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4859, Total reward=-1.5, Steps=39569, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4860, Total reward=-1.9, Steps=39582, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4861, Total reward=0.9, Steps=39587, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4862, Total reward=-1, Steps=39590, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4863, Total reward=-1.1, Steps=39594, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4864, Total reward=-1.1, Steps=39598, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4865, Total reward=-1.2, Steps=39603, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4866, Total reward=-1.4, Steps=39611, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4867, Total reward=-1.1, Steps=39615, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4868, Total reward=-0.4, Steps=39624, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4869, Total reward=-1, Steps=39627, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4870, Total reward=-0.3, Steps=39635, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4871, Total reward=-0.3, Steps=39643, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4872, Total reward=-0.4, Steps=39652, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4873, Total reward=-1, Steps=39655, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4874, Total reward=1, Steps=39660, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4875, Total reward=-1.6, Steps=39681, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4876, Total reward=-1.1, Steps=39685, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4877, Total reward=-1, Steps=39688, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4878, Total reward=-1.1, Steps=39692, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4879, Total reward=-1.4, Steps=39700, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4880, Total reward=-1.4, Steps=39707, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4881, Total reward=-0.6, Steps=39718, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4882, Total reward=-1.4, Steps=39726, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4883, Total reward=-1.7, Steps=39737, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4884, Total reward=-1, Steps=39740, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4885, Total reward=-1.1, Steps=39745, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4886, Total reward=-1.1, Steps=39749, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4887, Total reward=-1.4, Steps=39757, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4888, Total reward=-0.3, Steps=39765, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4889, Total reward=0.1, Steps=39778, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4890, Total reward=-1, Steps=39781, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4891, Total reward=-0.5, Steps=39791, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4892, Total reward=-1, Steps=39794, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4893, Total reward=-0.6, Steps=39805, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4894, Total reward=-1.1, Steps=39809, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4895, Total reward=-1.3, Steps=39815, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4896, Total reward=0.5, Steps=39824, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4897, Total reward=0.6, Steps=39832, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4898, Total reward=-0.8, Steps=39845, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4899, Total reward=-0.8, Steps=39858, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4900, Total reward=-0.4, Steps=39867, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4901, Total reward=-1.8, Steps=39879, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4902, Total reward=-0.9, Steps=39893, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4903, Total reward=0.8, Steps=39899, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4904, Total reward=-1.7, Steps=39910, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4905, Total reward=-1.2, Steps=39916, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4906, Total reward=-3.0, Steps=39941, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4907, Total reward=-2.0, Steps=39955, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4908, Total reward=-2.0, Steps=39970, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4909, Total reward=-0.8, Steps=39983, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4910, Total reward=-1, Steps=39986, Training iteration=19\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4910, Total reward=-2.0, Steps=40000, Training iteration=19\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4910, Total reward=-1, Steps=40000, Training iteration=19\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4910, Total reward=-1, Steps=40000, Training iteration=19\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4910, Total reward=-2.0, Steps=40000, Training iteration=19\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=4910, Total reward=-2.0, Steps=40000, Training iteration=19\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.6\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4911, Total reward=-1.1, Steps=40004, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4912, Total reward=-1.1, Steps=40008, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4913, Total reward=-0.7, Steps=40020, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4914, Total reward=-0.5, Steps=40030, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4915, Total reward=-1, Steps=40033, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4916, Total reward=-0.1, Steps=40039, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4917, Total reward=-1.1, Steps=40044, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4918, Total reward=-1.5, Steps=40052, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4919, Total reward=-1.5, Steps=40061, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4920, Total reward=-1, Steps=40064, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4921, Total reward=-2.2, Steps=40080, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4922, Total reward=-1.1, Steps=40085, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4923, Total reward=-0.1, Steps=40100, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4924, Total reward=-1, Steps=40103, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4925, Total reward=-1.1, Steps=40107, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4926, Total reward=-1.3, Steps=40114, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4927, Total reward=-2.7, Steps=40136, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4928, Total reward=-2.6, Steps=40157, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4929, Total reward=-2.3, Steps=40175, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4930, Total reward=-1.0, Steps=40190, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4931, Total reward=-1, Steps=40193, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4932, Total reward=-1.2, Steps=40198, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4933, Total reward=-1.2, Steps=40203, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4934, Total reward=-1.7, Steps=40214, Training iteration=19\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/38_Step-40214.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/38_Step-40214.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4935, Total reward=-2.0, Steps=40229, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4936, Total reward=-1.1, Steps=40234, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4937, Total reward=-1.1, Steps=40238, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4938, Total reward=-2.5, Steps=40258, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4939, Total reward=-1.6, Steps=40267, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4940, Total reward=-0.2, Steps=40274, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4941, Total reward=-1.1, Steps=40278, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4942, Total reward=-2.0, Steps=40292, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4943, Total reward=-2.7, Steps=40314, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4944, Total reward=-1.0, Steps=40329, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4945, Total reward=-1.2, Steps=40334, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4946, Total reward=-1.1, Steps=40338, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4947, Total reward=-1.3, Steps=40356, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4948, Total reward=-0.3, Steps=40364, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4949, Total reward=-0.4, Steps=40383, Training iteration=19\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4950, Total reward=-1, Steps=40387, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4951, Total reward=-0.1, Steps=40393, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4952, Total reward=-1.3, Steps=40400, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4953, Total reward=-0.9, Steps=40414, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4954, Total reward=-1.2, Steps=40419, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4955, Total reward=-0.8, Steps=40432, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4956, Total reward=-0.7, Steps=40444, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4957, Total reward=-1.0, Steps=40459, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4958, Total reward=-1, Steps=40462, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4959, Total reward=-1, Steps=40465, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4960, Total reward=-1, Steps=40469, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4961, Total reward=-1.3, Steps=40475, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4962, Total reward=-1.3, Steps=40482, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4963, Total reward=-2.3, Steps=40500, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4964, Total reward=0.3, Steps=40511, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4965, Total reward=-0.4, Steps=40520, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4966, Total reward=-0.1, Steps=40526, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4967, Total reward=-1.0, Steps=40541, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4968, Total reward=-1, Steps=40545, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4969, Total reward=-1, Steps=40548, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4970, Total reward=-1.2, Steps=40553, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4971, Total reward=-2.5, Steps=40573, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4972, Total reward=-1, Steps=40577, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4973, Total reward=-2.7, Steps=40599, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4974, Total reward=-0.8, Steps=40612, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4975, Total reward=-0.5, Steps=40622, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4976, Total reward=1, Steps=40626, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4977, Total reward=-2.2, Steps=40643, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4978, Total reward=-1.2, Steps=40649, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4979, Total reward=-1.3, Steps=40656, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4980, Total reward=-3.0, Steps=40681, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4981, Total reward=0.7, Steps=40688, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4982, Total reward=-1.1, Steps=40692, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4983, Total reward=0.7, Steps=40699, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4984, Total reward=-0.9, Steps=40713, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4985, Total reward=-1.3, Steps=40719, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4986, Total reward=-1.1, Steps=40723, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4987, Total reward=-1.1, Steps=40727, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4988, Total reward=-1.1, Steps=40731, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4989, Total reward=-1.1, Steps=40735, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4990, Total reward=-1.1, Steps=40739, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4991, Total reward=-2.1, Steps=40754, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4992, Total reward=0.4, Steps=40764, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4993, Total reward=-0.7, Steps=40776, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4994, Total reward=-2.0, Steps=40790, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4995, Total reward=-2.5, Steps=40810, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4996, Total reward=-1, Steps=40813, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4997, Total reward=-1.6, Steps=40823, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4998, Total reward=1, Steps=40827, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=4999, Total reward=-0.9, Steps=40841, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5000, Total reward=-0.8, Steps=40854, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5001, Total reward=-1.1, Steps=40859, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5002, Total reward=-2.1, Steps=40873, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5003, Total reward=-1.4, Steps=40892, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5004, Total reward=-1, Steps=40895, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5005, Total reward=-1, Steps=40898, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5006, Total reward=-2.2, Steps=40915, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5007, Total reward=-1, Steps=40918, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5008, Total reward=-0.4, Steps=40927, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5009, Total reward=-2.1, Steps=40941, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5010, Total reward=-1.2, Steps=40947, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5011, Total reward=-1.2, Steps=40952, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5012, Total reward=-1, Steps=40956, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5013, Total reward=0.6, Steps=40964, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5014, Total reward=-2.0, Steps=40979, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5015, Total reward=-0.4, Steps=40988, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5016, Total reward=-1.1, Steps=41004, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5017, Total reward=-0.2, Steps=41021, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5018, Total reward=-1.7, Steps=41032, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5019, Total reward=-0.4, Steps=41041, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5020, Total reward=0.9, Steps=41046, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5021, Total reward=-0.7, Steps=41058, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5022, Total reward=-0.2, Steps=41065, Training iteration=19\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5023, Total reward=-1.7, Steps=41075, Training iteration=19\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0014235026901587844, KL divergence=[0.], Entropy=[-0.02017503], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013155472464859486, KL divergence=[0.], Entropy=[-0.02033256], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011929185129702091, KL divergence=[0.], Entropy=[-0.02032431], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01056735496968031, KL divergence=[0.], Entropy=[-0.02038362], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018984312191605568, KL divergence=[0.], Entropy=[-0.02034347], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.019201116636395454, KL divergence=[0.], Entropy=[-0.0202901], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.016256073489785194, KL divergence=[0.], Entropy=[-0.02029835], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014746058732271194, KL divergence=[0.], Entropy=[-0.02029689], training epoch=7, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.015470999293029308, KL divergence=[0.], Entropy=[-0.02025846], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.015366313979029655, KL divergence=[0.], Entropy=[-0.02029875], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/39_Step-41075.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/39_Step-41075.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5024, Total reward=-1, Steps=41079, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5025, Total reward=-1.3, Steps=41085, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5026, Total reward=-3.1, Steps=41111, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5027, Total reward=-1.5, Steps=41120, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5028, Total reward=-1, Steps=41123, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5029, Total reward=-1.3, Steps=41130, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5030, Total reward=-1.7, Steps=41141, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5031, Total reward=-1.2, Steps=41146, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5032, Total reward=-1.1, Steps=41151, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5033, Total reward=-0.5, Steps=41171, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5034, Total reward=-1.1, Steps=41175, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5035, Total reward=-1.5, Steps=41184, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5036, Total reward=-1, Steps=41187, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5037, Total reward=-1, Steps=41190, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5038, Total reward=-2.1, Steps=41206, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5039, Total reward=-2.0, Steps=41221, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5040, Total reward=-2.3, Steps=41239, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5041, Total reward=-2.4, Steps=41258, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5042, Total reward=0.7, Steps=41265, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5043, Total reward=-1.2, Steps=41270, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5044, Total reward=-1.1, Steps=41274, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5045, Total reward=-1.3, Steps=41280, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5046, Total reward=-1.5, Steps=41289, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5047, Total reward=-1, Steps=41292, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5048, Total reward=-1.5, Steps=41300, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5049, Total reward=-1.2, Steps=41305, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5050, Total reward=-2.3, Steps=41323, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5051, Total reward=-2.0, Steps=41338, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5052, Total reward=-1, Steps=41342, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5053, Total reward=-1.2, Steps=41347, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5054, Total reward=-0.8, Steps=41360, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5055, Total reward=-2.3, Steps=41377, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5056, Total reward=0.8, Steps=41383, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5057, Total reward=0.8, Steps=41389, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5058, Total reward=-0.1, Steps=41395, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5059, Total reward=-1.4, Steps=41403, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5060, Total reward=-0.9, Steps=41417, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5061, Total reward=-2.8, Steps=41440, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5062, Total reward=-2.1, Steps=41456, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5063, Total reward=-2.0, Steps=41470, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5064, Total reward=-1.3, Steps=41476, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5065, Total reward=-1.2, Steps=41481, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5066, Total reward=0.8, Steps=41486, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5067, Total reward=-1.2, Steps=41492, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5068, Total reward=0.9, Steps=41497, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5069, Total reward=-1.3, Steps=41504, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5070, Total reward=-1.2, Steps=41509, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5071, Total reward=-1.2, Steps=41515, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5072, Total reward=-1.2, Steps=41520, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5073, Total reward=-1.2, Steps=41526, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5074, Total reward=0.8, Steps=41532, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5075, Total reward=-1.1, Steps=41536, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5076, Total reward=-1, Steps=41540, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5077, Total reward=-2.3, Steps=41558, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5078, Total reward=-1.2, Steps=41564, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5079, Total reward=-2.4, Steps=41583, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5080, Total reward=0.9, Steps=41588, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5081, Total reward=0.7, Steps=41596, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5082, Total reward=-1.2, Steps=41602, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5083, Total reward=-1.1, Steps=41606, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5084, Total reward=-1.1, Steps=41611, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5085, Total reward=-0.4, Steps=41630, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5086, Total reward=-1.1, Steps=41634, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5087, Total reward=-0.4, Steps=41643, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5088, Total reward=-1, Steps=41646, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5089, Total reward=0.8, Steps=41652, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5090, Total reward=-1.1, Steps=41656, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5091, Total reward=-1.4, Steps=41664, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5092, Total reward=0.6, Steps=41672, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5093, Total reward=-1, Steps=41675, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5094, Total reward=-1.5, Steps=41684, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5095, Total reward=-1.5, Steps=41693, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5096, Total reward=-2.3, Steps=41711, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5097, Total reward=-0.2, Steps=41718, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5098, Total reward=-1.1, Steps=41723, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5099, Total reward=-1.3, Steps=41730, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5100, Total reward=-0.8, Steps=41743, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5101, Total reward=-0.3, Steps=41751, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5102, Total reward=0.8, Steps=41757, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5103, Total reward=-1.1, Steps=41761, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5104, Total reward=0.4, Steps=41771, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5105, Total reward=-1.1, Steps=41775, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5106, Total reward=-1, Steps=41778, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5107, Total reward=-1.2, Steps=41783, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5108, Total reward=-1.1, Steps=41787, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5109, Total reward=-0.2, Steps=41794, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5110, Total reward=-1.2, Steps=41799, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5111, Total reward=0.8, Steps=41805, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5112, Total reward=0.7, Steps=41812, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5113, Total reward=-1.2, Steps=41817, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5114, Total reward=-1.1, Steps=41821, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5115, Total reward=-0.4, Steps=41830, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5116, Total reward=-1.2, Steps=41836, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5117, Total reward=-1.1, Steps=41840, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5118, Total reward=-2.2, Steps=41856, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5119, Total reward=-1.1, Steps=41861, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5120, Total reward=-2.2, Steps=41878, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5121, Total reward=-1.2, Steps=41884, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5122, Total reward=0.8, Steps=41890, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5123, Total reward=-2.2, Steps=41906, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5124, Total reward=-2.7, Steps=41928, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5125, Total reward=-1, Steps=41932, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5126, Total reward=-2.0, Steps=41947, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5127, Total reward=-1.4, Steps=41954, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5128, Total reward=0.6, Steps=41962, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5129, Total reward=-1.5, Steps=41970, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5130, Total reward=0.9, Steps=41975, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5131, Total reward=1, Steps=41979, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5132, Total reward=0.9, Steps=41984, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5133, Total reward=-1.2, Steps=41990, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5134, Total reward=-1.3, Steps=41997, Training iteration=20\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5134, Total reward=-2.0, Steps=42000, Training iteration=20\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5134, Total reward=-2.0, Steps=42000, Training iteration=20\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5134, Total reward=-2.0, Steps=42000, Training iteration=20\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5134, Total reward=-2.0, Steps=42000, Training iteration=20\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5134, Total reward=-2.0, Steps=42000, Training iteration=20\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5135, Total reward=-1.1, Steps=42004, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5136, Total reward=-1.1, Steps=42009, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5137, Total reward=-1.1, Steps=42013, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5138, Total reward=-1.1, Steps=42017, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5139, Total reward=-2.0, Steps=42031, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5140, Total reward=0.8, Steps=42037, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5141, Total reward=0.8, Steps=42043, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5142, Total reward=-0.7, Steps=42055, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5143, Total reward=-2.1, Steps=42071, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5144, Total reward=-0.9, Steps=42085, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5145, Total reward=-0.4, Steps=42094, Training iteration=20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5146, Total reward=-1.6, Steps=42104, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5147, Total reward=-1.1, Steps=42109, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5148, Total reward=-2.2, Steps=42126, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5149, Total reward=-2.4, Steps=42145, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5150, Total reward=-0.5, Steps=42155, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5151, Total reward=-1, Steps=42158, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5152, Total reward=-0.2, Steps=42165, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5153, Total reward=-1, Steps=42168, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5154, Total reward=-1.0, Steps=42183, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5155, Total reward=-1.4, Steps=42191, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5156, Total reward=-1.1, Steps=42196, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5157, Total reward=-1.3, Steps=42203, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5158, Total reward=-1.1, Steps=42208, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5159, Total reward=0.8, Steps=42214, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5160, Total reward=-1.1, Steps=42219, Training iteration=20\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/40_Step-42221.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/40_Step-42221.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5161, Total reward=-1.2, Steps=42225, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5162, Total reward=-1.0, Steps=42240, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5163, Total reward=-1.4, Steps=42247, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5164, Total reward=-1, Steps=42250, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5165, Total reward=-1.1, Steps=42254, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5166, Total reward=-1.6, Steps=42264, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5167, Total reward=-1.1, Steps=42268, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5168, Total reward=1, Steps=42272, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5169, Total reward=-1.1, Steps=42276, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5170, Total reward=-1.1, Steps=42280, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5171, Total reward=-1.5, Steps=42288, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5172, Total reward=-1.6, Steps=42298, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5173, Total reward=-1.4, Steps=42317, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5174, Total reward=-1.5, Steps=42326, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5175, Total reward=1, Steps=42330, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5176, Total reward=0.9, Steps=42335, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5177, Total reward=-1.1, Steps=42339, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5178, Total reward=-1, Steps=42342, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5179, Total reward=-1.1, Steps=42347, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5180, Total reward=-1.3, Steps=42353, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5181, Total reward=-1, Steps=42356, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5182, Total reward=-1.3, Steps=42363, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5183, Total reward=-2.7, Steps=42385, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5184, Total reward=-1.2, Steps=42390, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5185, Total reward=-1.1, Steps=42394, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5186, Total reward=0.4, Steps=42404, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5187, Total reward=-1.1, Steps=42409, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5188, Total reward=-1.2, Steps=42414, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5189, Total reward=-1.5, Steps=42423, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5190, Total reward=-1.4, Steps=42431, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5191, Total reward=-1.2, Steps=42436, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5192, Total reward=-1, Steps=42439, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5193, Total reward=0.6, Steps=42448, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5194, Total reward=-0.9, Steps=42462, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5195, Total reward=-2.1, Steps=42477, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5196, Total reward=-1, Steps=42480, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5197, Total reward=0.9, Steps=42485, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5198, Total reward=-1.3, Steps=42491, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5199, Total reward=-2.5, Steps=42511, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5200, Total reward=-0.5, Steps=42521, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5201, Total reward=-1.2, Steps=42526, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5202, Total reward=-1.8, Steps=42538, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5203, Total reward=-1.1, Steps=42542, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5204, Total reward=-1.5, Steps=42562, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5205, Total reward=-1, Steps=42565, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5206, Total reward=-1.0, Steps=42580, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5207, Total reward=0.7, Steps=42587, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5208, Total reward=-0.6, Steps=42598, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5209, Total reward=-1.3, Steps=42604, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5210, Total reward=-1, Steps=42607, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5211, Total reward=1, Steps=42611, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5212, Total reward=0, Steps=42616, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5213, Total reward=-1, Steps=42619, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5214, Total reward=-1, Steps=42622, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5215, Total reward=-1, Steps=42625, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5216, Total reward=-1.1, Steps=42630, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5217, Total reward=-1, Steps=42633, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5218, Total reward=-1.3, Steps=42639, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5219, Total reward=-1, Steps=42643, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5220, Total reward=-0.2, Steps=42650, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5221, Total reward=-1.1, Steps=42655, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5222, Total reward=-0.6, Steps=42666, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5223, Total reward=-1.2, Steps=42671, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5224, Total reward=-1.7, Steps=42682, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5225, Total reward=0.9, Steps=42687, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5226, Total reward=-2.1, Steps=42702, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5227, Total reward=-0.8, Steps=42715, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5228, Total reward=-2.0, Steps=42730, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5229, Total reward=-1, Steps=42734, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5230, Total reward=-1.5, Steps=42743, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5231, Total reward=-1.5, Steps=42752, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5232, Total reward=-1, Steps=42755, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5233, Total reward=-0.4, Steps=42764, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5234, Total reward=-0.7, Steps=42776, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5235, Total reward=-1.2, Steps=42782, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5236, Total reward=-1.4, Steps=42789, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5237, Total reward=-1, Steps=42793, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5238, Total reward=-1.2, Steps=42798, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5239, Total reward=-1, Steps=42801, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5240, Total reward=-1, Steps=42804, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5241, Total reward=-1.6, Steps=42813, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5242, Total reward=-1.8, Steps=42825, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5243, Total reward=-0.1, Steps=42831, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5244, Total reward=-1, Steps=42834, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5245, Total reward=-1.2, Steps=42840, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5246, Total reward=-0.6, Steps=42851, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5247, Total reward=-1, Steps=42854, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5248, Total reward=-0.7, Steps=42876, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5249, Total reward=-1.1, Steps=42880, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5250, Total reward=-1.2, Steps=42885, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5251, Total reward=-0.5, Steps=42895, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5252, Total reward=-1.1, Steps=42900, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5253, Total reward=-0.2, Steps=42907, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5254, Total reward=-2.8, Steps=42930, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5255, Total reward=-1.1, Steps=42934, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5256, Total reward=-2.6, Steps=42955, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5257, Total reward=-2.0, Steps=42970, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5258, Total reward=-1, Steps=42973, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5259, Total reward=-1.9, Steps=42986, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5260, Total reward=-1.1, Steps=42990, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5261, Total reward=-0.7, Steps=43002, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5262, Total reward=-1.2, Steps=43007, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5263, Total reward=-1, Steps=43010, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5264, Total reward=0.9, Steps=43015, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5265, Total reward=-1.1, Steps=43019, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5266, Total reward=-1, Steps=43023, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5267, Total reward=-1.6, Steps=43033, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5268, Total reward=-1.2, Steps=43038, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5269, Total reward=-1.1, Steps=43043, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5270, Total reward=-1.3, Steps=43049, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5271, Total reward=-1, Steps=43052, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5272, Total reward=-0.6, Steps=43063, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5273, Total reward=-1.4, Steps=43071, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5274, Total reward=-1.2, Steps=43076, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5275, Total reward=-1.3, Steps=43083, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5276, Total reward=-0.1, Steps=43089, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5277, Total reward=-1.1, Steps=43093, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5278, Total reward=-1.2, Steps=43098, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5279, Total reward=-1.4, Steps=43105, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5280, Total reward=-1.1, Steps=43109, Training iteration=20\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5281, Total reward=-1.0, Steps=43124, Training iteration=20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=0.008609688840806484, KL divergence=[0.], Entropy=[-0.02019304], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.017000550404191017, KL divergence=[0.], Entropy=[-0.02012397], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008341547101736069, KL divergence=[0.], Entropy=[-0.02010873], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.024310817942023277, KL divergence=[0.], Entropy=[-0.02006064], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013124095275998116, KL divergence=[0.], Entropy=[-0.02000138], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.00766280060634017, KL divergence=[0.], Entropy=[-0.02001655], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013710000552237034, KL divergence=[0.], Entropy=[-0.01994273], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.018344881013035774, KL divergence=[0.], Entropy=[-0.01997753], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01547254715114832, KL divergence=[0.], Entropy=[-0.01990928], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013669506646692753, KL divergence=[0.], Entropy=[-0.019898], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/41_Step-43124.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/41_Step-43124.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5282, Total reward=-1, Steps=43128, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5283, Total reward=-2.5, Steps=43148, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5284, Total reward=-1, Steps=43152, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5285, Total reward=-1.3, Steps=43159, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5286, Total reward=-1.2, Steps=43164, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5287, Total reward=-1, Steps=43167, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5288, Total reward=-2.5, Steps=43187, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5289, Total reward=-1.2, Steps=43193, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5290, Total reward=-1.1, Steps=43197, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5291, Total reward=-1.2, Steps=43203, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5292, Total reward=0.6, Steps=43210, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5293, Total reward=-1, Steps=43213, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5294, Total reward=-1.1, Steps=43217, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5295, Total reward=-1.3, Steps=43223, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5296, Total reward=-1.5, Steps=43231, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5297, Total reward=-1, Steps=43234, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5298, Total reward=-1, Steps=43237, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5299, Total reward=-1, Steps=43240, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5300, Total reward=-1.1, Steps=43244, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5301, Total reward=-1.4, Steps=43252, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5302, Total reward=-0.4, Steps=43261, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5303, Total reward=-1, Steps=43264, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5304, Total reward=-1, Steps=43267, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5305, Total reward=-1.4, Steps=43286, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5306, Total reward=-1.4, Steps=43293, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5307, Total reward=0.7, Steps=43299, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5308, Total reward=-1, Steps=43302, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5309, Total reward=-1, Steps=43305, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5310, Total reward=-1.7, Steps=43316, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5311, Total reward=-2.3, Steps=43334, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5312, Total reward=-2.4, Steps=43352, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5313, Total reward=-1.3, Steps=43358, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5314, Total reward=-0.3, Steps=43366, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5315, Total reward=-1.8, Steps=43377, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5316, Total reward=-1.3, Steps=43383, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5317, Total reward=-0.2, Steps=43390, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5318, Total reward=-1.2, Steps=43407, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5319, Total reward=-1.1, Steps=43423, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5320, Total reward=-2.3, Steps=43441, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5321, Total reward=-0.4, Steps=43450, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5322, Total reward=-1, Steps=43453, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5323, Total reward=-3.0, Steps=43478, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5324, Total reward=1, Steps=43482, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5325, Total reward=-0.6, Steps=43493, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5326, Total reward=-0.6, Steps=43504, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5327, Total reward=0.8, Steps=43509, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5328, Total reward=-1.1, Steps=43513, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5329, Total reward=-1.1, Steps=43517, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5330, Total reward=-1.1, Steps=43521, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5331, Total reward=-1.1, Steps=43525, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5332, Total reward=-1.2, Steps=43531, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5333, Total reward=-0.6, Steps=43542, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5334, Total reward=0.2, Steps=43554, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5335, Total reward=-1, Steps=43558, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5336, Total reward=-1.5, Steps=43567, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5337, Total reward=-0.6, Steps=43578, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5338, Total reward=-1.2, Steps=43595, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5339, Total reward=-1, Steps=43598, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5340, Total reward=-0.1, Steps=43604, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5341, Total reward=-1, Steps=43607, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5342, Total reward=0.7, Steps=43614, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5343, Total reward=-1.1, Steps=43618, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5344, Total reward=-1, Steps=43622, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5345, Total reward=-2.6, Steps=43643, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5346, Total reward=-1, Steps=43647, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5347, Total reward=-1.3, Steps=43653, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5348, Total reward=1, Steps=43657, Training iteration=21\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5349, Total reward=-1.8, Steps=43669, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5350, Total reward=-1.1, Steps=43673, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5351, Total reward=-1.1, Steps=43677, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5352, Total reward=-1, Steps=43680, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5353, Total reward=-1.1, Steps=43684, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5354, Total reward=-1.2, Steps=43690, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5355, Total reward=-1, Steps=43693, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5356, Total reward=-1.1, Steps=43697, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5357, Total reward=-1.2, Steps=43702, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5358, Total reward=-1.2, Steps=43707, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5359, Total reward=-1.1, Steps=43711, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5360, Total reward=-2.2, Steps=43728, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5361, Total reward=-1, Steps=43731, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5362, Total reward=-1.1, Steps=43735, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5363, Total reward=0.9, Steps=43740, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5364, Total reward=-1.1, Steps=43744, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5365, Total reward=-2.5, Steps=43763, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5366, Total reward=-1.1, Steps=43768, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5367, Total reward=-1.7, Steps=43779, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5368, Total reward=-2.8, Steps=43802, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5369, Total reward=-1.5, Steps=43811, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5370, Total reward=-2.5, Steps=43831, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5371, Total reward=-2.1, Steps=43847, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5372, Total reward=-1, Steps=43850, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5373, Total reward=-2.1, Steps=43866, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5374, Total reward=0.3, Steps=43877, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5375, Total reward=-1, Steps=43880, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5376, Total reward=0.6, Steps=43889, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5377, Total reward=-1.1, Steps=43893, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5378, Total reward=0.6, Steps=43901, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5379, Total reward=-1.2, Steps=43907, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5380, Total reward=0.0, Steps=43922, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5381, Total reward=-2.0, Steps=43937, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5382, Total reward=-1, Steps=43940, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5383, Total reward=-1.4, Steps=43947, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5384, Total reward=-1.0, Steps=43962, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5385, Total reward=-0.5, Steps=43972, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5386, Total reward=-1.3, Steps=43979, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5387, Total reward=-0.1, Steps=43994, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5388, Total reward=-1.1, Steps=43998, Training iteration=21\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5388, Total reward=-2.0, Steps=44000, Training iteration=21\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5388, Total reward=1, Steps=44000, Training iteration=21\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5388, Total reward=-2.0, Steps=44000, Training iteration=21\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5388, Total reward=-2.0, Steps=44000, Training iteration=21\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5388, Total reward=1, Steps=44000, Training iteration=21\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -0.8\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5389, Total reward=0, Steps=44005, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5390, Total reward=-1, Steps=44008, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5391, Total reward=-1.1, Steps=44012, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5392, Total reward=-1, Steps=44015, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5393, Total reward=0.3, Steps=44027, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5394, Total reward=-1.5, Steps=44035, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5395, Total reward=-2.0, Steps=44049, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5396, Total reward=-2.0, Steps=44064, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5397, Total reward=-1.2, Steps=44069, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5398, Total reward=-1.1, Steps=44074, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5399, Total reward=-1.6, Steps=44084, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5400, Total reward=-1.2, Steps=44090, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5401, Total reward=-0.4, Steps=44099, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5402, Total reward=-0.6, Steps=44110, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5403, Total reward=-1.1, Steps=44114, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5404, Total reward=-1.1, Steps=44118, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5405, Total reward=0.2, Steps=44131, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5406, Total reward=-2.0, Steps=44146, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5407, Total reward=-1, Steps=44150, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5408, Total reward=-2.2, Steps=44167, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5409, Total reward=-1, Steps=44170, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5410, Total reward=-0.4, Steps=44179, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5411, Total reward=-1, Steps=44183, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5412, Total reward=-1.5, Steps=44191, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5413, Total reward=-1.0, Steps=44206, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5414, Total reward=-2.7, Steps=44228, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5415, Total reward=-2.3, Steps=44245, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5416, Total reward=-1.5, Steps=44254, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5417, Total reward=-1.3, Steps=44260, Training iteration=21\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/42_Step-44260.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/42_Step-44260.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5418, Total reward=-1, Steps=44263, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5419, Total reward=-1.5, Steps=44272, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5420, Total reward=-1.7, Steps=44283, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5421, Total reward=0.2, Steps=44295, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5422, Total reward=-1.6, Steps=44305, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5423, Total reward=-0.5, Steps=44315, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5424, Total reward=-1.2, Steps=44320, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5425, Total reward=-0.7, Steps=44332, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5426, Total reward=-0.2, Steps=44339, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5427, Total reward=-1.3, Steps=44357, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5428, Total reward=0.8, Steps=44363, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5429, Total reward=-2.2, Steps=44380, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5430, Total reward=-1, Steps=44383, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5431, Total reward=-1.2, Steps=44389, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5432, Total reward=1, Steps=44393, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5433, Total reward=-1.1, Steps=44397, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5434, Total reward=-2.1, Steps=44413, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5435, Total reward=-1.1, Steps=44417, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5436, Total reward=-1.4, Steps=44424, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5437, Total reward=-1, Steps=44427, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5438, Total reward=-1.3, Steps=44433, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5439, Total reward=0.5, Steps=44442, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5440, Total reward=-1, Steps=44445, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5441, Total reward=-2.0, Steps=44460, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5442, Total reward=-0.8, Steps=44473, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5443, Total reward=-1.1, Steps=44478, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5444, Total reward=0.4, Steps=44488, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5445, Total reward=-2.0, Steps=44502, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5446, Total reward=0.9, Steps=44507, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5447, Total reward=0.9, Steps=44511, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5448, Total reward=-1, Steps=44514, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5449, Total reward=-1.1, Steps=44518, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5450, Total reward=-1, Steps=44521, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5451, Total reward=-1.3, Steps=44528, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5452, Total reward=1, Steps=44532, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5453, Total reward=-1.1, Steps=44536, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5454, Total reward=-1.7, Steps=44547, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5455, Total reward=-1.1, Steps=44551, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5456, Total reward=-1, Steps=44555, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5457, Total reward=-1, Steps=44559, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5458, Total reward=-1.1, Steps=44563, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5459, Total reward=-2.3, Steps=44581, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5460, Total reward=-0.3, Steps=44589, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5461, Total reward=-2.0, Steps=44603, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5462, Total reward=1, Steps=44606, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5463, Total reward=-1.2, Steps=44612, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5464, Total reward=-1.2, Steps=44617, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5465, Total reward=-0.5, Steps=44627, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5466, Total reward=0.8, Steps=44633, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5467, Total reward=-1, Steps=44636, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5468, Total reward=-2.3, Steps=44654, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5469, Total reward=0.8, Steps=44660, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5470, Total reward=-1, Steps=44663, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5471, Total reward=-1.1, Steps=44667, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5472, Total reward=-1, Steps=44670, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5473, Total reward=-1.3, Steps=44677, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5474, Total reward=-2.0, Steps=44691, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5475, Total reward=-2.1, Steps=44706, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5476, Total reward=-1, Steps=44710, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5477, Total reward=-1.3, Steps=44717, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5478, Total reward=-2.1, Steps=44733, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5479, Total reward=-1.2, Steps=44739, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5480, Total reward=-1.2, Steps=44756, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5481, Total reward=-1, Steps=44759, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5482, Total reward=1, Steps=44762, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5483, Total reward=-1.0, Steps=44777, Training iteration=21\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5484, Total reward=-1.2, Steps=44782, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5485, Total reward=-1.3, Steps=44789, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5486, Total reward=-1.6, Steps=44798, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5487, Total reward=-1, Steps=44801, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5488, Total reward=-1.2, Steps=44806, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5489, Total reward=-1, Steps=44809, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5490, Total reward=-1.2, Steps=44815, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5491, Total reward=-0.3, Steps=44823, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5492, Total reward=-1.2, Steps=44829, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5493, Total reward=-1, Steps=44832, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5494, Total reward=-1.2, Steps=44837, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5495, Total reward=-1, Steps=44840, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5496, Total reward=0.7, Steps=44847, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5497, Total reward=-1.4, Steps=44855, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5498, Total reward=-1.3, Steps=44861, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5499, Total reward=-2.0, Steps=44874, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5500, Total reward=-1, Steps=44877, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5501, Total reward=-0.9, Steps=44891, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5502, Total reward=-2.2, Steps=44908, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5503, Total reward=0.4, Steps=44918, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5504, Total reward=-1, Steps=44921, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5505, Total reward=-1.1, Steps=44925, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5506, Total reward=0.8, Steps=44931, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5507, Total reward=-0.2, Steps=44938, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5508, Total reward=-2.1, Steps=44954, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5509, Total reward=-0.3, Steps=44962, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5510, Total reward=-0.5, Steps=44972, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5511, Total reward=-1.1, Steps=44976, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5512, Total reward=0.7, Steps=44983, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5513, Total reward=-1.2, Steps=45000, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5514, Total reward=-1.1, Steps=45004, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5515, Total reward=-0.6, Steps=45015, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5516, Total reward=-1.1, Steps=45019, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5517, Total reward=-1.3, Steps=45025, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5518, Total reward=-2.1, Steps=45041, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5519, Total reward=-2.1, Steps=45057, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5520, Total reward=-2.1, Steps=45073, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5521, Total reward=-1.9, Steps=45085, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5522, Total reward=-0.1, Steps=45091, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5523, Total reward=-1, Steps=45094, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5524, Total reward=-1.3, Steps=45100, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5525, Total reward=-1.3, Steps=45118, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5526, Total reward=-1, Steps=45121, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5527, Total reward=-1.2, Steps=45126, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5528, Total reward=-1.1, Steps=45130, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5529, Total reward=-0.1, Steps=45136, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5530, Total reward=-0.7, Steps=45148, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5531, Total reward=-2.1, Steps=45164, Training iteration=21\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5532, Total reward=-0.3, Steps=45172, Training iteration=21\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.0036058027762919664, KL divergence=[0.], Entropy=[-0.01987976], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.006310418713837862, KL divergence=[0.], Entropy=[-0.01979526], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.007485796697437763, KL divergence=[0.], Entropy=[-0.01981946], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012425757944583893, KL divergence=[0.], Entropy=[-0.01971281], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012559475377202034, KL divergence=[0.], Entropy=[-0.01977041], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.010812974534928799, KL divergence=[0.], Entropy=[-0.01971595], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.022004080936312675, KL divergence=[0.], Entropy=[-0.01960865], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01664980687201023, KL divergence=[0.], Entropy=[-0.0196612], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.020415468141436577, KL divergence=[0.], Entropy=[-0.01960966], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01701202802360058, KL divergence=[0.], Entropy=[-0.01958249], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/43_Step-45172.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/43_Step-45172.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5533, Total reward=-1.1, Steps=45176, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5534, Total reward=-1.3, Steps=45183, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5535, Total reward=-1.7, Steps=45194, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5536, Total reward=-1, Steps=45197, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5537, Total reward=-1, Steps=45200, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5538, Total reward=-1.2, Steps=45206, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5539, Total reward=-1.1, Steps=45211, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5540, Total reward=-1.2, Steps=45216, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5541, Total reward=-1.2, Steps=45221, Training iteration=22\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5542, Total reward=-1.2, Steps=45226, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5543, Total reward=-1.3, Steps=45244, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5544, Total reward=-2.5, Steps=45264, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5545, Total reward=-1.1, Steps=45268, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5546, Total reward=-1.1, Steps=45272, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5547, Total reward=-2.1, Steps=45287, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5548, Total reward=0.9, Steps=45292, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5549, Total reward=-0.6, Steps=45303, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5550, Total reward=-0.8, Steps=45316, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5551, Total reward=-1, Steps=45320, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5552, Total reward=-1.2, Steps=45325, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5553, Total reward=-0.8, Steps=45338, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5554, Total reward=-1, Steps=45341, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5555, Total reward=-1, Steps=45344, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5556, Total reward=-2.3, Steps=45361, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5557, Total reward=-1, Steps=45365, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5558, Total reward=0.9, Steps=45370, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5559, Total reward=-2.0, Steps=45384, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5560, Total reward=0.1, Steps=45397, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5561, Total reward=0.7, Steps=45404, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5562, Total reward=-0.1, Steps=45410, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5563, Total reward=-1.3, Steps=45428, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5564, Total reward=-2.1, Steps=45444, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5565, Total reward=-1.1, Steps=45448, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5566, Total reward=-1.1, Steps=45452, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5567, Total reward=-0.7, Steps=45464, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5568, Total reward=-2.5, Steps=45484, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5569, Total reward=-2.1, Steps=45500, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5570, Total reward=-1.4, Steps=45508, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5571, Total reward=-0.5, Steps=45518, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5572, Total reward=0.7, Steps=45525, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5573, Total reward=-1.5, Steps=45533, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5574, Total reward=0.3, Steps=45544, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5575, Total reward=-1.4, Steps=45552, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5576, Total reward=-1.5, Steps=45560, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5577, Total reward=-1, Steps=45563, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5578, Total reward=-2.2, Steps=45580, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5579, Total reward=-1, Steps=45583, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5580, Total reward=-1, Steps=45586, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5581, Total reward=-1.3, Steps=45604, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5582, Total reward=-2.2, Steps=45621, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5583, Total reward=-1.1, Steps=45625, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5584, Total reward=-0.5, Steps=45635, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5585, Total reward=-1.7, Steps=45645, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5586, Total reward=-1, Steps=45648, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5587, Total reward=0.4, Steps=45658, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5588, Total reward=-2.1, Steps=45674, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5589, Total reward=-1.5, Steps=45682, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5590, Total reward=-1, Steps=45685, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5591, Total reward=-1, Steps=45689, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5592, Total reward=-1.1, Steps=45693, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5593, Total reward=-1, Steps=45696, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5594, Total reward=-0.8, Steps=45709, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5595, Total reward=-1.2, Steps=45715, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5596, Total reward=-1.1, Steps=45731, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5597, Total reward=-2.2, Steps=45748, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5598, Total reward=-1, Steps=45751, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5599, Total reward=-1, Steps=45754, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5600, Total reward=-2.3, Steps=45771, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5601, Total reward=-1.4, Steps=45779, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5602, Total reward=-0.4, Steps=45788, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5603, Total reward=-2.3, Steps=45806, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5604, Total reward=-1.8, Steps=45817, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5605, Total reward=-1.1, Steps=45821, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5606, Total reward=-2.1, Steps=45837, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5607, Total reward=-1.4, Steps=45856, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5608, Total reward=-1, Steps=45859, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5609, Total reward=-1.2, Steps=45864, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5610, Total reward=-1.2, Steps=45869, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5611, Total reward=-0.8, Steps=45882, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5612, Total reward=-0.7, Steps=45894, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5613, Total reward=-1, Steps=45897, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5614, Total reward=-1.2, Steps=45902, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5615, Total reward=-0.3, Steps=45910, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5616, Total reward=-1.1, Steps=45914, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5617, Total reward=-1.1, Steps=45919, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5618, Total reward=-1.9, Steps=45932, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5619, Total reward=-1.3, Steps=45938, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5620, Total reward=-1.1, Steps=45954, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5621, Total reward=-1.4, Steps=45961, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5622, Total reward=-1.1, Steps=45965, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5623, Total reward=-1, Steps=45968, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5624, Total reward=-2.2, Steps=45985, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5625, Total reward=0.7, Steps=45992, Training iteration=22\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5625, Total reward=-2.0, Steps=46000, Training iteration=22\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5625, Total reward=-2.0, Steps=46000, Training iteration=22\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5625, Total reward=-2.0, Steps=46000, Training iteration=22\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5625, Total reward=-2.0, Steps=46000, Training iteration=22\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5625, Total reward=-2.0, Steps=46000, Training iteration=22\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5626, Total reward=-1.5, Steps=46009, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5627, Total reward=-2.4, Steps=46028, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5628, Total reward=-0.8, Steps=46041, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5629, Total reward=0.4, Steps=46052, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5630, Total reward=-1.9, Steps=46064, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5631, Total reward=-1.2, Steps=46069, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5632, Total reward=-1.1, Steps=46073, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5633, Total reward=-2.1, Steps=46089, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5634, Total reward=0.6, Steps=46097, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5635, Total reward=-1.1, Steps=46101, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5636, Total reward=-1.1, Steps=46105, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5637, Total reward=-1.1, Steps=46109, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5638, Total reward=-2.6, Steps=46130, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5639, Total reward=-1.3, Steps=46137, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5640, Total reward=-2.0, Steps=46150, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5641, Total reward=0.9, Steps=46155, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5642, Total reward=0.0, Steps=46169, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5643, Total reward=-1.1, Steps=46173, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5644, Total reward=-1.2, Steps=46179, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5645, Total reward=-1.1, Steps=46183, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5646, Total reward=-1.3, Steps=46189, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5647, Total reward=-2.0, Steps=46203, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5648, Total reward=1, Steps=46207, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5649, Total reward=-1, Steps=46210, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5650, Total reward=-1, Steps=46214, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5651, Total reward=0.5, Steps=46223, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5652, Total reward=-1.2, Steps=46240, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5653, Total reward=-1.6, Steps=46250, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5654, Total reward=1, Steps=46254, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5655, Total reward=-1, Steps=46257, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5656, Total reward=-2.0, Steps=46272, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5657, Total reward=-1.5, Steps=46292, Training iteration=22\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/44_Step-46292.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/44_Step-46292.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5658, Total reward=-1.0, Steps=46307, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5659, Total reward=-2.0, Steps=46321, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5660, Total reward=-1.1, Steps=46325, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5661, Total reward=-1.7, Steps=46336, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5662, Total reward=-2.1, Steps=46351, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5663, Total reward=0.5, Steps=46360, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5664, Total reward=-1, Steps=46364, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5665, Total reward=-0.8, Steps=46377, Training iteration=22\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5666, Total reward=-1.1, Steps=46381, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5667, Total reward=-0.9, Steps=46395, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5668, Total reward=-3.1, Steps=46421, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5669, Total reward=-1.2, Steps=46426, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5670, Total reward=-1.5, Steps=46435, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5671, Total reward=-2.1, Steps=46451, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5672, Total reward=-1.1, Steps=46455, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5673, Total reward=-2.0, Steps=46470, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5674, Total reward=0.2, Steps=46482, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5675, Total reward=-0.1, Steps=46488, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5676, Total reward=-1, Steps=46491, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5677, Total reward=-0.8, Steps=46504, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5678, Total reward=0.9, Steps=46509, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5679, Total reward=-0.2, Steps=46516, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5680, Total reward=-2.8, Steps=46539, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5681, Total reward=-0.6, Steps=46550, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5682, Total reward=-1.2, Steps=46555, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5683, Total reward=-1.1, Steps=46559, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5684, Total reward=-1, Steps=46562, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5685, Total reward=-0.4, Steps=46571, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5686, Total reward=-1.1, Steps=46576, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5687, Total reward=-1, Steps=46579, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5688, Total reward=-1.4, Steps=46587, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5689, Total reward=-1.2, Steps=46593, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5690, Total reward=-2.0, Steps=46608, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5691, Total reward=-1, Steps=46612, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5692, Total reward=-1.2, Steps=46618, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5693, Total reward=-1.2, Steps=46623, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5694, Total reward=-1.1, Steps=46627, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5695, Total reward=-1.1, Steps=46643, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5696, Total reward=-1, Steps=46646, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5697, Total reward=-2.0, Steps=46661, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5698, Total reward=-0.6, Steps=46672, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5699, Total reward=0.9, Steps=46677, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5700, Total reward=-1, Steps=46680, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5701, Total reward=-1.4, Steps=46687, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5702, Total reward=-1, Steps=46691, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5703, Total reward=1, Steps=46694, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5704, Total reward=-1.1, Steps=46698, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5705, Total reward=-1.2, Steps=46703, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5706, Total reward=1, Steps=46706, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5707, Total reward=-1.1, Steps=46711, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5708, Total reward=-1.4, Steps=46719, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5709, Total reward=-2.2, Steps=46736, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5710, Total reward=0.9, Steps=46741, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5711, Total reward=-1, Steps=46744, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5712, Total reward=-0.9, Steps=46758, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5713, Total reward=-1.4, Steps=46766, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5714, Total reward=0.2, Steps=46778, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5715, Total reward=-1.4, Steps=46785, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5716, Total reward=-2.3, Steps=46803, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5717, Total reward=0.8, Steps=46809, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5718, Total reward=-2.8, Steps=46832, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5719, Total reward=-1, Steps=46835, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5720, Total reward=-1.1, Steps=46839, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5721, Total reward=-1.1, Steps=46843, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5722, Total reward=-2.3, Steps=46860, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5723, Total reward=-1.1, Steps=46864, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5724, Total reward=-2.1, Steps=46879, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5725, Total reward=-2.0, Steps=46893, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5726, Total reward=-1, Steps=46896, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5727, Total reward=0.1, Steps=46909, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5728, Total reward=-0.5, Steps=46919, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5729, Total reward=-1.4, Steps=46927, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5730, Total reward=0.1, Steps=46940, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5731, Total reward=-1, Steps=46943, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5732, Total reward=-1.3, Steps=46961, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5733, Total reward=-1.1, Steps=46965, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5734, Total reward=0, Steps=46970, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5735, Total reward=0.6, Steps=46978, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5736, Total reward=-0.3, Steps=46996, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5737, Total reward=-1.7, Steps=47007, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5738, Total reward=-1.4, Steps=47026, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5739, Total reward=0.7, Steps=47033, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5740, Total reward=-1.1, Steps=47037, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5741, Total reward=-1.2, Steps=47042, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5742, Total reward=-1, Steps=47046, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5743, Total reward=-1, Steps=47049, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5744, Total reward=-1.1, Steps=47053, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5745, Total reward=0, Steps=47058, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5746, Total reward=-1.2, Steps=47063, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5747, Total reward=0.2, Steps=47075, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5748, Total reward=-0.8, Steps=47088, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5749, Total reward=0.6, Steps=47096, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5750, Total reward=-1.2, Steps=47113, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5751, Total reward=-1.1, Steps=47117, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5752, Total reward=-1.1, Steps=47122, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5753, Total reward=-2.1, Steps=47138, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5754, Total reward=-1.1, Steps=47142, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5755, Total reward=-1.3, Steps=47148, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5756, Total reward=-1.1, Steps=47152, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5757, Total reward=-1.1, Steps=47157, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5758, Total reward=-2.5, Steps=47177, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5759, Total reward=-1.1, Steps=47182, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5760, Total reward=-1.2, Steps=47187, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5761, Total reward=-1.3, Steps=47193, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5762, Total reward=-0.5, Steps=47203, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5763, Total reward=-1.1, Steps=47207, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5764, Total reward=-0.4, Steps=47216, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5765, Total reward=-1, Steps=47219, Training iteration=22\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5766, Total reward=-0.5, Steps=47229, Training iteration=22\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.0017371077556163073, KL divergence=[0.], Entropy=[-0.01973692], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.008568063378334045, KL divergence=[0.], Entropy=[-0.01982828], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.010672371834516525, KL divergence=[0.], Entropy=[-0.01983923], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011739506386220455, KL divergence=[0.], Entropy=[-0.01982031], training epoch=3, learning_rate=0.00025\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPolicy training> Surrogate loss=-0.013428492471575737, KL divergence=[0.], Entropy=[-0.01978944], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013824593275785446, KL divergence=[0.], Entropy=[-0.01980574], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01403997465968132, KL divergence=[0.], Entropy=[-0.0197537], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014880860224366188, KL divergence=[0.], Entropy=[-0.01974027], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013231315650045872, KL divergence=[0.], Entropy=[-0.01975147], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013218604028224945, KL divergence=[0.], Entropy=[-0.01968562], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/45_Step-47229.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/45_Step-47229.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5767, Total reward=-2.0, Steps=47244, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5768, Total reward=-2.3, Steps=47262, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5769, Total reward=0, Steps=47267, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5770, Total reward=-0.6, Steps=47278, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5771, Total reward=-2.3, Steps=47296, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5772, Total reward=-1, Steps=47299, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5773, Total reward=-1, Steps=47303, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5774, Total reward=-1.2, Steps=47308, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5775, Total reward=-1.3, Steps=47315, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5776, Total reward=-1.2, Steps=47321, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5777, Total reward=-2.1, Steps=47336, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5778, Total reward=-1.2, Steps=47342, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5779, Total reward=-1.4, Steps=47349, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5780, Total reward=-1.2, Steps=47354, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5781, Total reward=-1, Steps=47358, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5782, Total reward=-1.2, Steps=47363, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5783, Total reward=-1, Steps=47366, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5784, Total reward=-1, Steps=47369, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5785, Total reward=-1.2, Steps=47386, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5786, Total reward=-0.3, Steps=47394, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5787, Total reward=-1.1, Steps=47399, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5788, Total reward=-1, Steps=47403, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5789, Total reward=-1.4, Steps=47411, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5790, Total reward=-1.2, Steps=47416, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5791, Total reward=-1.5, Steps=47424, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5792, Total reward=-1, Steps=47427, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5793, Total reward=-1.1, Steps=47431, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5794, Total reward=-1.1, Steps=47435, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5795, Total reward=-1, Steps=47438, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5796, Total reward=-1.6, Steps=47447, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5797, Total reward=-1.7, Steps=47457, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5798, Total reward=-0.6, Steps=47468, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5799, Total reward=-1.8, Steps=47480, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5800, Total reward=0.9, Steps=47485, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5801, Total reward=-0.3, Steps=47493, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5802, Total reward=-0.5, Steps=47503, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5803, Total reward=-1.1, Steps=47507, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5804, Total reward=0.9, Steps=47512, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5805, Total reward=-2.2, Steps=47529, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5806, Total reward=-1.1, Steps=47534, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5807, Total reward=-1.1, Steps=47539, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5808, Total reward=-1, Steps=47542, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5809, Total reward=-2.3, Steps=47560, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5810, Total reward=-1.1, Steps=47564, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5811, Total reward=1, Steps=47567, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5812, Total reward=-1.3, Steps=47573, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5813, Total reward=-1, Steps=47576, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5814, Total reward=-1.1, Steps=47580, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5815, Total reward=-2.1, Steps=47596, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5816, Total reward=-1.0, Steps=47611, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5817, Total reward=-1.5, Steps=47619, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5818, Total reward=-1.3, Steps=47625, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5819, Total reward=-0.5, Steps=47635, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5820, Total reward=0.8, Steps=47642, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5821, Total reward=-0.2, Steps=47649, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5822, Total reward=-1, Steps=47652, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5823, Total reward=-1, Steps=47655, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5824, Total reward=-1.4, Steps=47662, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5825, Total reward=-1.5, Steps=47682, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5826, Total reward=-2.6, Steps=47703, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5827, Total reward=-0.8, Steps=47716, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5828, Total reward=0.8, Steps=47722, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5829, Total reward=-1.2, Steps=47727, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5830, Total reward=-1.5, Steps=47735, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5831, Total reward=-1.1, Steps=47740, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5832, Total reward=-1.5, Steps=47760, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5833, Total reward=-1, Steps=47763, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5834, Total reward=-0.2, Steps=47770, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5835, Total reward=-0.8, Steps=47783, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5836, Total reward=-1.1, Steps=47787, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5837, Total reward=-1.1, Steps=47792, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5838, Total reward=-1.4, Steps=47800, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5839, Total reward=-1.3, Steps=47807, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5840, Total reward=-1.2, Steps=47812, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5841, Total reward=-1, Steps=47816, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5842, Total reward=-0.3, Steps=47824, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5843, Total reward=-1, Steps=47827, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5844, Total reward=-0.3, Steps=47835, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5845, Total reward=-2.1, Steps=47851, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5846, Total reward=-1.1, Steps=47855, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5847, Total reward=-1.1, Steps=47859, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5848, Total reward=-0.1, Steps=47865, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5849, Total reward=-1.3, Steps=47872, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5850, Total reward=-1.3, Steps=47879, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5851, Total reward=-2.9, Steps=47903, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5852, Total reward=-1.1, Steps=47908, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5853, Total reward=-0.3, Steps=47916, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5854, Total reward=-1.2, Steps=47922, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5855, Total reward=-1.4, Steps=47930, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5856, Total reward=-1.2, Steps=47936, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5857, Total reward=0.8, Steps=47942, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5858, Total reward=0.8, Steps=47948, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5859, Total reward=-2.3, Steps=47966, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5860, Total reward=-1, Steps=47969, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5861, Total reward=-2.2, Steps=47986, Training iteration=23\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5861, Total reward=-2.0, Steps=48000, Training iteration=23\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5861, Total reward=-2.0, Steps=48000, Training iteration=23\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5861, Total reward=-2.0, Steps=48000, Training iteration=23\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5861, Total reward=-2.0, Steps=48000, Training iteration=23\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=5861, Total reward=1, Steps=48000, Training iteration=23\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.4\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5862, Total reward=-0.6, Steps=48011, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5863, Total reward=-1.3, Steps=48017, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5864, Total reward=-1, Steps=48020, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5865, Total reward=-0.9, Steps=48034, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5866, Total reward=-1.4, Steps=48042, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5867, Total reward=-1.5, Steps=48051, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5868, Total reward=-1.2, Steps=48056, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5869, Total reward=-1.9, Steps=48069, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5870, Total reward=-1.3, Steps=48076, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5871, Total reward=0.9, Steps=48081, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5872, Total reward=-1.1, Steps=48085, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5873, Total reward=-1.1, Steps=48089, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5874, Total reward=0.6, Steps=48097, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5875, Total reward=-1, Steps=48100, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5876, Total reward=-2.3, Steps=48117, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5877, Total reward=-0.8, Steps=48130, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5878, Total reward=-1.7, Steps=48152, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5879, Total reward=-2.3, Steps=48170, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5880, Total reward=-1.6, Steps=48179, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5881, Total reward=-1.5, Steps=48188, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5882, Total reward=-1.5, Steps=48197, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5883, Total reward=-2.3, Steps=48215, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5884, Total reward=-0.1, Steps=48221, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5885, Total reward=-1.2, Steps=48226, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5886, Total reward=-2.4, Steps=48245, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5887, Total reward=-1.1, Steps=48250, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5888, Total reward=-1.8, Steps=48261, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5889, Total reward=-1.2, Steps=48266, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5890, Total reward=-1.1, Steps=48270, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5891, Total reward=-1, Steps=48273, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5892, Total reward=-1.4, Steps=48280, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5893, Total reward=-1.6, Steps=48290, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5894, Total reward=-1.1, Steps=48295, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5895, Total reward=-1, Steps=48298, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5896, Total reward=0.6, Steps=48306, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5897, Total reward=0.5, Steps=48315, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5898, Total reward=-2.1, Steps=48330, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5899, Total reward=-1.4, Steps=48338, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5900, Total reward=-0.2, Steps=48345, Training iteration=23\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/46_Step-48345.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/46_Step-48345.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5901, Total reward=-2.8, Steps=48368, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5902, Total reward=-3.1, Steps=48394, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5903, Total reward=0.3, Steps=48406, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5904, Total reward=-1.2, Steps=48412, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5905, Total reward=0.8, Steps=48419, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5906, Total reward=-0.4, Steps=48428, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5907, Total reward=-1.4, Steps=48436, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5908, Total reward=-1.2, Steps=48441, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5909, Total reward=-1, Steps=48444, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5910, Total reward=-1.2, Steps=48449, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5911, Total reward=-1.1, Steps=48453, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5912, Total reward=-1.4, Steps=48460, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5913, Total reward=-1.3, Steps=48466, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5914, Total reward=-1.6, Steps=48476, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5915, Total reward=0.0, Steps=48490, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5916, Total reward=0.8, Steps=48496, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5917, Total reward=-0.5, Steps=48506, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5918, Total reward=0.9, Steps=48511, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5919, Total reward=-2.1, Steps=48526, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5920, Total reward=-1, Steps=48529, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5921, Total reward=-1, Steps=48532, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5922, Total reward=-1.2, Steps=48538, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5923, Total reward=-2.0, Steps=48553, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5924, Total reward=-1, Steps=48557, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5925, Total reward=-0.4, Steps=48566, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5926, Total reward=-1, Steps=48569, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5927, Total reward=-0.7, Steps=48581, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5928, Total reward=-1, Steps=48585, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5929, Total reward=-1.3, Steps=48591, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5930, Total reward=0.8, Steps=48596, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5931, Total reward=0.5, Steps=48605, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5932, Total reward=0.7, Steps=48612, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5933, Total reward=-0.8, Steps=48625, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5934, Total reward=-2.1, Steps=48641, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5935, Total reward=-1.3, Steps=48648, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5936, Total reward=-2.4, Steps=48667, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5937, Total reward=-1.5, Steps=48676, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5938, Total reward=-1.2, Steps=48681, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5939, Total reward=-1.1, Steps=48685, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5940, Total reward=-1.1, Steps=48689, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5941, Total reward=-1.2, Steps=48694, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5942, Total reward=-1.4, Steps=48701, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5943, Total reward=-1.3, Steps=48707, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5944, Total reward=0.1, Steps=48720, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5945, Total reward=-1.2, Steps=48725, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5946, Total reward=-0.1, Steps=48731, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5947, Total reward=-1.5, Steps=48739, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5948, Total reward=-1, Steps=48742, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5949, Total reward=-1, Steps=48745, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5950, Total reward=-1.4, Steps=48753, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5951, Total reward=0.8, Steps=48759, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5952, Total reward=-1.0, Steps=48774, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5953, Total reward=-1.3, Steps=48780, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5954, Total reward=-1.1, Steps=48784, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5955, Total reward=-1.1, Steps=48788, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5956, Total reward=-1.3, Steps=48794, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5957, Total reward=-1.1, Steps=48799, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5958, Total reward=-1.3, Steps=48805, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5959, Total reward=-2.0, Steps=48819, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5960, Total reward=-1.4, Steps=48827, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5961, Total reward=0.4, Steps=48837, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5962, Total reward=-1.3, Steps=48855, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5963, Total reward=-1.2, Steps=48861, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5964, Total reward=-1, Steps=48864, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5965, Total reward=-0.8, Steps=48877, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5966, Total reward=-1.4, Steps=48884, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5967, Total reward=-1.4, Steps=48892, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5968, Total reward=-2.0, Steps=48906, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5969, Total reward=-0.4, Steps=48915, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5970, Total reward=-1.1, Steps=48919, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5971, Total reward=-1.2, Steps=48924, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5972, Total reward=-1.6, Steps=48945, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5973, Total reward=-2.3, Steps=48963, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5974, Total reward=-1.1, Steps=48979, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5975, Total reward=-1, Steps=48982, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5976, Total reward=-1, Steps=48985, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5977, Total reward=0.9, Steps=48990, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5978, Total reward=-1.3, Steps=48996, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5979, Total reward=0.4, Steps=49006, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5980, Total reward=-2.2, Steps=49023, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5981, Total reward=-1.0, Steps=49038, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5982, Total reward=-1.2, Steps=49044, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5983, Total reward=-1.4, Steps=49051, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5984, Total reward=-2.1, Steps=49067, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5985, Total reward=-2.1, Steps=49083, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5986, Total reward=-2.0, Steps=49098, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5987, Total reward=-1.1, Steps=49102, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5988, Total reward=-1.2, Steps=49108, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5989, Total reward=-2.0, Steps=49123, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5990, Total reward=-1, Steps=49126, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5991, Total reward=-1.6, Steps=49136, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5992, Total reward=-1.1, Steps=49141, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5993, Total reward=0.3, Steps=49152, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5994, Total reward=-1.2, Steps=49157, Training iteration=23\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5995, Total reward=-0.1, Steps=49163, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5996, Total reward=-1.2, Steps=49168, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5997, Total reward=-0.1, Steps=49174, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5998, Total reward=-1.5, Steps=49182, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=5999, Total reward=-2.0, Steps=49197, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6000, Total reward=-1.1, Steps=49201, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6001, Total reward=-1, Steps=49205, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6002, Total reward=-2.3, Steps=49223, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6003, Total reward=-1.1, Steps=49227, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6004, Total reward=-1.4, Steps=49235, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6005, Total reward=-2.3, Steps=49253, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6006, Total reward=-1.1, Steps=49257, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6007, Total reward=-0.9, Steps=49271, Training iteration=23\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6008, Total reward=-0.4, Steps=49280, Training iteration=23\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.002151313703507185, KL divergence=[0.], Entropy=[-0.01961787], training epoch=0, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=0.002145694103091955, KL divergence=[0.], Entropy=[-0.01956343], training epoch=1, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011543908156454563, KL divergence=[0.], Entropy=[-0.0196495], training epoch=2, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.01608116738498211, KL divergence=[0.], Entropy=[-0.01968278], training epoch=3, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012033281847834587, KL divergence=[0.], Entropy=[-0.01969414], training epoch=4, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.011477706953883171, KL divergence=[0.], Entropy=[-0.01970734], training epoch=5, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.012461326085031033, KL divergence=[0.], Entropy=[-0.0197161], training epoch=6, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.014776550233364105, KL divergence=[0.], Entropy=[-0.01963608], training epoch=7, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013047687709331512, KL divergence=[0.], Entropy=[-0.01965921], training epoch=8, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mPolicy training> Surrogate loss=-0.013825851492583752, KL divergence=[0.], Entropy=[-0.01962607], training epoch=9, learning_rate=0.00025\u001b[0m\n",
      "\u001b[31mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/47_Step-49280.ckpt.main_level.agent.main.online', '/opt/ml/output/data/checkpoint/47_Step-49280.ckpt.main_level.agent.main.online.onnx']\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6009, Total reward=-1.4, Steps=49287, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6010, Total reward=-0.2, Steps=49294, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6011, Total reward=-2.6, Steps=49315, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6012, Total reward=-1.1, Steps=49320, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6013, Total reward=0.6, Steps=49328, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6014, Total reward=1, Steps=49332, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6015, Total reward=-1.2, Steps=49337, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6016, Total reward=-1.7, Steps=49348, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6017, Total reward=-2.5, Steps=49368, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6018, Total reward=-1.1, Steps=49373, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6019, Total reward=-0.3, Steps=49381, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6020, Total reward=-0.2, Steps=49398, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6021, Total reward=-2.3, Steps=49415, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6022, Total reward=-1, Steps=49418, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6023, Total reward=-0.6, Steps=49429, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6024, Total reward=-2.0, Steps=49444, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6025, Total reward=-2.4, Steps=49463, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6026, Total reward=-1.2, Steps=49468, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6027, Total reward=-1.3, Steps=49474, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6028, Total reward=-0.3, Steps=49482, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6029, Total reward=-1.1, Steps=49487, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6030, Total reward=-1.2, Steps=49492, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6031, Total reward=-1.2, Steps=49498, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6032, Total reward=-2.1, Steps=49514, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6033, Total reward=-1, Steps=49517, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6034, Total reward=-1.3, Steps=49523, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6035, Total reward=-1, Steps=49526, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6036, Total reward=-1.0, Steps=49541, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6037, Total reward=-2.3, Steps=49559, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6038, Total reward=-2.3, Steps=49576, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6039, Total reward=-0.1, Steps=49582, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6040, Total reward=-1, Steps=49585, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6041, Total reward=0.1, Steps=49599, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6042, Total reward=-1, Steps=49602, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6043, Total reward=0.5, Steps=49611, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6044, Total reward=-1.1, Steps=49615, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6045, Total reward=-1, Steps=49618, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6046, Total reward=-1, Steps=49621, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6047, Total reward=0.4, Steps=49632, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6048, Total reward=-1.8, Steps=49644, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6049, Total reward=1, Steps=49648, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6050, Total reward=-1.3, Steps=49654, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6051, Total reward=-1.1, Steps=49659, Training iteration=24\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-06-07 15:47:46 Uploading - Uploading generated training model\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6052, Total reward=0.1, Steps=49673, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6053, Total reward=-2.1, Steps=49689, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6054, Total reward=-1.1, Steps=49705, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6055, Total reward=-1.3, Steps=49712, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6056, Total reward=-1.2, Steps=49718, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6057, Total reward=-0.9, Steps=49732, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6058, Total reward=-0.6, Steps=49743, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6059, Total reward=-1.1, Steps=49748, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6060, Total reward=-1.4, Steps=49755, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6061, Total reward=-0.6, Steps=49766, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6062, Total reward=-1.1, Steps=49770, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6063, Total reward=0.7, Steps=49777, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6064, Total reward=-1.3, Steps=49784, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6065, Total reward=-1, Steps=49788, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6066, Total reward=-1, Steps=49791, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6067, Total reward=-2.3, Steps=49809, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6068, Total reward=-1, Steps=49812, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6069, Total reward=-0.4, Steps=49821, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6070, Total reward=-2.8, Steps=49844, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6071, Total reward=-2.3, Steps=49862, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6072, Total reward=-1.5, Steps=49870, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6073, Total reward=-1.3, Steps=49877, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6074, Total reward=-1, Steps=49881, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6075, Total reward=-2.0, Steps=49896, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6076, Total reward=-1.3, Steps=49903, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6077, Total reward=0.3, Steps=49914, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6078, Total reward=-1.1, Steps=49918, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6079, Total reward=1, Steps=49921, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6080, Total reward=-1, Steps=49924, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6081, Total reward=-1.2, Steps=49929, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6082, Total reward=-1, Steps=49932, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6083, Total reward=-1, Steps=49935, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6084, Total reward=-1.5, Steps=49943, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6085, Total reward=-1, Steps=49946, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6086, Total reward=-1.1, Steps=49962, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6087, Total reward=-1.3, Steps=49968, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6088, Total reward=-1, Steps=49971, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6089, Total reward=-1.3, Steps=49978, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6090, Total reward=0.9, Steps=49983, Training iteration=24\u001b[0m\n",
      "\u001b[31mTraining> Name=main_level/agent, Worker=0, Episode=6091, Total reward=-1.1, Steps=49987, Training iteration=24\u001b[0m\n",
      "\u001b[31m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=6091, Total reward=-2.0, Steps=50000, Training iteration=24\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=6091, Total reward=-2.0, Steps=50000, Training iteration=24\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=6091, Total reward=-2.0, Steps=50000, Training iteration=24\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=6091, Total reward=-2.0, Steps=50000, Training iteration=24\u001b[0m\n",
      "\u001b[31mTesting> Name=main_level/agent, Worker=0, Episode=6091, Total reward=-2.0, Steps=50000, Training iteration=24\u001b[0m\n",
      "\u001b[31m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[31mONNX correction applied to discrete PPO agent.\u001b[0m\n",
      "\u001b[31m2019-06-07 15:47:43,597 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-06-07 15:48:03 Completed - Training job completed\n",
      "Billable seconds: 608\n"
     ]
    }
   ],
   "source": [
    "estimator = RLEstimator(source_dir='src',\n",
    "                        entry_point=\"train-coach.py\",\n",
    "                        dependencies=[\"common/sagemaker_rl\"],\n",
    "                        toolkit=RLToolkit.COACH,\n",
    "                        toolkit_version='0.11.0',\n",
    "                        framework=RLFramework.MXNET,\n",
    "                        role=role,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.m4.xlarge',\n",
    "                        output_path='s3://{}/'.format(bucket),\n",
    "                        base_job_name='DEMO-rl-tic-tac-toe',\n",
    "                        hyperparameters={'save_model': 1})\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deploy\n",
    "\n",
    "Normally we would evaluate our agent by looking for reward convergence or monitoring performance across epsisodes.  Other SageMaker RL example notebooks cover this in detail.  We'll skip that for the more tangible approach of testing the trained agent by playing against it ourselves.  To do that, we'll first deploy the agent to a realtime endpoint to get predictions.\n",
    "\n",
    "### Inference\n",
    "\n",
    "Our deployment code:\n",
    "1. Unpacks the ONNX model output and prepares it for inference in `model_fn`\n",
    "1. Generates predictions from our network, given state (a flattened tic-tac-toe board) in `transform_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmx\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet.contrib\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m onnx \u001b[34mas\u001b[39;49;00m onnx_mxnet\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m gluon, nd\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "    \r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    Load the onnx model. Called once when hosting service starts.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    :param: model_dir The directory where model files are stored.\u001b[39;49;00m\r\n",
      "\u001b[33m    :return: a model\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    onnx_path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.onnx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    ctx = mx.cpu() \u001b[37m# todo: pass into function\u001b[39;49;00m\r\n",
      "    \u001b[37m# load onnx model symbol and parameters\u001b[39;49;00m\r\n",
      "    sym, arg_params, aux_params = onnx_mxnet.import_model(onnx_path)\r\n",
      "    model_metadata = onnx_mxnet.get_model_metadata(onnx_path)\r\n",
      "    \u001b[37m# first index is name, second index is shape\u001b[39;49;00m\r\n",
      "    input_names = [inputs[\u001b[34m0\u001b[39;49;00m] \u001b[34mfor\u001b[39;49;00m inputs \u001b[35min\u001b[39;49;00m model_metadata.get(\u001b[33m'\u001b[39;49;00m\u001b[33minput_tensor_data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)]\r\n",
      "    input_symbols = [mx.sym.var(i) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m input_names]\r\n",
      "    net = gluon.nn.SymbolBlock(outputs=sym, inputs=input_symbols)\r\n",
      "    net_params = net.collect_params()\r\n",
      "    \u001b[37m# set parameters (on correct context)\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m arg_params:\r\n",
      "        \u001b[34mif\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m net_params:\r\n",
      "            net_params[param]._load_init(arg_params[param], ctx=ctx)\r\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m aux_params:\r\n",
      "        \u001b[34mif\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m net_params:\r\n",
      "            net_params[param]._load_init(aux_params[param], ctx=ctx)\r\n",
      "    \u001b[37m# hybridize for increase performance\u001b[39;49;00m\r\n",
      "    net.hybridize()\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m net\r\n",
      "    \r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtransform_fn\u001b[39;49;00m(net, data, input_content_type, output_content_type):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    Transform a request using the Gluon model. Called once per request.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    :param net: Gluon Model.\u001b[39;49;00m\r\n",
      "\u001b[33m    :param data: The request payload.\u001b[39;49;00m\r\n",
      "\u001b[33m    :param input_content_type: The request content type.\u001b[39;49;00m\r\n",
      "\u001b[33m    :param output_content_type: The (desired) response content type.\u001b[39;49;00m\r\n",
      "\u001b[33m    :return: response payload and content type.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    input_list = json.loads(data)\r\n",
      "    input_nd = mx.nd.array(input_list).expand_dims(\u001b[34m0\u001b[39;49;00m)\r\n",
      "    output = net(input_nd)\r\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mtype\u001b[39;49;00m(output) == \u001b[36mlist\u001b[39;49;00m:\r\n",
      "        output_list = [o.asnumpy().tolist() \u001b[34mfor\u001b[39;49;00m o \u001b[35min\u001b[39;49;00m output]\r\n",
      "    \u001b[34melif\u001b[39;49;00m \u001b[36mtype\u001b[39;49;00m(output) == mx.nd.NDArray:\r\n",
      "        output_list = [output.asnumpy().tolist()]\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(output_list), output_content_type\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/deploy-coach.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint\n",
    "\n",
    "Now we'll actually create a SageMaker endpoint to call for predictions.\n",
    "\n",
    "*Note, this step could be replaced by importing the ONNX model into the notebook environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, \n",
    "                             instance_type='ml.m4.xlarge', \n",
    "                             entry_point='deploy-coach.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Play \n",
    "\n",
    "Let's play our agent.  After running the cell below, just click on one the boxes to make your move.  To restart the game, simply execute the cell again.\n",
    "\n",
    "*This cell uses the `TicTacToeGame` class from `tic_tac_toe_game.py` script to build an extremely basic tic-tac-toe app within a Jupyter notebook.  The opponents moves are generated by invoking the `predictor` passed at initialization.  Please refer to the code for additional details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d471c786df48b19de1d708daf5b2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Button(layout=Layout(height='75px', width='75px'), style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = TicTacToeGame(predictor)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap Up\n",
    "\n",
    "In this notebook we trained a reinforcement learning agent to play a simple game of tic-tac-toe, using a custom Gym environment.  It could be built upon to solve other problems or improved by:\n",
    "\n",
    "- Training for more episodes\n",
    "- Using a different reinforcement learning algorithm\n",
    "- Tuning hyperparameters for improved performance\n",
    "- Or how about a nice game of [global thermonuclear war](https://youtu.be/s93KC4AGKnY?t=41)?\n",
    "\n",
    "Let's finish by cleaning up our endpoint to prevent any persistent costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
