{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24dcd04b",
   "metadata": {},
   "source": [
    "## Train Machine Learning Models using Amazon Keyspaces as a Data Source.  \n",
    "\n",
    "Created by \n",
    "- Vadim Lyakhovich (AWS)\n",
    "- Ram Pathangi (AWS)\n",
    "- Parth Patel (AWS)\n",
    "\n",
    "\n",
    "*Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved*  \n",
    "[*SPDX-License-Identifier: MIT-0*](https://github.com/aws/mit-0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada6130",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "The Notebook execution role must include permissions to access Amazon Keyspaces and Assume the role.\n",
    "\n",
    "*  To access Amazon Keyspaces database - use AmazonKeyspacesReadOnlyAccess or AmazonKeyspacesFullAccess managed policies. Use the _least privileged approach_ for your production application.  \n",
    "See more at\n",
    "[AWS Identity and Access Management for Amazon Keyspaces](https://docs.aws.amazon.com/keyspaces/latest/devguide/security-iam.html).\n",
    "\n",
    "* To assume the role, you need to have [sts:AssumeRole action](https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html) permissions.\n",
    "    ```\n",
    "    {\n",
    "      \"Version\": \"2012-10-17\",  \n",
    "      \"Statement\": [  \n",
    "        {  \n",
    "           \"Action\": [  \n",
    "           \"sts:AssumeRole\"  \n",
    "          ],  \n",
    "          \"Effect\": \"Allow\",  \n",
    "          \"Resource\": \"*\"  \n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "#### Note:\n",
    "Amazon Keyspaces is available in the following [AWS Regions](https://docs.aws.amazon.com/keyspaces/latest/devguide/programmatic.endpoints.html).\n",
    "\n",
    "This notebook was tested with conda_python3 kernel and should work with Python 3.x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704ece4",
   "metadata": {},
   "source": [
    "In this notebo,  \n",
    "\n",
    "1. First, we install Sigv4 driver to connect to Amazon Keyspaces \n",
    "\n",
    "> The Amazon Keyspaces SigV4 authentication plugin for Cassandra client drivers enables you to authenticate calls to Amazon Keyspaces ***using IAM access keys instead of user name and password***. To learn more about how the Amazon Keyspaces SigV4 plugin enables [IAM users, roles, and federated identities](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) to authenticate in Amazon Keyspaces API requests, see [AWS Signature Version 4 process (SigV4)](https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html)\n",
    "\n",
    "2. Next, we establish a connection to Amazon Keyspaces \n",
    "3. Next, we create new Keyspace ***blog*** and a new table ***online_retail*** \n",
    "3. Next, we will download retail data about customers.\n",
    "3. Next, we will ingest retail data about customers into Keyspaces.\n",
    "3. Next, we will read the ingested data into SageMaker and do feature engineering.\n",
    "3. Next, we will train the data for clustering.\n",
    "3. After the training is complete, we can view the mapping between customer and their associated cluster.\n",
    "3. And finally, Cleanup step to drop Keyspaces table to avoid future charges. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54433fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages and import dependencies\n",
    "\n",
    "# Installing Cassanda SigV4\n",
    "%pip install  cassandra-sigv4\n",
    "\n",
    "# Get Security certificate\n",
    "!curl https://certs.secureserver.net/repository/sf-class2-root.crt -O\n",
    "\n",
    "# Import\n",
    "from sagemaker import get_execution_role\n",
    "from cassandra.cluster import Cluster\n",
    "from ssl import SSLContext, PROTOCOL_TLSv1_2, CERT_REQUIRED\n",
    "from cassandra_sigv4.auth import SigV4AuthProvider\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import csv\n",
    "from cassandra import ConsistencyLevel\n",
    "from datetime import datetime\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Getting credentials from the role\n",
    "client = boto3.client(\"sts\")\n",
    "\n",
    "# Get notebook Role\n",
    "role = get_execution_role()\n",
    "role_info = {\"RoleArn\": role, \"RoleSessionName\": \"session1\"}\n",
    "print(role_info)\n",
    "\n",
    "credentials = client.assume_role(**role_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Cassandra Database from SageMaker Notebook using temporary credentials from the Role.\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=credentials[\"Credentials\"][\"AccessKeyId\"],\n",
    "    aws_secret_access_key=credentials[\"Credentials\"][\"SecretAccessKey\"],\n",
    "    aws_session_token=credentials[\"Credentials\"][\"SessionToken\"],\n",
    ")\n",
    "\n",
    "region_name = session.region_name\n",
    "\n",
    "# Set Context\n",
    "ssl_context = SSLContext(PROTOCOL_TLSv1_2)\n",
    "ssl_context.load_verify_locations(\"sf-class2-root.crt\")\n",
    "ssl_context.verify_mode = CERT_REQUIRED\n",
    "\n",
    "auth_provider = SigV4AuthProvider(session)\n",
    "\n",
    "keyspaces_host = \"cassandra.\" + region_name + \".amazonaws.com\"\n",
    "\n",
    "cluster = Cluster([keyspaces_host], ssl_context=ssl_context, auth_provider=auth_provider, port=9142)\n",
    "session = cluster.connect()\n",
    "\n",
    "\n",
    "# Read data from Keyspaces system table.  Keyspaces is serverless DB so you don't have to create Keyspaces DB ahead of time.\n",
    "r = session.execute(\"select * from system_schema.keyspaces\")\n",
    "\n",
    "# Read Keyspaces row into Panda DataFrame\n",
    "df = DataFrame(r)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d4799",
   "metadata": {},
   "source": [
    "In this step we will create a new ***blog_...*** keyspace  and ***online_retail*** table\n",
    "\n",
    "```\n",
    "CREATE KEYSPACE IF NOT EXISTS blog_yyyymmdd\n",
    "WITH\n",
    "    REPLICATION = {'class': 'SingleRegionStrategy'}\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS online_retail ( \n",
    " invoice\ttext,\n",
    " stock_code\ttext,\n",
    " description\ttext,\n",
    " quantity\tint,\n",
    " invoice_date\tdate,\n",
    " price\tdecimal,\n",
    " customer_id\ttext,\n",
    " country\ttext,\n",
    "   PRIMARY KEY (invoice,stock_code));\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keyspace\n",
    "\n",
    "dt = datetime.now()\n",
    "keyspaces_schema = \"blog_\" + str(dt.year) + str(dt.month) + str(dt.day)\n",
    "\n",
    "createKeyspace = \"\"\"CREATE KEYSPACE IF NOT EXISTS %s\n",
    "WITH\n",
    "    REPLICATION = {'class': 'SingleRegionStrategy'}; \"\"\"\n",
    "cr = session.execute(createKeyspace % keyspaces_schema)\n",
    "time.sleep(5)\n",
    "print(\"Keyspace '\" + keyspaces_schema + \"' created\")\n",
    "\n",
    "# Create Table\n",
    "createTable = \"\"\"CREATE TABLE IF NOT EXISTS %s.online_retail ( \n",
    " invoice text,\n",
    " stock_code text,\n",
    " description text,\n",
    " quantity int,\n",
    " invoice_date date,\n",
    " price decimal,\n",
    " customer_id text,\n",
    " country text,\n",
    "   PRIMARY KEY (invoice,stock_code));\n",
    "\"\"\"\n",
    "cr = session.execute(createTable % keyspaces_schema)\n",
    "time.sleep(20)\n",
    "print(\"Table 'online_retail' created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39141ac1",
   "metadata": {},
   "source": [
    "Let's read Online Retail CSV file and loaded into Keyspaces table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eca50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate test data.\n",
    "# Create Synthetic Data\n",
    "\n",
    "# csv file name\n",
    "filename = \"online_retail_II_20k.csv\"\n",
    "ROW_LIMIT = 20000\n",
    "PRINT_ROWS = 2000\n",
    "\n",
    "\n",
    "# initializing the titles and rows list\n",
    "fields = []\n",
    "rows = []\n",
    "\n",
    "insert = (\n",
    "    \"INSERT INTO \"\n",
    "    + keyspaces_schema\n",
    "    + '.online_retail (\"invoice\",\"stock_code\",\"description\",\"quantity\",\"invoice_date\",\"price\",\"customer_id\",\"country\") VALUES (?,?,?,?,?,?,?,?);'\n",
    ")\n",
    "\n",
    "prepared = session.prepare(insert)\n",
    "prepared.consistency_level = ConsistencyLevel.LOCAL_QUORUM\n",
    "\n",
    "\n",
    "print(\"Start Loading\", ROW_LIMIT, \"rows into the table at\", datetime.now())\n",
    "start_time = time.monotonic()\n",
    "\n",
    "# reading csv file.\n",
    "with open(filename, \"r\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    "\n",
    "    # extracting field names through first row\n",
    "    fields = next(csvreader)\n",
    "\n",
    "    # extracting each data row one by one\n",
    "    # print(fields)\n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            if (csvreader.line_num % PRINT_ROWS) == 0:\n",
    "                print(\"Rows so far: %d\" % (csvreader.line_num))\n",
    "                print(datetime.now())\n",
    "\n",
    "            # print(row)\n",
    "            inv_date = datetime.strptime(row[4], \"%m/%d/%y %H:%M\")\n",
    "            # print(inv_date)\n",
    "            r = session.execute(\n",
    "                prepared,\n",
    "                (\n",
    "                    str(row[0]),\n",
    "                    str(row[1]),\n",
    "                    str(row[2]),\n",
    "                    int(row[3]),\n",
    "                    inv_date,\n",
    "                    float(row[5]),\n",
    "                    str(row[6]),\n",
    "                    str(row[7]),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            if csvreader.line_num >= ROW_LIMIT:\n",
    "                break\n",
    "        except Exception as ex:\n",
    "            print(\"Error for row %d\" % (csvreader.line_num))\n",
    "            print(row)\n",
    "            print(ex)\n",
    "\n",
    "    # get total number of rows\n",
    "    print(\"Total no. of rows: %d\" % (csvreader.line_num))\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print(\"Load time:\", timedelta(seconds=end_time - start_time), \"for\", ROW_LIMIT, \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2770db5",
   "metadata": {},
   "source": [
    "### ML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967768a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "r = session.execute(\"select * from \" + keyspaces_schema + \".online_retail\")\n",
    "\n",
    "df = DataFrame(r)\n",
    "df.head(100)\n",
    "\n",
    "df.count()\n",
    "df[\"description\"].nunique()\n",
    "df[\"totalprice\"] = df[\"quantity\"] * df[\"price\"]\n",
    "df.groupby(\"invoice\").agg({\"totalprice\": \"sum\"}).head()\n",
    "\n",
    "df.groupby(\"description\").agg({\"price\": \"max\"}).sort_values(\"price\", ascending=False).head()\n",
    "df.sort_values(\"price\", ascending=False).head()\n",
    "df[\"country\"].value_counts().head()\n",
    "df.groupby(\"country\").agg({\"totalprice\": \"sum\"}).sort_values(\"totalprice\", ascending=False).head()\n",
    "\n",
    "returned = df[df[\"invoice\"].str.contains(\"C\", na=False)]\n",
    "returned.sort_values(\"quantity\", ascending=True).head()\n",
    "\n",
    "df.isnull().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()\n",
    "df.describe([0.05, 0.01, 0.25, 0.50, 0.75, 0.80, 0.90, 0.95, 0.99]).T\n",
    "df.drop(df.loc[df[\"customer_id\"] == \"\"].index, inplace=True)\n",
    "\n",
    "# Recency Metric\n",
    "import datetime as dt\n",
    "\n",
    "today_date = dt.date(2011, 12, 9)\n",
    "df[\"customer_id\"] = df[\"customer_id\"].astype(int)\n",
    "\n",
    "# create get the most recent invoice for each customer\n",
    "temp_df = df.groupby(\"customer_id\").agg({\"invoice_date\": \"max\"})\n",
    "temp_df[\"invoice_date\"] = temp_df[\"invoice_date\"].astype(str)\n",
    "temp_df[\"invoice_date\"] = pd.to_datetime(temp_df[\"invoice_date\"]).dt.date\n",
    "temp_df[\"Recency\"] = (today_date - temp_df[\"invoice_date\"]).dt.days\n",
    "recency_df = temp_df.drop(columns=[\"invoice_date\"])\n",
    "recency_df.head()\n",
    "\n",
    "# Frequency Metric\n",
    "temp_df = df.groupby([\"customer_id\", \"invoice\"]).agg({\"invoice\": \"count\"})\n",
    "freq_df = temp_df.groupby(\"customer_id\").agg({\"invoice\": \"count\"})\n",
    "freq_df.rename(columns={\"invoice\": \"Frequency\"}, inplace=True)\n",
    "\n",
    "# Monetary Metric\n",
    "monetary_df = df.groupby(\"customer_id\").agg({\"totalprice\": \"sum\"})\n",
    "monetary_df.rename(columns={\"totalprice\": \"Monetary\"}, inplace=True)\n",
    "rfm = pd.concat([recency_df, freq_df, monetary_df], axis=1)\n",
    "\n",
    "df = rfm\n",
    "df[\"RecencyScore\"] = pd.qcut(df[\"Recency\"], 5, labels=[5, 4, 3, 2, 1])\n",
    "df[\"FrequencyScore\"] = pd.qcut(df[\"Frequency\"].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n",
    "df[\"Monetary\"] = df[\"Monetary\"].astype(int)\n",
    "df[\"MonetaryScore\"] = pd.qcut(df[\"Monetary\"], 5, labels=[1, 2, 3, 4, 5])\n",
    "df[\"RFM_SCORE\"] = (\n",
    "    df[\"RecencyScore\"].astype(str)\n",
    "    + df[\"FrequencyScore\"].astype(str)\n",
    "    + df[\"MonetaryScore\"].astype(str)\n",
    ")\n",
    "seg_map = {\n",
    "    r\"[1-2][1-2]\": \"Hibernating\",\n",
    "    r\"[1-2][3-4]\": \"At Risk\",\n",
    "    r\"[1-2]5\": \"Can't Loose\",\n",
    "    r\"3[1-2]\": \"About to Sleep\",\n",
    "    r\"33\": \"Need Attention\",\n",
    "    r\"[3-4][4-5]\": \"Loyal Customers\",\n",
    "    r\"41\": \"Promising\",\n",
    "    r\"51\": \"New Customers\",\n",
    "    r\"[4-5][2-3]\": \"Potential Loyalists\",\n",
    "    r\"5[4-5]\": \"Champions\",\n",
    "}\n",
    "\n",
    "df[\"Segment\"] = df[\"RecencyScore\"].astype(str) + rfm[\"FrequencyScore\"].astype(str)\n",
    "df[\"Segment\"] = df[\"Segment\"].replace(seg_map, regex=True)\n",
    "df.head()\n",
    "rfm = df.loc[:, \"Recency\":\"Monetary\"]\n",
    "df.groupby(\"customer_id\").agg({\"Segment\": \"sum\"}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "sc = MinMaxScaler((0, 1))\n",
    "df = sc.fit_transform(rfm)\n",
    "\n",
    "# Clustering\n",
    "kmeans = KMeans(n_clusters=6).fit(df)\n",
    "\n",
    "# Result\n",
    "kumeler = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_df = pd.DataFrame({\"customer_id\": rfm.index, \"Kumeler\": kumeler})\n",
    "bucket_deta = final_df.groupby(\"Kumeler\").agg({\"customer_id\": \"count\"}).head()\n",
    "index_deta = final_df.groupby(\"Kumeler\").agg({\"Kumeler\": \"max\"}).head()\n",
    "index_deta[\"Kumeler\"] = index_deta[\"Kumeler\"].astype(int)\n",
    "dataFrame = pd.DataFrame(data=bucket_deta[\"customer_id\"], index=index_deta[\"Kumeler\"])\n",
    "dataFrame.rename(columns={\"customer_id\": \"Total Customers\"}).plot.bar(\n",
    "    rot=70, title=\"RFM clustoring\"\n",
    ")\n",
    "# dataFrame.plot.bar(rot=70, title=\"RFM clustoring\");\n",
    "plt.show(block=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a48c96",
   "metadata": {},
   "source": [
    "## Cleanup \n",
    "In this step we will drop the Keyspaces to prevent future charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteKeyspace = \"DROP KEYSPACE IF EXISTS \" + keyspaces_schema\n",
    "dr = session.execute(deleteKeyspace)\n",
    "time.sleep(5)\n",
    "print(\n",
    "    \"Dropping %s keyspace.  It may take a few seconds to a minute to complete deletion of keyspace and table.\"\n",
    "    % keyspaces_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272304e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
