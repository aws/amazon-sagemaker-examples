{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819c2b62-d2bd-408e-bb1e-7ff4dd73228c",
   "metadata": {},
   "source": [
    "# SageMaker Batch Transform with Torchserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9587e-a31b-4940-a972-e6a214f2583b",
   "metadata": {},
   "source": [
    "This notebook demonstrate how to use Sagemaker batch transform job and this example uses an open source Machine Translation model form [Flores 101 competition](http://www.statmt.org/wmt21/large-scale-multilingual-translation-task.html?fbclid=IwAR20x8ZIe9DeVYmBW7y-H9nLaTAoKqIfd2_KFzw99ru-JZ4NnkylRBTsfJA,) that focuses on law resources languages to evaluate the model using the dataset provided in the competition. the Torchserve handler code, docker file and evaluation dataset have been borrowed from [Flores competition repo](https://github.com/facebookresearch/flores/blob/main/dynalab/handler.py) as well. Thanks to Guillaume Wenzek and the team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4e703-3247-4eb3-ae9c-64482770e0bd",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b5f5e-3191-45fa-a838-b5214ef43a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import boto3, time, json\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210a669-e4e8-4491-a4e3-472a6dba35b9",
   "metadata": {},
   "source": [
    "**Initiate session and retrieve region, account details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ae0fa-f80d-4707-9189-65586a902960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "region = sess.region_name\n",
    "account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eccd3e6-374d-4567-a039-7011e8f403ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sess.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ab0bd-3c70-44fe-8af1-f1030757e276",
   "metadata": {},
   "source": [
    "#### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f020114-f758-43df-86af-9a8a74956685",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"flores_small\"\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = \"Dyna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694946b-3e3f-4370-b54b-513fc7aa8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://torchserve.pytorch.org/mar_files/flores_small.mar\n",
    "!tar cvfz {model_file_name}.tar.gz flores_small.mar\n",
    "!aws s3 cp {model_file_name}.tar.gz s3://{bucket_name}/{prefix}/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfbb38-42c0-4cc2-9c41-78c2936c70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = f\"s3://{bucket_name}/{prefix}/models/flores_small.tar.gz\"  # This should be changed to S3 path generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731da4b0-45fd-4d96-9ce3-c79dd92e5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"floressmall-torchserve-sagemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d98610-d3e7-4032-8267-8487a68a0b56",
   "metadata": {},
   "source": [
    "## Build a custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedfcb2-cb65-4706-8a87-9ad92940c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "container_name=flores-torchserve-sagemaker\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${container_name}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${container_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${container_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${container_name} docker/\n",
    "docker tag ${container_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077f529-1194-4c30-a36e-49b59bf9adc8",
   "metadata": {},
   "source": [
    "#### Create Sagemaker model, deploy and run batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca09ae-66b4-4fd7-bab9-bdc4405cb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_name = \"flores-torchserve-sagemaker\"\n",
    "image = f\"{account}.dkr.ecr.{region}.amazonaws.com/{registry_name}:latest\"\n",
    "\n",
    "container = {\"Image\": image, \"ModelDataUrl\": model_artifact}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09850460-e1aa-48d6-b749-c03a64b6baa3",
   "metadata": {},
   "source": [
    "### Batch transform jobs\n",
    "\n",
    "* The s3 bucket is the bucket_name that has been created at the start of the notebook.\n",
    "* Make sure in the bucket name you create the batch_input and batch_output folders as shown below.\n",
    "* Make sure the dataset files/ shared input files, are placed in the batch_input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e379b-669a-45ab-83e2-f6ffb8c8e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = f\"s3://{bucket_name}/Dyna/batch_transform_flores_torchserve_sagemaker/\"\n",
    "\n",
    "batch_output = f\"s3://{bucket_name}/Dyna/batch_transform_flores_torchserve_sagemaker_output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f976e7-9e7e-4646-a5e7-ed98e304d184",
   "metadata": {},
   "source": [
    "#### Data prep\n",
    "In this notebook, we'll use data from the flores101 dataset that's already been prepped to work with flores model. At a high-level, this data was downloaded from the [flores github repo](https://github.com/facebookresearch/flores#download-flores-101-dev-and-devtest-dataset) and prepped by passing in the path of the data to this [prepare()](https://github.com/facebookresearch/dynabench/blob/main/evaluation/datasets/mt/flores.py#L311) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3fdd7-245e-4400-8df5-70b445cc7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p flores_inputs\n",
    "!aws s3 cp --recursive s3://sagemaker-sample-files/datasets/text/flores/ flores_inputs\n",
    "!aws s3 cp --recursive flores_inputs/ {batch_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c6418-3e00-4a6c-812c-cbec13198792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "batch_job_name = \"flores-batch\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "batch_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6c8dd-ef13-4608-be4f-1d3a61a71cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"ModelClientConfig\": {\n",
    "        \"InvocationsTimeoutInSeconds\": 3600,\n",
    "        \"InvocationsMaxRetries\": 1,\n",
    "    },\n",
    "    \"TransformJobName\": batch_job_name,\n",
    "    \"ModelName\": model_name,\n",
    "    \"MaxConcurrentTransforms\": 1,\n",
    "    \"BatchStrategy\": \"MultiRecord\",\n",
    "    \"TransformOutput\": {\n",
    "        \"S3OutputPath\": batch_output,\n",
    "        \"AssembleWith\": \"Line\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    },\n",
    "    \"TransformInput\": {\n",
    "        \"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": batch_input}},\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"ContentType\": \"application/json\",\n",
    "    },\n",
    "    \"TransformResources\": {\"InstanceType\": \"ml.g4dn.xlarge\", \"InstanceCount\": 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29759d9c-7260-4511-bc71-66d89ff3f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sm.create_transform_job(**request)\n",
    "\n",
    "while True:\n",
    "    response = sm.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = response[\"TransformJobStatus\"]\n",
    "    if status == \"Completed\":\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == \"Failed\":\n",
    "        message = response[\"FailureReason\"]\n",
    "        print(\"Transform failed with the following error: {}\".format(message))\n",
    "        raise Exception(\"Transform job failed\")\n",
    "    print(\"Transform job is still in status: \" + status)\n",
    "    time.sleep(30)\n",
    "# The job should complete in approximately 7~10 minutes, depending on the instance type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbfdba-3a3f-431c-962e-42e2d828a53a",
   "metadata": {},
   "source": [
    "### Stop transform job, if not completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fce4f3-0548-48f9-a208-78b0a30125b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.stop_transform_job(TransformJobName=batch_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a85ca-11da-4f0b-9d3f-1d584991d995",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This notebook showed the steps to set up a Sagemaker batch trasnsform job that uses Torchserve under the hood for serving the model, this is useful to test production variants, different models or hyperparamters using a test dataset. To adopt this work to other applications, users can write their own custom handlers for Torchserve that decides the model initialization, data pre and post processing and inference logic along with other consideration about setting the batch transform job."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
