{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy pre-trained GluonCV SSD Mobilenet model with SageMaker Neo\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "    1. [Import SSD Mobilenet model from MXNet GluonCV](#Import-SSD-Mobilenet-model-from-MXNet-GluonCV)\n",
    "    2. [Upload model to S3](#Upload-model-to-S3)\n",
    "    3. [Use sagemaker MXNetModel to load pretrained MXNet model](#Use-sagemaker-MXNetModel-to-load-pretrained-MXNet-model)\n",
    "3. [Compile the pre-trained model using SageMaker Neo](#Compile-the-pre-trained-model-using-SageMaker-Neo)\n",
    "4. [Deploy-the-compiled-model-and-request-Inferences](#Deploy-the-compiled-model-and-request-Inferences)\n",
    "5. [Delete the Endpoint](#Delete-the-Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to load a pre-trained MXNet GluonCV SSD model, optimize the trained model using SageMaker Neo, and host the model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "Before getting started, make sure to select `Python 3 (Data Science)` kernel. Ensure that `Apache MXNet` and `OpenCV` packages are installed in the kernel.\n",
    "\n",
    "Next, we need to define a few variables and obtain certain permissions that will be needed later in the example. These are:\n",
    "\n",
    "* A SageMaker session\n",
    "* IAM role to give learning, storage & hosting access to your data\n",
    "* An S3 bucket, a folder & sub folders that will be used to store data and artifact\n",
    "\n",
    "To start, we need to upgrade the [SageMaker SDK for Python](https://sagemaker.readthedocs.io/en/stable/v2.html) to v2.33.0 or greater and latest MXNet GluonCV and restart the kernel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet\n",
    "!apt-get update\n",
    "!apt-get install -y python3-opencv\n",
    "!pip install --upgrade sagemaker>=2.33.0 gluoncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need an AWS account role with SageMaker access. This role is used to give SageMaker access to your data in S3. We also create a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need an S3 bucket that would be used for storing the model artifacts generated after training and compilation, training data and custom code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket and folders for saving code and model artifacts.\n",
    "# Feel free to specify different bucket/folders here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "folder = \"DEMO-ObjectDetection-SSD-MobileNet\"\n",
    "pretrained_model_sub_folder = folder + \"/pretrained-model\"\n",
    "compilation_output_sub_folder = folder + \"/compilation-output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To easily visualize the detection outputs we also define the following function. The function visualizes the high-confidence predictions with bounding box by filtering out low-confidence detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "    \"\"\"\n",
    "    visualize detections in one image\n",
    "    Parameters:\n",
    "    ----------\n",
    "    img_file : numpy.array\n",
    "        image, in bgr format\n",
    "    dets : numpy.array\n",
    "        ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "        each row is one object\n",
    "    classes : tuple or list of str\n",
    "        class names\n",
    "    thresh : float\n",
    "        score threshold\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    from matplotlib.patches import Rectangle\n",
    "\n",
    "    img = mpimg.imread(img_file)\n",
    "    plt.imshow(img)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    colors = dict()\n",
    "    klasses = dets[0][0]\n",
    "    scores = dets[1][0]\n",
    "    bbox = dets[2][0]\n",
    "    for i in range(len(classes)):\n",
    "        klass = klasses[i][0]\n",
    "        score = scores[i][0]\n",
    "        x0, y0, x1, y1 = bbox[i]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        cls_id = int(klass)\n",
    "        if cls_id not in colors:\n",
    "            colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "        xmin = int(x0 * width / 512)\n",
    "        ymin = int(y0 * height / 512)\n",
    "        xmax = int(x1 * width / 512)\n",
    "        ymax = int(y1 * height / 512)\n",
    "        rect = Rectangle(\n",
    "            (xmin, ymin),\n",
    "            xmax - xmin,\n",
    "            ymax - ymin,\n",
    "            fill=False,\n",
    "            edgecolor=colors[cls_id],\n",
    "            linewidth=3.5,\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        class_name = str(cls_id)\n",
    "        if classes and len(classes) > cls_id:\n",
    "            class_name = classes[cls_id]\n",
    "        plt.gca().text(\n",
    "            xmin,\n",
    "            ymin - 2,\n",
    "            \"{:s} {:.3f}\".format(class_name, score),\n",
    "            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "            fontsize=12,\n",
    "            color=\"white\",\n",
    "        )\n",
    "    plt.tight_layout(rect=[0, 0, 2, 2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing object categories\n",
    "object_categories = [\n",
    "    \"aeroplane\",\n",
    "    \"bicycle\",\n",
    "    \"bird\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"chair\",\n",
    "    \"cow\",\n",
    "    \"diningtable\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"motorbike\",\n",
    "    \"person\",\n",
    "    \"pottedplant\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "    \"train\",\n",
    "    \"tvmonitor\",\n",
    "]\n",
    "\n",
    "# Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20\n",
    "threshold = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the test image into the memory. The test image used in this notebook is from [PEXELS](https://www.pexels.com/) which remains unseen until the time of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "test_file = \"test.jpg\"\n",
    "test_image = PIL.Image.open(test_file)\n",
    "test_image = np.asarray(test_image.resize((512, 512)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SSD Mobilenet model from MXNet GluonCV\n",
    "This example uses pre-trained MXNet GluonCV SSD model initially published in:\n",
    "> Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg. SSD: Single Shot MultiBox Detector. ECCV 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluoncv as gcv\n",
    "import tarfile\n",
    "\n",
    "net = gcv.model_zoo.get_model(\"ssd_512_mobilenet1.0_voc\", pretrained=True)\n",
    "net.hybridize()\n",
    "net(mx.nd.ones((1, 3, 512, 512)))\n",
    "net.export(\"model\")\n",
    "tar = tarfile.open(\"ssd_512_mobilenet1.0_voc.tar.gz\", \"w:gz\")\n",
    "\n",
    "for name in [\"model-0000.params\", \"model-symbol.json\"]:\n",
    "    tar.add(name)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload model to S3\n",
    "Upload the pre-trained model to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = sess.upload_data(\n",
    "    path=\"ssd_512_mobilenet1.0_voc.tar.gz\", bucket=bucket, key_prefix=pretrained_model_sub_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to setup training and compilation output locations in S3, where the respective model artifacts will be dumped. We also setup the s3 location for training data and custom code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Location to save the model artifact after training\n",
    "s3_pretrained_model_location = \"s3://{}/{}\".format(bucket, pretrained_model_sub_folder)\n",
    "\n",
    "# S3 Location to save the model artifact after compilation\n",
    "s3_compilation_output_location = \"s3://{}/{}\".format(bucket, compilation_output_sub_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sagemaker MXNetModel to load pretrained MXNet model\n",
    "When loading the model, user is expected to provide the `entry_point` script required by the model. We set `MMS_DEFAULT_RESPONSE_TIMEOUT` environment variable to `500` for MXNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% H\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "from sagemaker.mxnet import MXNetPredictor\n",
    "\n",
    "pre_trained_model = MXNetModel(\n",
    "    model_data=pretrained_model_path,\n",
    "    predictor_cls=MXNetPredictor,\n",
    "    framework_version=\"1.8\",\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    entry_point=\"ssd_entry_point.py\",\n",
    "    py_version=\"py3\",\n",
    "    env={\"MMS_DEFAULT_RESPONSE_TIMEOUT\": \"500\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the pre-trained model using SageMaker Neo\n",
    "\n",
    "After loading the pretrained model we can use SageMaker Neo's ``compile()`` API to compile the pretrained model. When calling ``compile()``, the user is expected to provide all the correct input shapes required by the model for successful compilation. We also specify the target instance family, the name of our IAM execution role, S3 bucket to which the compiled model would be stored.\n",
    "\n",
    "For this example, we will choose `ml_p3` as the target instance family while compiling the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "compiled_model = pre_trained_model.compile(\n",
    "    job_name=\"ssd-512-mobilenet-{}\".format(time.strftime(\"%Y%m%d%I%M%S\")),\n",
    "    target_instance_family=\"ml_p3\",\n",
    "    input_shape={\"data\": [1, 3, 512, 512]},\n",
    "    role=role,\n",
    "    framework=\"mxnet\",\n",
    "    framework_version=\"1.8\",\n",
    "    output_path=s3_compilation_output_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the compiled model and request Inferences\n",
    "\n",
    "We have to deploy the compiled model within the instance family for which the trained model was compiled. Since we have compiled for `ml_p3` we can deploy to any `ml.p3` instance type. For this example we will choose `ml.p3.2xlarge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "neo_object_detector = compiled_model.deploy(initial_instance_count=1, instance_type=\"ml.p3.2xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = neo_object_detector.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the detections.\n",
    "visualize_detection(test_file, response, object_categories, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "Having an endpoint running will incur some costs. Therefore, as an optional clean-up job, you can delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Endpoint name: \" + neo_object_detector.endpoint_name)\n",
    "neo_object_detector.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}