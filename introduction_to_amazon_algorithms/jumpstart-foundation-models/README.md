# Amazon SageMaker Examples

### JumpStart Foundation Models

These examples provide quick walkthroughs to get you up and running with Amazon SageMaker JumpStart Foundation Models.

- [JumpStart Text Generation Inference](jumpstart-text-generation-inference.ipynb) provides a single notebook for all JumpStart text generation models using default payloads retrieved from the JumpStartModel.
- [Llama-2 Text Generation](llama-2-text-completion.ipynb) and [Llama-2 Chat Completion](llama-2-chat-completion.ipynb) demonstrate text generation using Meta's Llama-2 pretrained and fine-tuned chat models, respectfully.
- [Code LIama fine-tuning](code-llama-fine-tuning-evaluate-human-eval.ipynb) demonstrate Code Llama fine-tuning and evaluation using [human-eval repository](https://github.com/openai/human-eval).
- [Llama Guard Text Moderation](llama-guard-text-moderation.ipynb) demonstrates using a Llama Guard model to moderate a conversation in conjunction with a Llama-2 model.
- [Gemma Text Generation Fine-tuning](gemma-fine-tuning.ipynb) demonstrates fine-tuning and deployment on Google's Gemma text generation models in SageMaker JumpStart.
- [Text2Text Generation Flan T5 UL2](text2text-generation-flan-t5-ul2.ipynb) demonstrates Text2Text generation using state-of-the-art pretrained Flan T5 models from [Hugging Face](https://huggingface.co/docs/transformers/model_doc/flan-t5) which take an input text containing the task and returns the output of the accomplished task. 
- [Text2Text Generation BloomZ](text2text-generation-bloomz.ipynb) demonstrates Text generation using state-of-the-art pretrained BloomZ 7B1 models from [Hugging Face](https://huggingface.co/bigscience/bloomz-7b1) which take an input text containing the task and returns the output of the accomplished task. In addition to the tasks that Flan T5 can perform, BloomZ can perform multilingual text classification, question and answering, code generation, paragraph rephrase, and More.
- [Text Generation Few Shot Learning](text-generation-few-shot-learning.ipynb) demonstrates Text generation using state-of-the-art pretrained GPT-J-6B models from [Hugging Face](https://huggingface.co/EleutherAI/gpt-j-6B) which takes a text string as input and predicts a sequence of next few words. These models can, for example, fill in incomplete text or paraphrase.
- [BloomZ 176B Few Shot and Zero Shot Learning](bloom-z-176b-few-shot-and-zero-shot-learning.ipynb) demonstrates over 20 few-shot and zero-shot learning tasks using state-of-the-art pretrained BloomZ 176B model from [Hugging Face](https://huggingface.co/bigscience/bloomz).
- [Text Generation Chatbot](text-generation-chatbot.ipynb) demonstrates text generation within a chatbot context using a variety of pretrained JumpStart models, to include a variety of models, to include [Falcon-7B-Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct), [Falcon-40B-Instruct](https://huggingface.co/tiiuae/falcon-40b-instruct), [RedPajama-INCITE-Chat-3B](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1), [RedPajama-INCITE-7B-Chat](https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat), and [GPT-NeoXT-Chat-Base-20B](https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B).
- [Retrieval Augmented Generation: Question and Answering based on custom data](question_answering_retrieval_augmented_generation/question_answering_jumpstart_knn.ipynb) demonstrates how to use retrieval-augmented generation based approach to perform question and answering with JumpStart embedding and large language models.
- [Retrieval Augmented Generation: Question and Answering based on custom data with LangChain](question_answering_retrieval_augmented_generation/question_answering_langchain_jumpstart.ipynb) demonstrates how to use retrieval-augmented generation based approach to perform question and answering with LangChain library and JumpStart embedding and large language models.
- [Retrieval-Augmented Generation: Question Answering using LLama-2, Pinecone & Custom Dataset](question_answering_retrieval_augmented_generation/question_answering_pinecone_llama-2_jumpstart.ipynb) demonstrates how to use retrieval-augmented generation based approach to perform question and answering with Llama-2 Large Language Model and JumpStart embedding and Pinecone vector database.
- [Retrieval-Augmented Generation: Question Answering using LangChain and Cohere's Generate and Embedding Models from SageMaker JumpStart](question_answering_retrieval_augmented_generation/question_answering_Cohere+langchain_jumpstart.ipynb) demonstrates how to use Cohere Generate model to answer questions using a library of documents as a reference, by using Cohere embedding model for document embeddings and retrieval. 
- [Domain adaption fine-tuning of large language model](domain-adaption-finetuning-gpt-j-6b.ipynb) demonstrates how to use SageMaker SDK to fine-tune large language model like GPT-J-6B from [Hugging Face](https://huggingface.co/EleutherAI/gpt-j-6b) on domain-specific dataset and deploy the fine-tuned model for inference.
- [Instruction fine-tuning of large language model Falcon 7B](falcon-7b-instruction-domain-adaptation-finetuning.ipynb) demonstrates how to use SageMaker SDK to instruction and domain-adaptation fine-tune large language model like Falcon-7B from [Hugging Face](https://huggingface.co/tiiuae/falcon-7b) and deploy the fine-tuned model for inference.
- [Instruction fine-tuning of large language model Mistral 7B](mistral-7b-instruction-domain-adaptation-finetuning.ipynb) demonstrates how to use SageMaker SDK to instruction and domain-adaptation fine-tune large language model like Mistral-7B from [Hugging Face](https://huggingface.co/mistralai/Mistral-7B-v0.1) and deploy the fine-tuned model for inference.
- [Automatic Speech Recognition](automatic-speech-recognition.ipynb) demonstrates Automatic Speech Recognition using Whipser models from [Hugging Face](https://huggingface.co/openai/whisper-large-v2) which takes an audio file and outputs the transcription.
- [Image Generation Stable Diffusion](image-generation-stable-diffusion.ipynb) demonstrates Image Generation using the Stable Diffusion models.
- [Text Embedding and Sentence Similarity](question_answering_retrieval_augmented_generation/text-embedding-sentence-similarity.ipynb) demonstrates generating embeddings and sentence similarity.
- [Retrieval-Augmented Generation: Question Answering using LLama-2, Text Embedding Models](question_answering_retrieval_augmented_generation/question_answering_text_embedding_llama-2_jumpstart.ipynb) demonstrates how to use retrieval-augmented generation based approach to perform question and answering with Llama-2 Large Language Model and JumpStart Text Embedding Models.
- [AWS Trainium and Inferentia for LIama-2 finetuning and deployment in JumpStart](aws-trainium-inferentia-finetuning-deployment/llama-2-trainium-inferentia-finetuning-deployment.ipynb) Fine-tune and deploy Llama-2 models on [AWS Trainium](https://aws.amazon.com/ec2/instance-types/trn1/) and [AWS Inferentia](https://aws.amazon.com/ec2/instance-types/inf2/) based instances in SageMaker JumpStart.
- [Open-Llama Text Generation](text-generation-open-llama.ipynb) demonstrate text generation using Open-Llama models.
- [Text2Text Generation Flan T5](text2text-generation-flan-t5.ipynb) demonstrates Text2Text generation using state-of-the-art pretrained Flan T5 models from [Hugging Face](https://huggingface.co/docs/transformers/model_doc/flan-t5) which take an input text containing the task and returns the output of the accomplished task.


