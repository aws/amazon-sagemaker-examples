{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor analysis using Amazon SageMaker Debugger\n",
    "\n",
    "Looking at the distributions of activation inputs/outputs, gradients and weights per layer can give useful insights. For instance, it helps to understand whether the model runs into problems like neuron saturation, whether there are layers in your model that are not learning at all or whether the network consists of too many layers etc. \n",
    "\n",
    "The following animation shows the distribution of gradients of a convolutional layer from an example application  as the training progresses. We can see that it starts as Gaussian distribution but then becomes more and more narrow. We can also see that the range of gradients starts very small (order of $1e-5$) and becomes even tinier as training progresses. If tiny gradients are observed from the start of training, it is an indication that we should check the hyperparameters of our model. \n",
    "\n",
    "![](images/example.gif)\n",
    "\n",
    "In this notebook we will train a poorly configured neural network and use Amazon SageMaker Debugger with custom rules to aggregate and analyse specific tensors. Before we proceed let us install the smdebug binary which allows us to perform interactive analysis in this notebook. After installing it, please restart the kernel, and when you come back skip this cell.\n",
    "\n",
    "### Installing smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smdebug\n",
      "  Downloading smdebug-0.7.2-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (3.11.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from smdebug) (20.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.18.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.12.45)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->smdebug) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->smdebug) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (2.4.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.45 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (1.15.45)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.45->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.45->boto3>=1.10.32->smdebug) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.45->boto3>=1.10.32->smdebug) (1.25.8)\n",
      "Installing collected packages: smdebug\n",
      "Successfully installed smdebug-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!  python -m pip install smdebug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the inputs for the training job\n",
    "\n",
    "Now we'll call the Sagemaker MXNet Estimator to kick off a training job . The `entry_point_script` points to the MXNet training script. The users can create a custom *SessionHook* in their training script. If they chose not to create such hook in the training script (similar to the one we will be using in this example) Amazon SageMaker Debugger will create the appropriate *SessionHook* based on specified *DebugHookConfig* parameters.\n",
    "\n",
    "The `hyperparameters` are the parameters that will be passed to the training script. We choose `Uniform(1)` as initializer and learning rate of `0.001`. This leads to the model not training well because the model is poorly initialized.\n",
    "\n",
    "The goal of a good intialization is \n",
    "- to break the symmetry such that parameters do not receive same gradients and updates\n",
    "- to keep variance similar across layers\n",
    "\n",
    "A bad intialization may lead to vanishing or exploiding gradients and the model not training at all. Once the training is finished we will look at the distirbutions of activation inputs/outputs, gradients and weights across the training to see how these hyperparameters influenced the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = \"mnist.py\"\n",
    "bad_hyperparameters = {\"initializer\": 2, \"lr\": 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "LOCATION_IN_BUCKET = \"smdebug-mnist-tensor-analysis\"\n",
    "\n",
    "s3_bucket_for_tensors = \"s3://{BUCKET_NAME}/{LOCATION_IN_BUCKET}\".format(\n",
    "    BUCKET_NAME=BUCKET_NAME, LOCATION_IN_BUCKET=LOCATION_IN_BUCKET\n",
    ")\n",
    "estimator = MXNet(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=\"mxnet\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    train_volume_size=400,\n",
    "    source_dir=\"src\",\n",
    "    entry_point=entry_point_script,\n",
    "    hyperparameters=bad_hyperparameters,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=s3_bucket_for_tensors,\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"all\", parameters={\"include_regex\": \".*\", \"save_interval\": \"100\"})\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 location of tensors\n",
    "\n",
    "We can get information related to the training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'mxnet-2020-04-27-21-37-10-765',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-2:441510144314:training-job/mxnet-2020-04-27-21-37-10-765',\n",
       " 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-east-2-441510144314/mxnet-2020-04-27-21-37-10-765/output/model.tar.gz'},\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'SecondaryStatus': 'Completed',\n",
       " 'HyperParameters': {'initializer': '2',\n",
       "  'lr': '0.001',\n",
       "  'sagemaker_container_log_level': '20',\n",
       "  'sagemaker_enable_cloudwatch_metrics': 'false',\n",
       "  'sagemaker_job_name': '\"mxnet-2020-04-27-21-37-10-765\"',\n",
       "  'sagemaker_program': '\"mnist.py\"',\n",
       "  'sagemaker_region': '\"us-east-2\"',\n",
       "  'sagemaker_submit_directory': '\"s3://sagemaker-us-east-2-441510144314/mxnet-2020-04-27-21-37-10-765/source/sourcedir.tar.gz\"'},\n",
       " 'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-2.amazonaws.com/mxnet-training:1.6.0-cpu-py3',\n",
       "  'TrainingInputMode': 'File',\n",
       "  'EnableSageMakerMetricsTimeSeries': True},\n",
       " 'RoleArn': 'arn:aws:iam::441510144314:role/service-role/AmazonSageMaker-ExecutionRole-20200110T121244',\n",
       " 'InputDataConfig': [],\n",
       " 'OutputDataConfig': {'KmsKeyId': '',\n",
       "  'S3OutputPath': 's3://sagemaker-us-east-2-441510144314/'},\n",
       " 'ResourceConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "  'InstanceCount': 1,\n",
       "  'VolumeSizeInGB': 400},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'CreationTime': datetime.datetime(2020, 4, 27, 21, 37, 11, 114000, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2020, 4, 27, 21, 38, 59, 637000, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2020, 4, 27, 21, 40, 25, 536000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 4, 27, 21, 40, 25, 536000, tzinfo=tzlocal()),\n",
       " 'SecondaryStatusTransitions': [{'Status': 'Starting',\n",
       "   'StartTime': datetime.datetime(2020, 4, 27, 21, 37, 11, 114000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2020, 4, 27, 21, 38, 59, 637000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Preparing the instances for training'},\n",
       "  {'Status': 'Downloading',\n",
       "   'StartTime': datetime.datetime(2020, 4, 27, 21, 38, 59, 637000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2020, 4, 27, 21, 39, 17, 668000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Downloading input data'},\n",
       "  {'Status': 'Training',\n",
       "   'StartTime': datetime.datetime(2020, 4, 27, 21, 39, 17, 668000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2020, 4, 27, 21, 40, 18, 275000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training image download completed. Training in progress.'},\n",
       "  {'Status': 'Uploading',\n",
       "   'StartTime': datetime.datetime(2020, 4, 27, 21, 40, 18, 275000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2020, 4, 27, 21, 40, 25, 536000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Uploading generated training model'},\n",
       "  {'Status': 'Completed',\n",
       "   'StartTime': datetime.datetime(2020, 4, 27, 21, 40, 25, 536000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2020, 4, 27, 21, 40, 25, 536000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training job completed'}],\n",
       " 'EnableNetworkIsolation': False,\n",
       " 'EnableInterContainerTrafficEncryption': False,\n",
       " 'EnableManagedSpotTraining': False,\n",
       " 'TrainingTimeInSeconds': 86,\n",
       " 'BillableTimeInSeconds': 86,\n",
       " 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-2-441510144314/smdebug-mnist-tensor-analysis',\n",
       "  'CollectionConfigurations': [{'CollectionName': 'all',\n",
       "    'CollectionParameters': {'include_regex': '.*', 'save_interval': '100'}}]},\n",
       " 'ResponseMetadata': {'RequestId': '55f450b8-eb76-42a3-ac13-3f63dcf37c8a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '55f450b8-eb76-42a3-ac13-3f63dcf37c8a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2666',\n",
       "   'date': 'Mon, 27 Apr 2020 21:43:35 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the S3 location of the tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors are stored in:  s3://sagemaker-us-east-2-441510144314/smdebug-mnist-tensor-analysis/mxnet-2020-04-27-21-37-10-765/debug-output\n"
     ]
    }
   ],
   "source": [
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "print(\"Tensors are stored in: \", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download tensors from S3\n",
    "\n",
    "Now we will download the tensors from S3, so that we can visualize them in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tensors into folder:  /tmp/debug-output\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"/tmp/{}\".format(path.split(\"/\")[-1])\n",
    "os.system(\"aws s3 cp --recursive {} {}\".format(path, folder_name))\n",
    "print(\"Downloading tensors into folder: \", folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the tensors from our training job, it is time to plot the distribution of different layers. \n",
    "In the following sections we will use Amazon SageMaker Debugger and custom rules to retrieve certain tensors. Typically, rules are supposed to return True or False. However in this notebook we will use custom rules to return dictionaries of aggregated tensors per layer and step, which we then plot afterwards.\n",
    "\n",
    "### Activation outputs\n",
    "This rule will use Amazon SageMaker Debugger to retrieve tensors from the ReLU output layers. It sums the activations across batch and steps. If there is a large fraction of ReLUs outputing 0 across many steps it means that the neuron is dying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug.rules.rule_invoker import invoke_rule\n",
    "from smdebug.exceptions import NoMoreData\n",
    "from smdebug.rules.rule import Rule\n",
    "import numpy as np\n",
    "import utils\n",
    "import collections\n",
    "import os\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:20:52.397 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:20:52.414 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule ActivationOutputs at step 0\n",
      "[2020-04-27 22:20:52.416 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:20:53.418 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:20:53.432 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 0 tensor  conv0_relu_output_0  has 48.82066514756944% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.438 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 0 tensor  conv1_relu_output_0  has 51.22558593749999% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.440 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 0 tensor  dense0_relu_output_0  has 53.001302083333336% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.441 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 0 tensor  dense1_relu_output_0  has 51.58110119047619% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.455 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 100 tensor  conv0_relu_output_0  has 54.463930483217595% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.461 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 100 tensor  conv1_relu_output_0  has 94.9755859375% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.463 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 100 tensor  dense0_relu_output_0  has 54.19270833333333% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.464 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 100 tensor  dense1_relu_output_0  has 62.034970238095234% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.477 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 200 tensor  conv0_relu_output_0  has 51.88417787905093% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.484 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 200 tensor  conv1_relu_output_0  has 99.99072265625% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.486 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 200 tensor  dense0_relu_output_0  has 72.10286458333334% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.487 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 200 tensor  dense1_relu_output_0  has 71.08444940476191% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.503 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 300 tensor  conv0_relu_output_0  has 54.520670572916664% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.509 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 300 tensor  conv1_relu_output_0  has 99.998046875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.511 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 300 tensor  dense0_relu_output_0  has 74.36848958333333% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.512 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 300 tensor  dense1_relu_output_0  has 74.39546130952381% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.524 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 400 tensor  conv0_relu_output_0  has 53.19756401909722% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.531 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 400 tensor  conv1_relu_output_0  has 99.99853515625% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.533 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 400 tensor  dense0_relu_output_0  has 74.61588541666667% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.535 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 400 tensor  dense1_relu_output_0  has 74.75818452380952% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.550 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 500 tensor  conv0_relu_output_0  has 51.72277379918982% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.556 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 500 tensor  conv1_relu_output_0  has 99.9970703125% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.559 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 500 tensor  dense0_relu_output_0  has 73.34635416666667% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.560 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 500 tensor  dense1_relu_output_0  has 73.32589285714286% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.574 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 600 tensor  conv0_relu_output_0  has 51.398157190393526% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.581 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 600 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.583 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 600 tensor  dense0_relu_output_0  has 75.72916666666667% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.585 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 600 tensor  dense1_relu_output_0  has 74.93489583333334% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.599 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 700 tensor  conv0_relu_output_0  has 52.541097005208336% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.606 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 700 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.609 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 700 tensor  dense0_relu_output_0  has 76.49088541666667% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.610 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 700 tensor  dense1_relu_output_0  has 72.49813988095238% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.624 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 800 tensor  conv0_relu_output_0  has 51.32310655381944% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.631 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 800 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.633 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 800 tensor  dense0_relu_output_0  has 74.81119791666667% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.635 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 800 tensor  dense1_relu_output_0  has 72.50744047619048% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.649 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 900 tensor  conv0_relu_output_0  has 51.25800238715278% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.655 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 900 tensor  conv1_relu_output_0  has 99.998046875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.658 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 900 tensor  dense0_relu_output_0  has 73.3984375% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.659 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 900 tensor  dense1_relu_output_0  has 74.44196428571429% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.674 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1000 tensor  conv0_relu_output_0  has 53.025083188657405% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.681 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1000 tensor  conv1_relu_output_0  has 99.9990234375% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.683 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1000 tensor  dense0_relu_output_0  has 75.59895833333333% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.685 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1000 tensor  dense1_relu_output_0  has 74.63727678571429% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.699 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1100 tensor  conv0_relu_output_0  has 51.27111364293982% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.706 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1100 tensor  conv1_relu_output_0  has 99.99853515625% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.708 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1100 tensor  dense0_relu_output_0  has 76.95963541666667% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.710 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1100 tensor  dense1_relu_output_0  has 74.70238095238095% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.724 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1200 tensor  conv0_relu_output_0  has 51.57109013310185% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.731 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1200 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.734 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1200 tensor  dense0_relu_output_0  has 75.61848958333334% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.735 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1200 tensor  dense1_relu_output_0  has 74.93489583333334% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.750 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1300 tensor  conv0_relu_output_0  has 51.947021484375% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.757 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1300 tensor  conv1_relu_output_0  has 99.99951171875% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.759 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1300 tensor  dense0_relu_output_0  has 76.46484375% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.760 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1300 tensor  dense1_relu_output_0  has 78.40401785714286% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.775 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1400 tensor  conv0_relu_output_0  has 52.25129304108796% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.782 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1400 tensor  conv1_relu_output_0  has 99.9990234375% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.784 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1400 tensor  dense0_relu_output_0  has 77.0703125% activation outputs which are smaller than 0 \n",
      "[2020-04-27 22:20:53.785 f8455ab5c5ab:17 INFO <ipython-input-9-c7f9e2eb0647>:17]  Step 1400 tensor  dense1_relu_output_0  has 72.51674107142857% activation outputs which are smaller than 0 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class ActivationOutputs(Rule):\n",
    "    def __init__(self, base_trial):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*relu_output\"):\n",
    "            if \"gradients\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = collections.OrderedDict()\n",
    "                    if step not in self.tensors[tname]:\n",
    "                        self.tensors[tname][step] = 0\n",
    "                    neg_values = np.where(tensor <= 0)[0]\n",
    "                    if len(neg_values) > 0:\n",
    "                        self.logger.info(\n",
    "                            f\" Step {step} tensor  {tname}  has {len(neg_values)/tensor.size*100}% activation outputs which are smaller than 0 \"\n",
    "                        )\n",
    "                    batch_over_sum = np.sum(tensor, axis=0) / tensor.shape[0]\n",
    "                    self.tensors[tname][step] += batch_over_sum\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = ActivationOutputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(\n",
    "    rule.tensors, filename=\"images/activation_outputs.gif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/activation_outputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/activation_outputs.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Inputs\n",
    "In this rule we look at the inputs into activation function, rather than the output. This can be helpful to understand if there are extreme negative or positive values that saturate the activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:22:24.752 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:22:24.767 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule ActivationInputs at step 0\n",
      "[2020-04-27 22:22:24.768 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:22:25.770 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:22:25.778 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 48.82066514756944% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.783 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 51.22558593749999% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.785 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 53.001302083333336% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.786 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 51.58110119047619% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.796 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 54.463930483217595% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.801 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 94.9755859375% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.803 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 54.19270833333333% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.804 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 62.034970238095234% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.814 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.88417787905093% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.819 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99072265625% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.820 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 72.10286458333334% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.822 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 71.08444940476191% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.831 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 54.520670572916664% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.837 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.998046875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.838 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 74.36848958333333% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.839 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.39546130952381% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.849 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 53.19756401909722% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.854 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99853515625% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.856 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 74.61588541666667% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.857 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.75818452380952% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.868 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.72277379918982% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.873 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.9970703125% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.875 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 73.34635416666667% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.876 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 73.32589285714286% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.886 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.398157190393526% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.892 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.893 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 75.72916666666667% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.894 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.93489583333334% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.905 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 52.541097005208336% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.910 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.911 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 76.49088541666667% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.913 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 72.49813988095238% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.923 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.32310655381944% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.929 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.931 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 74.81119791666667% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.934 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 72.50744047619048% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.944 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.25800238715278% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.949 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.998046875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.951 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 73.3984375% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.952 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.44196428571429% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.963 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 53.025083188657405% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.968 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.9990234375% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.969 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 75.59895833333333% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.971 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.63727678571429% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.981 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.27111364293982% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.986 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99853515625% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.988 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 76.95963541666667% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.989 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.70238095238095% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:25.999 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.57109013310185% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.005 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.006 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 75.61848958333334% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.008 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 74.93489583333334% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.018 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 51.947021484375% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.024 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.99951171875% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.025 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 76.46484375% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.026 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 78.40401785714286% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.037 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv0_relu_input_0  has 52.25129304108796% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.042 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  conv1_relu_input_0  has 99.9990234375% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.044 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense0_relu_input_0  has 77.0703125% activation inputs which are smaller than 0 \n",
      "[2020-04-27 22:22:26.045 f8455ab5c5ab:17 INFO <ipython-input-12-92e74c737aaa>:17]  Tensor  dense1_relu_input_0  has 72.51674107142857% activation inputs which are smaller than 0 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class ActivationInputs(Rule):\n",
    "    def __init__(self, base_trial):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*relu_input\"):\n",
    "            if \"gradients\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "                    if step not in self.tensors[tname]:\n",
    "                        self.tensors[tname][step] = 0\n",
    "                    neg_values = np.where(tensor <= 0)[0]\n",
    "                    if len(neg_values) > 0:\n",
    "                        self.logger.info(\n",
    "                            f\" Tensor  {tname}  has {len(neg_values)/tensor.size*100}% activation inputs which are smaller than 0 \"\n",
    "                        )\n",
    "                    batch_over_sum = np.sum(tensor, axis=0) / tensor.shape[0]\n",
    "                    self.tensors[tname][step] += batch_over_sum\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = ActivationInputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename=\"images/activation_inputs.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that second convolutional layer `conv1_relu_input_0` receives only negative input values, which means that all ReLUs in this layer output 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/activation_inputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/activation_inputs.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "The following code retrieves the gradients and plots their distribution. If variance is tiny, that means that the model parameters do not get updated effectively with each training step or that the training has converged to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:25:51.768 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:25:51.781 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule GradientsLayer at step 0\n",
      "[2020-04-27 22:25:51.782 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:25:52.784 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:25:52.786 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -5149.84033203125 31646.48828125 \n",
      "[2020-04-27 22:25:52.787 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -13980.2021484375 39929.21484375 \n",
      "[2020-04-27 22:25:52.788 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -1813.0926513671875 10602.732421875 \n",
      "[2020-04-27 22:25:52.789 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -6368.1806640625 38688.0 \n",
      "[2020-04-27 22:25:52.790 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -179.64866638183594 347.4178466796875 \n",
      "[2020-04-27 22:25:52.792 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -5038.26171875 9037.4365234375 \n",
      "[2020-04-27 22:25:52.793 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -82.91046905517578 76.00481414794922 \n",
      "[2020-04-27 22:25:52.794 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -18866.3359375 17484.91015625 \n",
      "[2020-04-27 22:25:52.795 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -17.0 57.0 \n",
      "[2020-04-27 22:25:52.796 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -20504.265625 61322.046875 \n",
      "[2020-04-27 22:25:52.800 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -1617.0311279296875 727.3082885742188 \n",
      "[2020-04-27 22:25:52.801 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -1517.2711181640625 1360.6627197265625 \n",
      "[2020-04-27 22:25:52.802 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -277.4026184082031 278.95660400390625 \n",
      "[2020-04-27 22:25:52.803 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -1220.47412109375 1047.916748046875 \n",
      "[2020-04-27 22:25:52.804 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -59.79769515991211 67.69261932373047 \n",
      "[2020-04-27 22:25:52.806 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -75.69705963134766 105.90653228759766 \n",
      "[2020-04-27 22:25:52.807 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -8.260823249816895 15.506786346435547 \n",
      "[2020-04-27 22:25:52.808 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -112.7426986694336 113.8670654296875 \n",
      "[2020-04-27 22:25:52.809 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.345627784729004 8.66802978515625 \n",
      "[2020-04-27 22:25:52.810 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -245.2377471923828 379.2154235839844 \n",
      "[2020-04-27 22:25:52.814 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -101.66511535644531 11.746068954467773 \n",
      "[2020-04-27 22:25:52.815 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -65.13233947753906 111.70040130615234 \n",
      "[2020-04-27 22:25:52.816 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -8.534814834594727 25.94390296936035 \n",
      "[2020-04-27 22:25:52.817 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -40.51245880126953 116.62594604492188 \n",
      "[2020-04-27 22:25:52.818 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -25.741046905517578 42.52741241455078 \n",
      "[2020-04-27 22:25:52.820 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -4.424605369567871 4.874677658081055 \n",
      "[2020-04-27 22:25:52.821 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -12.612415313720703 9.365806579589844 \n",
      "[2020-04-27 22:25:52.822 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -2.4334120750427246 2.1119964122772217 \n",
      "[2020-04-27 22:25:52.823 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.060829162597656 6.018675327301025 \n",
      "[2020-04-27 22:25:52.824 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -5.438522815704346 4.632100582122803 \n",
      "[2020-04-27 22:25:52.828 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -31.52714729309082 28.255945205688477 \n",
      "[2020-04-27 22:25:52.829 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -52.1895866394043 69.72014617919922 \n",
      "[2020-04-27 22:25:52.830 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 18.45484733581543 \n",
      "[2020-04-27 22:25:52.831 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -8.653250694274902 127.38655090332031 \n",
      "[2020-04-27 22:25:52.832 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -36.64728546142578 42.69761276245117 \n",
      "[2020-04-27 22:25:52.834 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -7.016548156738281 10.46964168548584 \n",
      "[2020-04-27 22:25:52.835 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -10.914785385131836 17.35120391845703 \n",
      "[2020-04-27 22:25:52.836 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -1.5331487655639648 2.1940650939941406 \n",
      "[2020-04-27 22:25:52.837 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -7.36464262008667 7.412864685058594 \n",
      "[2020-04-27 22:25:52.838 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -7.040934085845947 7.418706893920898 \n",
      "[2020-04-27 22:25:52.841 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -64.73793029785156 27.20878028869629 \n",
      "[2020-04-27 22:25:52.842 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -45.57298278808594 47.520347595214844 \n",
      "[2020-04-27 22:25:52.844 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 16.196287155151367 \n",
      "[2020-04-27 22:25:52.845 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 82.97894287109375 \n",
      "[2020-04-27 22:25:52.846 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -22.91037368774414 20.32585906982422 \n",
      "[2020-04-27 22:25:52.847 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -2.707063674926758 2.870230197906494 \n",
      "[2020-04-27 22:25:52.848 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -6.570956230163574 9.99987506866455 \n",
      "[2020-04-27 22:25:52.849 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.6772371530532837 0.8163791298866272 \n",
      "[2020-04-27 22:25:52.850 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -3.027226448059082 4.121616840362549 \n",
      "[2020-04-27 22:25:52.852 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -2.004786968231201 1.9083017110824585 \n",
      "[2020-04-27 22:25:52.855 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -95.70741271972656 17.63048553466797 \n",
      "[2020-04-27 22:25:52.856 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -165.47361755371094 82.15006256103516 \n",
      "[2020-04-27 22:25:52.857 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -3.5999011993408203 38.76963424682617 \n",
      "[2020-04-27 22:25:52.858 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -17.21964454650879 162.36268615722656 \n",
      "[2020-04-27 22:25:52.860 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -25.76466178894043 23.140644073486328 \n",
      "[2020-04-27 22:25:52.861 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -4.461329460144043 5.040010452270508 \n",
      "[2020-04-27 22:25:52.862 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -6.486667156219482 10.687053680419922 \n",
      "[2020-04-27 22:25:52.863 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -1.6570074558258057 2.758233070373535 \n",
      "[2020-04-27 22:25:52.864 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.014965534210205 5.386890888214111 \n",
      "[2020-04-27 22:25:52.865 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -7.363559722900391 7.27754545211792 \n",
      "[2020-04-27 22:25:52.869 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -2.41868257522583 13.387530326843262 \n",
      "[2020-04-27 22:25:52.870 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -9.894062042236328 11.664155006408691 \n",
      "[2020-04-27 22:25:52.871 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -6.718662261962891 0.0 \n",
      "[2020-04-27 22:25:52.872 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -24.936752319335938 0.0 \n",
      "[2020-04-27 22:25:52.873 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -31.229568481445312 32.75321578979492 \n",
      "[2020-04-27 22:25:52.875 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -0.08978071808815002 0.11575950682163239 \n",
      "[2020-04-27 22:25:52.876 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -6.885076999664307 11.950864791870117 \n",
      "[2020-04-27 22:25:52.877 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.1465906947851181 0.2634112238883972 \n",
      "[2020-04-27 22:25:52.878 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -3.868048906326294 6.423059940338135 \n",
      "[2020-04-27 22:25:52.879 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.22638662159442902 0.3604522943496704 \n",
      "[2020-04-27 22:25:52.883 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -4.006610870361328 4.26582670211792 \n",
      "[2020-04-27 22:25:52.884 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -8.007227897644043 7.861775875091553 \n",
      "[2020-04-27 22:25:52.885 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 3.4121253490448 \n",
      "[2020-04-27 22:25:52.886 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 22.860107421875 \n",
      "[2020-04-27 22:25:52.887 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -27.923139572143555 29.385908126831055 \n",
      "[2020-04-27 22:25:52.889 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -0.4813162684440613 0.6209366917610168 \n",
      "[2020-04-27 22:25:52.890 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -11.290090560913086 11.552780151367188 \n",
      "[2020-04-27 22:25:52.891 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.23507824540138245 0.2357713282108307 \n",
      "[2020-04-27 22:25:52.892 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.617587566375732 5.22601318359375 \n",
      "[2020-04-27 22:25:52.893 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.4557512700557709 0.2950083017349243 \n",
      "[2020-04-27 22:25:52.897 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -30.382892608642578 4.175470352172852 \n",
      "[2020-04-27 22:25:52.898 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -34.21318054199219 26.863500595092773 \n",
      "[2020-04-27 22:25:52.899 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 9.502142906188965 \n",
      "[2020-04-27 22:25:52.900 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 36.42455291748047 \n",
      "[2020-04-27 22:25:52.901 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -45.90071487426758 43.033145904541016 \n",
      "[2020-04-27 22:25:52.902 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -3.6235783100128174 3.4359898567199707 \n",
      "[2020-04-27 22:25:52.904 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -5.5072021484375 17.035451889038086 \n",
      "[2020-04-27 22:25:52.905 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.8212846517562866 0.6541135311126709 \n",
      "[2020-04-27 22:25:52.906 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -6.26908016204834 7.63941764831543 \n",
      "[2020-04-27 22:25:52.907 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -4.426249027252197 2.9874744415283203 \n",
      "[2020-04-27 22:25:52.910 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -16.208253860473633 18.61284637451172 \n",
      "[2020-04-27 22:25:52.911 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -27.896995544433594 41.30409622192383 \n",
      "[2020-04-27 22:25:52.913 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -7.884207725524902 7.240376949310303 \n",
      "[2020-04-27 22:25:52.914 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -39.63383483886719 28.860776901245117 \n",
      "[2020-04-27 22:25:52.916 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -28.69450569152832 47.52030563354492 \n",
      "[2020-04-27 22:25:52.918 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -4.688067436218262 4.360113143920898 \n",
      "[2020-04-27 22:25:52.919 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -12.74375057220459 8.661504745483398 \n",
      "[2020-04-27 22:25:52.920 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -1.205727458000183 1.3138247728347778 \n",
      "[2020-04-27 22:25:52.921 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.553890705108643 3.744802951812744 \n",
      "[2020-04-27 22:25:52.923 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -5.305088520050049 2.020052671432495 \n",
      "[2020-04-27 22:25:52.926 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -9.36766242980957 8.030630111694336 \n",
      "[2020-04-27 22:25:52.927 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -16.960205078125 13.7196626663208 \n",
      "[2020-04-27 22:25:52.928 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -0.18103402853012085 5.486399173736572 \n",
      "[2020-04-27 22:25:52.930 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -0.6137489080429077 36.34244155883789 \n",
      "[2020-04-27 22:25:52.931 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -18.87697982788086 30.843612670898438 \n",
      "[2020-04-27 22:25:52.932 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -0.39189717173576355 0.3830419182777405 \n",
      "[2020-04-27 22:25:52.933 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -10.17051887512207 12.880867004394531 \n",
      "[2020-04-27 22:25:52.935 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.2679915726184845 0.3036436140537262 \n",
      "[2020-04-27 22:25:52.936 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.262083053588867 5.559200763702393 \n",
      "[2020-04-27 22:25:52.937 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -0.5808815360069275 0.2632489502429962 \n",
      "[2020-04-27 22:25:52.941 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -6.194462299346924 2.2857325077056885 \n",
      "[2020-04-27 22:25:52.942 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -4.452066421508789 4.230159759521484 \n",
      "[2020-04-27 22:25:52.943 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: -0.032487671822309494 1.5249730348587036 \n",
      "[2020-04-27 22:25:52.944 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: -0.13874106109142303 4.512594223022461 \n",
      "[2020-04-27 22:25:52.945 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -50.828277587890625 39.78963088989258 \n",
      "[2020-04-27 22:25:52.947 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -3.774961233139038 3.3157076835632324 \n",
      "[2020-04-27 22:25:52.952 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -10.937799453735352 14.700889587402344 \n",
      "[2020-04-27 22:25:52.953 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.7937904596328735 0.9154173731803894 \n",
      "[2020-04-27 22:25:52.954 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -9.970462799072266 6.8490800857543945 \n",
      "[2020-04-27 22:25:52.955 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -2.8608531951904297 2.6764142513275146 \n",
      "[2020-04-27 22:25:52.959 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -1.2990520000457764 0.2271302342414856 \n",
      "[2020-04-27 22:25:52.960 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -2.055903196334839 1.3293263912200928 \n",
      "[2020-04-27 22:25:52.961 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 0.7663621306419373 \n",
      "[2020-04-27 22:25:52.962 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 2.149507522583008 \n",
      "[2020-04-27 22:25:52.963 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -20.742401123046875 21.405094146728516 \n",
      "[2020-04-27 22:25:52.965 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -1.1737643480300903 1.0772308111190796 \n",
      "[2020-04-27 22:25:52.966 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -10.518623352050781 12.878310203552246 \n",
      "[2020-04-27 22:25:52.967 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.29439577460289 0.3287479281425476 \n",
      "[2020-04-27 22:25:52.968 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -7.216102123260498 6.097813606262207 \n",
      "[2020-04-27 22:25:52.970 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -1.519209861755371 0.5045807361602783 \n",
      "[2020-04-27 22:25:52.973 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -4.244566917419434 0.36177772283554077 \n",
      "[2020-04-27 22:25:52.974 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -7.24577522277832 8.068381309509277 \n",
      "[2020-04-27 22:25:52.975 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 2.1815106868743896 \n",
      "[2020-04-27 22:25:52.977 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 11.20015811920166 \n",
      "[2020-04-27 22:25:52.978 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -22.95243263244629 27.935787200927734 \n",
      "[2020-04-27 22:25:52.979 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -4.544219970703125 6.162412166595459 \n",
      "[2020-04-27 22:25:52.980 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -8.209747314453125 7.804721355438232 \n",
      "[2020-04-27 22:25:52.981 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -1.062230110168457 0.9078865051269531 \n",
      "[2020-04-27 22:25:52.982 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -4.590793609619141 5.132489204406738 \n",
      "[2020-04-27 22:25:52.984 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -5.097039699554443 2.7630226612091064 \n",
      "[2020-04-27 22:25:52.987 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_bias  has gradients range: -38.07282638549805 16.622339248657227 \n",
      "[2020-04-27 22:25:52.988 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv0_weight  has gradients range: -37.36157989501953 54.26838302612305 \n",
      "[2020-04-27 22:25:52.989 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_bias  has gradients range: 0.0 13.919588088989258 \n",
      "[2020-04-27 22:25:52.991 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/conv1_weight  has gradients range: 0.0 58.94915771484375 \n",
      "[2020-04-27 22:25:52.992 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_bias  has gradients range: -15.17860221862793 24.616369247436523 \n",
      "[2020-04-27 22:25:52.993 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense0_weight  has gradients range: -3.867265462875366 4.611002445220947 \n",
      "[2020-04-27 22:25:52.994 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_bias  has gradients range: -5.959875106811523 7.464860439300537 \n",
      "[2020-04-27 22:25:52.996 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense1_weight  has gradients range: -0.8550781011581421 0.8905887007713318 \n",
      "[2020-04-27 22:25:52.997 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_bias  has gradients range: -5.588850975036621 3.3401448726654053 \n",
      "[2020-04-27 22:25:52.998 f8455ab5c5ab:17 INFO <ipython-input-15-1efdd7f3ed18>:13]  Tensor  gradient/dense2_weight  has gradients range: -4.332571506500244 3.0080392360687256 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class GradientsLayer(Rule):\n",
    "    def __init__(self, base_trial):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*gradient\"):\n",
    "            try:\n",
    "                tensor = self.base_trial.tensor(tname).value(step)\n",
    "                if tname not in self.tensors:\n",
    "                    self.tensors[tname] = {}\n",
    "\n",
    "                self.logger.info(\n",
    "                    f\" Tensor  {tname}  has gradients range: {np.min(tensor)} {np.max(tensor)} \"\n",
    "                )\n",
    "                self.tensors[tname][step] = tensor\n",
    "            except:\n",
    "                self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = GradientsLayer(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename=\"images/gradients.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/gradients.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/gradients.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check variance across layers\n",
    "The rule retrieves gradients, but this time we compare variance of gradient distribution across layers. We want to identify if there is a large difference between the min and max variance per training step. For instance, very deep neural networks may suffer from vanishing gradients the deeper we go. By checking this ratio we can determine if we run into such a situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:26:25.950 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:26:25.966 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule GradientsAcrossLayers at step 0\n",
      "[2020-04-27 22:26:25.967 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:26:26.969 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:26:26.971 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 135150592.0 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:26.972 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 135150592.0 159276240.0 Ratio: 1.1785093545913696\n",
      "[2020-04-27 22:26:26.973 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 8339952.0 159276240.0 Ratio: 19.097980499267578\n",
      "[2020-04-27 22:26:26.974 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 8339952.0 159276240.0 Ratio: 19.097980499267578\n",
      "[2020-04-27 22:26:26.975 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 8522.7109375 159276240.0 Ratio: 18688.447265625\n",
      "[2020-04-27 22:26:26.977 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 8522.7109375 159276240.0 Ratio: 18688.447265625\n",
      "[2020-04-27 22:26:26.978 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 816.9637451171875 159276240.0 Ratio: 194961.203125\n",
      "[2020-04-27 22:26:26.979 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 816.9637451171875 159276240.0 Ratio: 194961.203125\n",
      "[2020-04-27 22:26:26.981 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 554.4755859375 159276240.0 Ratio: 287255.65625\n",
      "[2020-04-27 22:26:26.982 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 0 current ratio: 554.4755859375 159276240.0 Ratio: 287255.65625\n",
      "[2020-04-27 22:26:26.985 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 542837.3125 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:26.986 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 233198.3125 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:26.988 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 17263.08984375 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:26.989 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 17263.08984375 27421.759765625 Ratio: 1.5884618759155273\n",
      "[2020-04-27 22:26:26.990 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 346.3892517089844 27421.759765625 Ratio: 79.16458129882812\n",
      "[2020-04-27 22:26:26.991 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 50.84667205810547 27421.759765625 Ratio: 539.3029174804688\n",
      "[2020-04-27 22:26:26.993 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 21.27505111694336 27421.759765625 Ratio: 1288.916259765625\n",
      "[2020-04-27 22:26:26.994 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 21.27505111694336 27421.759765625 Ratio: 1288.916259765625\n",
      "[2020-04-27 22:26:26.995 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 21.27505111694336 27421.759765625 Ratio: 1288.916259765625\n",
      "[2020-04-27 22:26:26.996 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 100 current ratio: 21.27505111694336 27421.759765625 Ratio: 1288.916259765625\n",
      "[2020-04-27 22:26:27.000 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 1186.0352783203125 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.001 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 1103.24267578125 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.002 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 67.06768798828125 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.003 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 67.06768798828125 159.85687255859375 Ratio: 2.3835155963897705\n",
      "[2020-04-27 22:26:27.004 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 67.06768798828125 159.85687255859375 Ratio: 2.3835155963897705\n",
      "[2020-04-27 22:26:27.006 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 0.023273566737771034 159.85687255859375 Ratio: 6868.60205078125\n",
      "[2020-04-27 22:26:27.007 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 0.023273566737771034 159.85687255859375 Ratio: 6868.60205078125\n",
      "[2020-04-27 22:26:27.008 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 0.023273566737771034 159.85687255859375 Ratio: 6868.60205078125\n",
      "[2020-04-27 22:26:27.010 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 0.023273566737771034 159.85687255859375 Ratio: 6868.60205078125\n",
      "[2020-04-27 22:26:27.011 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 200 current ratio: 0.023273566737771034 159.85687255859375 Ratio: 6868.60205078125\n",
      "[2020-04-27 22:26:27.014 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 515.3092041015625 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.016 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 515.3092041015625 673.0396728515625 Ratio: 1.306088924407959\n",
      "[2020-04-27 22:26:27.017 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 19.87226104736328 673.0396728515625 Ratio: 33.8682975769043\n",
      "[2020-04-27 22:26:27.020 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 19.87226104736328 673.0396728515625 Ratio: 33.8682975769043\n",
      "[2020-04-27 22:26:27.021 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 19.87226104736328 673.0396728515625 Ratio: 33.8682975769043\n",
      "[2020-04-27 22:26:27.023 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 0.01733490452170372 673.0396728515625 Ratio: 38825.69140625\n",
      "[2020-04-27 22:26:27.024 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 0.01733490452170372 673.0396728515625 Ratio: 38825.69140625\n",
      "[2020-04-27 22:26:27.025 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 0.01733490452170372 673.0396728515625 Ratio: 38825.69140625\n",
      "[2020-04-27 22:26:27.026 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 0.01733490452170372 673.0396728515625 Ratio: 38825.69140625\n",
      "[2020-04-27 22:26:27.028 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 300 current ratio: 0.01733490452170372 673.0396728515625 Ratio: 38825.69140625\n",
      "[2020-04-27 22:26:27.031 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 928.9985961914062 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.032 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 297.640625 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.033 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 15.993744850158691 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.035 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 15.993744850158691 29.116140365600586 Ratio: 1.8204704523086548\n",
      "[2020-04-27 22:26:27.036 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 15.993744850158691 34.61952590942383 Ratio: 2.1645665168762207\n",
      "[2020-04-27 22:26:27.037 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 0.002362065715715289 34.61952590942383 Ratio: 14656.4619140625\n",
      "[2020-04-27 22:26:27.038 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 0.002362065715715289 34.61952590942383 Ratio: 14656.4619140625\n",
      "[2020-04-27 22:26:27.040 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 0.002362065715715289 34.61952590942383 Ratio: 14656.4619140625\n",
      "[2020-04-27 22:26:27.041 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 0.002362065715715289 34.61952590942383 Ratio: 14656.4619140625\n",
      "[2020-04-27 22:26:27.042 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 400 current ratio: 0.002362065715715289 34.61952590942383 Ratio: 14656.4619140625\n",
      "[2020-04-27 22:26:27.046 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 1612.4898681640625 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.047 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 1429.26123046875 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.048 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 89.83195495605469 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.049 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 89.83195495605469 234.8433380126953 Ratio: 2.6142516136169434\n",
      "[2020-04-27 22:26:27.050 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 43.61869812011719 234.8433380126953 Ratio: 5.384006023406982\n",
      "[2020-04-27 22:26:27.052 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 0.011688556522130966 234.8433380126953 Ratio: 20091.73046875\n",
      "[2020-04-27 22:26:27.053 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 0.011688556522130966 234.8433380126953 Ratio: 20091.73046875\n",
      "[2020-04-27 22:26:27.054 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 0.011688556522130966 234.8433380126953 Ratio: 20091.73046875\n",
      "[2020-04-27 22:26:27.055 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 0.011688556522130966 234.8433380126953 Ratio: 20091.73046875\n",
      "[2020-04-27 22:26:27.057 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 500 current ratio: 0.011688556522130966 234.8433380126953 Ratio: 20091.73046875\n",
      "[2020-04-27 22:26:27.060 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 31.90549659729004 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.062 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 14.34399700164795 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.063 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 2.644946813583374 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.064 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 2.644946813583374 2.99973464012146 Ratio: 1.1341379880905151\n",
      "[2020-04-27 22:26:27.065 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 2.644946813583374 40.85332107543945 Ratio: 15.44580078125\n",
      "[2020-04-27 22:26:27.066 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 1.8411362816550536e-06 40.85332107543945 Ratio: 22189190.0\n",
      "[2020-04-27 22:26:27.068 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 1.8411362816550536e-06 40.85332107543945 Ratio: 22189190.0\n",
      "[2020-04-27 22:26:27.069 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 1.8411362816550536e-06 40.85332107543945 Ratio: 22189190.0\n",
      "[2020-04-27 22:26:27.070 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 1.8411362816550536e-06 40.85332107543945 Ratio: 22189190.0\n",
      "[2020-04-27 22:26:27.071 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 600 current ratio: 1.8411362816550536e-06 40.85332107543945 Ratio: 22189190.0\n",
      "[2020-04-27 22:26:27.075 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.120075702667236 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.076 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.120075702667236 12.20245361328125 Ratio: 1.9938403367996216\n",
      "[2020-04-27 22:26:27.077 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 0.682183563709259 12.20245361328125 Ratio: 17.887346267700195\n",
      "[2020-04-27 22:26:27.078 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 0.682183563709259 12.20245361328125 Ratio: 17.887346267700195\n",
      "[2020-04-27 22:26:27.079 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 0.682183563709259 42.211490631103516 Ratio: 61.87702560424805\n",
      "[2020-04-27 22:26:27.081 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.691928138025105e-05 42.211490631103516 Ratio: 630782.1875\n",
      "[2020-04-27 22:26:27.082 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.691928138025105e-05 42.211490631103516 Ratio: 630782.1875\n",
      "[2020-04-27 22:26:27.083 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.691928138025105e-05 42.211490631103516 Ratio: 630782.1875\n",
      "[2020-04-27 22:26:27.084 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.691928138025105e-05 42.211490631103516 Ratio: 630782.1875\n",
      "[2020-04-27 22:26:27.086 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 700 current ratio: 6.691928138025105e-05 42.211490631103516 Ratio: 630782.1875\n",
      "[2020-04-27 22:26:27.089 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 127.13235473632812 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.090 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 127.13235473632812 133.708251953125 Ratio: 1.0517247915267944\n",
      "[2020-04-27 22:26:27.091 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 5.290472507476807 133.708251953125 Ratio: 25.273405075073242\n",
      "[2020-04-27 22:26:27.093 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 5.290472507476807 133.708251953125 Ratio: 25.273405075073242\n",
      "[2020-04-27 22:26:27.094 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 5.290472507476807 133.708251953125 Ratio: 25.273405075073242\n",
      "[2020-04-27 22:26:27.095 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 0.0025186585262417793 133.708251953125 Ratio: 53087.08984375\n",
      "[2020-04-27 22:26:27.096 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 0.0025186585262417793 133.708251953125 Ratio: 53087.08984375\n",
      "[2020-04-27 22:26:27.097 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 0.0025186585262417793 133.708251953125 Ratio: 53087.08984375\n",
      "[2020-04-27 22:26:27.099 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 0.0025186585262417793 133.708251953125 Ratio: 53087.08984375\n",
      "[2020-04-27 22:26:27.100 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 800 current ratio: 0.0025186585262417793 133.708251953125 Ratio: 53087.08984375\n",
      "[2020-04-27 22:26:27.104 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 133.9089813232422 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.105 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 120.24006652832031 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.106 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 7.1951093673706055 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.108 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 7.1951093673706055 17.802467346191406 Ratio: 2.474245548248291\n",
      "[2020-04-27 22:26:27.109 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 7.1951093673706055 72.29354858398438 Ratio: 10.047595977783203\n",
      "[2020-04-27 22:26:27.110 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 0.004477491602301598 72.29354858398438 Ratio: 16145.9931640625\n",
      "[2020-04-27 22:26:27.112 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 0.004477491602301598 72.29354858398438 Ratio: 16145.9931640625\n",
      "[2020-04-27 22:26:27.113 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 0.004477491602301598 72.29354858398438 Ratio: 16145.9931640625\n",
      "[2020-04-27 22:26:27.114 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 0.004477491602301598 72.29354858398438 Ratio: 16145.9931640625\n",
      "[2020-04-27 22:26:27.115 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 900 current ratio: 0.004477491602301598 72.29354858398438 Ratio: 16145.9931640625\n",
      "[2020-04-27 22:26:27.119 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 30.299272537231445 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.120 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 30.299272537231445 39.399986267089844 Ratio: 1.3003607988357544\n",
      "[2020-04-27 22:26:27.121 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 1.7733855247497559 39.399986267089844 Ratio: 22.217384338378906\n",
      "[2020-04-27 22:26:27.122 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 1.7733855247497559 39.399986267089844 Ratio: 22.217384338378906\n",
      "[2020-04-27 22:26:27.124 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 1.7733855247497559 39.86183166503906 Ratio: 22.477815628051758\n",
      "[2020-04-27 22:26:27.125 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 5.755776510341093e-05 39.86183166503906 Ratio: 692553.5\n",
      "[2020-04-27 22:26:27.126 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 5.755776510341093e-05 39.86183166503906 Ratio: 692553.5\n",
      "[2020-04-27 22:26:27.128 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 5.755776510341093e-05 39.86183166503906 Ratio: 692553.5\n",
      "[2020-04-27 22:26:27.129 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 5.755776510341093e-05 39.86183166503906 Ratio: 692553.5\n",
      "[2020-04-27 22:26:27.130 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1000 current ratio: 5.755776510341093e-05 39.86183166503906 Ratio: 692553.5\n",
      "[2020-04-27 22:26:27.134 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 11.354304313659668 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.135 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 2.6843271255493164 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.136 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.22761689126491547 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.137 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.22761689126491547 0.3647533059120178 Ratio: 1.6024879217147827\n",
      "[2020-04-27 22:26:27.138 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.22761689126491547 77.35369110107422 Ratio: 339.84161376953125\n",
      "[2020-04-27 22:26:27.140 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.001992658944800496 77.35369110107422 Ratio: 38819.33203125\n",
      "[2020-04-27 22:26:27.141 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.001992658944800496 77.35369110107422 Ratio: 38819.33203125\n",
      "[2020-04-27 22:26:27.142 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.001992658944800496 77.35369110107422 Ratio: 38819.33203125\n",
      "[2020-04-27 22:26:27.143 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.001992658944800496 77.35369110107422 Ratio: 38819.33203125\n",
      "[2020-04-27 22:26:27.145 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1100 current ratio: 0.001992658944800496 77.35369110107422 Ratio: 38819.33203125\n",
      "[2020-04-27 22:26:27.148 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.2086801379919052 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.149 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.2086801379919052 0.21724243462085724 Ratio: 1.041030764579773\n",
      "[2020-04-27 22:26:27.150 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.034412749111652374 0.21724243462085724 Ratio: 6.31284761428833\n",
      "[2020-04-27 22:26:27.151 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.025111373513936996 0.21724243462085724 Ratio: 8.65115737915039\n",
      "[2020-04-27 22:26:27.153 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.025111373513936996 29.94378662109375 Ratio: 1192.439208984375\n",
      "[2020-04-27 22:26:27.154 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.00032806280069053173 29.94378662109375 Ratio: 91274.5546875\n",
      "[2020-04-27 22:26:27.155 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.00032806280069053173 29.94378662109375 Ratio: 91274.5546875\n",
      "[2020-04-27 22:26:27.157 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.00032806280069053173 29.94378662109375 Ratio: 91274.5546875\n",
      "[2020-04-27 22:26:27.158 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.00032806280069053173 29.94378662109375 Ratio: 91274.5546875\n",
      "[2020-04-27 22:26:27.159 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1200 current ratio: 0.00032806280069053173 29.94378662109375 Ratio: 91274.5546875\n",
      "[2020-04-27 22:26:27.163 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 2.924529790878296 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.164 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 2.924529790878296 6.251096725463867 Ratio: 2.1374707221984863\n",
      "[2020-04-27 22:26:27.165 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.27884700894355774 6.251096725463867 Ratio: 22.41765785217285\n",
      "[2020-04-27 22:26:27.166 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.27884700894355774 6.251096725463867 Ratio: 22.41765785217285\n",
      "[2020-04-27 22:26:27.167 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.27884700894355774 35.37714767456055 Ratio: 126.869384765625\n",
      "[2020-04-27 22:26:27.169 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.006202871911227703 35.37714767456055 Ratio: 5703.349609375\n",
      "[2020-04-27 22:26:27.170 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.006202871911227703 35.37714767456055 Ratio: 5703.349609375\n",
      "[2020-04-27 22:26:27.172 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.006202871911227703 35.37714767456055 Ratio: 5703.349609375\n",
      "[2020-04-27 22:26:27.173 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.006202871911227703 35.37714767456055 Ratio: 5703.349609375\n",
      "[2020-04-27 22:26:27.174 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1300 current ratio: 0.006202871911227703 35.37714767456055 Ratio: 5703.349609375\n",
      "[2020-04-27 22:26:27.178 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 440.8072509765625 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.179 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 248.11984252929688 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.180 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 11.648333549499512 0 Ratio: 0.0\n",
      "[2020-04-27 22:26:27.182 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 11.648333549499512 32.488555908203125 Ratio: 2.789116144180298\n",
      "[2020-04-27 22:26:27.183 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 11.648333549499512 32.488555908203125 Ratio: 2.789116144180298\n",
      "[2020-04-27 22:26:27.185 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 0.0029379758052527905 32.488555908203125 Ratio: 11058.142578125\n",
      "[2020-04-27 22:26:27.186 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 0.0029379758052527905 32.488555908203125 Ratio: 11058.142578125\n",
      "[2020-04-27 22:26:27.187 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 0.0029379758052527905 32.488555908203125 Ratio: 11058.142578125\n",
      "[2020-04-27 22:26:27.188 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 0.0029379758052527905 32.488555908203125 Ratio: 11058.142578125\n",
      "[2020-04-27 22:26:27.190 f8455ab5c5ab:17 INFO <ipython-input-18-0c18f883c3b5>:17]  Step 1400 current ratio: 0.0029379758052527905 32.488555908203125 Ratio: 11058.142578125\n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class GradientsAcrossLayers(Rule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_trial,\n",
    "    ):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*gradient\"):\n",
    "            try:\n",
    "                tensor = self.base_trial.tensor(tname).value(step)\n",
    "                if step not in self.tensors:\n",
    "                    self.tensors[step] = [np.inf, 0]\n",
    "                variance = np.var(tensor.flatten())\n",
    "                if variance < self.tensors[step][0]:\n",
    "                    self.tensors[step][0] = variance\n",
    "                elif variance > self.tensors[step][1]:\n",
    "                    self.tensors[step][1] = variance\n",
    "                self.logger.info(\n",
    "                    f\" Step {step} current ratio: {self.tensors[step][0]} {self.tensors[step][1]} Ratio: {self.tensors[step][1] / self.tensors[step][0]}\"\n",
    "                )\n",
    "            except:\n",
    "                self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = GradientsAcrossLayers(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check min and max values of the gradients across layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 variance of gradients:  554.4756  to  159276240.0\n",
      "Step 100 variance of gradients:  21.275051  to  27421.76\n",
      "Step 200 variance of gradients:  0.023273567  to  159.85687\n",
      "Step 300 variance of gradients:  0.017334905  to  673.0397\n",
      "Step 400 variance of gradients:  0.0023620657  to  34.619526\n",
      "Step 500 variance of gradients:  0.0116885565  to  234.84334\n",
      "Step 600 variance of gradients:  1.8411363e-06  to  40.85332\n",
      "Step 700 variance of gradients:  6.691928e-05  to  42.21149\n",
      "Step 800 variance of gradients:  0.0025186585  to  133.70825\n",
      "Step 900 variance of gradients:  0.0044774916  to  72.29355\n",
      "Step 1000 variance of gradients:  5.7557765e-05  to  39.86183\n",
      "Step 1100 variance of gradients:  0.001992659  to  77.35369\n",
      "Step 1200 variance of gradients:  0.0003280628  to  29.943787\n",
      "Step 1300 variance of gradients:  0.006202872  to  35.377148\n",
      "Step 1400 variance of gradients:  0.0029379758  to  32.488556\n"
     ]
    }
   ],
   "source": [
    "for step in rule.tensors:\n",
    "    print(\n",
    "        \"Step\",\n",
    "        step,\n",
    "        \"variance of gradients: \",\n",
    "        rule.tensors[step][0],\n",
    "        \" to \",\n",
    "        rule.tensors[step][1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of weights\n",
    "This rule retrieves the weight tensors and checks the variance. If the distribution does not change much across steps it may indicate that the learning rate is too low, that gradients are too small or that the training has converged to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:26:27.303 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:26:27.321 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule WeightRatio at step 0\n",
      "[2020-04-27 22:26:27.323 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:26:28.326 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:26:28.327 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.2814779281616211 \n",
      "[2020-04-27 22:26:28.331 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3394239842891693 \n",
      "[2020-04-27 22:26:28.332 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3329920768737793 \n",
      "[2020-04-27 22:26:28.334 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3357633054256439 \n",
      "[2020-04-27 22:26:28.335 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.33459386229515076 \n",
      "[2020-04-27 22:26:28.339 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.18824437260627747 \n",
      "[2020-04-27 22:26:28.340 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.31524181365966797 \n",
      "[2020-04-27 22:26:28.341 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33269569277763367 \n",
      "[2020-04-27 22:26:28.343 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33430221676826477 \n",
      "[2020-04-27 22:26:28.344 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3178540766239166 \n",
      "[2020-04-27 22:26:28.348 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17195990681648254 \n",
      "[2020-04-27 22:26:28.349 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3088184595108032 \n",
      "[2020-04-27 22:26:28.350 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326626121997833 \n",
      "[2020-04-27 22:26:28.352 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33413469791412354 \n",
      "[2020-04-27 22:26:28.353 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3159906268119812 \n",
      "[2020-04-27 22:26:28.357 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.17003734409809113 \n",
      "[2020-04-27 22:26:28.358 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3079167902469635 \n",
      "[2020-04-27 22:26:28.359 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326609432697296 \n",
      "[2020-04-27 22:26:28.361 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33412644267082214 \n",
      "[2020-04-27 22:26:28.362 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3158993721008301 \n",
      "[2020-04-27 22:26:28.365 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16902482509613037 \n",
      "[2020-04-27 22:26:28.366 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3074690103530884 \n",
      "[2020-04-27 22:26:28.368 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33266007900238037 \n",
      "[2020-04-27 22:26:28.369 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33412203192710876 \n",
      "[2020-04-27 22:26:28.370 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3158499598503113 \n",
      "[2020-04-27 22:26:28.374 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16830061376094818 \n",
      "[2020-04-27 22:26:28.375 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3071542978286743 \n",
      "[2020-04-27 22:26:28.376 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.332659512758255 \n",
      "[2020-04-27 22:26:28.378 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33411905169487 \n",
      "[2020-04-27 22:26:28.379 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3158169090747833 \n",
      "[2020-04-27 22:26:28.382 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1678180992603302 \n",
      "[2020-04-27 22:26:28.384 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30694863200187683 \n",
      "[2020-04-27 22:26:28.385 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33265912532806396 \n",
      "[2020-04-27 22:26:28.386 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33411726355552673 \n",
      "[2020-04-27 22:26:28.387 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31579694151878357 \n",
      "[2020-04-27 22:26:28.391 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.167400062084198 \n",
      "[2020-04-27 22:26:28.392 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30677223205566406 \n",
      "[2020-04-27 22:26:28.394 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326588273048401 \n",
      "[2020-04-27 22:26:28.395 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3341156840324402 \n",
      "[2020-04-27 22:26:28.396 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31577932834625244 \n",
      "[2020-04-27 22:26:28.400 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16703404486179352 \n",
      "[2020-04-27 22:26:28.401 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30660226941108704 \n",
      "[2020-04-27 22:26:28.402 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326585292816162 \n",
      "[2020-04-27 22:26:28.404 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3341141939163208 \n",
      "[2020-04-27 22:26:28.405 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31576237082481384 \n",
      "[2020-04-27 22:26:28.408 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16684456169605255 \n",
      "[2020-04-27 22:26:28.409 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3065086007118225 \n",
      "[2020-04-27 22:26:28.411 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326583206653595 \n",
      "[2020-04-27 22:26:28.412 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3341132402420044 \n",
      "[2020-04-27 22:26:28.413 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3157515525817871 \n",
      "[2020-04-27 22:26:28.416 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16657119989395142 \n",
      "[2020-04-27 22:26:28.418 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.306401789188385 \n",
      "[2020-04-27 22:26:28.419 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33265814185142517 \n",
      "[2020-04-27 22:26:28.420 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3341123163700104 \n",
      "[2020-04-27 22:26:28.422 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3157411217689514 \n",
      "[2020-04-27 22:26:28.425 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16639144718647003 \n",
      "[2020-04-27 22:26:28.426 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30630478262901306 \n",
      "[2020-04-27 22:26:28.428 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33265799283981323 \n",
      "[2020-04-27 22:26:28.429 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33411142230033875 \n",
      "[2020-04-27 22:26:28.430 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3157315254211426 \n",
      "[2020-04-27 22:26:28.434 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.1662261188030243 \n",
      "[2020-04-27 22:26:28.435 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.306240439414978 \n",
      "[2020-04-27 22:26:28.436 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326578736305237 \n",
      "[2020-04-27 22:26:28.438 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.33411091566085815 \n",
      "[2020-04-27 22:26:28.439 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.315725713968277 \n",
      "[2020-04-27 22:26:28.443 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16605880856513977 \n",
      "[2020-04-27 22:26:28.444 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.30617889761924744 \n",
      "[2020-04-27 22:26:28.445 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.33265775442123413 \n",
      "[2020-04-27 22:26:28.447 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3341103196144104 \n",
      "[2020-04-27 22:26:28.448 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.3157185912132263 \n",
      "[2020-04-27 22:26:28.451 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv0_weight  has weights with variance: 0.16584762930870056 \n",
      "[2020-04-27 22:26:28.452 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  conv1_weight  has weights with variance: 0.3061014711856842 \n",
      "[2020-04-27 22:26:28.454 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense0_weight  has weights with variance: 0.3326576054096222 \n",
      "[2020-04-27 22:26:28.455 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense1_weight  has weights with variance: 0.3341095745563507 \n",
      "[2020-04-27 22:26:28.456 f8455ab5c5ab:17 INFO <ipython-input-20-f8ca0a68fd3b>:14]  Tensor  dense2_weight  has weights with variance: 0.31571054458618164 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class WeightRatio(Rule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_trial,\n",
    "    ):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*weight\"):\n",
    "            if \"gradient\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "\n",
    "                    self.logger.info(\n",
    "                        f\" Tensor  {tname}  has weights with variance: {np.var(tensor.flatten())} \"\n",
    "                    )\n",
    "                    self.tensors[tname][step] = tensor\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = WeightRatio(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename=\"images/weights.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/weights.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/weights.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "This rule retrieves layer inputs excluding activation inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:32:04.465 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:32:04.478 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule Inputs at step 0\n",
      "[2020-04-27 22:32:04.479 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:32:05.481 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:32:05.484 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0022085905075073 \n",
      "[2020-04-27 22:32:05.486 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 4.837328910827637 \n",
      "[2020-04-27 22:32:05.487 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 61.04131317138672 \n",
      "[2020-04-27 22:32:05.489 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 4858.85498046875 \n",
      "[2020-04-27 22:32:05.490 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 101189.0859375 \n",
      "[2020-04-27 22:32:05.492 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 61.04131317138672 \n",
      "[2020-04-27 22:32:05.494 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0022085905075073 \n",
      "[2020-04-27 22:32:05.498 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 3.8557262420654297 \n",
      "[2020-04-27 22:32:05.501 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 45.9383430480957 \n",
      "[2020-04-27 22:32:05.502 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 4755455.5 \n",
      "[2020-04-27 22:32:05.503 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 6.94427490234375 \n",
      "[2020-04-27 22:32:05.507 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0382660627365112 \n",
      "[2020-04-27 22:32:05.509 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 0.9459593892097473 \n",
      "[2020-04-27 22:32:05.511 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 0.17505891621112823 \n",
      "[2020-04-27 22:32:05.512 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 7.910542964935303 \n",
      "[2020-04-27 22:32:05.514 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 86.47700500488281 \n",
      "[2020-04-27 22:32:05.515 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 0.17505891621112823 \n",
      "[2020-04-27 22:32:05.517 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0382660627365112 \n",
      "[2020-04-27 22:32:05.521 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 0.6746492981910706 \n",
      "[2020-04-27 22:32:05.524 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 0.05903790891170502 \n",
      "[2020-04-27 22:32:05.525 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 2002.4222412109375 \n",
      "[2020-04-27 22:32:05.527 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.425537109375 \n",
      "[2020-04-27 22:32:05.531 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0198570489883423 \n",
      "[2020-04-27 22:32:05.533 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.1717904806137085 \n",
      "[2020-04-27 22:32:05.534 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 0.0001082921153283678 \n",
      "[2020-04-27 22:32:05.536 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.006595073267817497 \n",
      "[2020-04-27 22:32:05.537 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.08806044608354568 \n",
      "[2020-04-27 22:32:05.539 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 0.0001082921153283678 \n",
      "[2020-04-27 22:32:05.541 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0198570489883423 \n",
      "[2020-04-27 22:32:05.545 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 0.9156947731971741 \n",
      "[2020-04-27 22:32:05.547 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.707789644773584e-05 \n",
      "[2020-04-27 22:32:05.548 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 2.1487646102905273 \n",
      "[2020-04-27 22:32:05.550 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 9.058349609375 \n",
      "[2020-04-27 22:32:05.554 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0281227827072144 \n",
      "[2020-04-27 22:32:05.556 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.253706932067871 \n",
      "[2020-04-27 22:32:05.557 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 3.753396595129743e-05 \n",
      "[2020-04-27 22:32:05.559 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0021490983199328184 \n",
      "[2020-04-27 22:32:05.560 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.044917792081832886 \n",
      "[2020-04-27 22:32:05.562 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 3.753396595129743e-05 \n",
      "[2020-04-27 22:32:05.563 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0281227827072144 \n",
      "[2020-04-27 22:32:05.568 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 0.9761512875556946 \n",
      "[2020-04-27 22:32:05.570 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 9.383727956446819e-06 \n",
      "[2020-04-27 22:32:05.572 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.8199729919433594 \n",
      "[2020-04-27 22:32:05.573 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.21331787109375 \n",
      "[2020-04-27 22:32:05.577 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9971755743026733 \n",
      "[2020-04-27 22:32:05.579 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.2787492275238037 \n",
      "[2020-04-27 22:32:05.581 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 6.2718777371628676e-06 \n",
      "[2020-04-27 22:32:05.582 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0003672760212793946 \n",
      "[2020-04-27 22:32:05.584 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.0041027916595339775 \n",
      "[2020-04-27 22:32:05.585 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 6.2718777371628676e-06 \n",
      "[2020-04-27 22:32:05.587 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9971755743026733 \n",
      "[2020-04-27 22:32:05.591 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 0.9919278025627136 \n",
      "[2020-04-27 22:32:05.594 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 1.5680340084145428e-06 \n",
      "[2020-04-27 22:32:05.595 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.06334616988897324 \n",
      "[2020-04-27 22:32:05.597 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.45159912109375 \n",
      "[2020-04-27 22:32:05.601 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9978470206260681 \n",
      "[2020-04-27 22:32:05.603 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.3073381185531616 \n",
      "[2020-04-27 22:32:05.604 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 0.00012139216414652765 \n",
      "[2020-04-27 22:32:05.606 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.007483721245080233 \n",
      "[2020-04-27 22:32:05.607 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.12912829220294952 \n",
      "[2020-04-27 22:32:05.609 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 0.00012139216414652765 \n",
      "[2020-04-27 22:32:05.611 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9978470206260681 \n",
      "[2020-04-27 22:32:05.615 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.028836965560913 \n",
      "[2020-04-27 22:32:05.617 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 3.0349472581292503e-05 \n",
      "[2020-04-27 22:32:05.619 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 1.7704318761825562 \n",
      "[2020-04-27 22:32:05.620 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.39056396484375 \n",
      "[2020-04-27 22:32:05.624 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.008055567741394 \n",
      "[2020-04-27 22:32:05.626 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.3306946754455566 \n",
      "[2020-04-27 22:32:05.628 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 3.252170444056901e-08 \n",
      "[2020-04-27 22:32:05.629 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 2.365610998822376e-05 \n",
      "[2020-04-27 22:32:05.630 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.00015047297347337008 \n",
      "[2020-04-27 22:32:05.632 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 3.252170444056901e-08 \n",
      "[2020-04-27 22:32:05.634 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.008055567741394 \n",
      "[2020-04-27 22:32:05.638 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0411734580993652 \n",
      "[2020-04-27 22:32:05.640 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 8.130546014228912e-09 \n",
      "[2020-04-27 22:32:05.642 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.002294825157150626 \n",
      "[2020-04-27 22:32:05.643 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 9.003662109375 \n",
      "[2020-04-27 22:32:05.648 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0232324600219727 \n",
      "[2020-04-27 22:32:05.650 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.3793084621429443 \n",
      "[2020-04-27 22:32:05.651 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 4.94571509079833e-07 \n",
      "[2020-04-27 22:32:05.653 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 4.7780114982742816e-05 \n",
      "[2020-04-27 22:32:05.654 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.00031508668325841427 \n",
      "[2020-04-27 22:32:05.656 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 4.94571509079833e-07 \n",
      "[2020-04-27 22:32:05.660 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0232324600219727 \n",
      "[2020-04-27 22:32:05.664 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0787978172302246 \n",
      "[2020-04-27 22:32:05.667 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 1.2364471047021652e-07 \n",
      "[2020-04-27 22:32:05.668 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.0036758738569915295 \n",
      "[2020-04-27 22:32:05.669 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.27044677734375 \n",
      "[2020-04-27 22:32:05.674 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9817230105400085 \n",
      "[2020-04-27 22:32:05.676 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.331855058670044 \n",
      "[2020-04-27 22:32:05.677 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 8.019285814953037e-06 \n",
      "[2020-04-27 22:32:05.679 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0005264292121864855 \n",
      "[2020-04-27 22:32:05.680 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.006017645820975304 \n",
      "[2020-04-27 22:32:05.682 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 8.019285814953037e-06 \n",
      "[2020-04-27 22:32:05.684 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9817230105400085 \n",
      "[2020-04-27 22:32:05.688 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0465368032455444 \n",
      "[2020-04-27 22:32:05.691 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.004851694437093e-06 \n",
      "[2020-04-27 22:32:05.693 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.04721779003739357 \n",
      "[2020-04-27 22:32:05.694 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.9287109375 \n",
      "[2020-04-27 22:32:05.698 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0242054462432861 \n",
      "[2020-04-27 22:32:05.700 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.378627061843872 \n",
      "[2020-04-27 22:32:05.702 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 2.1695792383980006e-05 \n",
      "[2020-04-27 22:32:05.703 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.001327343052253127 \n",
      "[2020-04-27 22:32:05.705 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.018383827060461044 \n",
      "[2020-04-27 22:32:05.706 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 2.1695792383980006e-05 \n",
      "[2020-04-27 22:32:05.708 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0242054462432861 \n",
      "[2020-04-27 22:32:05.713 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0938211679458618 \n",
      "[2020-04-27 22:32:05.715 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 5.424161372502567e-06 \n",
      "[2020-04-27 22:32:05.717 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.31357529759407043 \n",
      "[2020-04-27 22:32:05.718 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.96673583984375 \n",
      "[2020-04-27 22:32:05.722 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 0.9887260794639587 \n",
      "[2020-04-27 22:32:05.724 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.371474266052246 \n",
      "[2020-04-27 22:32:05.726 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 1.5929039363982156e-05 \n",
      "[2020-04-27 22:32:05.728 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0008869253215380013 \n",
      "[2020-04-27 22:32:05.729 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.016046544536948204 \n",
      "[2020-04-27 22:32:05.731 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 1.5929039363982156e-05 \n",
      "[2020-04-27 22:32:05.733 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 0.9887260794639587 \n",
      "[2020-04-27 22:32:05.737 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0736607313156128 \n",
      "[2020-04-27 22:32:05.740 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 3.982330781582277e-06 \n",
      "[2020-04-27 22:32:05.741 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.4613666534423828 \n",
      "[2020-04-27 22:32:05.743 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.71478271484375 \n",
      "[2020-04-27 22:32:05.747 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.044722557067871 \n",
      "[2020-04-27 22:32:05.749 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.4431350231170654 \n",
      "[2020-04-27 22:32:05.751 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 3.6252138670533895e-05 \n",
      "[2020-04-27 22:32:05.752 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.002536121755838394 \n",
      "[2020-04-27 22:32:05.754 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.03773382306098938 \n",
      "[2020-04-27 22:32:05.755 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 3.6252138670533895e-05 \n",
      "[2020-04-27 22:32:05.757 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.044722557067871 \n",
      "[2020-04-27 22:32:05.764 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1411879062652588 \n",
      "[2020-04-27 22:32:05.767 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 9.063288416655269e-06 \n",
      "[2020-04-27 22:32:05.769 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.8734733462333679 \n",
      "[2020-04-27 22:32:05.770 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 9.15234375 \n",
      "[2020-04-27 22:32:05.775 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0004746913909912 \n",
      "[2020-04-27 22:32:05.777 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.396453857421875 \n",
      "[2020-04-27 22:32:05.778 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 2.1215093966020504e-06 \n",
      "[2020-04-27 22:32:05.780 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.00013638548261951655 \n",
      "[2020-04-27 22:32:05.781 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.0017073529306799173 \n",
      "[2020-04-27 22:32:05.783 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 2.1215093966020504e-06 \n",
      "[2020-04-27 22:32:05.785 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0004746913909912 \n",
      "[2020-04-27 22:32:05.792 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.0999025106430054 \n",
      "[2020-04-27 22:32:05.795 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 5.303852503857343e-07 \n",
      "[2020-04-27 22:32:05.797 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.018587639555335045 \n",
      "[2020-04-27 22:32:05.798 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.761474609375 \n",
      "[2020-04-27 22:32:05.806 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.033023476600647 \n",
      "[2020-04-27 22:32:05.808 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.4274266958236694 \n",
      "[2020-04-27 22:32:05.810 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 1.6721925931051373e-05 \n",
      "[2020-04-27 22:32:05.811 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0012562214396893978 \n",
      "[2020-04-27 22:32:05.813 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.015492375008761883 \n",
      "[2020-04-27 22:32:05.814 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 1.6721925931051373e-05 \n",
      "[2020-04-27 22:32:05.816 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.033023476600647 \n",
      "[2020-04-27 22:32:05.824 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1269475221633911 \n",
      "[2020-04-27 22:32:05.826 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 4.180543328402564e-06 \n",
      "[2020-04-27 22:32:05.828 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.15919239819049835 \n",
      "[2020-04-27 22:32:05.829 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 8.51171875 \n",
      "[2020-04-27 22:32:05.834 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv0_input_0  has inputs with variance: 1.0635137557983398 \n",
      "[2020-04-27 22:32:05.836 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  conv1_input_0  has inputs with variance: 1.4563753604888916 \n",
      "[2020-04-27 22:32:05.838 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense0_input_0  has inputs with variance: 8.708776476851199e-06 \n",
      "[2020-04-27 22:32:05.839 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense1_input_0  has inputs with variance: 0.0006208218983374536 \n",
      "[2020-04-27 22:32:05.841 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  dense2_input_0  has inputs with variance: 0.007469493895769119 \n",
      "[2020-04-27 22:32:05.842 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  flatten0_input_0  has inputs with variance: 8.708776476851199e-06 \n",
      "[2020-04-27 22:32:05.844 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  hybridsequential0_input_0  has inputs with variance: 1.0635137557983398 \n",
      "[2020-04-27 22:32:05.851 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool0_input_0  has inputs with variance: 1.1511449813842773 \n",
      "[2020-04-27 22:32:05.853 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  pool1_input_0  has inputs with variance: 2.177228680011467e-06 \n",
      "[2020-04-27 22:32:05.855 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_0  has inputs with variance: 0.1533646434545517 \n",
      "[2020-04-27 22:32:05.856 f8455ab5c5ab:17 INFO <ipython-input-23-c408f5ccc2ae>:14]  Tensor  softmaxcrossentropyloss0_input_1  has inputs with variance: 7.86468505859375 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class Inputs(Rule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_trial,\n",
    "    ):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*input\"):\n",
    "            if \"relu\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "\n",
    "                    self.logger.info(\n",
    "                        f\" Tensor  {tname}  has inputs with variance: {np.var(tensor.flatten())} \"\n",
    "                    )\n",
    "                    self.tensors[tname][step] = tensor\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = Inputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename=\"images/layer_inputs.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/layer_inputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/layer_inputs.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer outputs\n",
    "This rule retrieves outputs of layers excluding activation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 22:32:42.983 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output at path /tmp/debug-output\n",
      "[2020-04-27 22:32:42.998 f8455ab5c5ab:17 INFO rule_invoker.py:15] Started execution of rule Outputs at step 0\n",
      "[2020-04-27 22:32:43.002 f8455ab5c5ab:17 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-04-27 22:32:44.004 f8455ab5c5ab:17 INFO trial.py:210] Loaded all steps\n",
      "[2020-04-27 22:32:44.009 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 3.8557262420654297 \n",
      "[2020-04-27 22:32:44.012 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 45.9383430480957 \n",
      "[2020-04-27 22:32:44.013 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 4858.85498046875 \n",
      "[2020-04-27 22:32:44.014 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 101189.0859375 \n",
      "[2020-04-27 22:32:44.015 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 4755455.5 \n",
      "[2020-04-27 22:32:44.017 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 61.04131317138672 \n",
      "[2020-04-27 22:32:44.018 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 4755455.5 \n",
      "[2020-04-27 22:32:44.019 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 4.837328910827637 \n",
      "[2020-04-27 22:32:44.021 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 61.04131317138672 \n",
      "[2020-04-27 22:32:44.022 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 5444150.0 \n",
      "[2020-04-27 22:32:44.028 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 0.6746492981910706 \n",
      "[2020-04-27 22:32:44.030 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 0.05903790891170502 \n",
      "[2020-04-27 22:32:44.031 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 7.910542964935303 \n",
      "[2020-04-27 22:32:44.033 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 86.47700500488281 \n",
      "[2020-04-27 22:32:44.034 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 2002.4222412109375 \n",
      "[2020-04-27 22:32:44.035 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 0.17505891621112823 \n",
      "[2020-04-27 22:32:44.036 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 2002.4222412109375 \n",
      "[2020-04-27 22:32:44.038 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 0.9459593892097473 \n",
      "[2020-04-27 22:32:44.039 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 0.17505891621112823 \n",
      "[2020-04-27 22:32:44.040 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 1036.709228515625 \n",
      "[2020-04-27 22:32:44.046 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 0.9156947731971741 \n",
      "[2020-04-27 22:32:44.048 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.707789644773584e-05 \n",
      "[2020-04-27 22:32:44.050 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.006595073267817497 \n",
      "[2020-04-27 22:32:44.051 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.08806044608354568 \n",
      "[2020-04-27 22:32:44.052 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 2.1487646102905273 \n",
      "[2020-04-27 22:32:44.053 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 0.0001082921153283678 \n",
      "[2020-04-27 22:32:44.055 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 2.1487646102905273 \n",
      "[2020-04-27 22:32:44.056 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.1717904806137085 \n",
      "[2020-04-27 22:32:44.058 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 0.0001082921153283678 \n",
      "[2020-04-27 22:32:44.059 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 2.7193961143493652 \n",
      "[2020-04-27 22:32:44.064 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 0.9761512875556946 \n",
      "[2020-04-27 22:32:44.067 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 9.383727956446819e-06 \n",
      "[2020-04-27 22:32:44.068 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0021490983199328184 \n",
      "[2020-04-27 22:32:44.069 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.044917792081832886 \n",
      "[2020-04-27 22:32:44.071 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.8199729919433594 \n",
      "[2020-04-27 22:32:44.072 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 3.753396595129743e-05 \n",
      "[2020-04-27 22:32:44.073 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.8199729919433594 \n",
      "[2020-04-27 22:32:44.075 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.253706932067871 \n",
      "[2020-04-27 22:32:44.076 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 3.753396595129743e-05 \n",
      "[2020-04-27 22:32:44.077 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 3.8310861587524414 \n",
      "[2020-04-27 22:32:44.084 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 0.9919278025627136 \n",
      "[2020-04-27 22:32:44.086 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 1.5680340084145428e-06 \n",
      "[2020-04-27 22:32:44.087 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0003672760212793946 \n",
      "[2020-04-27 22:32:44.092 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.0041027916595339775 \n",
      "[2020-04-27 22:32:44.093 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.06334616988897324 \n",
      "[2020-04-27 22:32:44.094 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 6.2718777371628676e-06 \n",
      "[2020-04-27 22:32:44.096 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.06334616988897324 \n",
      "[2020-04-27 22:32:44.097 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.2787492275238037 \n",
      "[2020-04-27 22:32:44.099 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 6.2718777371628676e-06 \n",
      "[2020-04-27 22:32:44.100 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.08870527893304825 \n",
      "[2020-04-27 22:32:44.106 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.028836965560913 \n",
      "[2020-04-27 22:32:44.109 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 3.0349472581292503e-05 \n",
      "[2020-04-27 22:32:44.110 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.007483721245080233 \n",
      "[2020-04-27 22:32:44.111 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.12912829220294952 \n",
      "[2020-04-27 22:32:44.112 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 1.7704318761825562 \n",
      "[2020-04-27 22:32:44.114 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 0.00012139216414652765 \n",
      "[2020-04-27 22:32:44.115 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 1.7704318761825562 \n",
      "[2020-04-27 22:32:44.116 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.3073381185531616 \n",
      "[2020-04-27 22:32:44.118 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 0.00012139216414652765 \n",
      "[2020-04-27 22:32:44.119 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 1.3741402626037598 \n",
      "[2020-04-27 22:32:44.125 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0411734580993652 \n",
      "[2020-04-27 22:32:44.128 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 8.130546014228912e-09 \n",
      "[2020-04-27 22:32:44.129 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 2.365610998822376e-05 \n",
      "[2020-04-27 22:32:44.130 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.00015047297347337008 \n",
      "[2020-04-27 22:32:44.132 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.002294825157150626 \n",
      "[2020-04-27 22:32:44.133 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 3.252170444056901e-08 \n",
      "[2020-04-27 22:32:44.134 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.002294825157150626 \n",
      "[2020-04-27 22:32:44.136 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.3306946754455566 \n",
      "[2020-04-27 22:32:44.137 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 3.252170444056901e-08 \n",
      "[2020-04-27 22:32:44.138 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.002003903966397047 \n",
      "[2020-04-27 22:32:44.144 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0787978172302246 \n",
      "[2020-04-27 22:32:44.147 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 1.2364471047021652e-07 \n",
      "[2020-04-27 22:32:44.148 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 4.7780114982742816e-05 \n",
      "[2020-04-27 22:32:44.150 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.00031508668325841427 \n",
      "[2020-04-27 22:32:44.151 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.0036758738569915295 \n",
      "[2020-04-27 22:32:44.152 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 4.94571509079833e-07 \n",
      "[2020-04-27 22:32:44.153 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.0036758738569915295 \n",
      "[2020-04-27 22:32:44.155 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.3793084621429443 \n",
      "[2020-04-27 22:32:44.157 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 4.94571509079833e-07 \n",
      "[2020-04-27 22:32:44.158 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.001982209738343954 \n",
      "[2020-04-27 22:32:44.164 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0465368032455444 \n",
      "[2020-04-27 22:32:44.167 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.004851694437093e-06 \n",
      "[2020-04-27 22:32:44.168 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0005264292121864855 \n",
      "[2020-04-27 22:32:44.169 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.006017645820975304 \n",
      "[2020-04-27 22:32:44.170 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.04721779003739357 \n",
      "[2020-04-27 22:32:44.172 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 8.019285814953037e-06 \n",
      "[2020-04-27 22:32:44.173 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.04721779003739357 \n",
      "[2020-04-27 22:32:44.177 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.331855058670044 \n",
      "[2020-04-27 22:32:44.178 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 8.019285814953037e-06 \n",
      "[2020-04-27 22:32:44.179 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.1639312207698822 \n",
      "[2020-04-27 22:32:44.186 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0938211679458618 \n",
      "[2020-04-27 22:32:44.188 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 5.424161372502567e-06 \n",
      "[2020-04-27 22:32:44.190 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.001327343052253127 \n",
      "[2020-04-27 22:32:44.191 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.018383827060461044 \n",
      "[2020-04-27 22:32:44.192 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.31357529759407043 \n",
      "[2020-04-27 22:32:44.193 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 2.1695792383980006e-05 \n",
      "[2020-04-27 22:32:44.195 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.31357529759407043 \n",
      "[2020-04-27 22:32:44.196 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.378627061843872 \n",
      "[2020-04-27 22:32:44.198 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 2.1695792383980006e-05 \n",
      "[2020-04-27 22:32:44.199 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.30675774812698364 \n",
      "[2020-04-27 22:32:44.205 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0736607313156128 \n",
      "[2020-04-27 22:32:44.208 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 3.982330781582277e-06 \n",
      "[2020-04-27 22:32:44.209 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0008869253215380013 \n",
      "[2020-04-27 22:32:44.210 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.016046544536948204 \n",
      "[2020-04-27 22:32:44.212 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.4613666534423828 \n",
      "[2020-04-27 22:32:44.213 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 1.5929039363982156e-05 \n",
      "[2020-04-27 22:32:44.214 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.4613666534423828 \n",
      "[2020-04-27 22:32:44.216 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.371474266052246 \n",
      "[2020-04-27 22:32:44.218 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 1.5929039363982156e-05 \n",
      "[2020-04-27 22:32:44.219 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.04083283618092537 \n",
      "[2020-04-27 22:32:44.225 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1411879062652588 \n",
      "[2020-04-27 22:32:44.228 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 9.063288416655269e-06 \n",
      "[2020-04-27 22:32:44.229 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.002536121755838394 \n",
      "[2020-04-27 22:32:44.230 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.03773382306098938 \n",
      "[2020-04-27 22:32:44.231 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.8734733462333679 \n",
      "[2020-04-27 22:32:44.233 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 3.6252138670533895e-05 \n",
      "[2020-04-27 22:32:44.234 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.8734733462333679 \n",
      "[2020-04-27 22:32:44.236 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.4431350231170654 \n",
      "[2020-04-27 22:32:44.237 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 3.6252138670533895e-05 \n",
      "[2020-04-27 22:32:44.238 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.043457046151161194 \n",
      "[2020-04-27 22:32:44.245 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.0999025106430054 \n",
      "[2020-04-27 22:32:44.247 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 5.303852503857343e-07 \n",
      "[2020-04-27 22:32:44.249 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.00013638548261951655 \n",
      "[2020-04-27 22:32:44.250 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.0017073529306799173 \n",
      "[2020-04-27 22:32:44.251 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.018587639555335045 \n",
      "[2020-04-27 22:32:44.253 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 2.1215093966020504e-06 \n",
      "[2020-04-27 22:32:44.254 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.018587639555335045 \n",
      "[2020-04-27 22:32:44.256 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.396453857421875 \n",
      "[2020-04-27 22:32:44.257 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 2.1215093966020504e-06 \n",
      "[2020-04-27 22:32:44.258 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.0009186549577862024 \n",
      "[2020-04-27 22:32:44.265 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1269475221633911 \n",
      "[2020-04-27 22:32:44.267 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 4.180543328402564e-06 \n",
      "[2020-04-27 22:32:44.269 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0012562214396893978 \n",
      "[2020-04-27 22:32:44.270 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.015492375008761883 \n",
      "[2020-04-27 22:32:44.271 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.15919239819049835 \n",
      "[2020-04-27 22:32:44.273 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 1.6721925931051373e-05 \n",
      "[2020-04-27 22:32:44.274 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.15919239819049835 \n",
      "[2020-04-27 22:32:44.276 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.4274266958236694 \n",
      "[2020-04-27 22:32:44.277 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 1.6721925931051373e-05 \n",
      "[2020-04-27 22:32:44.278 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.0026462958194315434 \n",
      "[2020-04-27 22:32:44.285 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv0_output_0  has inputs with variance: 1.1511449813842773 \n",
      "[2020-04-27 22:32:44.287 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  conv1_output_0  has inputs with variance: 2.177228680011467e-06 \n",
      "[2020-04-27 22:32:44.289 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense0_output_0  has inputs with variance: 0.0006208218983374536 \n",
      "[2020-04-27 22:32:44.290 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense1_output_0  has inputs with variance: 0.007469493895769119 \n",
      "[2020-04-27 22:32:44.291 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  dense2_output_0  has inputs with variance: 0.1533646434545517 \n",
      "[2020-04-27 22:32:44.292 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  flatten0_output_0  has inputs with variance: 8.708776476851199e-06 \n",
      "[2020-04-27 22:32:44.294 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  hybridsequential0_output_0  has inputs with variance: 0.1533646434545517 \n",
      "[2020-04-27 22:32:44.295 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool0_output_0  has inputs with variance: 1.4563753604888916 \n",
      "[2020-04-27 22:32:44.297 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  pool1_output_0  has inputs with variance: 8.708776476851199e-06 \n",
      "[2020-04-27 22:32:44.298 f8455ab5c5ab:17 INFO <ipython-input-26-54f31e2b0743>:14]  Tensor  softmaxcrossentropyloss0_output_0  has inputs with variance: 0.38224971294403076 \n",
      "The training has ended and there is no more data to be analyzed. This is expected behavior.\n"
     ]
    }
   ],
   "source": [
    "class Outputs(Rule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_trial,\n",
    "    ):\n",
    "        super().__init__(base_trial)\n",
    "        self.tensors = collections.OrderedDict()\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        for tname in self.base_trial.tensor_names(regex=\".*output\"):\n",
    "            if \"relu\" not in tname:\n",
    "                try:\n",
    "                    tensor = self.base_trial.tensor(tname).value(step)\n",
    "                    if tname not in self.tensors:\n",
    "                        self.tensors[tname] = {}\n",
    "\n",
    "                    self.logger.info(\n",
    "                        f\" Tensor  {tname}  has inputs with variance: {np.var(tensor.flatten())} \"\n",
    "                    )\n",
    "                    self.tensors[tname][step] = tensor\n",
    "                except:\n",
    "                    self.logger.warning(f\"Can not fetch tensor {tname}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "trial = create_trial(folder_name)\n",
    "rule = Outputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(rule.tensors, filename=\"images/layer_outputs.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/layer_outputs.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/layer_outputs.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison \n",
    "In the previous section we have looked at the distribution of gradients, activation outputs and weights of a model that has not trained well due to poor initialization. Now we will compare some of these distributions with a model that has been well intialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = \"mnist.py\"\n",
    "hyperparameters = {\"lr\": 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=\"mxnet\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    train_volume_size=400,\n",
    "    source_dir=\"src\",\n",
    "    entry_point=entry_point_script,\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=s3_bucket_for_tensors,\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"all\", parameters={\"include_regex\": \".*\", \"save_interval\": \"100\"})\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get S3 path where tensors have been stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors are stored in:  s3://sagemaker-us-east-2-441510144314/smdebug-mnist-tensor-analysis/mxnet-2020-04-27-23-22-21-264/debug-output\n"
     ]
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "path = description[\"DebugHookConfig\"][\"S3OutputPath\"] + \"/\" + job_name + \"/debug-output\"\n",
    "print(\"Tensors are stored in: \", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tensors from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tensors into folder:  /tmp/debug-output_2\n"
     ]
    }
   ],
   "source": [
    "folder_name2 = \"/tmp/{}_2\".format(path.split(\"/\")[-1])\n",
    "os.system(\"aws s3 cp --recursive {} {}\".format(path, folder_name2))\n",
    "print(\"Downloading tensors into folder: \", folder_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "\n",
    "Lets compare distribution of gradients of the convolutional layers of both trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7e87990373ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientsLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minvoke_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNoMoreData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_trial' is not defined"
     ]
    }
   ],
   "source": [
    "trial = create_trial(folder_name)\n",
    "rule = GradientsLayer(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6173c401a4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdict_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gradient/conv0_weight_bad_hyperparameters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gradient/conv0_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdict_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gradient/conv1_weight_bad_hyperparameters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gradient/conv1_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rule' is not defined"
     ]
    }
   ],
   "source": [
    "dict_gradients = {}\n",
    "dict_gradients[\"gradient/conv0_weight_bad_hyperparameters\"] = rule.tensors[\"gradient/conv0_weight\"]\n",
    "dict_gradients[\"gradient/conv1_weight_bad_hyperparameters\"] = rule.tensors[\"gradient/conv1_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-27 23:02:30.733 f8455ab5c5ab:17 INFO local_trial.py:35] Loading trial debug-output_2 at path /tmp/debug-output_2\n",
      "[2020-04-27 23:02:50.754 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:02:52.757 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:02:54.760 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:02:56.763 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:02:58.766 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:00.769 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:02.772 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:04.775 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:06.778 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:08.781 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:10.784 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:12.787 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:14.790 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:16.793 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:18.796 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:20.799 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:22.802 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:24.804 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:26.807 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:28.810 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:30.813 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:32.816 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:34.819 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:36.822 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:38.825 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:40.828 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:42.831 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:44.834 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:46.837 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:48.840 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:50.843 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:52.844 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:54.846 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:56.848 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:03:58.849 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:00.851 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:02.854 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:04.856 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:06.859 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:08.862 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:10.865 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:12.868 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:14.871 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:16.876 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:18.878 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:20.879 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:22.882 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:24.886 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:26.888 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:28.892 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:30.895 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:32.898 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:34.901 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:36.903 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:38.906 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:40.909 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:42.912 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:44.915 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:46.918 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:48.921 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:50.924 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:52.927 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:54.930 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:56.932 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:04:58.934 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:00.937 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:02.940 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:04.943 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:06.946 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:08.951 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:10.954 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:12.957 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:14.960 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:16.962 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:18.965 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:20.968 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:22.972 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:24.974 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:26.977 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:28.978 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:30.979 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:32.981 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:34.982 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:36.983 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:38.985 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:40.987 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:42.990 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:44.994 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:46.996 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:48.999 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:51.002 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:53.006 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:55.008 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:57.011 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:05:59.014 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:01.017 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:03.019 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:05.023 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:07.026 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:09.029 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:11.031 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:13.034 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:15.036 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:17.039 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:19.042 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:21.044 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:23.047 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:25.050 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:27.053 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:29.056 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:31.059 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:33.062 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:35.064 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:37.068 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:39.070 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:41.073 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:43.076 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:45.079 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:47.082 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:49.084 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:51.087 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:53.090 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:55.093 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:57.096 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:06:59.099 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:01.102 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:03.105 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:05.108 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:07.109 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:09.111 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:11.114 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:13.117 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:15.120 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:17.123 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:19.126 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:21.129 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:23.132 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:25.135 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:27.138 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:29.141 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:31.144 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:33.147 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:35.150 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:37.153 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:39.156 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:41.159 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:43.162 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:45.165 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:47.168 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:49.171 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:51.174 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:53.177 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:55.180 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:57.183 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:07:59.186 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:01.189 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:03.192 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:05.195 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:07.198 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:09.201 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:11.204 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:13.207 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:15.210 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:17.211 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:19.215 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:21.218 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:23.221 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:25.223 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:27.226 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:29.230 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:31.231 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:33.237 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:35.240 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:37.243 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:39.246 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:41.247 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:43.250 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:45.253 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:47.256 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:49.258 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:51.261 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:53.264 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:55.267 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:57.270 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:08:59.271 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:01.273 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:03.276 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:05.279 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:07.282 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:09.285 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:11.288 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:13.291 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:15.294 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:17.297 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:19.300 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:21.303 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:23.306 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:25.307 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:27.310 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:29.313 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:31.316 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:33.319 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:35.322 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:37.325 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:39.328 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:41.331 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:43.334 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:45.336 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:47.338 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:49.342 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:51.343 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:53.346 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:55.348 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:57.350 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:09:59.353 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:01.356 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:03.359 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:05.362 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:07.365 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:09.368 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:11.371 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:13.374 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:15.377 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:17.380 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:19.382 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:21.385 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:23.387 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:25.390 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:27.393 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:29.396 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:31.399 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:33.403 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:35.406 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:37.409 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:39.410 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:41.412 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:43.413 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:45.414 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:47.417 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:49.420 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:51.423 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:53.426 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:55.429 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:57.432 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:10:59.435 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:01.438 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:03.441 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:05.444 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:07.447 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:09.450 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:11.453 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:13.454 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:15.457 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:17.460 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:19.463 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:21.466 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:23.469 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:25.472 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:27.475 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:29.478 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:31.481 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:33.484 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:35.486 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:37.489 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:39.491 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:41.493 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:43.496 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:45.499 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:47.502 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:49.505 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:51.507 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:53.510 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:55.511 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n",
      "[2020-04-27 23:11:57.514 f8455ab5c5ab:17 WARNING trial.py:148] Waiting to read collections files generated by the training job,from /tmp/debug-output_2. If this has been a while, you might want to check that the trial is pointed at the right path.\n"
     ]
    }
   ],
   "source": [
    "trial = create_trial(folder_name2)\n",
    "rule = GradientsLayer(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gradients[\"gradient/conv0_weight_good_hyperparameters\"] = rule.tensors[\"gradient/conv0_weight\"]\n",
    "dict_gradients[\"gradient/conv1_weight_good_hyperparameters\"] = rule.tensors[\"gradient/conv1_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(\n",
    "    dict_gradients, filename=\"images/gradients_comparison.gif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the poorly initalized model, gradients are fluctuating a lot leading to very high variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"images/gradients_comparison.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation inputs\n",
    "\n",
    "Lets compare distribution of activation inputs of both trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(folder_name)\n",
    "rule = ActivationInputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_activation_inputs = {}\n",
    "dict_activation_inputs[\"conv0_relu_input_0_bad_hyperparameters\"] = rule.tensors[\n",
    "    \"conv0_relu_input_0\"\n",
    "]\n",
    "dict_activation_inputs[\"conv1_relu_input_0_bad_hyperparameters\"] = rule.tensors[\n",
    "    \"conv1_relu_input_0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(folder_name2)\n",
    "rule = ActivationInputs(trial)\n",
    "try:\n",
    "    invoke_rule(rule)\n",
    "except NoMoreData:\n",
    "    print(\n",
    "        \"The training has ended and there is no more data to be analyzed. This is expected behavior.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_activation_inputs[\"conv0_relu_input_0_good_hyperparameters\"] = rule.tensors[\n",
    "    \"conv0_relu_input_0\"\n",
    "]\n",
    "dict_activation_inputs[\"conv1_relu_input_0_good_hyperparameters\"] = rule.tensors[\n",
    "    \"conv1_relu_input_0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_interactive_matplotlib_histogram(\n",
    "    dict_activation_inputs, filename=\"images/activation_inputs_comparison.gif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of activation inputs into first activation layer `conv0_relu_input_0` look quite similar in both trials. However in the case of the second layer they drastically differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"images/activation_inputs_comparison.gif\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
