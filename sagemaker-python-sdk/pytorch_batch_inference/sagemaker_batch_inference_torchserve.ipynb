{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615b38ad-e8e5-49f4-a66a-036534c62798",
   "metadata": {},
   "source": [
    "# SageMaker Realtime Dynamic Batching Inference with Torchserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7434c-2d73-41dc-a56c-7db10b9f552f",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce290e30-dadc-4fa8-bd15-7db4bafe4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import boto3, time, json\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5ef87-09c4-44ac-9dc4-748cc90960e4",
   "metadata": {},
   "source": [
    "**Initiate session and retrieve region, account details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474ea986-41bc-413b-88e6-470f7258d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3227d6a8-3db5-4938-86db-59f2deec2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "region = sess.region_name\n",
    "account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa306e3b-0f01-46d3-b35e-4700ff7c38ad",
   "metadata": {},
   "source": [
    "**Prepare model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac74bc9-8463-45fe-b090-3a3a4bff6f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-04 00:30:12--  https://awsbatchblog.s3.us-west-2.amazonaws.com/BERTSeqClassification.mar\n",
      "Resolving awsbatchblog.s3.us-west-2.amazonaws.com (awsbatchblog.s3.us-west-2.amazonaws.com)... 52.218.136.145\n",
      "Connecting to awsbatchblog.s3.us-west-2.amazonaws.com (awsbatchblog.s3.us-west-2.amazonaws.com)|52.218.136.145|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 405606799 (387M) [binary/octet-stream]\n",
      "Saving to: ‘BERTSeqClassification.mar’\n",
      "\n",
      "BERTSeqClassificati 100%[===================>] 386.82M  51.5MB/s    in 7.0s    \n",
      "\n",
      "2021-11-04 00:30:19 (55.1 MB/s) - ‘BERTSeqClassification.mar’ saved [405606799/405606799]\n",
      "\n",
      "Archive:  BERTSeqClassification.mar\n",
      "  inflating: ./bert_model/model.py   \n",
      "  inflating: ./bert_model/pytorch_model.bin  \n",
      "  inflating: ./bert_model/index_to_name.json  \n",
      "  inflating: ./bert_model/setup_config.json  \n",
      "  inflating: ./bert_model/config.json  \n",
      "  inflating: ./bert_model/Transformer_handler_generalized.py  \n",
      "  inflating: ./bert_model/MAR-INF/MANIFEST.json  \n",
      "./\n",
      "./model.py\n",
      "./pytorch_model.bin\n",
      "./index_to_name.json\n",
      "./MAR-INF/\n",
      "./MAR-INF/MANIFEST.json\n",
      "./setup_config.json\n",
      "./config.json\n",
      "./Transformer_handler_generalized.py\n",
      "upload: ./BERTSeqClassificationZip.tar.gz to s3://sagemaker-us-west-2-850464037171/ts-dynamic-batching/models/BERTSeqClassificationZip.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-850464037171/ts-dynamic-batching/models/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = sm_sess.default_bucket()\n",
    "prefix = \"ts-dynamic-batching\"\n",
    "model_file_name = \"BERTSeqClassificationZip\"\n",
    "\n",
    "!wget https://awsbatchblog.s3.us-west-2.amazonaws.com/BERTSeqClassification.mar\n",
    "!mkdir -p bert_model\n",
    "!unzip BERTSeqClassification.mar -d ./bert_model/\n",
    "!tar cvfz {model_file_name}.tar.gz  -C ./bert_model/ .\n",
    "\n",
    "!aws s3 cp BERTSeqClassificationZip.tar.gz s3://{bucket}/{prefix}/models/\n",
    "\n",
    "!rm -rf bert_model\n",
    "\n",
    "f\"s3://{bucket}/{prefix}/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbed613-c3cd-4d10-95a6-93eecc4a7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = f's3://{bucket}/{prefix}/models/BERTSeqClassificationZip.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdb7075-f6d4-4d6e-8192-ebe436746d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hf-dynamic-torchserve-sagemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8119e33-fed7-4685-aa4c-caa468262e13",
   "metadata": {},
   "source": [
    "## Using AWS Deep Learning Container\n",
    "`Note: See end of notebook for using a custom container`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930811ed-b740-4852-9671-37f797400cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a pytorch inference DLC image that ships with sagemaker-pytorch-inference-toolkit v2.0.7. This version includes support for Torchserve environment variables used below.\n",
    "image_uri = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:1.9.0-gpu-py38-cu111-ubuntu20.04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d34fb-980e-402a-9773-e86d03c7bb1a",
   "metadata": {},
   "source": [
    "#### Create Sagemaker model, deploy and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d847dd-ab32-4313-b616-32f166bfacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "env_variables_dict = {\n",
    "    \"SAGEMAKER_TS_BATCH_SIZE\": \"3\",\n",
    "    \"SAGEMAKER_TS_MAX_BATCH_DELAY\": \"100000\"\n",
    "}\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artifact,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    source_dir=\"code\",\n",
    "    framework_version='1.9',\n",
    "    entry_point=\"inference.py\",\n",
    "    env=env_variables_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bff4c42-9b5f-43dc-80d9-6d0e96082cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# Change the instance type as necessary, or use 'local' for executing in Sagemaker local mode\n",
    "instance_type = \"ml.c5.18xlarge\"\n",
    "\n",
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type=instance_type, serializer=sagemaker.serializers.JSONSerializer(), deserializer=sagemaker.deserializers.BytesDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274615f4-5247-4bff-accc-f66112730a16",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9d5b9-435c-4b3b-9f0f-c49207738b01",
   "metadata": {},
   "source": [
    "#### The following prediction call could timeout for certain instance types (SageMaker 60 second limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6100ea7-9f25-429b-a6f0-2ac7713549b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 0.2232494354248047\n",
      "ENDPOINT RESULT: b'[\"Not Accepted\"]'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "result = predictor.predict(\"{Bloomberg has decided to publish a new report on global economic situation.}\")\n",
    "print(\"TIME:\", time.time() - start)\n",
    "print(\"ENDPOINT RESULT:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96f5af-4621-4bce-8fbf-56df873e9136",
   "metadata": {},
   "source": [
    "#### This following prediction calls could timeout since the first call to predictor hangs waiting for response on certain instance types, although some may succeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d7977d-9457-4108-a6a4-c6a5ca40c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 0.220505952835083\n",
      "ENDPOINT RESULT 1: b'[\"Not Accepted\"]'\n",
      "ENDPOINT RESULT 2: b'[\"Not Accepted\"]'\n",
      "ENDPOINT RESULT 3: b'[\"Not Accepted\"]'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "result1 = predictor.predict(\"{Bloomberg has decided to publish a new report on global economic situation.}\")\n",
    "result2 = predictor.predict(\"{Bloomberg has decided to publish a new report on global economic situation.}\")\n",
    "result3 = predictor.predict(\"{Bloomberg has decided to publish a new report on global economic situation.}\")\n",
    "\n",
    "print(\"TIME:\", time.time() - start)\n",
    "print(\"ENDPOINT RESULT 1:\", result1)\n",
    "print(\"ENDPOINT RESULT 2:\", result2)\n",
    "print(\"ENDPOINT RESULT 3:\", result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d63f34-f14a-4a2e-8db7-9bc2307df40a",
   "metadata": {},
   "source": [
    "#### By spawning a pool of 3 processes we're able to return the results successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd983997-038d-4e1e-8540-e34ba5ffd0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'[\"Not Accepted\"]', b'[\"Not Accepted\"]', b'[\"Not Accepted\"]']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def invoke(endpoint_name):\n",
    "    predictor = sagemaker.predictor.Predictor(endpoint_name,\n",
    "                                              sm_sess,\n",
    "                                              serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                                              deserializer=sagemaker.deserializers.BytesDeserializer())\n",
    "    return predictor.predict(\"{Bloomberg has decided to publish a new report on global economic situation.}\")\n",
    "\n",
    "endpoint_name = predictor.endpoint_name\n",
    "pool = multiprocessing.Pool(3)\n",
    "results = pool.map(invoke, 3*[endpoint_name])\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad59b939-744a-45cf-82fa-efbbf1cac2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcf207-bf4e-4600-80b4-6375f1e14eb5",
   "metadata": {},
   "source": [
    "## Using a custom container\n",
    "\n",
    "#### Details (Also see ./docker/)\n",
    "* Prebaked config.properties file included\n",
    "  * 1.66 Minute Batch Delay (Longer than SageMaker 60s Timeout)\n",
    "  * Batch size of 3\n",
    "  * Note: the image needs to be built and pushed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c909803b-d35b-4d13-a085-08025b006987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "container_name=custom-dynamic-torchserve\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${container_name}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${container_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${container_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${container_name} docker/\n",
    "docker tag ${container_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
