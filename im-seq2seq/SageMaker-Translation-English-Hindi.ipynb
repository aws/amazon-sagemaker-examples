{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation English-Hindi Example Using SageMaker Seq2Seq\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)\n",
    "  1. [Permissions and environment variables](#Permissions-and-environment-variables)\n",
    "  2. [Data Ingestion](#Data-Ingestion)\n",
    "3. [Training the Machine Translation model](#Training-the-Machine-Translation-model)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "  1. [Import model into hosting](#Import-model-into-hosting)\n",
    "  2. [Create endpoint configuration](#Create-endpoint-configuration)\n",
    "  3. [Create endpoint](#Create-endpoint)\n",
    "  4. [Validate the model for use](#Validate-the-model-for-use)\n",
    "5. [Use a pretrained model](#Use-a-pretrained-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to our Machine Translation end-to-end example! In this demo, we will train a English-Hindi translation model and will test the predictions on a few examples.\n",
    "\n",
    "IronMan seq2seq algorithm is built on top of [Sockeye](https://github.com/awslabs/sockeye), a sequence-to-sequence framework for Neural Machine Translation based on MXNet. IronMan Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites and Preprocessing\n",
    "\n",
    "### Permissions and environment variables\n",
    "\n",
    "Here we set up the linkage and authentication to AWS services. There are three parts to this:\n",
    "\n",
    "1. The credentials and region for the account that's running training. Upload the credentials in the normal AWS credentials file format using the jupyter upload feature. The region must always be `us-west-2` during the Beta program.\n",
    "2. The roles used to give learning and hosting access to your data. See the documentation for how to specify these.\n",
    "3. The S3 bucket that you want to use for training and model data.\n",
    "\n",
    "_Note:_ Credentials for hosted notebooks will be automated before the final release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# For plotting attention matrix later on\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_DEFAULT_REGION']='us-west-2'\n",
    "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = os.getcwd() + '/credentials'\n",
    "\n",
    "s3_access_role='<<s3 access role>>'\n",
    "model_role='<<model role>>'\n",
    "\n",
    "bucket='<<s3 bucket>>' # put your s3 bucket name here, and create s3 bucket\n",
    "bucket_path = 'https://s3-us-west-2.amazonaws.com/{}'.format(bucket)\n",
    "\n",
    "# ECS Docker image for SageMaker Seq2Seq.\n",
    "docker_image = \"433757028032.dkr.ecr.us-west-2.amazonaws.com/seq2seq:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "        \n",
    "def upload_to_s3(channel, file):\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, \"rb\")\n",
    "    key = channel + '/' + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "\n",
    "# English-Hindi dataset\n",
    "download('https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/recordio/train/train.rec')\n",
    "download('https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/recordio/validation/val.rec')\n",
    "download('https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/recordio/vocab/vocab.src.json')\n",
    "download('https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/recordio/vocab/vocab.trg.json')\n",
    "\n",
    "\n",
    "upload_to_s3('eng-hindi/train', 'train.rec')\n",
    "upload_to_s3('eng-hindi/validation', 'val.rec')\n",
    "upload_to_s3('eng-hindi/vocab', 'vocab.src.json')\n",
    "upload_to_s3('eng-hindi/vocab', 'vocab.trg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "job_name = 'translation-eng-hindi-iitb-p2-16x-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": docker_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": s3_access_role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": bucket_path + \"/eng-hindi\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.16xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"max_seq_len_source\": \"100\",\n",
    "        \"max_seq_len_target\": \"100\",\n",
    "        \"optimized_metric\": \"bleu\",\n",
    "        \"batch_size\": \"512\",\n",
    "        \"checkpoint_frequency_num_batches\": \"1000\",\n",
    "        \"rnn_num_hidden\": \"512\",\n",
    "        \"num_layers_encoder\": \"2\",\n",
    "        \"num_layers_decoder\": \"2\",\n",
    "        \"num_embed_source\": \"512\",\n",
    "        \"num_embed_target\": \"512\",\n",
    "        \"checkpoint_threshold\": \"2\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 144000\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + '/train',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"vocab\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + '/vocab',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + '/validation',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "ease = boto3.Session().client(service_name='sagemaker')\n",
    "ease.create_training_job(**create_training_params)\n",
    "\n",
    "status = ease.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "while status !='Completed' and status!='Failed':\n",
    "    time.sleep(30)\n",
    "    status = ease.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Now wait for the model artifacts to get uploaded to S3\n",
    "and proceed to the next step after you see %s folder\n",
    "in your S3 bucket.\"\"\" % job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "### Skip to [Use a pretrained model](#Use-a-pretrained-model) to play with a pretrained model\n",
    "\n",
    "In order to set up hosting, we have to import the model from training to hosting. A common question would be, why wouldn't we automatically go from training to hosting? As we worked through examples of what customers were looking to do with hosting, we realized that the Amazon ML model of hosting was unlikely to be sufficient for all customers.\n",
    "\n",
    "As a result, we have introduced some flexibility with respect to model deployment, with the goal of additional model deployment targets after launch. In the short term, that introduces some complexity, but we are actively working on making that easier for customers, even before GA.\n",
    "\n",
    "### Import model into hosting\n",
    "Next, you register the model with hosting. This allows you the flexibility of importing models trained elsewhere, as well as the choice of not importing models if the target of model creation is AWS Lambda, AWS Greengrass, Amazon Redshift, Amazon Athena, or other deployment target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sage = boto3.client('sagemaker')\n",
    "\n",
    "model_name=job_name + '-model'\n",
    "print(model_name)\n",
    "\n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': docker_image,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = model_role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "At launch, we will support configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, customers create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way.\n",
    "\n",
    "In addition, the endpoint configuration describes the instance type required for model deployment, and at launch will describe the autoscaling configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqEndpointConfig-2017-11-03-00-27-38\n",
      "Endpoint Config Arn: arn:aws:im:us-west-2:032969728358:endpoint-config/Seq2SeqEndpointConfig-2017-11-03-00-27-38\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'Seq2SeqEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'p2.xlarge',\n",
    "        'MaxInstanceCount':1,\n",
    "        'MinInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, the customer creates the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqEndpoint-2017-11-03-01-17-43\n",
      "arn:aws:im:us-west-2:032969728358:endpoint/Seq2SeqEndpoint-2017-11-03-01-17-43\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:im:us-west-2:032969728358:endpoint/Seq2SeqEndpoint-2017-11-03-01-17-43\n",
      "Status: InService\n",
      "CPU times: user 64 ms, sys: 12 ms, total: 76 ms\n",
      "Wall time: 9min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'Seq2SeqEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sage.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Finally, the customer can now validate the model for use. They can obtain the endpoint from the client library using the result from previous operations, and generate predictions from the trained model using that endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = boto3.Session().client(service_name='sagemaker-runtime') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'target': 'आप कैसे हैं ?'}]\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = [\"let us dance on the floor !\", \"do you know how to drive a car ?\",\n",
    "            \"you are so awesome !\"]\n",
    "\n",
    "payload = {\"instances\" : []}\n",
    "for sent in sentences:\n",
    "    payload[\"instances\"].append({\"data\" : sent})\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating model, endpoint and endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pretrained_model_s3 = \"https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/recordio/translation-eng-hindi-iitb-p2-16x-2017-11-18-04-55-12/output/model.tar.gz\"\n",
    "\n",
    "sage = boto3.client('sagemaker')\n",
    "model_name = 'EngHindi-'  + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(model_name)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': docker_image,\n",
    "    'ModelDataUrl': pretrained_model_s3\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = model_role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])\n",
    "\n",
    "endpoint_config_name = 'EngHindiEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'p2.xlarge',\n",
    "        'MaxInstanceCount':1,\n",
    "        'MinInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])\n",
    "\n",
    "endpoint_name = 'EngHindiEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sage.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = boto3.Session().client(service_name='sagemaker-runtime') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sentences = [\"let us dance on the floor !\", \"do you know how to drive a car ?\",\n",
    "            \"you are so awesome !\"]\n",
    "\n",
    "payload = {\"instances\" : []}\n",
    "for sent in sentences:\n",
    "    payload[\"instances\"].append({\"data\" : sent})\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the Attention Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `\"attention_matrix\":\"true\"` in `configuration` of the data instance will return the attention matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'what is your age ?'\n",
    "\n",
    "payload = {\"instances\" : [{\n",
    "                            \"data\" : sentence,\n",
    "                            \"configuration\" : {\"attention_matrix\":\"true\"}\n",
    "                          }\n",
    "                         ]}\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)['predictions'][0]\n",
    "\n",
    "source = sentence\n",
    "target = response[\"target\"]\n",
    "attention_matrix = np.array(response[\"matrix\"])\n",
    "\n",
    "print(\"Source: %s \\nTarget: %s\" % (source, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install the Hindi font for attention matrix\n",
    "!sudo wget https://cghs.nic.in/mangal.ttf -o /usr/share/fonts/mangal.ttf\n",
    "hindi_font = FontProperties(fname = 'mangal.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(attention_matrix, target, source):\n",
    "    source_tokens = source.split()\n",
    "    target_tokens = target.split()\n",
    "    assert attention_matrix.shape[0] == len(target_tokens)\n",
    "    plt.imshow(attention_matrix.transpose(), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.xlabel(\"target\")\n",
    "    plt.ylabel(\"source\")\n",
    "    plt.gca().set_xticks([i for i in range(0, len(target_tokens))])\n",
    "    plt.gca().set_yticks([i for i in range(0, len(source_tokens))])\n",
    "    plt.gca().set_xticklabels(target_tokens, fontproperties=hindi_font)\n",
    "    plt.gca().set_yticklabels(source_tokens)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAEYCAYAAAAag+AEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQUS0lSUywlSU2xlCQ1xVKS1JT/BjT4xqE9EBE3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9eea6922b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_matrix(attention_matrix, target, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
