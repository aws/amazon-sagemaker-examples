{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow's tf.data.service with Amazon SageMaker Training Heterogeneous Clusters\n",
    "\n",
    "---\n",
    "### Intro\n",
    "\n",
    "Heterogeneous clusters enables launching training jobs that use multiple instance types in a single job. This  capability can improve your training cost and speed by running different parts of the model training on the most suitable instance type. This use case typically happens in computer vision DL training, where training is bottlnecked on CPU resources needed for data augmentation, leaving the expensive GPU underutilized. Heterogeneous clusters allows you to add more CPU resources to fully utilize GPUs to increase training speed and cost-efficiency. For more details, you can find the documentation of this feature [here](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html).\n",
    "\n",
    "This notebook demonstrates how to use Heterogeneous Clusters feature of SageMaker Training with TensorFlow's [tf.data.service](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service).\n",
    "\n",
    "In this sample notebook, we'll be training a CPU intensive Deep Learning computer vision workload. We'll be comparing between a homogeneous and a heterogeneous training configurations. Both jobs we'll run train with the same data, pre-processing, and other relevant parameters:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td width=43%><b>Homogeneous Training Job</b><br/>\n",
    "    In a Homogeneous training job the ml.p4d.24xlarge instance GPUs are under-utilized due to a CPU bottleneck.</td>\n",
    "    <td width=57%><b>Heterogeneous Training Job</b><br/>\n",
    "    In a Heterogeneous training job, we add two ml.c5.18xlarge instances with extra CPU cores, to reduce the CPU bottleneck and drive up GPU usage, to improve training speed cost-efficiency.\n",
    "    </td>\n",
    "   </tr> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <img src=images/basic-homogeneous-job.png alt=\"homogeneous training job\" /></td>\n",
    "    <td><img src=images/basic-heterogeneous-job.png alt=\"Heterogeneous training job\" /></td>\n",
    "   </tr> \n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workload Details\n",
    "Training data is stored in TFRecord files in `data` folder, and generated from [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset using `generate_cifar10_tfrecords.py` script. The data pre-processing pipeline includes: parsing images, dilation, blur filtering, and a number of [TensorFlow preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers). We'll use a [Resnet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50) architecture. The job runs on an 8 GPUs instance, p4d.24xlarge, and uses Horovod for data parallelizaion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Heterogeneous clusters Training\n",
    "We then define `instance_groups` in the TensorFlow estimator to enable training jobs to leverage Heterogeneous Cluster features. \n",
    "The data pre-processing code runs on the CPU nodes (here referred as **data_group or data group**), whereas the Deep Neural Network training code runs on the GPU nodes (here referred as **dnn_group or dnn group**). In this example, the inter-node communication between CPU and GPU instance_groups is implemented using [TensorFlow data service feature](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service). This feature was introduced in TensorFlow version 2.3 which provides APIs for defining dedicated worker machines for performing data preprocessing. Note that SageMaker's Heterogeneous cluster does not provide out-of-the-box support for inter-instance_group communication. \n",
    "\n",
    "\n",
    "The training script (`launcher.py`) runs on all the nodes regardless of which instance_group it belongs to. However, it has the logic to detect (using SageMaker's `instance_group` environment variables) whether the node it is running on belongs to data_group or dnn_group. \n",
    "\n",
    "If it is data_group, it spawns a separate process by executing `train_data.py`. This script runs a dispatcher server service on the first node of the instance group. And, on all the nodes in the same instance_group, it runs the worker server service. A dispatch server is responsible for distributing preprocessing tasks to one, or more, worker servers, each of which load the raw data directly from storage, and send the processed data to the GPU device. A dispatcher server listens on port 6000, whereas the worker server listens on port 6001. By applying `tf.data.experimental.service.distribute` to your dataset, you can program the dataset to run all preprocessing operations up to the point of application, on the workers. TFRecord files are copied over to instances in this group, as the workers load the raw data from those files. In this example, we are using 2 instances of ml.c5.18xlarge in the data_group. While dispatching the data to the dnn_group, the main entrypoint script `launcher.py` listens on port 16000 for a shutdown request coming from the data group. The train_data.py waits for shutdown action from the parent process.\n",
    "\n",
    "If the node belongs to dnn_group, the main training script (`launcher.py`) spawns a separate set of processes by executing `train_dnn.py`. This script contains a deep neural network algorithm/code. And, in some cases, can host additional data-preprocessing components to maximize the use of CPUs on dnn nodes. The set of processes running DNN training consumes a stream of processed dataset from the Dispatcher server (the first node in the data_group at port 6000), and runs model training. The dnn_group can also run distributed training on multiple nodes defined by parameter instance_count (see details under **Setting up the training environment** section of this notebook). Once the model is trained on the dataset, the dnn_group establishes a connection back to the dispatcher server on port 16000 to signal shutdown request. \n",
    "\n",
    "\n",
    "A graphical view of how the data flows is shown below in Heterogeneous Cluster training with tf.data.service:\n",
    "\n",
    "**NEED TO BE UPDATED**\n",
    "\n",
    "<img src=images/tf.data.service-diagram.png width=600px>\n",
    "\n",
    "\n",
    "This notebook refers following files and folders:\n",
    "\n",
    "- Folders: \n",
    "  - `code`: this has the training scripts, grpc client-server code, \n",
    "  - `images`: contains images referred in notebook\n",
    "- Files: \n",
    "  - `launcher.py`: entry point training script. This script is executed on all the nodes irrespective of which group it belongs to. Explained above. \n",
    "  - `train_data.py`: this script runs on the data_group nodes and responsible for setting up dispatcher and worker servers\n",
    "  - `train_dnn.py`: this script runs on the dnn_group nodes, and responsible for DNN training code/algorithm. \n",
    "  - `requirements.txt`: defines package required for tensorflow-addon and protobuf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**NOTE**\n",
    "\n",
    "As an alternative to following this notebook, you follow (readme.md)[./readme.md] which allows you to setup and launch the training job from an IDE or command line.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At a high level, the notebook covers:\n",
    "-  A Setting up Amazon SageMaker Studio Notebook \n",
    "-  Preparing Training dataset and uploading to Amazon S3\n",
    "-  Setting up the Training environment\n",
    "-  Submitting the Training job\n",
    "-  Monitor and visualize the CloudWatch metrics\n",
    "-  Comparing time-to-train and cost-to-train\n",
    "-  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Setting up SageMaker Studio notebook\n",
    "#### Before you start\n",
    "Ensure you have selected Python 3 (_TensorFlow 2.6 Python 3.8 CPU Optimized_) image for your SageMaker Studio Notebook instance, and running on _ml.t3.medium_ instance type.\n",
    "\n",
    "#### Step 1 - Upgrade SageMaker SDK and dependent packages \n",
    "Heterogeneous Clusters for Amazon SageMaker model training was [announced](https://aws.amazon.com/about-aws/whats-new/2022/07/announcing-heterogeneous-clusters-amazon-sagemaker-model-training) on 07/08/2022. As a first step, ensure you have updated SageMaker SDK, PyTorch, and Boto3 client that enables this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m pip install --upgrade boto3 botocore awscli sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Restart the notebook kernel \n",
    "From the Jupyter Lab menu bar **Kernel > Restart Kernel...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Valdiate SageMaker Python SDK and Tensorflow versions\n",
    "Ensure the output of the cell below reflects:\n",
    "\n",
    "- SageMaker Python SDK version 2.98.0 or above, \n",
    "- boto3 1.24 or above \n",
    "- botocore 1.27 or above \n",
    "- TensorFlow 2.6 or above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sagemaker\n",
      "Version: 2.99.0\n",
      "---\n",
      "Name: boto3\n",
      "Version: 1.21.32\n",
      "---\n",
      "Name: botocore\n",
      "Version: 1.24.32\n",
      "---\n",
      "Name: tensorflow\n",
      "Version: 2.8.0\n",
      "---\n",
      "Name: protobuf\n",
      "Version: 3.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip show sagemaker boto3 botocore tensorflow protobuf |egrep 'Name|Version|---'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Preparing Training Dataset and Uploading to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 1: Download cifar10 dataset and convert them into tfrecord\n",
    "The training data set is stored in TFRecord files in `data` folder, and generated from CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 ./generate_cifar10_tfrecords.py --data-dir ./data\n",
    "rm -rf /tmp/data.old && mv data data.old && mkdir data && cp data.old/train/train.1.tfrecords ./data/ && cp data.old/train/train.2.tfrecords ./data/ && mv data.old /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 2: Upload the tfrecord training data to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"cifar10-tfrecord\"\n",
    "bucket = sess.default_bucket()\n",
    "print(f\"Uploading data from ./data to s3://{bucket}/{prefix}/\")\n",
    "s3path = sess.upload_data(path=\"./data\", bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "data_uri = TrainingInput(\n",
    "    s3path,\n",
    "    # instance_groups=['data_group'], # we don't need to restrict training channel to a specific group as we have data workers in both groups\n",
    "    input_mode=\"FastFile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Setting up training environment\n",
    "#### Step 1: Import SageMaker components and setup the IAM role and S3 bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_path=s3://sagemaker-us-east-1-331113010199/cifar10-tfrecord\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.instance_group import InstanceGroup\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "output_path = \"s3://\" + sess.default_bucket() + \"/cifar10-tfrecord\"\n",
    "print(f\"role={role}\")\n",
    "print(f\"output_path={output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Running a Homogenous training job\n",
    "In this step we define and submit a homogenous training job. It use a single instance type (p4d.24xlarge) with 8 GPUs, and analysis will show its CPU bound causing its GPUs to be underutilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.instance_group import InstanceGroup\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import os\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\": 3,\n",
    "    \"steps_per_epoch\": 500,\n",
    "    \"batch_size\": 1024,\n",
    "    \"tf_data_mode\": \"local\",  # We won't be using tf.data.service ('service') for this homogenous job\n",
    "    \"num_of_data_workers\": 0,  # We won't be using tf.data.service ('service') for this homogenous job\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"launcher.py\",\n",
    "    source_dir=\"code\",\n",
    "    framework_version=\"2.9.1\",\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    volume_size=10,\n",
    "    max_run=1800,  # 30 minutes\n",
    "    disable_profiler=True,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    instance_count=1,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution={\n",
    "        \"mpi\": {\n",
    "            \"enabled\": True,\n",
    "            \"processes_per_host\": 8,  # 8 GPUs per host\n",
    "            \"custom_mpi_options\": \"--NCCL_DEBUG WARN\",\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Submit the training job\n",
    "\n",
    "Note: For the logs, click on **View logs** from the **Training Jobs** node in **Amazon SageMaker Console**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-09 14:00:51 Starting - Starting the training job......\n",
      "2022-09-09 14:01:29 Starting - Preparing the instances for training.............................................\n",
      "2022-09-09 14:10:05 Downloading - Downloading input data\n",
      "2022-09-09 14:10:05 Training - Downloading the training image.....................\n",
      "2022-09-09 14:13:36 Training - Training image download completed. Training in progress.2022-09-09 14:13:42.807713: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-09-09 14:13:42.818598: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-09-09 14:13:43.564275: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-09-09 14:13:53,522 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2022-09-09 14:13:54,624 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/usr/local/bin/python3.9 -m pip install -r requirements.txt\n",
      "Collecting protobuf==3.20.1\n",
      "Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 49.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow-addons==0.17.0\n",
      "Downloading tensorflow_addons-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 65.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from tensorflow-addons==0.17.0->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.9/site-packages (from tensorflow-addons==0.17.0->-r requirements.txt (line 2)) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->tensorflow-addons==0.17.0->-r requirements.txt (line 2)) (3.0.9)\n",
      "Installing collected packages: protobuf, tensorflow-addons\n",
      "Attempting uninstall: protobuf\n",
      "Found existing installation: protobuf 3.19.4\n",
      "Uninstalling protobuf-3.19.4:\n",
      "Successfully uninstalled protobuf-3.19.4\n",
      "Attempting uninstall: tensorflow-addons\n",
      "Found existing installation: tensorflow-addons 0.17.1\n",
      "Uninstalling tensorflow-addons-0.17.1:\n",
      "Successfully uninstalled tensorflow-addons-0.17.1\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-models-official 2.9.1 requires tensorflow~=2.9.0, which is not installed.\n",
      "tensorflow-gpu 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
      "sagemaker-training 4.1.4.dev0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
      "Successfully installed protobuf-3.20.1 tensorflow-addons-0.17.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2022-09-09 14:14:07,337 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2022-09-09 14:14:07,337 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2022-09-09 14:14:07,515 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2022-09-09 14:14:07,515 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "2022-09-09 14:14:07,540 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "2022-09-09 14:14:07,541 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:8'] process_per_hosts: 8 num_processes: 8\n",
      "2022-09-09 14:14:07,542 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "2022-09-09 14:14:07,627 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"--NCCL_DEBUG WARN\",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 8\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 1024,\n",
      "        \"epochs\": 3,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"num_of_data_workers\": 0,\n",
      "        \"steps_per_epoch\": 500,\n",
      "        \"tf_data_mode\": \"local\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"homogenous-20220909T140047Z\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-331113010199/homogenous-20220909T140047Z/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"launcher\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"launcher.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":1024,\"epochs\":3,\"model_dir\":\"/opt/ml/model\",\"num_of_data_workers\":0,\"steps_per_epoch\":500,\"tf_data_mode\":\"local\"}\n",
      "SM_USER_ENTRY_POINT=launcher.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"--NCCL_DEBUG WARN\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"training\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.p4d.24xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=launcher\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=96\n",
      "SM_NUM_GPUS=8\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-331113010199/homogenous-20220909T140047Z/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"--NCCL_DEBUG WARN\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p4d.24xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":1024,\"epochs\":3,\"model_dir\":\"/opt/ml/model\",\"num_of_data_workers\":0,\"steps_per_epoch\":500,\"tf_data_mode\":\"local\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"job_name\":\"homogenous-20220909T140047Z\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-331113010199/homogenous-20220909T140047Z/source/sourcedir.tar.gz\",\"module_name\":\"launcher\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"launcher.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"1024\",\"--epochs\",\"3\",\"--model_dir\",\"/opt/ml/model\",\"--num_of_data_workers\",\"0\",\"--steps_per_epoch\",\"500\",\"--tf_data_mode\",\"local\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_HP_BATCH_SIZE=1024\n",
      "SM_HP_EPOCHS=3\n",
      "SM_HP_MODEL_DIR=/opt/ml/model\n",
      "SM_HP_NUM_OF_DATA_WORKERS=0\n",
      "SM_HP_STEPS_PER_EPOCH=500\n",
      "SM_HP_TF_DATA_MODE=local\n",
      "PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "mpirun --host algo-1:8 -np 8 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=WARN -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_CURRENT_INSTANCE_TYPE -x SM_CURRENT_INSTANCE_GROUP -x SM_CURRENT_INSTANCE_GROUP_HOSTS -x SM_INSTANCE_GROUPS -x SM_INSTANCE_GROUPS_DICT -x SM_DISTRIBUTION_INSTANCE_GROUPS -x SM_IS_HETERO -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TRAINING -x SM_HP_BATCH_SIZE -x SM_HP_EPOCHS -x SM_HP_MODEL_DIR -x SM_HP_NUM_OF_DATA_WORKERS -x SM_HP_STEPS_PER_EPOCH -x SM_HP_TF_DATA_MODE -x PYTHONPATH /usr/local/bin/python3.9 -m mpi4py launcher.py --batch_size 1024 --epochs 3 --model_dir /opt/ml/model --num_of_data_workers 0 --steps_per_epoch 500 --tf_data_mode local\n",
      "Data for JOB [47713,1] offset 0 Total slots allocated 8\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: ip-10-0-222-41#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 3 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 4 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 5 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 6 Bound: N/A\n",
      " #011Process OMPI jobid: [47713,1] App: 0 Process rank: 7 Bound: N/A\n",
      " =============================================================\n",
      "[1,mpirank:1,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:1,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:1,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:4,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:4,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:4,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:3,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:3,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:3,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:2,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:2,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:2,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:5,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:5,algo-1]<stdout>:current_host=algo-1[1,mpirank:5,algo-1]<stdout>:\n",
      "[1,mpirank:5,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:6,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:6,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:6,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:0,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:0,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:0,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:7,algo-1]<stdout>:env.is_hetero=False\n",
      "[1,mpirank:7,algo-1]<stdout>:current_host=algo-1\n",
      "[1,mpirank:7,algo-1]<stdout>:Opening process: ['python', './train_dnn.py', '--batch_size', '1024', '--epochs', '3', '--model_dir', '/opt/ml/model', '--num_of_data_workers', '0', '--steps_per_epoch', '500', '--tf_data_mode', 'local']\n",
      "[1,mpirank:1,algo-1]<stderr>:2022-09-09 14:14:08.584464: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:3,algo-1]<stderr>:2022-09-09 14:14:08.584460: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:4,algo-1]<stderr>:2022-09-09 14:14:08.584460: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:6,algo-1]<stderr>:2022-09-09 14:14:08.584460: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:1,algo-1]<stderr>:2022-09-09 14:14:08.584609: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:3,algo-1]<stderr>:2022-09-09 14:14:08.584611: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:4,algo-1]<stderr>:2022-09-09 14:14:08.584609: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:6,algo-1]<stderr>:2022-09-09 14:14:08.584612: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:0,algo-1]<stderr>:2022-09-09 14:14:08.597322: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:7,algo-1]<stderr>:2022-09-09 14:14:08.597321: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:2,algo-1]<stderr>:2022-09-09 14:14:08.597325: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:5,algo-1]<stderr>:2022-09-09 14:14:08.597325: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:0,algo-1]<stderr>:2022-09-09 14:14:08.597462: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:7,algo-1]<stderr>:2022-09-09 14:14:08.597464: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:2,algo-1]<stderr>:2022-09-09 14:14:08.597464: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:5,algo-1]<stderr>:2022-09-09 14:14:08.597466: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "[1,mpirank:6,algo-1]<stderr>:2022-09-09 14:14:08.619434: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:4,algo-1]<stderr>:2022-09-09 14:14:08.619434: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:1,algo-1]<stderr>:2022-09-09 14:14:08.619434: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:3,algo-1]<stderr>:2022-09-09 14:14:08.619435: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:5,algo-1]<stderr>:2022-09-09 14:14:08.632294: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:2,algo-1]<stderr>:2022-09-09 14:14:08.632294: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:0,algo-1]<stderr>:2022-09-09 14:14:08.632294: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:7,algo-1]<stderr>:2022-09-09 14:14:08.632297: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "[1,mpirank:3,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:3,algo-1]<stdout>:hvd.local_rank() 3\n",
      "[1,mpirank:6,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:4,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:1,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:4,algo-1]<stdout>:hvd.local_rank() 4\n",
      "[1,mpirank:1,algo-1]<stdout>:hvd.local_rank() 1\n",
      "[1,mpirank:6,algo-1]<stdout>:hvd.local_rank() 6\n",
      "[1,mpirank:7,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:7,algo-1]<stdout>:hvd.local_rank() 7\n",
      "[1,mpirank:0,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:0,algo-1]<stdout>:hvd.local_rank() 0\n",
      "[1,mpirank:2,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:5,algo-1]<stdout>:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "[1,mpirank:2,algo-1]<stdout>:hvd.local_rank() 2\n",
      "[1,mpirank:5,algo-1]<stdout>:hvd.local_rank() 5\n",
      "[1,mpirank:6,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:2,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:0,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:7,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:5,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:1,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:4,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:3,algo-1]<stdout>:Running in local tf_data_mode.\n",
      "[1,mpirank:0,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:7,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:5,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:4,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:2,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:3,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:1,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:6,algo-1]<stdout>:Epoch 1/3\n",
      "[1,mpirank:5,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:5,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:5,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:0,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:0,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:0,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:7,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:7,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:7,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:2,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:2,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:2,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:6,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:6,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:6,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:3,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:3,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:3,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:4,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:4,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:4,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:1,algo-1]<stdout>:Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "[1,mpirank:1,algo-1]<stdout>:If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "[1,mpirank:1,algo-1]<stdout>:Warning! MPI libs are missing, but python applications are still available.\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:180 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:183 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:184 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:181 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:179 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:182 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.179 algo-1:178 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.180 algo-1:177 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[1,mpirank:2,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:0,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:7,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:5,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:3,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:2,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:0,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:4,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:7,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:6,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:5,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:3,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:1,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:4,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:6,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:1,algo-1]<stderr>:/usr/local/lib/python3.9/site-packages/smdebug-1.0.17b20220701-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:183 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:181 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:180 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:179 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:184 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:178 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.472 algo-1:177 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.473 algo-1:182 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.540 algo-1:184 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.540 algo-1:180 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.540 algo-1:183 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.540 algo-1:181 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.540 algo-1:179 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.540 algo-1:178 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:182 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:177 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:183 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:180 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:181 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:184 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:179 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:178 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:177 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:182 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:183 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:180 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:183 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:180 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:181 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:184 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:181 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:184 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:179 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.541 algo-1:178 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:179 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:182 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:183 INFO hook.py:421] Monitoring the collections: metrics, losses, sm_metrics\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:177 INFO hook.py:254] Saving to /opt/ml/output/tensors\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:178 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:182 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:177 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[1,mpirank:2,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:180 INFO hook.py:421] Monitoring the collections: metrics, losses, sm_metrics\n",
      "[1,mpirank:7,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:184 INFO hook.py:421] Monitoring the collections: metrics, sm_metrics, losses\n",
      "[1,mpirank:5,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:181 INFO hook.py:421] Monitoring the collections: sm_metrics, losses, metrics\n",
      "[1,mpirank:3,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:179 INFO hook.py:421] Monitoring the collections: sm_metrics, metrics, losses\n",
      "[1,mpirank:4,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:178 INFO hook.py:421] Monitoring the collections: sm_metrics, losses, metrics\n",
      "[1,mpirank:6,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:182 INFO hook.py:421] Monitoring the collections: metrics, sm_metrics, losses\n",
      "[1,mpirank:1,algo-1]<stdout>:[2022-09-09 14:14:18.542 algo-1:177 INFO hook.py:421] Monitoring the collections: losses, metrics, sm_metrics\n",
      "[1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.2\n",
      "[1,mpirank:0,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2464s vs `on_train_batch_end` time: 0.6223s). Check your callbacks.\n",
      "[1,mpirank:0,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2464s vs `on_train_batch_end` time: 0.6223s). Check your callbacks.\n",
      "[1,mpirank:1,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2464s vs `on_train_batch_end` time: 0.6224s). Check your callbacks.\n",
      "[1,mpirank:1,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2464s vs `on_train_batch_end` time: 0.6224s). Check your callbacks.\n",
      "[1,mpirank:6,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2445s vs `on_train_batch_end` time: 0.6226s). Check your callbacks.\n",
      "[1,mpirank:6,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2445s vs `on_train_batch_end` time: 0.6226s). Check your callbacks.\n",
      "[1,mpirank:7,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2465s vs `on_train_batch_end` time: 0.6225s). Check your callbacks.\n",
      "[1,mpirank:7,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2465s vs `on_train_batch_end` time: 0.6225s). Check your callbacks.\n",
      "[1,mpirank:2,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2474s vs `on_train_batch_end` time: 0.6225s). Check your callbacks.\n",
      "[1,mpirank:2,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2474s vs `on_train_batch_end` time: 0.6225s). Check your callbacks.\n",
      "[1,mpirank:4,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2478s vs `on_train_batch_end` time: 0.6224s). Check your callbacks.\n",
      "[1,mpirank:4,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2478s vs `on_train_batch_end` time: 0.6224s). Check your callbacks.\n",
      "[1,mpirank:5,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2489s vs `on_train_batch_end` time: 0.6224s). Check your callbacks.\n",
      "[1,mpirank:5,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2489s vs `on_train_batch_end` time: 0.6224s). Check your callbacks.\n",
      "[1,mpirank:3,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2503s vs `on_train_batch_end` time: 0.6223s). Check your callbacks.\n",
      "[1,mpirank:3,algo-1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2503s vs `on_train_batch_end` time: 0.6223s). Check your callbacks.\n",
      "[1,mpirank:6,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:7,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:5,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:3,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:4,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:1,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:2,algo-1]<stdout>:500/500 - 131s - loss: 1.9972 - lr: 0.0033 - 131s/epoch - 261ms/step\n",
      "[1,mpirank:6,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:3,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:5,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:4,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:1,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:2,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:7,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:0,algo-1]<stdout>:500/500 - 132s - loss: 1.9972 - lr: 0.0033 - 132s/epoch - 263ms/step\n",
      "[1,mpirank:0,algo-1]<stdout>:Epoch 2/3\n",
      "[1,mpirank:3,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:1,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:7,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:6,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:2,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:4,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:3,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:7,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:2,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:1,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:6,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:4,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:5,algo-1]<stdout>:500/500 - 104s - loss: 1.8961 - lr: 0.0057 - 104s/epoch - 208ms/step\n",
      "[1,mpirank:5,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:0,algo-1]<stdout>:500/500 - 105s - loss: 1.8961 - lr: 0.0057 - 105s/epoch - 209ms/step\n",
      "[1,mpirank:0,algo-1]<stdout>:Epoch 3/3\n",
      "[1,mpirank:6,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:1,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Epoch 3: finished gradual learning rate warmup to 0.008.\n",
      "[1,mpirank:5,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:4,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:7,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:2,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:3,algo-1]<stdout>:500/500 - 106s - loss: 1.8536 - lr: 0.0080 - 106s/epoch - 211ms/step\n",
      "[1,mpirank:0,algo-1]<stdout>:500/500 - 105s - loss: 1.8536 - lr: 0.0080 - 105s/epoch - 211ms/step\n",
      "[1,mpirank:7,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:5,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:4,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:2,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:3,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:6,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:1,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "[1,mpirank:0,algo-1]<stderr>:WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\n",
      "[1,mpirank:0,algo-1]<stdout>:Process train_dnn.py closed with returncode=0\n",
      "2022-09-09 14:20:18,708 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2022-09-09 14:20:18,708 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2022-09-09 14:20:18,708 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2022-09-09 14:20:24 Uploading - Uploading generated training model\n",
      "2022-09-09 14:21:00 Completed - Training job completed\n",
      "Training seconds: 674\n",
      "Billable seconds: 674\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    inputs=data_uri,\n",
    "    job_name=\"homogenous-\" + datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Analyzing the homogenous training job throughput and resource usage\n",
    "We'll examine: CPU and GPU usage. Epoch time and step time\n",
    "\n",
    "#### CPU and GPU usage analysis\n",
    "In the screenshot below we observe that close to all the 96 vCPU of the instance is utilized. While GPU utilization is only ~40%. Clearly if we had more vCPUs we could increase GPU usage signifiantly to increase job throughput\n",
    "\n",
    "Note: To view your own job Click on **View instance metrics** from the **Training jobs** node in **Amazon SageMaker Console**. Then to rescale the CloudWatch Metrics to 100% on CPU utilization for algo-1 and algo-2, use CloudWatch \"Add Math\" feature and average it out by no. of vCPUs/GPUs on those instance types.  \n",
    "<img src=\"images/metrics homogenous cpu and gpu usage.png\" width=75%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch time and step time analysis\n",
    "For 2nd and 3rd epochs the below should printout: 105s/epoch - 209ms/step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture homogenous_logs\n",
    "estimator.sagemaker_session.logs_for_job(estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing step time for epochs and steps for homogenous-20220909T140047Z\n",
      "[1,mpirank:0,algo-1]<stdout>:500/500 - 132s - loss: 1.9972 - lr: 0.0033 - 132s/epoch - 263ms/step\n",
      "[1,mpirank:0,algo-1]<stdout>:500/500 - 105s - loss: 1.8961 - lr: 0.0057 - 105s/epoch - 209ms/step\n",
      "[1,mpirank:0,algo-1]<stdout>:500/500 - 105s - loss: 1.8536 - lr: 0.0080 - 105s/epoch - 211ms/step\n"
     ]
    }
   ],
   "source": [
    "print(f\"Printing step time for epochs and steps for {estimator.latest_training_job.name}\")\n",
    "for line in homogenous_logs.stdout.split(\"\\n\"):\n",
    "    if \"mpirank:0\" in line and \"/epoch\" in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Running a Heterogeneous Training Job\n",
    "We'll now run a training job in heterogeneous clusters mode.  \n",
    "Note the changes from the homogenous cluster job:  \n",
    "- We define two new instance groups that are provided to the `estimator` as the `instance_groups` parameter that replaces the homogenous paramters `instance_type` and `instance_count`.\n",
    "- In the `distribution` parameter for Horovod we added a new parameter `instance_groups` that is used to limit the MPI cluster to run in the  `dnn_group`. The MPI cluster should include only the GPU nodes that run Horovod (which needs MPI). The `data_group` instances should not be part of the MPI cluster, as they set up their on `tf.data.service` cluster.\n",
    "\n",
    "More on the two instance groups config we use:\n",
    "- `data_group` - two ml.c5.18xlarge instances, each with 72 vCPUs to handle data preprocessing. Reading data from S3, preprocessing it, and forwarding it to the `dnn_group`.\n",
    "- `dnn_group` - a single p4d.24xlarge instance, with 8 GPUs and 96 vCPUs. to handle deep neural network optimization (forward backword passes) releing on 8 GPUs and some of the 96 vPCUs. To fully utilize 96 vCPUs in the `dnn_group`, we'll be starting data workers on all instances in both groups, therefore we have 240 vCPUs (96+72+72) in total available for preprocessing (minus vCPUs used for the neural network optimization process).\n",
    "\n",
    "There are three Python scripts to know about:\n",
    "The 1st is `train_dnn.py` - This is your training script for the neural network, you should edit it to match your own use case. Note how this script isn't aware of the Heterogeneous clusters setup, except when it initializes the tf.data dataset calling this line: `ds = ds.apply(tf.data.experimental.service.distribute(...)`.  \n",
    "The 2nd and 3rd scripts, which you're not suppose to edit when adapting to your own use case, do the heavy lifting required for using tf.data.service over the Heterogeneous clusters feature.  \n",
    "`train_data.py` include functions to start/stop tf.service.data process like a dispatcher and WorkerServer. \n",
    "`launcher.py` has several responsibilities: \n",
    "- a single entrypoint script for all instances in all instance groups (SageMaker will start the same script on all instances).\n",
    "- Identify which instance group the node belong to, and start the relevant script accordingly (`train_dnn.py` or  `train_data.py` or sometimes both).\n",
    "- Takes measures to ensure that tf.data.sevice processes shutdown when training completes, as the training job completes only when all instances exit. Remember that training job.\n",
    "- Allow to start more than one process (for example, on the dnn_gruop instances we'll run both the `train_dnn.py` and a tf.data.service worker to utilize the instance CPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.instance_group import InstanceGroup\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import os\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\": 10,\n",
    "    \"steps_per_epoch\": 500,\n",
    "    \"batch_size\": 1024,\n",
    "    \"tf_data_mode\": \"service\",  # We'll be using tf.data.service for this Heterogeneous clusters job\n",
    "    \"num_of_data_workers\": 2,  # We won't be using tf.data.service for this Heterogeneous clusters job\n",
    "}\n",
    "\n",
    "# Group for CPU instances to run tf.data.service dispatcher/workers processes.\n",
    "data_group = InstanceGroup(\"data_group\", \"ml.c5.18xlarge\", 3)\n",
    "# Group for deep neural network (dnn) with accleartors (e.g., GPU, FPGA, etc.)\n",
    "dnn_group = InstanceGroup(\"dnn_group\", \"ml.p4d.24xlarge\", 1)\n",
    "\n",
    "estimator2 = TensorFlow(\n",
    "    entry_point=\"launcher.py\",\n",
    "    source_dir=\"code\",\n",
    "    framework_version=\"2.9.1\",\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    volume_size=10,\n",
    "    max_run=1800,  # 30 minutes\n",
    "    disable_profiler=True,\n",
    "    # instance_type='ml.p4d.24xlarge',\n",
    "    # instance_count=1,\n",
    "    instance_groups=[data_group, dnn_group],\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution={\n",
    "        \"mpi\": {\n",
    "            \"enabled\": True,\n",
    "            \"processes_per_host\": 8,  # 8 GPUs per host\n",
    "            \"custom_mpi_options\": \"--NCCL_DEBUG WARN\",\n",
    "        },\n",
    "        \"instance_groups\": [dnn_group],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Submit the training job\n",
    "\n",
    "Note1: For the logs, click on **View logs** from the **Training Jobs** node in **Amazon SageMaker Console**. \n",
    "Note2: Ignore the 0 billable seconds shown below. See actual billable seconds in the AWS web console > SageMaker > Training Jobs > this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11 09:50:28 Starting - Starting the training job......\n",
      "2022-09-11 09:51:17 Starting - Preparing the instances for training.................................................\n",
      "2022-09-11 09:59:42 Downloading - Downloading input data...\n",
      "2022-09-11 09:59:52 Training - Downloading the training image..................\n",
      "2022-09-11 10:03:24 Training - Training image download completed. Training in progress..........................................................\n",
      "2022-09-11 10:12:43 Uploading - Uploading generated training model...\n",
      "2022-09-11 10:13:19 Completed - Training job completed\n",
      "..Training seconds: 0\n",
      "Billable seconds: 0\n"
     ]
    }
   ],
   "source": [
    "estimator2.fit(\n",
    "    inputs=data_uri,\n",
    "    job_name=\"heterogenous-\" + datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Analyzing the Heterogeneous training job throughput and resource usage\n",
    "We'll examine: CPU and GPU usage. Epoch time and step time.\n",
    "\n",
    "#### CPU and GPU usage analysis\n",
    " In the screenshot below we observe that GPU usage has increase to 73% (compared to ~40% in the homogenous training run) which is what we were aiming for. The CPU usage on all 3 instances are close to 90% CPU uage.  \n",
    " \n",
    "Note: To view your own job Click on **View instance metrics** from the **Training jobs** node in **Amazon SageMaker Console**. Then to rescale the CloudWatch Metrics to 100% on CPU utilization for algo-1 and algo-2, use CloudWatch \"Add Math\" feature and average it out by no. of vCPUs/GPUs on those instance types.  \n",
    "<img src=\"images/metrics Heterogeneous cpu and gpu usage.png\" width=75%/>\n",
    "\n",
    "#### Epoch time and step time analysis\n",
    "For 2nd epoch onwards you should see this printout in the logs of the dnn_gruop instance (p4d.24xlarge): 45s/epoch - 89ms/step.\n",
    "Note that the instances are named: Algo1, Algo2, Algo3 randomly on each execution, so you'll need to open all instances logs to find the dnn_group instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Comparing time-to-train and cost-to-train\n",
    "The table below summarizes both jobs. We can see that:\n",
    "- The Heterogeneous job is <b>2.4x faster to train</b> (86ms/step) than the homogeneous job (208ms/step).\n",
    "- The Heterogeneous job is <b>50% cheaper to train</b> than the homogenous job. This is despite the heterogenous costs more per hour ($45/hour vs $37/hour), due to the two extra c5.18xlarge instances included in the heterogenous job `($45 = $37.7 + 2 * $3.67` \n",
    "The cost-to-train formula we used: change in houly price `($45/$37.7) ` times `reduction-in-time-to-train (86ms/208ms)`  =  50% = `($45/$37.7) * (86ms/208ms)`. \n",
    "\n",
    "<img src=images/homogeneous-vs-heterogeneous-results-table.png alt=\"results table\" />\n",
    "\n",
    "## F. Conclusion\n",
    "In this notebook, we demonstrated how to leverage Heterogeneous cluster feature of SageMaker Training, with TensorFlow to achieve better price performance and increase training speed. To get started you can copy this example project and only change the `train_dnn.py` script. To run the job, you could use this notebook, or the `start_job.py`."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "77c0de85c2cb739aa5100af7b92fb9d2075368f0e653f4148499a56c989df5f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
