{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fleet Predictive Maintenance: Part 2. Feature Engineering and Exploratory Data Visualization\n",
    "\n",
    "*Using SageMaker Studio to Predict Fault Classification*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This notebook is part of a sequence of notebooks whose purpose is to demonstrate a Predictive Maintenance (PrM) solution for automobile fleet maintenance via Amazon SageMaker Studio so that business users have a quick path towards a PrM POC. In this notebook, we will be focusing on feature engineering. It is the second notebook in a series of notebooks. You can choose to run this notebook by itself or in sequence with the other notebooks listed below. Please see the [README.md](README.md) for more information about this use case implement of this sequence of notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Data Prep: Processing Job from SageMaker Data Wrangler Output](./1_dataprep_dw_job_predmaint.ipynb)\n",
    "1. [Data Prep: Featurization](./2_dataprep_predmaint.ipynb) (current notebook)\n",
    "1. [Train, Tune and Predict using Batch Transform](./3_train_tune_predict_predmaint.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notes: \n",
    "\n",
    "* Due to cost consideration, the goal of this example is to show you how to use some of SageMaker Studio's features, not necessarily to achieve the best result. \n",
    "* We use the built-in classification algorithm in this example, and a Python 3 (Data Science) Kernel is required.\n",
    "* The nature of predictive maintenace solutions, requires a domain knowledge expert of the system or machinery. With this in mind, we will make assumptions here for certain elements of this solution with the acknowldgement that these assumptions should be informed by a domain expert and a main business stakeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id ='2_Contents' > </a>\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Feature Engineering](#Feature-Engineering)\n",
    "1. [Visualization of the Data Distributions](#Visualization-of-the-Data-Distributions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Let's start by:\n",
    "\n",
    "* Installing and importing any dependencies\n",
    "* Instantiating SageMaker session\n",
    "* Specifying the S3 bucket and prefix that you want to use for your training and model data. This should be within the same region as SageMaker training\n",
    "* Defining the IAM role used to give training access to your data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any missing dependencies\n",
    "!pip install -qU 'sagemaker-experiments==0.1.24' 'sagemaker>=2.16.1' 'boto3' 'awswrangler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import collections\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SageMaker dependencies\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "import awswrangler as wr\n",
    "\n",
    "# This instantiates a SageMaker session that we will be operating in.\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# This object represents the IAM role that we are assigned.\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# prefix is the path within the bucket where SageMaker stores the output from training jobs.\n",
    "prefix_prm = \"predmaint\"  # place to upload training files within the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature Engineering \n",
    "\n",
    "For PrM, feature selection, generation and engineering is extremely important and very depended on domain expertise and understanding of the systems involved. For our solution, we will focus on the some simple features such as:\n",
    "* lag features \n",
    "* rolling average\n",
    "* rolling standard deviation \n",
    "* age of the engines \n",
    "* categorical labels\n",
    "\n",
    "These features serve as a small example of the potential features that could be created. Other features to consider are changes in the sensor values within a window, change from the initial value or number over a defined threshold. For additional guidance on Feature Engineering, visit the [SageMaker Tabular Feature Engineering guide](). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load up our cleaned dataset, which can be produced by following the steps in the notebook [Data Prep: Processing Job from SageMaker Data Wrangler Output](./1_dataprep_dw_job_predmaint.ipynb) (the first section in this notebook series). See the [Background](#Background) section at the beginning of the notebook for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet = pd.read_csv(\"fleet_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "plot_fleet = fleet.loc[fleet[\"vehicle_id\"] == 1]\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "axs[0].plot(plot_fleet[\"datetime\"], plot_fleet[\"voltage\"])\n",
    "axs[1].plot(plot_fleet[\"datetime\"], plot_fleet[\"current\"])\n",
    "axs[2].plot(plot_fleet[\"datetime\"], plot_fleet[\"resistance\"])\n",
    "\n",
    "axs[0].set_ylabel(\"voltage\")\n",
    "axs[1].set_ylabel(\"current\")\n",
    "axs[2].set_ylabel(\"resistance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "plot_fleet = fleet.loc[fleet[\"vehicle_id\"] == 2]\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "axs[0].plot(plot_fleet[\"datetime\"], plot_fleet[\"voltage\"])\n",
    "axs[1].plot(plot_fleet[\"datetime\"], plot_fleet[\"current\"])\n",
    "axs[2].plot(plot_fleet[\"datetime\"], plot_fleet[\"resistance\"])\n",
    "\n",
    "axs[0].set_ylabel(\"voltage\")\n",
    "axs[1].set_ylabel(\"current\")\n",
    "axs[2].set_ylabel(\"resistance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the proportion of failures to non-failure\n",
    "print(fleet[\"target\"].value_counts())\n",
    "print(\n",
    "    \"\\nPercent of failures in the dataset: \"\n",
    "    + str(fleet[\"target\"].value_counts()[1] / len(fleet[\"target\"]))\n",
    ")\n",
    "print(\n",
    "    \"Number of vehicles with 1+ failures: \"\n",
    "    + str(fleet[fleet[\"target\"] == 1][\"vehicle_id\"].drop_duplicates().count())\n",
    "    + \"\\n\"\n",
    ")\n",
    "\n",
    "# view the percentage distribution of target column\n",
    "print(fleet[\"target\"].value_counts() / np.float(len(fleet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that percentage of observations of the class label 0 (no failure) and 1 (failure) is 80.42% and 19.58% respectively. So, this is a class imbalanced problem. For PrM, class imbalance is oftentimes a problem as failues happen less frequently and businesses do not want to allow for more failures than is necessary. There are a variety of techniques for dealing with class imbalances in data such as [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html). For this use case, we will leverage SageMaker's Estimator built-in hyperparameters to I will deal with imbalance. We discuss more in a later section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = fleet.groupby([\"vehicle_id\"])[\"target\"].sum().rename(\"percentage of failures\")\n",
    "fail_percent = pd.DataFrame(p / 100)\n",
    "print(fail_percent.sort_values(\"percentage of failures\", ascending=False).head(20))\n",
    "# fail_percent.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "print(fleet.isnull().sum())\n",
    "\n",
    "# check sensor readings for zeros\n",
    "fleet[fleet.loc[:, \"voltage\":\"resistance\"].values == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optional: load in the fleet dataset from above\n",
    "# fleet = pd.read_csv('fleet_data.csv')\n",
    "fleet.datetime = pd.to_datetime(fleet.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lag features for voltage, current and resistance\n",
    "# we will only look as 2 lags\n",
    "for i in range(1, 2):\n",
    "    fleet[\"voltage_lag_\" + str(i)] = (\n",
    "        fleet.groupby(\"vehicle_id\")[\"voltage\"].shift(i).fillna(method=\"bfill\", limit=7)\n",
    "    )\n",
    "    fleet[\"current_lag_\" + str(i)] = (\n",
    "        fleet.groupby(\"vehicle_id\")[\"current\"].shift(i).fillna(method=\"bfill\", limit=7)\n",
    "    )\n",
    "    fleet[\"resistance_lag_\" + str(i)] = (\n",
    "        fleet.groupby(\"vehicle_id\")[\"resistance\"].shift(i).fillna(method=\"bfill\", limit=7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rolling stats for voltage, current and resistance group by vehicle_id\n",
    "stats = pd.DataFrame()\n",
    "grouped = fleet.groupby(\"vehicle_id\")\n",
    "\n",
    "# windows set to 4\n",
    "# you could also add in additional rolling window lengths based on the machinery and domain knowledge\n",
    "mean = [\n",
    "    (col + \"_\" + \"rolling_mean_\" + str(win), grouped[col].rolling(window=win).mean())\n",
    "    for win in [4]\n",
    "    for col in [\"voltage\", \"current\", \"resistance\"]\n",
    "]\n",
    "std = [\n",
    "    (col + \"_\" + \"rolling_std_\" + str(win), grouped[col].rolling(window=win).std())\n",
    "    for win in [4]\n",
    "    for col in [\"voltage\", \"current\", \"resistance\"]\n",
    "]\n",
    "df_mean = pd.DataFrame.from_dict(collections.OrderedDict(mean))\n",
    "df_std = pd.DataFrame.from_dict(collections.OrderedDict(std))\n",
    "stats = (\n",
    "    pd.concat([df_mean, df_std], axis=1)\n",
    "    .reset_index()\n",
    "    .set_index(\"level_1\")\n",
    "    .fillna(method=\"bfill\", limit=7)\n",
    ")  # fill backward\n",
    "stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet_lagged = pd.concat([fleet, stats.drop(columns=[\"vehicle_id\"])], axis=1)\n",
    "fleet_lagged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution\n",
    "round(fleet_lagged.describe(), 2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualization of the Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a single engine's histograms\n",
    "# we will lood at vehicle_id 2 as it has 1+ failures\n",
    "def plot_engine_hists(sensor_data):\n",
    "    cols = sensor_data.columns\n",
    "    n_cols = min(len(cols), 4)\n",
    "    n_rows = int(np.ceil(len(cols) / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "    plt.tight_layout()\n",
    "    axes = axes.flatten()\n",
    "    for col, ax in zip(cols, axes):\n",
    "        sns.distplot(sensor_data[[col]], ax=ax, label=col)\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"p\")\n",
    "\n",
    "\n",
    "plot_engine_hists(fleet_lagged[fleet_lagged[\"vehicle_id\"] == 2].loc[:, \"voltage\":])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a diagram that looks like the diagram below.\n",
    "\n",
    "![](engine_histogram_output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features used for one-hot encoding the categorical features including make, model, engine_type and vehicle_class\n",
    "features = fleet_lagged.drop(columns=[\"make\", \"model\", \"year\", \"vehicle_class\", \"engine_type\"])\n",
    "features.to_csv(\"features.csv\", index=False)\n",
    "features_created_prm = True\n",
    "%store features_created_prm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have kept the EDA and feature engineering limited here, there is much more that could be done. Additional analysis could be done to understand if the relationships between the make and model and/or the engine type and failure rates. Also, much more analysis could be done based on discussions with domain experts and their in-depth understandings of the systems based on experience.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's split our data into train, test and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PrM, we will want to split the data based on a time-dependent record splitting strategy since the data is time series sensor readings. We will make the splits by choosing a points in time based on the desired size of the training, test and validations sets. To prevent any records in the training set from sharing time windows with the records in the test set, we remove any records at the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will devote 80% to training, and we will save 10% for test and ~10% for validation (less the dropped records to avoid data leakage)\n",
    "train_size = int(len(features) * 0.80)\n",
    "val_size = int(len(features) * 0.10)\n",
    "\n",
    "# order by datetime in order to split on time\n",
    "ordered = features.sort_values(\"datetime\")\n",
    "\n",
    "# make train, test and validation splits\n",
    "train, test, val = (\n",
    "    ordered[0:train_size],\n",
    "    ordered[train_size : train_size + val_size],\n",
    "    ordered.tail(val_size),\n",
    ")\n",
    "train.sort_values([\"vehicle_id\", \"datetime\"], inplace=True)\n",
    "\n",
    "# make sure there is no data leakage between train, test and validation\n",
    "test = test.loc[test[\"datetime\"] > train[\"datetime\"].max()]\n",
    "val = val.loc[val[\"datetime\"] > test[\"datetime\"].max()]\n",
    "\n",
    "print(\"First train datetime: \", train[\"datetime\"].min())\n",
    "print(\"Last train datetime: \", train[\"datetime\"].max(), \"\\n\")\n",
    "print(\"First test datetime: \", test[\"datetime\"].min())\n",
    "print(\"Last test datetime: \", test[\"datetime\"].max(), \"\\n\")\n",
    "print(\"First validation datetime: \", val[\"datetime\"].min())\n",
    "print(\"Last validation datetime: \", val[\"datetime\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"datetime\", \"vehicle_id\"], axis=1)\n",
    "\n",
    "test = test.sort_values([\"vehicle_id\", \"datetime\"])\n",
    "test = test.drop([\"datetime\", \"vehicle_id\"], axis=1)\n",
    "\n",
    "val = val.sort_values([\"vehicle_id\", \"datetime\"])\n",
    "val = val.drop([\"datetime\", \"vehicle_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Observations: \", len(ordered))\n",
    "print(\"Number of observations in the training data:\", len(train))\n",
    "print(\"Number of observations in the test data:\", len(test))\n",
    "print(\"Number of observations in the validation data:\", len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting data to the appropriate format for Estimator\n",
    "\n",
    "Amazon SageMaker implementation of Linear Learner takes either csv format or recordIO-wrapped protobuf. We will start by scaling the features and saving the data files to csv format. Then, we will save the data to file. If you are using your own data, and it is too large to fit in memory, protobuf might be a better option than csv. For more information on data formats for training, please refer to [Common Data Formats for Training](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale all features for train, test and validation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "train = pd.DataFrame(scaler.fit_transform(train))\n",
    "test = pd.DataFrame(scaler.transform(test))\n",
    "val = pd.DataFrame(scaler.transform(val))\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"test.csv\", header=False, index=False)\n",
    "test.loc[:, 1:].to_csv(\"test_x.csv\", header=False, index=False)\n",
    "val.to_csv(\"validation.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Notebook : Train\n",
    "\n",
    "### SageMaker Estimator and Experiments\n",
    "\n",
    "Once you have selected some models that you would like to try out, SageMaker Experiments can be a great tool to track and compare all of the models before selecting the best model to deploy. We will set up an experiment using SageMaker experiments to track all the model training iterations for the Linear Learner Estimator we will try. You can read more about [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) to learn about experiment features, tracking and comparing outputs.   "
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
