{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f30914",
   "metadata": {},
   "source": [
    "# Hosting ControlNet/Lora models on SageMaker using DJL container.\n",
    "\n",
    "In this notebook, we explore how to host ControlNet/Lora models on SageMaker asynchronous endpoint using the Large Model Inference container that packages DJL model server.\n",
    "\n",
    "In this notebook, under the hood we use stable-diffusion-webui to generate image with Lora and ControlNet support. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdeeaf5",
   "metadata": {},
   "source": [
    "## Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103e5c4",
   "metadata": {},
   "source": [
    "Initialize the variables for SageMaker default bucket, role, and AWS account ID, and current AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "region_name = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14934beb",
   "metadata": {},
   "source": [
    "Execute the script - build_and_push.sh to build Docker images for SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd76a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x build_and_push.sh && ./build_and_push.sh $region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269bce9",
   "metadata": {},
   "source": [
    "Upload the dummy file to S3 to meet the requirement of SageMaker Endpoint for model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff15324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = \"s3://{0}/stable-diffusion-webui/data/model.tar.gz\".format(bucket)\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm dummy\n",
    "!aws s3 cp model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff27f5c",
   "metadata": {},
   "source": [
    "## Deploy to SageMaker Asychronous Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369589a7",
   "metadata": {},
   "source": [
    "Initialized the variables for URI of Docker Inference Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9258d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = None\n",
    "image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-inference-api:latest\".format(\n",
    "    account_id, region_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d863b5",
   "metadata": {},
   "source": [
    "Define the models configuration in order to download those models from one of source - HTTP, S3 and HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0d7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "huggingface_models = [\n",
    "    {\n",
    "        \"repo_id\": \"runwayml/stable-diffusion-v1-5\",\n",
    "        \"filename\": \"v1-5-pruned.ckpt\",\n",
    "        \"name\": \"Stable-diffusion\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_canny.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "]\n",
    "\n",
    "http_models = [\n",
    "    {\n",
    "        \"uri\": \"https://civitai.com/api/download/models/7627\",\n",
    "        \"filename\": \"2bNierAutomataLora_v2b.safetensors\",\n",
    "        \"name\": \"Lora\",\n",
    "    }\n",
    "]\n",
    "\n",
    "model_environment = {\n",
    "    \"ckpt\": \"/tmp/models/Stable-diffusion/v1-5-pruned.ckpt\",\n",
    "    \"huggingface_models\": json.dumps(huggingface_models),\n",
    "    \"http_models\": json.dumps(http_models),\n",
    "    \"generated_images_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/generated/\",\n",
    "    \"embeddings_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/embeddings/\",\n",
    "    \"hypernetwork_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/hypernetwork/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d46a26",
   "metadata": {},
   "source": [
    "Define the model, instance type and instance initial count for SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2269be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=model_environment,\n",
    "    predictor_cls=Predictor,\n",
    ")\n",
    "\n",
    "instance_type = \"ml.g4dn.2xlarge\"\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d90af",
   "metadata": {},
   "source": [
    "Define the SageMaker Asychronous Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178979d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"stable-diffusion-webui\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a87f2b1",
   "metadata": {},
   "source": [
    "Here we use asynchronous inference since asynchronous inference is more suitable for workloads with large payload sizes and long inference processing times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553f34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=instance_count,\n",
    "    volume_size_in_gb=225,\n",
    "    container_startup_health_check_timeout=1800,\n",
    "    async_inference_config=async_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402fb991",
   "metadata": {},
   "source": [
    "## Generate images using Lora models\n",
    "\n",
    "LoRA (Low-Rank Adaptation of Large Language Models) models have become the standard to extend the Stable Diffusion models. Let's use Lora model to generate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc827f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"model\": \"v1-5-pruned.ckpt\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"enable_hr\": False,\n",
    "        \"denoising_strength\": 0,\n",
    "        \"firstphase_width\": 0,\n",
    "        \"firstphase_height\": 0,\n",
    "        \"hr_scale\": 2,\n",
    "        \"hr_upscaler\": \"\",\n",
    "        \"hr_second_pass_steps\": 0,\n",
    "        \"hr_resize_x\": 0,\n",
    "        \"hr_resize_y\": 0,\n",
    "        \"prompt\": \"yorha no. 2 type b, 1girl, bangs, black blindfold, black dress, black gloves, black hairband, blindfold, blindfold removed, breasts, cleavage cutout, clothing cutout, commentary request, dress, gloves, hairband, half-closed eyes, hand up, highres, io (sinking=carousel), juliet sleeves, long sleeves, looking at viewer, medium breasts, mole, mole under mouth, nier (series), nier automata, no blindfold, parted lips, puffy sleeves, short hair, solo, thighhighs, turtleneck, upper body, white hair, bokeh <lora:2bNierAutomataLora_v2b:0.5>\",\n",
    "        \"styles\": [\"\"],\n",
    "        \"seed\": 2674865251,\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": \"\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"negative_prompt\": \"(worst quality, low quality:1.3)\",\n",
    "        \"eta\": 0,\n",
    "        \"s_churn\": 0,\n",
    "        \"s_tmax\": 0,\n",
    "        \"s_tmin\": 0,\n",
    "        \"s_noise\": 1,\n",
    "        \"override_settings\": {},\n",
    "        \"override_settings_restore_afterwards\": True,\n",
    "        \"script_args\": [],\n",
    "        \"sampler_index\": \"DPM++ SDE Karras\",\n",
    "        \"script_name\": \"\",\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0650058",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f374d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb599ec5",
   "metadata": {},
   "source": [
    "Wait until the asychronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e5213",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f5760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    for image_uri in json.loads(body)[\"images\"]:\n",
    "        image_bucket, image_key = get_bucket_and_key(image_uri)\n",
    "        image_object = s3_resource.Object(image_bucket, image_key)\n",
    "        image = Image.open(io.BytesIO(image_object.get()[\"Body\"].read()))\n",
    "        image.show()\n",
    "        image.save(datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.jpg\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8746a",
   "metadata": {},
   "source": [
    "## Generate images using ControlNet models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786af504",
   "metadata": {},
   "source": [
    "ControlNet is a neural network structure to control diffusion models by adding extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca0f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    with io.BytesIO() as output_bytes:\n",
    "        image.save(output_bytes, format=\"JPEG\")\n",
    "        bytes_data = output_bytes.getvalue()\n",
    "\n",
    "    encoded_string = base64.b64encode(bytes_data)\n",
    "\n",
    "    base64_str = str(encoded_string, \"utf-8\")\n",
    "    mimetype = \"image/jpeg\"\n",
    "    image_encoded_in_base64 = (\n",
    "        \"data:\" + (mimetype if mimetype is not None else \"\") + \";base64,\" + base64_str\n",
    "    )\n",
    "    return image_encoded_in_base64\n",
    "\n",
    "\n",
    "def decode_base64_to_image(encoding):\n",
    "    if encoding.startswith(\"data:image/\"):\n",
    "        encoding = encoding.split(\";\")[1].split(\",\")[1]\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(encoding)))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf55eb2",
   "metadata": {},
   "source": [
    "Open an image for as ControlNet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31132ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"./images/inference/ControlNet/bal-source.png\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61621bb8",
   "metadata": {},
   "source": [
    "Define the payload for SageMaker inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9c4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"model\": \"v1-5-pruned.ckpt\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"enable_hr\": False,\n",
    "        \"denoising_strength\": 0,\n",
    "        \"firstphase_width\": 0,\n",
    "        \"firstphase_height\": 0,\n",
    "        \"hr_scale\": 2,\n",
    "        \"hr_upscaler\": \"\",\n",
    "        \"hr_second_pass_steps\": 0,\n",
    "        \"hr_resize_x\": 0,\n",
    "        \"hr_resize_y\": 0,\n",
    "        \"prompt\": \"ballon\",\n",
    "        \"styles\": [\"\"],\n",
    "        \"seed\": -1,\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": \"\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"negative_prompt\": \"\",\n",
    "        \"eta\": 0,\n",
    "        \"s_churn\": 0,\n",
    "        \"s_tmax\": 0,\n",
    "        \"s_tmin\": 0,\n",
    "        \"s_noise\": 1,\n",
    "        \"override_settings\": {},\n",
    "        \"override_settings_restore_afterwards\": True,\n",
    "        \"script_args\": [],\n",
    "        \"sampler_index\": \"DPM++ SDE Karras\",\n",
    "        \"script_name\": \"\",\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {\n",
    "            \"controlnet\": {\n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"enabled\": True,\n",
    "                        \"module\": \"none\",\n",
    "                        \"model\": \"control_sd15_canny [fef5e48e]\",\n",
    "                        \"weight\": 1,\n",
    "                        \"image\": encode_image_to_base64(image),\n",
    "                        \"low_vram\": False,\n",
    "                        \"processor_res\": 64,\n",
    "                        \"threshold_a\": 64,\n",
    "                        \"threshold_b\": 64,\n",
    "                        \"guidance_start\": 0,\n",
    "                        \"guidance_end\": 1,\n",
    "                        \"guess_mode\": False,\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d87948",
   "metadata": {},
   "source": [
    "Wait until the asynchronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec8437",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ac845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    for image_uri in json.loads(body)[\"images\"]:\n",
    "        image_bucket, image_key = get_bucket_and_key(image_uri)\n",
    "        image_object = s3_resource.Object(image_bucket, image_key)\n",
    "        image = Image.open(io.BytesIO(image_object.get()[\"Body\"].read()))\n",
    "        image.show()\n",
    "        image.save(datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.jpg\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9397e",
   "metadata": {},
   "source": [
    "## [Optional] Create auto-scaling group for SageMaker endpoint in case you want to scale it based on specific metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd08eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(\n",
    "    endpoint_name, min_capcity=1, max_capcity=2, target_value=5\n",
    "):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f\"Request-ScalingPolicy-{endpoint_name}\",\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600,  # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300,  # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870b48e",
   "metadata": {},
   "source": [
    "## Resource cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
