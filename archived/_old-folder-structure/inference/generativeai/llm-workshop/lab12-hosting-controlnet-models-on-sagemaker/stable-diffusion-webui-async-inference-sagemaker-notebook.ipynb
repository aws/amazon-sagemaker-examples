{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f343192-4cdb-468d-8048-500ac638228a",
   "metadata": {},
   "source": [
    "# Generative Fill example on Amazon SageMaker using DLC container.\n",
    "\n",
    "In this notebook, we explore how to build generative fill application and host Stable Diffusion/ ControlNet / segment anything models on SageMaker asynchronous endpoint using BYOC (Bring-your-own-container).\n",
    "\n",
    "In this notebook, under the hood we use stable-diffusion-webui and extensions to generate image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a566f-927a-4f78-baa2-f31875143781",
   "metadata": {},
   "source": [
    "Note - Amazon Web Services has no control or authority over the third-party generative AI service referenced in this Workshop, and does not make any representations or warranties that the third-party generative AI service is secure, virus-free, operational, or compatible with your production environment and standards. You are responsible for making your own independent assessment of the content provided in this Workshop, and take measures to ensure that you comply with your own specific quality control practices and standards, and the local rules, laws, regulations, licenses and terms of use that apply to you, your content, and the third-party generative AI service referenced in this Workshop. The content of this Workshop: (a) is for informational purposes only, (b) represents current Amazon Web Services product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Beijing Sinnet Technology Co., Ltd. (“Sinnet”), Ningxia Western Cloud Data Technology Co., Ltd. (“NWCD”), Amazon Connect Technology Services (Beijing) Co., Ltd. (“Amazon”), or their respective affiliates, suppliers or licensors.  Amazon Web Services’ content, products or services are provided “as is” without warranties, representations, or conditions of any kind, whether express or implied.  The responsibilities and liabilities of Sinnet, NWCD or Amazon to their respective customers are controlled by the applicable customer agreements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722516a0-6940-4860-b698-3e62f3906796",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e385cdf-8a17-4d3b-9213-d4f857907f70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3541ed7-e45e-4434-97f8-aff5b7ad9b45",
   "metadata": {},
   "source": [
    "Initialize the variables for SageMaker default bucket, role, and AWS account ID, and current AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56bceb-6a53-4bdc-85dc-703afb76bc77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "region_name = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351f2a2-8cb7-4731-a936-1178a6cf7bed",
   "metadata": {},
   "source": [
    "Execute the script to build Docker images for SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6c37f-ccfb-41cd-a0d6-2988ca536bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh -s \"$region_name\"\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "region=$1\n",
    "echo \"$region $1\"\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "docker login -u AWS -p $(aws ecr get-login-password --region $region) 763104351884.dkr.ecr.$region.amazonaws.com\n",
    "\n",
    "# Get the account number associated with the current IAM credentials\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    exit 255\n",
    "fi\n",
    "\n",
    "inference_image=all-in-one-ai-stable-diffusion-webui-inference-api\n",
    "inference_fullname=${account}.dkr.ecr.${region}.amazonaws.com/${inference_image}:latest\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${inference_image}\" --region ${region} || aws ecr create-repository --repository-name \"${inference_image}\" --region ${region}\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${inference_image}\" --region ${region}\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "docker login -u AWS -p $(aws ecr get-login-password --region $region) $account.dkr.ecr.$region.amazonaws.com\n",
    "\n",
    "aws ecr set-repository-policy \\\n",
    "    --repository-name \"${inference_image}\" \\\n",
    "    --policy-text \"file://ecr-policy.json\" \\\n",
    "    --region ${region}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${inference_image} -f Dockerfile.inference . --build-arg REGION=${region}\n",
    "\n",
    "docker tag ${inference_image} ${inference_fullname}\n",
    "\n",
    "docker push ${inference_fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac742d7-c1b1-4bf9-aad1-60b28296f595",
   "metadata": {},
   "source": [
    "Upload the dummy file to S3 to meet the requirement of SageMaker Endpoint for model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686c6d8-ae5e-490f-b9d2-163a5a199a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = \"s3://{0}/stable-diffusion-webui/data/model.tar.gz\".format(bucket)\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm dummy\n",
    "!aws s3 cp model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71cbd8-d3b0-4771-b40e-bc2e98afa673",
   "metadata": {},
   "source": [
    "## Deploy to SageMaker Asychronous Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094f3ae-362f-4fa5-b2de-c4dcb6463542",
   "metadata": {},
   "source": [
    "Initialized the variables for URI of Docker Inference Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08489692-2df3-4833-905c-2e0a6b59e962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = None\n",
    "image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-inference-api:latest\".format(\n",
    "    account_id, region_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e013c82-4839-4663-a588-19aa115486f7",
   "metadata": {},
   "source": [
    "Define the models configuration in order to download those models from one of source - HTTP, S3 and HuggingFace. Note: Here as an example the Lora model - 2bNierAutomataLora_v2b.safetensors and ControlNet model - control_sd15_canny.pth are going to be downloaded from Civitai and Huggingface directly once the SageMaker endpoint is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb7716-7fbf-4d3e-9228-9d4c866c5d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "huggingface_models = [\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet-v1-1\",\n",
    "        \"filename\": \"control_v11p_sd15_inpaint.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    }\n",
    "]\n",
    "\n",
    "model_environment = {\n",
    "    \"huggingface_models\": json.dumps(huggingface_models),\n",
    "    \"embeddings_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/embeddings/\",\n",
    "    \"hypernetwork_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/hypernetwork/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba80cbb-fac7-4425-850a-8c3b7c4a205d",
   "metadata": {},
   "source": [
    "Define the model, instance type and instance initial count for SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5b8ac-0d4b-4dae-9561-dbf8f3580237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=model_environment,\n",
    "    predictor_cls=Predictor,\n",
    ")\n",
    "\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc946fb-e790-4beb-b519-8e4264ed1aa1",
   "metadata": {},
   "source": [
    "Define the SageMaker Asychronous Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b72569-91fa-4192-9c63-a5173485a755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"stable-diffusion-webui\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e5c97-c33a-450e-aa80-bf5318225265",
   "metadata": {},
   "source": [
    "Here we use asynchronous inference since asynchronous inference is more suitable for workloads with large payload sizes and long inference processing times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513a98c-78ea-4893-98cf-314dc7278715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=instance_count,\n",
    "    volume_size_in_gb=225,\n",
    "    container_startup_health_check_timeout=1800,\n",
    "    async_inference_config=async_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f488f-6024-46b8-8364-642fc89487a1",
   "metadata": {},
   "source": [
    "## Generate initial image using text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d9d25-2074-4b29-a437-4530d7cff5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"prompt\": \"((Best quality)), ((masterpiece)), ((realistic)), (detailed), cute panda ((standing in a asian garden with cherry trees)) ((masterpiece)), absurdres, HDR\",\n",
    "        \"negative_prompt\": \"(bad quality)\",\n",
    "        \"seed\": 2816240246,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 768,\n",
    "        \"alwayson_scripts\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369c699-5d63-400a-8f43-c2474ef52da4",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebf380-7126-4118-9f1f-932ec75f2c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbaee6-3732-4f21-8260-91cbe56748d5",
   "metadata": {},
   "source": [
    "Wait until the asychronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a4069-cacc-4721-8c4b-d5468efb643a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ace299-f064-4f5b-b4d7-d2a98e72869f",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f831db6-a9ce-429f-a0af-18055af7bc02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    image_object = json.loads(body)[\"images\"][0]\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_object)))\n",
    "    image.show()\n",
    "    initial_image_filename = datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.png\")\n",
    "    image.save(initial_image_filename)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57075b0-9b48-492e-9d6b-4c236bf3301b",
   "metadata": {},
   "source": [
    "## Expand initial image using text prompt and ControlNet models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b1d29-9ba8-4ba9-87c9-d970ab85e0d7",
   "metadata": {},
   "source": [
    "ControlNet is a neural network structure to control diffusion models by adding extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763fd5c-e82d-45ac-8311-1c9a17df161a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    with io.BytesIO() as output_bytes:\n",
    "        if isinstance(image, dict):\n",
    "            image = image[\"image\"]\n",
    "        format = \"PNG\" if image.mode == \"RGBA\" else \"JPEG\"\n",
    "        image.save(output_bytes, format=format)\n",
    "        bytes_data = output_bytes.getvalue()\n",
    "\n",
    "    encoded_string = base64.b64encode(bytes_data)\n",
    "\n",
    "    base64_str = str(encoded_string, \"utf-8\")\n",
    "    mimetype = \"image/jpeg\" if format == \"JPEG\" else \"image/png\"\n",
    "    image_encoded_in_base64 = (\n",
    "        \"data:\" + (mimetype if mimetype is not None else \"\") + \";base64,\" + base64_str\n",
    "    )\n",
    "    return image_encoded_in_base64\n",
    "\n",
    "\n",
    "def decode_base64_to_image(encoding):\n",
    "    if encoding.startswith(\"data:image/\"):\n",
    "        encoding = encoding.split(\";\")[1].split(\",\")[1]\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(encoding)))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b8a8e-8d42-4c3e-9b64-5a5d8a7ce3f3",
   "metadata": {},
   "source": [
    "Define the payload for SageMaker inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35fc868-7a35-4ebf-accb-4fae77af13cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"image-to-image\",\n",
    "    \"img2img_payload\": {\n",
    "        \"prompt\": \"((Best quality)), ((masterpiece)), ((realistic)), (detailed), cute panda ((standing in a asian garden with cherry trees)) ((masterpiece)), absurdres, HDR\",\n",
    "        \"negative_prompt\": \"(bad quality)\",\n",
    "        \"init_images\": [encode_image_to_base64(image)],\n",
    "        \"mask\": None,\n",
    "        \"steps\": 20,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"denoising_strength\": 0.8,\n",
    "        \"seed\": 2866147124,\n",
    "        \"height\": 768,\n",
    "        \"width\": 1280,\n",
    "        \"resize_mode\": 0,\n",
    "        \"include_init_images\": False,\n",
    "        \"alwayson_scripts\": {\n",
    "            \"controlnet\": {\n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"enabled\": True,\n",
    "                        \"module\": \"inpaint_only+lama\",\n",
    "                        \"model\": \"control_v11p_sd15_inpaint [ebff9138]\",\n",
    "                        \"image\": encode_image_to_base64(image),\n",
    "                        \"resize_mode\": \"Resize and Fill\",\n",
    "                        \"low_vram\": False,\n",
    "                        \"weight\": 1,\n",
    "                        \"guidance_start\": 0,\n",
    "                        \"guidance_end\": 1,\n",
    "                        \"pixel_perfect\": False,\n",
    "                        \"control_mode\": \"ControlNet is more important\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a049c-7ef0-4347-a703-6cfb7a229505",
   "metadata": {},
   "source": [
    "Wait until the asynchronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b49508-348e-47e3-aebf-34656dba5158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a71b9-11fb-4f7b-a093-ba46f724bbf0",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a3335-5441-467f-8cc3-db745903cdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    image_object = json.loads(body)[\"images\"][0]\n",
    "    image2 = Image.open(BytesIO(base64.b64decode(image_object)))\n",
    "    image2.show()\n",
    "    image2.save(datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.png\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8c2a3-f800-49ec-87ae-8d42581648f5",
   "metadata": {},
   "source": [
    "## Run generative fill application built with Gradio framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a5e5d-7250-481e-a898-5aab78cc2878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c907a7a-8006-4fa4-885f-8b1699a84c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/xieyongliang/generative-fill-webui.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcb160-3679-4124-b694-52c900a04c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd ./generative-fill-webui && export sagemaker_endpoint=$endpoint_name && pip install -r requirements.txt && python ui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f9570-6b5e-48fe-9794-11d31d4498c8",
   "metadata": {},
   "source": [
    "## [Optional] Create auto-scaling group for SageMaker endpoint in case you want to scale it based on specific metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b45375-8c4b-42f8-9eff-a52ef8490cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(\n",
    "    endpoint_name, min_capcity=1, max_capcity=2, target_value=5\n",
    "):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f\"Request-ScalingPolicy-{endpoint_name}\",\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600,  # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300,  # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d89ef-34d8-4da8-b3c6-6ac9671e4337",
   "metadata": {},
   "source": [
    "## Resource cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba3039-c6a1-4873-86fc-cb4f3c91ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49650af8-f937-4c93-af38-669e6e29bd8e",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
