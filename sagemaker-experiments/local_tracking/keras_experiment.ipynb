{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9590386b-3011-41b7-ad13-9e9b0f333831",
   "metadata": {},
   "source": [
    "# Track a model being trained in a notebook\n",
    "\n",
    "This notebook shows how you can use the SageMaker SDK to track a Machine Learning experiment. \n",
    "\n",
    "We introduce two concepts in this notebook -\n",
    "\n",
    "* *Experiment:* An experiment is a collection of runs. When you initialize a run in your training loop, you include the name of the experiment that the run belongs to. Experiment names must be unique within your AWS account. \n",
    "* *Run:* A run consists of all the inputs, parameters, configurations, and results for one iteration of model training. Initialize an experiment run for tracking a training job with Run(). \n",
    "\n",
    "In this notebook we train a Keras model using the MNIST dataset. We use a Keras callback to log metrics to an Experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d28dfa-f88f-4320-b3f1-87436e972a52",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** To run this notebook, use the `TensorFlow 2.6 Python CPU Optimized image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b4a04-cfc1-4c51-98c3-eb264319ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614bd72-736e-4e11-8010-f3cc0c7218fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.experiments.run import Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34edbc1-4af1-4d95-a6d8-b65794106d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "boto_sess = boto3.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sm = boto_sess.client(\"sagemaker\")\n",
    "region = boto_sess.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22790f8b-efd7-44c5-abd9-95777b3503cd",
   "metadata": {},
   "source": [
    "### Prepare the data used for training the model\n",
    "\n",
    "Here we use the mnist dataset available with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bcfb1-d173-450e-be19-bda3fa14f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e5137-b118-4e2d-af36-a21ae2273239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cf0df-ee2a-45e8-b098-449016359db9",
   "metadata": {},
   "source": [
    "### Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4354d1-fa42-464e-b6ba-6bde912cad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dropout=0.5):\n",
    "    \"\"\" \"\"\"\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b2b53-139f-45f7-84b4-9f4aa3f9efd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define the Keras callback to log metrics to the run\n",
    "\n",
    "The Keras Callback class provides a method `on_epoch_end` which emits metrics at the end of each epoch. All emitted metrics will be logged in the run passed to the callback,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da9d5b-2e3d-472f-b4e4-87f92e03241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentCallback(keras.callbacks.Callback):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, run, model, x_test, y_test):\n",
    "        \"\"\"Save params in constructor\"\"\"\n",
    "        self.run = run\n",
    "        self.model = model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" \"\"\"\n",
    "        keys = list(logs.keys())\n",
    "        for key in keys:\n",
    "            run.log_metric(name=key, value=logs[key], step=epoch)\n",
    "            print(\"Epoch: {}\\n{} -> {}\".format(epoch, key, logs[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcecc5-e00a-4af0-b6e3-7984e6d543ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the model in the notebook and track it in an Experiment\n",
    "\n",
    "Here we train the keras model locally on the instance that this notebook is running on.\n",
    "\n",
    "As part of the run, we track each of the input artifacts. These artifacts are written to files before the artifact is logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6143a2f-96ea-4609-912d-558558895c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save datasets to file\n",
    "\n",
    "!mkdir -p datasets\n",
    "np.save(\"datasets/input_train.npy\", x_train)\n",
    "np.save(\"datasets/input_test.npy\", x_test)\n",
    "np.save(\"datasets/input_train_labels.npy\", y_train)\n",
    "np.save(\"datasets/input_test_labels.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3471abdc-6fba-4d79-92bf-ff8b5fd98804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.experiments.run import Run\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "dropout = 0.5\n",
    "\n",
    "model = get_model(dropout)\n",
    "\n",
    "experiment_name = \"local-keras-experiment\"\n",
    "with Run(experiment_name=experiment_name, sagemaker_session=sagemaker_session) as run:\n",
    "    run.log_parameter(\"batch_size\", batch_size)\n",
    "    run.log_parameter(\"epochs\", epochs)\n",
    "    run.log_parameter(\"dropout\", 0.5)\n",
    "\n",
    "    run.log_file(\"datasets/input_train.npy\", is_output=False)\n",
    "    run.log_file(\"datasets/input_test.npy\", is_output=False)\n",
    "    run.log_file(\"datasets/input_train_labels.npy\", is_output=False)\n",
    "    run.log_file(\"datasets/input_test_labels.npy\", is_output=False)\n",
    "\n",
    "    # Train locally\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[ExperimentCallback(run, model, x_test, y_test)],\n",
    "    )\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "\n",
    "    run.log_metric(name=\"Final Test Loss\", value=score[0])\n",
    "    run.log_metric(name=\"Final Test Accuracy\", value=score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1307f6a-fcd1-4228-b18d-4e2b90383c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
