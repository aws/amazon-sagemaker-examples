{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PyTorch Models using Horovod with Open MPI\n",
    "\n",
    "*(This notebook was tested with the \"Python 3 (PyTorch CPU Optimized)\" kernel.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "[Horovod](https://horovod.readthedocs.io/en/stable/summary_include.html) is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and MXNet. Horovod can be used to train your models faster on Amazon SageMaker, and this notebook shows you how to run Horovod directly with Open MPI.\n",
    "\n",
    "Amazon SageMaker is a fully-managed service that provides developers and data scientists with the ability to build, train, and deploy machine learning (ML) models quickly. Amazon SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high-quality models. The SageMaker Python SDK makes it easy to train and deploy models in Amazon SageMaker with several different machine learning and deep learning frameworks, including PyTorch.\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "* Upload a data set to S3\n",
    "* Train a simple neural network with Horovod\n",
    "* Deploy a model to a SageMaker endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this example, we use the MNIST data set. MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Data\n",
    "\n",
    "The MNIST data set can be downloaded with the `torchvision.datasets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# ipywidgets is required to display loading bars in Jupyter. Because ipywidgets is not installed in\n",
    "# the container by default, we're temporarily disabling the loading bar.\n",
    "def gen_bar_updater():\n",
    "    return lambda count, block_size, total_size: None\n",
    "torchvision.datasets.utils.gen_bar_updater = gen_bar_updater\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing the Data\n",
    "\n",
    "Let's preview what the input images look like. We can do this using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4)\n",
    "images, labels = next(iter(dataloader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "plt.imshow(grid.permute(1, 2, 0))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the Data\n",
    "\n",
    "We use the `sagemaker.Session.upload` function to upload our datasets to an S3 location. The return value, `inputs`, identifies the location of our data.\n",
    "\n",
    "To upload our data to S3, we need to specify an S3 bucket and prefix. These should be within the same region as the Notebook Instance, training, and hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'pytorch-horovod-mpi-example'\n",
    "inputs = S3Uploader.upload('data', 's3://{}/{}/data'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrypoint Script\n",
    "\n",
    "In order to use Horovod with OpenMPI, we use a shell script as the training entry point. The shell script invokes our Python training script as part of an Open MPI command. You can learn more about running Horovod with MPI at https://horovod.readthedocs.io/en/stable/mpirun.html.\n",
    "\n",
    "Here's what the shell script looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat src/train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using 4 GPUs because that's the number of GPUs on a ml.p2.8xlarge instance, but if you're using a different instance type you may need to change the value of the`-np` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horovod-specific Code\n",
    "\n",
    "As you read the training script below, take note of these Horovod-specific modifications:\n",
    "\n",
    "* We start off by running `hvd.init()` and pinning each GPU to a single process\n",
    "* While constructing the `torch.optim.SGD` optimizer, we scale the learning rate by the number of workers (if you're wondering why we do this, see [this paper](https://arxiv.org/abs/1706.02677))\n",
    "* We wrap `torch.optim.SGD` with `hvd.DistributedOptimized` and broadcast the initial model state to the other processes\n",
    "* We gaurd the `save` function with `hvd.local_rank() != 0` to ensure the model is saved only on worker 0. This is done to prevent other workers from corrupting the checkpoint\n",
    "\n",
    "For more information about using Horovod with PyTorch, please see the [Horovod documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#prepare-a-pytorch-training-script).\n",
    "\n",
    "#### SageMaker-specific Code\n",
    "\n",
    "Outside of the Horovod-specific code, the training code is very similar to a training script we might run outside of Amazon SageMaker, but we can access useful properties about the training environment through various environment variables. For this notebook, our script retrieves the following environment variable values:\n",
    "\n",
    "* `SM_HOSTS`: a list of hosts on the container network.\n",
    "* `SM_CURRENT_HOST`: the name of the current container on the container network.\n",
    "* `SM_MODEL_DIR`: the location for model artifacts. This directory is uploaded to Amazon S3 at the end of the training job.\n",
    "* `SM_CHANNEL_TRAINING`: the location of our training data.\n",
    "* `SM_NUM_GPUS`: the number of GPUs available to the current container.\n",
    "\n",
    "For more about writing a PyTorch training script with SageMaker, please see the [SageMaker documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#prepare-a-pytorch-training-script). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IAM role arn is used to give training and hosting access to your data. See the Amazon SageMaker Roles for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyTorch` class allows us to run our training script as a job on SageMaker. We need to configure it with our training script, an IAM role, the number and type of training instances, and hyperparameters. In this case we are going to run our training job on a ml.p2.8xlarge instance, which contains four Tesla K80 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='train.sh',\n",
    "                    source_dir='src',\n",
    "                    role=role,\n",
    "                    framework_version='1.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.8xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we train our model, we can deploy it to a SageMaker Endpoint, which serves prediction requests in real-time. An implementation of `model_fn` is required for our entry point script. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-training-toolkit).\n",
    "\n",
    "Here's the inference script we're using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments to the deploy function allow us to set the number and type of instances that are used for the Endpoint. These do not need to be the same as the values we used for the training job. Here we deploy the model to a single ml.c5.xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.c5.xlarge',\n",
    "    entry_point='inference.py', \n",
    "    source_dir='src'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the predictor to classify hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The input images are displayed again\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "plt.imshow(grid.permute(1, 2, 0))  \n",
    "plt.show()\n",
    "\n",
    "outputs = predictor.predict(images)\n",
    "predictions = np.argmax(outputs, axis=1)\n",
    "\n",
    "print('Predictions:', ' '.join('%4s' % predictions[i] for i in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, our model correctly classifies the digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.4-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
