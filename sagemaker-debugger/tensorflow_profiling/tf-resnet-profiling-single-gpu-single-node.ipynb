{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-relations",
   "metadata": {
    "papermill": {
     "duration": 0.009904,
     "end_time": "2021-06-17T00:10:52.189558",
     "exception": false,
     "start_time": "2021-06-17T00:10:52.179654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Profiling TensorFlow Single GPU Single Node Training Job with Amazon SageMaker Debugger\n",
    "\n",
    "This notebook will walk you through creating a TensorFlow training job with the SageMaker Debugger profiling feature enabled. It will create a single GPU single node training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-picture",
   "metadata": {
    "papermill": {
     "duration": 0.009889,
     "end_time": "2021-06-17T00:10:52.209421",
     "exception": false,
     "start_time": "2021-06-17T00:10:52.199532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install sagemaker and smdebug\n",
    "To use the new Debugger profiling features, ensure that you have the latest versions of SageMaker and SMDebug SDKs installed. The following cell updates the libraries and restarts the Jupyter kernel to apply the updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-realtor",
   "metadata": {
    "papermill": {
     "duration": 0.015814,
     "end_time": "2021-06-17T00:10:57.856264",
     "exception": false,
     "start_time": "2021-06-17T00:10:57.840450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Create a Training Job with Profiling Enabled<a class=\"anchor\" id=\"option-1\"></a>\n",
    "\n",
    "You will use the standard [SageMaker Estimator API for Tensorflow](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to create training jobs. To enable profiling, create a `ProfilerConfig` object and pass it to the `profiler_config` parameter of the `TensorFlow` estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-newport",
   "metadata": {
    "papermill": {
     "duration": 0.015586,
     "end_time": "2021-06-17T00:10:57.887622",
     "exception": false,
     "start_time": "2021-06-17T00:10:57.872036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define hyperparameters\n",
    "\n",
    "Define hyperparameters such as number of epochs, batch size, and data augmentation. You can increase batch size to increases system utilization, but it may result in CPU bottlneck problems. Data preprocessing of a large batch size with augmentation requires a heavy computation. You can disable data_augmentation to see the impact on the system utilization. \n",
    "\n",
    "For demonstration purpose, the following hyperparameters are prepared to increase CPU usage, leading to GPU starvation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ethical-palestine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T00:10:57.923086Z",
     "iopub.status.busy": "2021-06-17T00:10:57.922445Z",
     "iopub.status.idle": "2021-06-17T00:10:57.924163Z",
     "shell.execute_reply": "2021-06-17T00:10:57.924539Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2021-06-17T00:10:57.924668",
     "exception": false,
     "start_time": "2021-06-17T00:10:57.903365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epoch\": 1, \"batch_size\": 64, \"data_augmentation\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-palestinian",
   "metadata": {
    "papermill": {
     "duration": 0.027248,
     "end_time": "2021-06-17T00:10:57.967865",
     "exception": false,
     "start_time": "2021-06-17T00:10:57.940617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configure rules\n",
    "We specify the following rules:\n",
    "- loss_not_decreasing: checks if loss is decreasing and triggers if the loss has not decreased by a certain persentage in the last few iterations\n",
    "- LowGPUUtilization: checks if GPU is under-utilizated \n",
    "- ProfilerReport: runs the entire set of performance rules and create a final output report with further insights and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-strap",
   "metadata": {
    "execution": {},
    "papermill": {
     "duration": 1.019187,
     "end_time": "2021-06-17T00:10:59.011804",
     "exception": false,
     "start_time": "2021-06-17T00:10:57.992617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-trigger",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Specify a profiler configuration\n",
    "The following configuration will capture system metrics at 500 milliseconds. The system metrics include utilization per CPU, GPU, memory utilization per CPU, GPU as well I/O and network.\n",
    "\n",
    "Debugger will capture detailed profiling information from step 5 to step 15. This information includes Horovod metrics, dataloading, preprocessing, operators running on CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-journey",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(\n",
    "        local_path=\"/opt/ml/output/profiler/\", start_step=5, num_steps=10\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-athletics",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get the image URI\n",
    "The image that we will is dependent on the region that you are running this notebook in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-procedure",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/tensorflow-training:2.3.1-gpu-py37-cu110-ubuntu18.04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-terrain",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define estimator\n",
    "\n",
    "To enable profiling, you need to pass the Debugger profiling configuration (`profiler_config`), a list of Debugger rules (`rules`), and the image URI (`image_uri`) to the estimator. Debugger enables monitoring and profiling while the SageMaker estimator requests a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-dance",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri=image_uri,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.8xlarge\",\n",
    "    entry_point=\"train_tf.py\",\n",
    "    source_dir=\"entry_point\",\n",
    "    profiler_config=profiler_config,\n",
    "    hyperparameters=hyperparameters,\n",
    "    rules=rules,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-toilet",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-winter",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.  Analyze Profiling Data\n",
    "\n",
    "Copy outputs of the following cell (`training_job_name` and `region`) to run the analysis notebooks `profiling_generic_dashboard.ipynb`, `analyze_performance_bottlenecks.ipynb`, and `profiling_interactive_analysis.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-leeds",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-wholesale",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "While the training is still in progress you can visualize the performance data in SageMaker Studio or in the notebook.\n",
    "Debugger provides utilities to plot system metrics in form of timeline charts or heatmaps. Checkout out the notebook \n",
    "[profiling_interactive_analysis.ipynb](analysis_tools/profiling_interactive_analysis.ipynb) for more details. In the following code cell we plot the total CPU and GPU utilization as timeseries charts. To visualize other metrics such as I/O, memory, network you simply need to extend the list passed to `select_dimension` and `select_events`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-cookbook",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-slope",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-florence",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Download Debugger Profiling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-classic",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The profiling report rule will create an html report `profiler-report.html` with a summary of builtin rules and recommenades of next steps. You can find this report in your S3 bucket.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-importance",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report in {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-headquarters",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For more information about how to download and open the Debugger profiling report, see [SageMaker Debugger Profiling Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html) in the SageMaker developer guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-consensus",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.040143,
   "end_time": "2021-06-17T00:10:59.384885",
   "environment_variables": {},
   "exception": null,
   "input_path": "tf-resnet-profiling-single-gpu-single-node.ipynb",
   "output_path": "/opt/ml/processing/output/tf-resnet-profiling-single-gpu-single-node-2021-06-17-00-06-43.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-17T00:10:51.344742",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
