{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2ac1559-3729-4cf3-acee-d4bb15c6f53d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amazon SageMaker Feature Store: Feature Processor Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd7d612",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c339cb18",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to get started with Feature Processor using SageMaker python SDK, create feature groups, perform batch transformation and ingest processed input data to feature groups.\n",
    "\n",
    "We first demonstrate how to use `@feature-processor` decorator to run the job locally and then show how to use `@remote` decorator to execute large batch transform and ingestion on SageMaker training job remotely. Besides, the SDK provides APIs to create scheduled pipelines based on transformation code.\n",
    "\n",
    "If you would like to learn more about Feature Processor, see documentation [Feature Processing](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-feature-processing.html) for more info and examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8b4ba90-e512-46bf-bfa9-541213021e86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup For Notebook\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e45c4dd7",
   "metadata": {},
   "source": [
    "### Setup Runtime Environment\n",
    "\n",
    "First we create a new kernel to execute this notebook.\n",
    "1. Launch a new terminal in the current image (the '$_' icon at the top of this notebook).\n",
    "2. Execute the commands: \n",
    "```\n",
    "conda create --name feature-processing-py-3.9 python=3.9 -y\n",
    "conda activate feature-processing-py-3.9\n",
    "conda install ipykernel -y\n",
    "conda install openjdk -y\n",
    "```\n",
    "3. Return to this notebook and select the kernel with Image: 'Data Science' and Kernel: 'feature-processing-py-3.9'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a65db47d",
   "metadata": {},
   "source": [
    "Alternatively If you run this notebook on SageMaker Studio, you can execute the following cell to install runtime dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd6006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk -y\n",
    "%pip install ipykernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f50b2d1f",
   "metadata": {},
   "source": [
    "To get the Feature Processor module, we need to reinstall the SageMaker python SDK along with extra dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351b428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install 'sagemaker[feature-processor]' --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32941c-2df3-4014-a65f-133d19e43d46",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Restart the kernel.\n",
    "\"\"\"\n",
    "from IPython.display import display_html\n",
    "\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0598d-2b49-415c-9d23-c5caa9303323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to save the cell code in a file and execute the cell as well. This will be used later to create Lineage artifact for the code. \n",
    "\"\"\"\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_execute(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = \"w\"\n",
    "    if len(argz) == 2 and argz[0] == \"-a\":\n",
    "        mode = \"a\"\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell)\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a303d7bc",
   "metadata": {},
   "source": [
    "### Create Feature Groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f57390a2",
   "metadata": {},
   "source": [
    "First we start by creating two feature groups. One feature group is used for storing raw car sales dataset which is located in `data/car_data.csv`. We create another feature group to store aggregated feature values after feature processing, for example average value of `mileage`, `price` and `msrp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c6571-3f2f-49b5-a49a-3654ab076241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up feature groups.\n",
    "\"\"\"\n",
    "\n",
    "import boto3, time\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker import get_execution_role\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_featurestore_runtime_client = boto3.client(\"sagemaker-featurestore-runtime\")\n",
    "\n",
    "aws_account_id = sagemaker_session.account_id()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = \"feature-store/feature-processing\"\n",
    "\n",
    "s3_data_prefix = f\"{s3_prefix}/data-sets\"\n",
    "s3_offline_store_prefix = f\"{s3_prefix}/offline-store\"\n",
    "offline_store_role = get_execution_role()\n",
    "\n",
    "\"\"\"\n",
    "Feature Group Definitions.\n",
    "\"\"\"\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum\n",
    "\n",
    "# S3 Data Source - Car Sales, and uploads to S3\n",
    "CAR_SALES_DATA_DIR = \"./data/car_data.csv\"\n",
    "RAW_CAR_SALES_S3_URI = S3Uploader.upload(CAR_SALES_DATA_DIR, f\"s3://{s3_bucket}/{s3_data_prefix}\")\n",
    "\n",
    "# Feature Group - Car Sales\n",
    "CAR_SALES_FG_NAME = \"car-data\"\n",
    "CAR_SALES_FG_ARN = f\"arn:aws:sagemaker:{region}:{aws_account_id}:feature-group/{CAR_SALES_FG_NAME}\"\n",
    "CAR_SALES_FG_ROLE_ARN = offline_store_role\n",
    "CAR_SALES_FG_OFFLINE_STORE_S3_URI = f\"s3://{s3_bucket}/{s3_offline_store_prefix}\"\n",
    "CAR_SALES_FG_FEATURE_DEFINITIONS = [\n",
    "    FeatureDefinition(feature_name=\"id\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"model\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"model_year\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"status\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"mileage\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"price\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"msrp\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"ingest_time\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "]\n",
    "CAR_SALES_FG_RECORD_IDENTIFIER_NAME = \"id\"\n",
    "CAR_SALES_FG_EVENT_TIME_FEATURE_NAME = \"ingest_time\"\n",
    "\n",
    "# Feature Group - Aggregated Car Sales\n",
    "AGG_CAR_SALES_FG_NAME = \"car-data-aggregated\"\n",
    "AGG_CAR_SALES_FG_ARN = (\n",
    "    f\"arn:aws:sagemaker:{region}:{aws_account_id}:feature-group/{AGG_CAR_SALES_FG_NAME}\"\n",
    ")\n",
    "AGG_CAR_SALES_FG_ROLE_ARN = offline_store_role\n",
    "AGG_CAR_SALES_FG_OFFLINE_STORE_S3_URI = f\"s3://{s3_bucket}/{s3_offline_store_prefix}\"\n",
    "AGG_CAR_SALES_FG_FEATURE_DEFINITIONS = [\n",
    "    FeatureDefinition(feature_name=\"model_year_status\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"avg_mileage\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"max_mileage\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"avg_price\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"max_price\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"avg_msrp\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"max_msrp\", feature_type=FeatureTypeEnum.STRING),\n",
    "    FeatureDefinition(feature_name=\"ingest_time\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "]\n",
    "AGG_CAR_SALES_FG_RECORD_IDENTIFIER_NAME = \"model_year_status\"\n",
    "AGG_CAR_SALES_FG_EVENT_TIME_FEATURE_NAME = \"ingest_time\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create the Feature Groups.\n",
    "\"\"\"\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "# Create Feature Group -  Car sale records.\n",
    "car_sales_fg = FeatureGroup(\n",
    "    name=CAR_SALES_FG_NAME,\n",
    "    feature_definitions=CAR_SALES_FG_FEATURE_DEFINITIONS,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "try:\n",
    "    create_car_sales_fg_resp = car_sales_fg.create(\n",
    "        record_identifier_name=CAR_SALES_FG_RECORD_IDENTIFIER_NAME,\n",
    "        event_time_feature_name=CAR_SALES_FG_EVENT_TIME_FEATURE_NAME,\n",
    "        s3_uri=CAR_SALES_FG_OFFLINE_STORE_S3_URI,\n",
    "        enable_online_store=True,\n",
    "        role_arn=CAR_SALES_FG_ROLE_ARN,\n",
    "    )\n",
    "    print(f\"Created feature group {create_car_sales_fg_resp}\")\n",
    "except Exception as e:\n",
    "    if \"ResourceInUse\" in str(e):\n",
    "        print(\"Feature Group already exists\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# Create Feature Group -  Aggregated car sales records.\n",
    "agg_car_sales_fg = FeatureGroup(\n",
    "    name=AGG_CAR_SALES_FG_NAME,\n",
    "    feature_definitions=AGG_CAR_SALES_FG_FEATURE_DEFINITIONS,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "try:\n",
    "    create_agg_car_sales_fg_resp = agg_car_sales_fg.create(\n",
    "        record_identifier_name=AGG_CAR_SALES_FG_RECORD_IDENTIFIER_NAME,\n",
    "        event_time_feature_name=AGG_CAR_SALES_FG_EVENT_TIME_FEATURE_NAME,\n",
    "        s3_uri=AGG_CAR_SALES_FG_OFFLINE_STORE_S3_URI,\n",
    "        enable_online_store=True,\n",
    "        role_arn=AGG_CAR_SALES_FG_ROLE_ARN,\n",
    "    )\n",
    "    print(f\"Created feature group {create_agg_car_sales_fg_resp}\")\n",
    "    print(\"Sleeping for a bit, to let Feature Groups get ready.\")\n",
    "    time.sleep(15)\n",
    "except Exception as e:\n",
    "    if \"ResourceInUse\" in str(e):\n",
    "        print(\"Feature Group already exists\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75d9c534-7b9d-40da-a99b-54aa8f927f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `@feature_processor`\n",
    "\n",
    "The following example demonstrates how to use the @feature_processor decorator to load data from Amazon S3 to a SageMaker Feature Group. \n",
    "\n",
    "A `@feature_processor` decorated function automatically loads data from the configured inputs, applies the feature processing code and ingests the transformed data to a feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029580ed-bb28-4ae7-a937-ecfe123cee8e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%write_and_execute car-data-ingestion.py\n",
    "\n",
    "from sagemaker.feature_store.feature_processor import (\n",
    "    feature_processor,\n",
    "    FeatureGroupDataSource,\n",
    "    CSVDataSource,\n",
    ")\n",
    "\n",
    "\n",
    "@feature_processor(\n",
    "    inputs=[CSVDataSource(RAW_CAR_SALES_S3_URI)],\n",
    "    output=CAR_SALES_FG_ARN,\n",
    "    target_stores=[\"OfflineStore\"],\n",
    ")\n",
    "def transform(raw_s3_data_as_df):\n",
    "    \"\"\"Load data from S3, perform basic feature engineering, store it in a Feature Group\"\"\"\n",
    "    from pyspark.sql.functions import regexp_replace\n",
    "    from pyspark.sql.functions import lit\n",
    "    import time\n",
    "\n",
    "    transformed_df = (\n",
    "        raw_s3_data_as_df.withColumn(\"Price\", regexp_replace(\"Price\", \"\\$\", \"\"))\n",
    "        # Rename Columns\n",
    "        .withColumnRenamed(\"Id\", \"id\")\n",
    "        .withColumnRenamed(\"Model\", \"model\")\n",
    "        .withColumnRenamed(\"Year\", \"model_year\")\n",
    "        .withColumnRenamed(\"Status\", \"status\")\n",
    "        .withColumnRenamed(\"Mileage\", \"mileage\")\n",
    "        .withColumnRenamed(\"Price\", \"price\")\n",
    "        .withColumnRenamed(\"MSRP\", \"msrp\")\n",
    "        # Add Event Time\n",
    "        .withColumn(\"ingest_time\", lit(int(time.time())))\n",
    "        # Remove punctuation and fluff; replace with NA\n",
    "        .withColumn(\"mileage\", regexp_replace(\"mileage\", \"(,)|(mi\\.)\", \"\"))\n",
    "        .withColumn(\"mileage\", regexp_replace(\"mileage\", \"Not available\", \"NA\"))\n",
    "        .withColumn(\"price\", regexp_replace(\"price\", \",\", \"\"))\n",
    "        .withColumn(\"msrp\", regexp_replace(\"msrp\", \"(^MSRP\\s\\\\$)|(,)\", \"\"))\n",
    "        .withColumn(\"msrp\", regexp_replace(\"msrp\", \"Not specified\", \"NA\"))\n",
    "        .withColumn(\"msrp\", regexp_replace(\"msrp\", \"\\\\$\\d+[a-zA-Z\\s]+\", \"NA\"))\n",
    "        .withColumn(\"model\", regexp_replace(\"model\", \"^\\d\\d\\d\\d\\s\", \"\"))\n",
    "    )\n",
    "\n",
    "    transformed_df.show()\n",
    "\n",
    "    return transformed_df\n",
    "\n",
    "\n",
    "# Execute the FeatureProcessor and show the results.\n",
    "transform()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ef02b7-7b38-4c00-99fb-4caed9773321",
   "metadata": {},
   "source": [
    "## `@feature_processor + @remote`\n",
    "\n",
    "The following example demonstrates how to run your feature processing code remotely.\n",
    "\n",
    "This is useful if you are working with large data sets that require hardware more powerful than locally available. You can decorate your code with the `@remote` decorator to run your local Python code as a single or multi-node distributed SageMaker training job. For more information on running your code as a SageMaker training job, see [Run your local code as a SageMaker training job](https://docs.aws.amazon.com/sagemaker/latest/dg/train-remote-decorator.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f50d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a requirements.txt and specify sagemaker as a remote job dependency.\n",
    "\"\"\"\n",
    "sagemaker_version = sagemaker.__version__\n",
    "with open(\"requirements.txt\", \"w\") as file:\n",
    "    file.write(f\"sagemaker=={sagemaker_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907584ef-88fe-4a9f-9c99-299362845935",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from sagemaker.remote_function import remote\n",
    "from sagemaker.feature_store.feature_processor import (\n",
    "    feature_processor,\n",
    "    CSVDataSource,\n",
    "    FeatureGroupDataSource,\n",
    ")\n",
    "from sagemaker.remote_function.spark_config import SparkConfig\n",
    "\n",
    "\n",
    "@remote(\n",
    "    spark_config=SparkConfig(),\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    dependencies=\"./requirements.txt\",\n",
    "    # keep_alive_period_in_seconds=900  # Requires an account limit increase to enable warm pooling.\n",
    ")\n",
    "@feature_processor(\n",
    "    inputs=[FeatureGroupDataSource(CAR_SALES_FG_ARN)],\n",
    "    output=AGG_CAR_SALES_FG_ARN,\n",
    "    target_stores=[\"OfflineStore\"],\n",
    ")\n",
    "def aggregate(source_feature_group, spark):\n",
    "    \"\"\"\n",
    "    Aggregate the data using a SQL query and UDF.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    from pyspark.sql.types import StringType\n",
    "    from pyspark.sql.functions import udf\n",
    "\n",
    "    @udf(returnType=StringType())\n",
    "    def custom_concat(*cols, delimeter: str = \"\"):\n",
    "        return delimeter.join(cols)\n",
    "\n",
    "    spark.udf.register(\"custom_concat\", custom_concat)\n",
    "\n",
    "    # Execute SQL string.\n",
    "    source_feature_group.createOrReplaceTempView(\"car_data\")\n",
    "    aggregated_car_data = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT \n",
    "            custom_concat(model, \"_\", model_year, \"_\", status) as model_year_status,\n",
    "            AVG(price) as avg_price,\n",
    "            MAX(price) as max_price,\n",
    "            AVG(mileage) as avg_mileage,\n",
    "            MAX(mileage) as max_mileage,\n",
    "            AVG(msrp) as avg_msrp,\n",
    "            MAX(msrp) as max_msrp,\n",
    "            \"{int(time.time())}\" as ingest_time\n",
    "        FROM car_data\n",
    "        GROUP BY model_year_status\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    aggregated_car_data.show()\n",
    "\n",
    "    return aggregated_car_data\n",
    "\n",
    "\n",
    "# Execute the aggregate\n",
    "aggregate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11e1a26a-35f1-4477-b71f-17c18c604ea7",
   "metadata": {},
   "source": [
    "## `to_pipeline and schedule`\n",
    "\n",
    "The following example demonstrates how to operationalize your feature processor by promoting it to a SageMaker Pipeline and configuring a schedule to execute it on a regular basis. This example uses the aggregate function defined above. Note, in order to create a pipeline, please make sure your method is annotated by both `@remote` and `@feature-processor` decorators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf53b3-c394-47eb-b0be-6e51466d7b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Upload the transformation_code.py saved earlier to S3, to track it in SageMaker ML Lineage.\n",
    "\"\"\"\n",
    "from sagemaker.s3 import S3Uploader, s3_path_join\n",
    "\n",
    "car_data_s3_uri = s3_path_join(\n",
    "    \"s3://\", sagemaker_session.default_bucket(), \"transformation_code\", \"car-data-ingestion.py\"\n",
    ")\n",
    "\n",
    "S3Uploader.upload(local_path=\"car-data-ingestion.py\", desired_s3_uri=car_data_s3_uri)\n",
    "\n",
    "print(car_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3934b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Annotate the transform method with @remote decorator so that we create Feature Processor Pipeline for it.\n",
    "\"\"\"\n",
    "transform = remote(\n",
    "    transform,\n",
    "    spark_config=SparkConfig(),\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    dependencies=\"./requirements.txt\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83ef5ce7",
   "metadata": {},
   "source": [
    "In the following example, we will create and schedule the pipeline using `to_pipeline` and `schedule` method. If you want to test the job before scheduling, you can use `execute` to start only one execution.\n",
    "\n",
    "The SDK also provides two extra methods `describe` and `list_pipelines` for you to get insights about the pipeline info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8cc26-259e-4fa9-accf-ba1b72914fad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker.feature_store.feature_processor as fp\n",
    "from sagemaker.feature_store.feature_processor import TransformationCode\n",
    "\n",
    "\"\"\"\n",
    "Create a Feature Processor Pipeline and start one execution.\n",
    "\"\"\"\n",
    "car_data_pipeline_name = f\"{CAR_SALES_FG_NAME}-ingestion-pipeline\"\n",
    "car_data_pipeline_arn = fp.to_pipeline(\n",
    "    pipeline_name=car_data_pipeline_name,\n",
    "    step=transform,\n",
    "    transformation_code=TransformationCode(s3_uri=car_data_s3_uri),\n",
    ")\n",
    "print(f\"Created SageMaker Pipeline: {car_data_pipeline_arn}.\")\n",
    "\n",
    "car_data_pipeline_execution_arn = fp.execute(pipeline_name=car_data_pipeline_name)\n",
    "print(f\"Started an execution with execution arn: {car_data_pipeline_execution_arn}\")\n",
    "\n",
    "fp.describe(pipeline_name=car_data_pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca016a1-65bb-4b4b-953e-b9ca55756e61",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a Feature Processor Pipeline and start one execution.\n",
    "\"\"\"\n",
    "car_data_aggregated_pipeline_name = f\"{AGG_CAR_SALES_FG_NAME}-ingestion-pipeline\"\n",
    "car_data_aggregated_pipeline_arn = fp.to_pipeline(\n",
    "    pipeline_name=car_data_aggregated_pipeline_name, step=aggregate\n",
    ")\n",
    "print(f\"Created SageMaker Pipeline: {car_data_aggregated_pipeline_arn}.\")\n",
    "\n",
    "car_data_aggregated_pipeline_execution_arn = fp.execute(\n",
    "    pipeline_name=car_data_aggregated_pipeline_name\n",
    ")\n",
    "print(f\"Started an execution with execution arn: {car_data_aggregated_pipeline_execution_arn}\")\n",
    "\n",
    "\"\"\"\n",
    "Schedule the pipeline.\n",
    "\"\"\"\n",
    "fp.schedule(\n",
    "    pipeline_name=car_data_aggregated_pipeline_name,\n",
    "    schedule_expression=\"rate(24 hours)\",\n",
    "    state=\"ENABLED\",\n",
    ")\n",
    "print(f\"Created a schedule.\")\n",
    "\n",
    "fp.describe(pipeline_name=car_data_aggregated_pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2660dd0-31ff-4952-a4b3-66d9d1a5652a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Processor Pipelines in this account.\n",
    "\"\"\"\n",
    "fp.list_pipelines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2d9751-e288-42db-b5fa-081939be66aa",
   "metadata": {},
   "source": [
    "## Explorating feature processing pipelines and ML Lineage.\n",
    "\n",
    "You can track scheduled SageMaker Pipelines with SageMaker Lineage in Amazon SageMaker Studio. This includes tracking scheduled executions, visualizing lineage to trace features back to their data sources, and viewing shared feature processing code all in one environment. \n",
    "\n",
    "Find the feature groups that were created in this notebook and view the Pipeline Executions and Lineage tabs.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e9af135",
   "metadata": {},
   "source": [
    "## Clean up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the scheduled pipeline\n",
    "fp.schedule(\n",
    "    pipeline_name=car_data_aggregated_pipeline_name,\n",
    "    schedule_expression=\"rate(24 hours)\",\n",
    "    state=\"DISABLED\",\n",
    ")\n",
    "\n",
    "print(f\"Disabled the schedule.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec416be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete feature groups\n",
    "car_sales_fg.delete()\n",
    "agg_car_sales_fg.delete()\n",
    "\n",
    "print(f\"Feature groups are deleted.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c1ebc50",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/prepare_data|sm-feature_store_feature_processor|sm-feature_store_feature_processor.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.10.0 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.10.1-cpu-py39-ubuntu20.04-sagemaker-v1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
