{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PyTorch Models using Horovod with Open MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Horovod is a distributed deep learning training framework that is used to speed up deep learning workloads. This notebook will show you how to train your PyTorch models using Horovod with Open MPI. Using the Sagemaker Python SDK, we will:\n",
    "\n",
    "* Upload a data set to S3\n",
    "* Train a simple neural network with Horovod\n",
    "* Deploy a model to a SageMaker endpoint\n",
    "\n",
    "You can learn more about Horovod and MPI at the following links:\n",
    "\n",
    "* https://horovod.readthedocs.io/en/stable/pytorch.html\n",
    "* https://horovod.readthedocs.io/en/stable/mpirun.html \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this example, we'll use the MNIST data set. MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Data\n",
    "\n",
    "The MNIST data set is easily accessible through the `torchvision.datasets` package. Note that even though we've set `train=false`, the code downloads both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing the Data\n",
    "\n",
    "Let's preview what the input images look like. We can do this using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4)\n",
    "images, labels = next(iter(dataloader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "plt.imshow(grid.permute(1, 2, 0))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the Data\n",
    "\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n",
    "\n",
    "To upload our data to S3, we need to specify an S3 bucket and prefix. These should be within the same region as the Notebook Instance, training, and hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'pytorch-horovod-mpi-example'\n",
    "inputs = S3Uploader.upload('data', 's3://{}/{}/data'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In order to use Horovod with OpenMPI, we'll have to use a shell script as the training entry point. The shell script invoke our Python training script as part of an Open MPI command.\n",
    "\n",
    "Here's what the shell script looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpirun -np 8 \\\n",
      "    -bind-to none -map-by slot \\\n",
      "    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\\n",
      "    -mca pml ob1 -mca btl ^openib \\\n",
      "    python train.py"
     ]
    }
   ],
   "source": [
    "!cat src/train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the actual training script, here's what we're using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\"\"\"Functions for training a simple neural network.\"\"\"\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmultiprocessing\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m transforms, datasets\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mhorovod\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mhvd\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Net\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m(args):\n",
      "    \u001b[33m\"\"\"Main program.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m torch.cuda.is_available():\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected CUDA-capable device but found none.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    init(args.seed)\n",
      "\n",
      "    transform = transforms.Compose([\n",
      "        transforms.ToTensor(),\n",
      "        transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))\n",
      "    ])\n",
      "    dataset = datasets.MNIST(\n",
      "        root=args.data_dir,\n",
      "        train=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        transform=transform)\n",
      "\n",
      "    model = Net().to(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    train(model,\n",
      "          dataset,\n",
      "          batch_size=args.batch_size,\n",
      "          num_epochs=args.epochs,\n",
      "          momentum=args.momentum,\n",
      "          learning_rate=args.lr)\n",
      "\n",
      "    save(model, args.model_dir)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minit\u001b[39;49;00m(seed):\n",
      "    \u001b[33m\"\"\"Initialize Horovod and PyTorch for distributed training.\"\"\"\u001b[39;49;00m\n",
      "    hvd.init()\n",
      "    torch.manual_seed(seed)\n",
      "    torch.cuda.set_device(hvd.local_rank())\n",
      "    torch.cuda.manual_seed(seed)\n",
      "    torch.set_num_threads(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model,\n",
      "          dataset,\n",
      "          batch_size=\u001b[34m4\u001b[39;49;00m,\n",
      "          num_epochs=\u001b[34m2\u001b[39;49;00m,\n",
      "          momentum=\u001b[34m0.9\u001b[39;49;00m,\n",
      "          learning_rate=\u001b[34m0.001\u001b[39;49;00m):\n",
      "    \u001b[33m\"\"\"Trains a model over a dataset.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Arguments:\u001b[39;49;00m\n",
      "\u001b[33m        model (nn.Module): A PyTorch model.\u001b[39;49;00m\n",
      "\u001b[33m        dataset (torch.utils.data.Dataset): The training dataset.\u001b[39;49;00m\n",
      "\u001b[33m        batch_size (int): The number of samples per batch to predict.\u001b[39;49;00m\n",
      "\u001b[33m        num_epochs (int): The number of times the dataset will be iterated over.\u001b[39;49;00m\n",
      "\u001b[33m        momentum (float): The SGD momentum factor.\u001b[39;49;00m\n",
      "\u001b[33m        learning_rate (float): The learning rate.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    sampler = torch.utils.data.distributed.DistributedSampler(\n",
      "        dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m forkserver_is_available():\n",
      "        multiprocessing_context = \u001b[33m\"\u001b[39;49;00m\u001b[33mforkserver\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        multiprocessing_context = \u001b[33m\"\u001b[39;49;00m\u001b[33mfork\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "    dataloader = torch.utils.data.DataLoader(\n",
      "        dataset,\n",
      "        batch_size=batch_size,\n",
      "        sampler=sampler,\n",
      "        num_workers=\u001b[34m1\u001b[39;49;00m,\n",
      "        pin_memory=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        multiprocessing_context=multiprocessing_context)\n",
      "\n",
      "    criterion = torch.nn.CrossEntropyLoss()\n",
      "\n",
      "    optimizer = torch.optim.SGD(model.parameters(),\n",
      "                                lr=learning_rate * hvd.local_size(),\n",
      "                                momentum=momentum)\n",
      "\n",
      "    hvd.broadcast_parameters(model.state_dict(), root_rank=\u001b[34m0\u001b[39;49;00m)\n",
      "    hvd.broadcast_optimizer_state(optimizer, root_rank=\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "    optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\n",
      "\n",
      "    model.train()\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(num_epochs):\n",
      "        sampler.set_epoch(epoch)\n",
      "        \u001b[34mfor\u001b[39;49;00m inputs, labels \u001b[35min\u001b[39;49;00m dataloader:\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            inputs = inputs.to(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            labels = labels.to(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "            outputs = model(inputs)\n",
      "            loss = criterion(outputs, labels)\n",
      "            loss.backward()\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave\u001b[39;49;00m(model, directory):\n",
      "    \u001b[33m\"\"\"Saves the parameters of a trained model to a file.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Arguments:\u001b[39;49;00m\n",
      "\u001b[33m        model (nn.Module): A PyTorch model.\u001b[39;49;00m\n",
      "\u001b[33m        directory (str): Path to the directory where the model will be saved.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    state_dict = model.cpu().state_dict()\n",
      "    file_path = os.path.join(directory, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    torch.save(state_dict, file_path)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mforkserver_is_available\u001b[39;49;00m():\n",
      "    \u001b[33m\"\"\"Returns true if forkserver can be used as a multiprocessing context.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mhasattr\u001b[39;49;00m(\n",
      "        mp, \u001b[33m'\u001b[39;49;00m\u001b[33m_supports_context\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    ) \u001b[35mand\u001b[39;49;00m mp._supports_context \u001b[35mand\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mforkserver\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m mp.get_all_start_methods()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m2\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of total epochs to run (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m4\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mBS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mbatch size (default: 4)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\n",
      "                        default=\u001b[34m0.001\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minitial learning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\n",
      "                        default=\u001b[34m0.9\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mmomentum (default: 0.9)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m42\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 42)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    args = parser.parse_args()\n",
      "    main(args)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how it's not any different than a training script you might write outside of SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IAM role arn is used to give training and hosting access to your data. See the Amazon SageMaker Roles for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyTorch` class allows us to run our training script as a job on SageMaker. We need to configure it with our training script, an IAM role, the number and type of training instances, and hyperparameters. In this case we are going to run our training job on a ml.p8.xlarge instance, which contains eight Tesla K80 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='train.sh',\n",
    "                    source_dir=\"src\",\n",
    "                    role=role,\n",
    "                    framework_version='1.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.8xlarge',\n",
    "                    hyperparameters={'epochs': 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-16 01:33:53 Starting - Starting the training job...\n",
      "2020-06-16 01:33:56 Starting - Launching requested ML instances.........\n",
      "2020-06-16 01:35:36 Starting - Preparing the instances for training.........\n",
      "2020-06-16 01:37:01 Downloading - Downloading input data...\n",
      "2020-06-16 01:37:30 Training - Downloading the training image......\n",
      "2020-06-16 01:38:44 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,354 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,430 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,437 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,731 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,732 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,732 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:45,732 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp274bpti9/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=11133 sha256=c6769afe30e9559ab8df473b7c6dab44d5fc746b9ccebedfc1e181e623e55792\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k0_dyaw4/wheels/a5/b6/37/12baf676a10b1acd1cfc4204a42de88d3478560238c2f866d5\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-06-16 01:38:48,232 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 6\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-06-16-01-33-53-398\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-425883134870/pytorch-training-2020-06-16-01-33-53-398/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.sh\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":6}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-425883134870/pytorch-training-2020-06-16-01-33-53-398/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":6},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-06-16-01-33-53-398\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-425883134870/pytorch-training-2020-06-16-01-33-53-398/source/sourcedir.tar.gz\",\"module_name\":\"train.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"6\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/bin/sh -c ./train.sh --epochs 6\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:78 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:84 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:81 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:79 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:83 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:84 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:84 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:78 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:84 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:78 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:81 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.705 algo-1:78 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:81 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:83 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:81 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:83 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:79 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:83 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:79 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:78 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:79 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:81 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:84 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:83 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.706 algo-1:79 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.710 algo-1:80 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.711 algo-1:80 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.711 algo-1:80 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.711 algo-1:80 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.711 algo-1:80 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.716 algo-1:85 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.716 algo-1:85 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.717 algo-1:85 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.717 algo-1:85 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.717 algo-1:85 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.721 algo-1:82 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.721 algo-1:82 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.721 algo-1:82 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.721 algo-1:82 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:38:55.722 algo-1:82 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34mNCCL version 2.4.8+cuda10.1\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.233.115<0>\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Channel 00 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Channel 01 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO Ring 00 : 7[7] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO Ring 00 : 6[6] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO Ring 00 : 5[5] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO Ring 00 : 3[3] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO Ring 00 : 4[4] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO Ring 01 : 7[7] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO Ring 01 : 6[6] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO Ring 01 : 5[5] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO Ring 01 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO Ring 01 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO Ring 01 : 3[3] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO Ring 01 : 4[4] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Ring 01 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Using 128 threads, Min Comp Cap 3, Trees disabled\u001b[0m\n",
      "\u001b[34malgo-1:84:366 [6] NCCL INFO comm 0x7fac44216220 rank 6 nranks 8 cudaDev 6 nvmlDev 6 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:83:358 [5] NCCL INFO comm 0x7f3a882161c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:79:359 [1] NCCL INFO comm 0x7fb4142178b0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:80:360 [2] NCCL INFO comm 0x7f4884217950 rank 2 nranks 8 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:81:361 [3] NCCL INFO comm 0x7fcc642161f0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:82:364 [4] NCCL INFO comm 0x7f86582161d0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:85:365 [7] NCCL INFO comm 0x7fdd38216110 rank 7 nranks 8 cudaDev 7 nvmlDev 7 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO comm 0x7f4a38229070 rank 0 nranks 8 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:78:369 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\n",
      "2020-06-16 01:39:55 Uploading - Uploading generated training model\u001b[34m[2020-06-16 01:39:50.720 algo-1:83 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.720 algo-1:81 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.720 algo-1:79 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.721 algo-1:84 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.721 algo-1:78 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.722 algo-1:80 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.722 algo-1:82 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m[2020-06-16 01:39:50.722 algo-1:85 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-06-16 01:39:52,262 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-16 01:40:02 Completed - Training job completed\n",
      "Training seconds: 181\n",
      "Billable seconds: 181\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we need to use the `PyTorch` estimator object to create a `PyTorchModel` object and set a different `entry_point`, otherwise, the training script `train.py` will be used for inference. (Note that the new `entry_point` must be under the same `source_dir` as `train.py`). Then we use the `PyTorchModel` object to deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "An implementation of `model_fn` is required for inference script. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-training-toolkit).\n",
    "\n",
    "Here's the inference script we're using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. Here we will deploy the model to a single ml.c5.xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorchModel object with a different entry_point\n",
    "model = estimator.create_model(entry_point=\"inference.py\", source_dir=\"src\")\n",
    "# Deploy the model to a ml.c5.xlarge instance\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this predictor to classify hand-written digits. We'll try to predict the images we displayed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "outputs = predictor.predict(images)\n",
    "predictions = np.argmax(outputs, axis=1)\n",
    "\n",
    "print('Predictions:', ' '.join('%4s' % predictions[i] for i in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, our model correctly classifies the digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
