{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774a659",
   "metadata": {},
   "source": [
    "Here we will show you how to use stable-diffusion-webui to generate image with Lora and ControlNet support. The stable-diffusion-webui will be hosted at Amazon SageMaker asynchronous endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016ec68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "region_name = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246b642",
   "metadata": {},
   "source": [
    "Logout from AWS public ECR to avoid the authentication token is expired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker logout public.ecr.aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a615bee",
   "metadata": {},
   "source": [
    "Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788db8d-3b69-4807-b83e-eaff32195190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./build_and_push.sh $region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21e8a1-86c4-4f83-98a4-cdb5204aa9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = \"s3://{0}/stable-diffusion-webui/data/model.tar.gz\".format(bucket)\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm dummy\n",
    "!aws s3 cp model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d24f73-e016-4b16-b5b2-cefb51e356a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = None\n",
    "image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-inference-api:latest\".format(\n",
    "    account_id, region_name\n",
    ")\n",
    "base_name = sagemaker.utils.base_name_from_image(image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376be72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "huggingface_models = [\n",
    "    {\n",
    "        \"repo_id\": \"stabilityai/stable-diffusion-2-1\",\n",
    "        \"filename\": \"v2-1_768-ema-pruned.ckpt\",\n",
    "        \"name\": \"Stable-diffusion\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"runwayml/stable-diffusion-v1-5\",\n",
    "        \"filename\": \"v1-5-pruned.ckpt\",\n",
    "        \"name\": \"Stable-diffusion\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_canny.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_depth.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_normal.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_openpose.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_scribble.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"lllyasviel/ControlNet\",\n",
    "        \"filename\": \"models/control_sd15_seg.pth\",\n",
    "        \"name\": \"ControlNet\",\n",
    "    },\n",
    "    {\n",
    "        \"repo_id\": \"andite/anything-v4.0\",\n",
    "        \"filename\": \"anything-v4.5-pruned.safetensors\",\n",
    "        \"name\": \"Lora\",\n",
    "    },\n",
    "]\n",
    "\n",
    "http_models = [\n",
    "    {\n",
    "        \"uri\": \"https://civitai.com/api/download/models/7627\",\n",
    "        \"filename\": \"2bNierAutomataLora_v2b.safetensors\",\n",
    "        \"name\": \"Lora\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\",\n",
    "        \"filename\": \"v2-1_768-ema-pruned.yaml\",\n",
    "        \"name\": \"Stable-diffusion\",\n",
    "    },\n",
    "]\n",
    "\n",
    "model_environment = {\n",
    "    \"ckpt\": \"/tmp/models/Stable-diffusion/v1-5-pruned.ckpt\",\n",
    "    \"huggingface_models\": json.dumps(huggingface_models),\n",
    "    \"http_models\": json.dumps(http_models),\n",
    "    \"generated_images_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/generated\",\n",
    "    \"embeddings_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/embeddings\",\n",
    "    \"hypernetwork_s3uri\": f\"s3://{bucket}/stable-diffusion-webui/hypernetwork\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d421d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=model_environment,\n",
    "    predictor_cls=Predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4da136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g4dn.2xlarge\"\n",
    "instance_count = 1\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"stable-diffusion-webui\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3ab80",
   "metadata": {},
   "source": [
    "Here we use asynchronous inference since asynchronous inference is more suitable for workloads with large payload sizes and long inference processing times. Asynchronous inference also works for stable-diffusion-webui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb508a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=instance_count,\n",
    "    volume_size_in_gb=225,\n",
    "    container_startup_health_check_timeout=1800,\n",
    "    async_inference_config=async_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bdd67",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39c9a4-7f96-42f1-8bec-cc02bc1b51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54519ea",
   "metadata": {},
   "source": [
    "LoRA (Low-Rank Adaptation of Large Language Models) models have become the standard to extend the Stable Diffusion models. Let's use Lora model to generate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d00e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"model\": \"v1-5-pruned.ckpt\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"enable_hr\": False,\n",
    "        \"denoising_strength\": 0,\n",
    "        \"firstphase_width\": 0,\n",
    "        \"firstphase_height\": 0,\n",
    "        \"hr_scale\": 2,\n",
    "        \"hr_upscaler\": \"\",\n",
    "        \"hr_second_pass_steps\": 0,\n",
    "        \"hr_resize_x\": 0,\n",
    "        \"hr_resize_y\": 0,\n",
    "        \"prompt\": \"yorha no. 2 type b, 1girl, bangs, black blindfold, black dress, black gloves, black hairband, blindfold, blindfold removed, breasts, cleavage cutout, clothing cutout, commentary request, dress, gloves, hairband, half-closed eyes, hand up, highres, io (sinking=carousel), juliet sleeves, long sleeves, looking at viewer, medium breasts, mole, mole under mouth, nier (series), nier automata, no blindfold, parted lips, puffy sleeves, short hair, solo, thighhighs, turtleneck, upper body, white hair, bokeh <lora:2bNierAutomataLora_v2b:0.5>\",\n",
    "        \"styles\": [\"\"],\n",
    "        \"seed\": 2674865251,\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": \"\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"negative_prompt\": \"(worst quality, low quality:1.3)\",\n",
    "        \"eta\": 0,\n",
    "        \"s_churn\": 0,\n",
    "        \"s_tmax\": 0,\n",
    "        \"s_tmin\": 0,\n",
    "        \"s_noise\": 1,\n",
    "        \"override_settings\": {},\n",
    "        \"override_settings_restore_afterwards\": True,\n",
    "        \"script_args\": [],\n",
    "        \"sampler_index\": \"DPM++ SDE Karras\",\n",
    "        \"script_name\": \"\",\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789711d",
   "metadata": {},
   "source": [
    "Wait until the asynchronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0b78b-ecd4-4e3c-bae0-c32d2a2d3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5ee14-5c6d-442a-ac76-98663b799283",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea512f5b-da4f-47e5-8198-ecfd644d80b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    for image_uri in json.loads(body)[\"images\"]:\n",
    "        image_bucket, image_key = get_bucket_and_key(image_uri)\n",
    "        image_object = s3_resource.Object(image_bucket, image_key)\n",
    "        image = Image.open(io.BytesIO(image_object.get()[\"Body\"].read()))\n",
    "        image.show()\n",
    "        image.save(datetime.now().strftime(\"%Y%m%d%H%M%S.jpg\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d880cf",
   "metadata": {},
   "source": [
    "ControlNet is a neural network structure to control diffusion models by adding extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7675b7-cbb1-4343-9964-c9c6534aac38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    with io.BytesIO() as output_bytes:\n",
    "        image.save(output_bytes, format=\"JPEG\")\n",
    "        bytes_data = output_bytes.getvalue()\n",
    "\n",
    "    encoded_string = base64.b64encode(bytes_data)\n",
    "\n",
    "    base64_str = str(encoded_string, \"utf-8\")\n",
    "    mimetype = \"image/jpeg\"\n",
    "    image_encoded_in_base64 = (\n",
    "        \"data:\" + (mimetype if mimetype is not None else \"\") + \";base64,\" + base64_str\n",
    "    )\n",
    "    return image_encoded_in_base64\n",
    "\n",
    "\n",
    "def decode_base64_to_image(encoding):\n",
    "    if encoding.startswith(\"data:image/\"):\n",
    "        encoding = encoding.split(\";\")[1].split(\",\")[1]\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(encoding)))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171d989-446c-4c78-8e8c-67eb1673376d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"./images/inference/ControlNet/bal-source.png\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b58b8f-1fe3-4c41-9bf4-610e7aaf2292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"model\": \"v1-5-pruned.ckpt\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"enable_hr\": False,\n",
    "        \"denoising_strength\": 0,\n",
    "        \"firstphase_width\": 0,\n",
    "        \"firstphase_height\": 0,\n",
    "        \"hr_scale\": 2,\n",
    "        \"hr_upscaler\": \"\",\n",
    "        \"hr_second_pass_steps\": 0,\n",
    "        \"hr_resize_x\": 0,\n",
    "        \"hr_resize_y\": 0,\n",
    "        \"prompt\": \"ballon\",\n",
    "        \"styles\": [\"\"],\n",
    "        \"seed\": -1,\n",
    "        \"subseed\": -1,\n",
    "        \"subseed_strength\": 0,\n",
    "        \"seed_resize_from_h\": -1,\n",
    "        \"seed_resize_from_w\": -1,\n",
    "        \"sampler_name\": \"\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"restore_faces\": False,\n",
    "        \"tiling\": False,\n",
    "        \"do_not_save_samples\": False,\n",
    "        \"do_not_save_grid\": False,\n",
    "        \"negative_prompt\": \"\",\n",
    "        \"eta\": 0,\n",
    "        \"s_churn\": 0,\n",
    "        \"s_tmax\": 0,\n",
    "        \"s_tmin\": 0,\n",
    "        \"s_noise\": 1,\n",
    "        \"override_settings\": {},\n",
    "        \"override_settings_restore_afterwards\": True,\n",
    "        \"script_args\": [],\n",
    "        \"sampler_index\": \"DPM++ SDE Karras\",\n",
    "        \"script_name\": \"\",\n",
    "        \"send_images\": True,\n",
    "        \"save_images\": False,\n",
    "        \"alwayson_scripts\": {\n",
    "            \"controlnet\": {\n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"enabled\": True,\n",
    "                        \"module\": \"none\",\n",
    "                        \"model\": \"control_sd15_canny [fef5e48e]\",\n",
    "                        \"weight\": 1,\n",
    "                        \"image\": encode_image_to_base64(image),\n",
    "                        \"low_vram\": False,\n",
    "                        \"processor_res\": 64,\n",
    "                        \"threshold_a\": 64,\n",
    "                        \"threshold_b\": 64,\n",
    "                        \"guidance_start\": 0,\n",
    "                        \"guidance_end\": 1,\n",
    "                        \"guess_mode\": False,\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2775d8",
   "metadata": {},
   "source": [
    "Wait until the asynchronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484ba4e-8691-4c63-ab2f-c8580e5364dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38f8ad-b546-4cd2-8f24-86271032cd06",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d24432-044a-4059-a423-652390ff4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    for image_uri in json.loads(body)[\"images\"]:\n",
    "        image_bucket, image_key = get_bucket_and_key(image_uri)\n",
    "        image_object = s3_resource.Object(image_bucket, image_key)\n",
    "        image = Image.open(io.BytesIO(image_object.get()[\"Body\"].read()))\n",
    "        image.show()\n",
    "        image.save(datetime.now().strftime(\"%Y%m%d%H%M%S.jpg\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04df861",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de653c58",
   "metadata": {},
   "source": [
    "[Optional] Create auto-scaling group for SageMaker endpoint in case you want to scale it based on specific metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(\n",
    "    endpoint_name, min_capcity=1, max_capcity=2, target_value=5\n",
    "):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f\"Request-ScalingPolicy-{endpoint_name}\",\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600,  # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300,  # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c604463",
   "metadata": {},
   "source": [
    "Resource cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e913f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
