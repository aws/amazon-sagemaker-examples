{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting a pre-trained Object Detection model with Chainer\n",
    "\n",
    "Amazon SageMaker is a great place to train models, but even if you've trained your model outside of SageMaker, you can still take advantage of SageMaker hosting.\n",
    "\n",
    "In this notebook, we will demonstrate how to host a pre-trained Chainer model on Amazon SageMaker. We'll send images to a model that identifies objects in an image, and draws bounding boxes around those objects.\n",
    "\n",
    "For more information about the Chainer container, see the sagemaker-chainer-containers repository and the sagemaker-python-sdk repository:\n",
    "\n",
    "* https://github.com/aws/sagemaker-chainer-containers\n",
    "* https://github.com/aws/sagemaker-python-sdk\n",
    "\n",
    "For more on Chainer and ChainerCV, please visit the Chainer and ChainerCV repositories:\n",
    "\n",
    "* https://github.com/chainer/chainer\n",
    "* https://github.com/chainer/chainercv\n",
    "\n",
    "This notebook is adapted from the [SSD](https://github.com/chainer/chainercv/tree/master/examples/ssd) example in the ChainerCV repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# This role retrieves the SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Model Weights\n",
    "\n",
    "We download model weights from a model that has already been trained, create a compressed tarball from it, and upload it to S3. The Chainer container will download and load this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Download the model weights.\n",
    "try:\n",
    "    region = boto3.Session().region_name\n",
    "    bucket = 'sagemaker-sample-data-{}'.format(region)\n",
    "    s3 = boto3.resource('s3')\n",
    "    key = 'models/ssd_model.npz'\n",
    "    s3.Bucket(bucket).download_file(key, '/tmp/ssd_model.npz')\n",
    "\n",
    "# Tar and compress the model.\n",
    "    with tarfile.open('/tmp/model.tar.gz', \"w:gz\") as tar:\n",
    "         tar.add('/tmp/ssd_model.npz', arcname='ssd_model.npz')\n",
    "\n",
    "    # Upload the model for the Chainer container to pull it during hosting.\n",
    "    uploaded_model = sagemaker_session.upload_data(\n",
    "                         path='/tmp/model.tar.gz', \n",
    "                         key_prefix='notebook/chainercv_ssd')\n",
    "    print('model uploaded to %s', uploaded_model)\n",
    "finally:\n",
    "    os.remove('/tmp/ssd_model.npz')\n",
    "    os.remove('/tmp/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the Chainer script to run on Amazon SageMaker\n",
    "\n",
    "### Hosting and Inference\n",
    "\n",
    "We will run the `chainercv_ssd.py` script below on SageMaker. This script contains two functions which are used to load the model and predict with the model. The function hooks for hosting and inference recognized by the container are listed below:\n",
    "\n",
    "\n",
    "* **`model_fn(model_dir)` (always required for hosting)**: This function is invoked to load model artifacts from those written into `model_dir` during training.\n",
    "\n",
    "  In the script below, we load the model artifacts into an `SSD300` instance, passing in a path to the model weights and the number of labels:\n",
    "  \n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    # Loads the uploaded pretrained SSD model.\n",
    "    chainer.config.train = False\n",
    "    path = os.path.join(model_dir, 'ssd_model.npz')\n",
    "    model = SSD300(n_fg_class=len(voc_bbox_label_names), pretrained_model=path)\n",
    "    return model\n",
    "```\n",
    "\n",
    "\n",
    "* `input_fn(input_data, content_type)`: This function is invoked to deserialize prediction data when a prediction request is made. The return value is passed to predict_fn. `input_fn` accepts two arguments: `input_data`, which is the serialized input data in the body of the prediction request, and `content_type`, the MIME type of the data\n",
    "\n",
    "\n",
    "* `predict_fn(input_data, model)`: This function accepts the return value of `input_fn` (as `input_data`) and the return value of `model_fn`, `model`, and returns inferences obtained from the model.\n",
    "\n",
    "  In this case, our model returns bounding boxes, labels, and scores, so `predict_fn` returns a NumPy array containing the bounding box (represented as a Python list), label, and score:\n",
    "  \n",
    "```python\n",
    "def predict_fn(input_data, model):\n",
    "    with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "        bboxes, labels, scores = model.predict([input_data])\n",
    "        bbox, label, score = bboxes[0], labels[0], scores[0]\n",
    "        return np.array([bbox.tolist(), label, score])\n",
    "```\n",
    "  \n",
    "  \n",
    "* `output_fn(prediction, accept)`: This function is invoked to serialize the return value from `predict_fn`, passed in via `prediction`, back to the SageMaker client in response to prediction requests\n",
    "\n",
    "\n",
    "This script implements `model_fn`, and `predict_fn`, but relies on the default `input_fn` and `output_fn`. The script is reproduced in its entirety below.\n",
    "\n",
    "For more on implementing these functions, see the documentation at https://github.com/aws/sagemaker-python-sdk.\n",
    "\n",
    "For more on the functions provided by the Chainer container, see https://github.com/aws/sagemaker-chainer-containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize chainercv_ssd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting the Model\n",
    "\n",
    "We construct an instance of `ChainerModel`, passing in S3 URL to the uploaded model to `model_data` and the script to `entry_point`. We'll host on a single `ml.m4.xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.chainer.model import ChainerModel\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "\n",
    "model = ChainerModel(model_data=uploaded_model,\n",
    "                     role=role,\n",
    "                     entry_point='chainercv_ssd.py')\n",
    "\n",
    "endpoint_name = 'chainer-ssd-{}'.format(sagemaker_timestamp())\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.m4.xlarge',\n",
    "                         initial_instance_count=1,\n",
    "                         endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions with the Hosted Model\n",
    "\n",
    "Our pre-trained model is now hosted on SageMaker and loaded in the instance. We can use the `predictor` to obtain predictions from our hosted model.\n",
    "\n",
    "First, let's examine an image that we'd like to detect objects for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainercv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "image = chainercv.utils.read_image('images/dog.jpg', color=True)\n",
    "image = np.ascontiguousarray(image, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainercv.visualizations.vis_image import vis_image\n",
    "vis_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtain predictions. Our model can accept an image (as a NumPy array) and return labels corresponding to objects in the image, scores corresponding to the confidence of those labels, and bounding boxes around those objects.\n",
    "\n",
    "We pass in the image as a numpy array to `predictor.predict`, and `predict_fn` will be invoked with the arrays we send. We retrieve the bounding boxes, labels, and scores the model predicts given the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox, label, score = predictor.predict(image)\n",
    "print('bounding box: {}\\nlabel: {}\\nscore: {}'.format(bbox, label, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the bounding boxes predicted by the hosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainercv.visualizations import vis_bbox\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "import matplotlib.pyplot as plt\n",
    "vis_bbox(image, bbox, label, score, label_names=voc_bbox_label_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for other images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display_images(image_path):\n",
    "    image = chainercv.utils.read_image(image_path, color=True)\n",
    "    image = np.ascontiguousarray(image, dtype=np.uint8)\n",
    "\n",
    "    vis_image(image)\n",
    "    bbox, label, score = predictor.predict(image)\n",
    "    vis_bbox(image, bbox, label, score, label_names=voc_bbox_label_names)\n",
    "    plt.show()\n",
    "\n",
    "predict_and_display_images('images/dogs.jpg')\n",
    "predict_and_display_images('images/cats.jpg')\n",
    "predict_and_display_images('images/cows.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p36",
   "language": "python",
   "name": "conda_chainer_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.      amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
