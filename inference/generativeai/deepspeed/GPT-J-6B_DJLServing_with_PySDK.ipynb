{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc8544a",
   "metadata": {},
   "source": [
    "# Serve GPT-J-6B on SageMaker with DJL Serving using the SageMaker Python SDK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00723380",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44e266",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Background\n",
    "\n",
    "This notebook will illustrate how one can use [DJL Serving](https://sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html) to deploy text generation models like GPT-J-6B on SageMaker for real-time inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0932633",
   "metadata": {},
   "source": [
    "### Update and install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5764af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -U pip --quiet\n",
    "pip install -U sagemaker --quiet\n",
    "pip install -U boto3 --quiet\n",
    "pip install -U transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50f3d34",
   "metadata": {},
   "source": [
    "### Configure instance type, S3 bucket etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2748bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Replace with your own settings - we recommend the ml.g5.12xlarge instance for this notebook\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "session = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = session._region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c74eb",
   "metadata": {},
   "source": [
    "### Specifying the Model\n",
    "\n",
    "With DJL Serving on SageMaker, one can provide the model artifacts in 2 ways.\n",
    "1. A HuggingFace Hub model ID\n",
    "2. Model Artifacts uploaded to S3 saved in the HuggingFace pretrained format.\n",
    "\n",
    "For more details on the model artifact structure, please see the [DJL Serving SageMaker docs](https://sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html#model-artifacts).\n",
    "\n",
    "We highly recommend the S3 option. DJL Serving implements a fast downloading mechanism for models stored in S3, which can significantly reduce the endpoint startup time compared to using a HuggingFace Hub model ID. For production use-cases, we recommend storing model artifacts in S3. For experimentation and smaller models, using a HuggingFace Hub model ID is the easiest way to get started.\n",
    "\n",
    "We will demonstrate both options in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c41db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Using a HuggingFace Hub model ID\n",
    "\n",
    "The EleutherAI/gpt-j-6b model is available from HuggingFace [here](https://huggingface.co/EleutherAI/gpt-j-6b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"EleutherAI/gpt-j-6b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a81e49",
   "metadata": {},
   "source": [
    "#### Using a Pretrained Model stored in S3\n",
    "\n",
    "The following code demonstrates how to save a model and upload it to S3 so that it can be downloaded and served by SageMaker using DJL Serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed351307",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sagemaker.s3 import S3Uploader\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# model = AutoModel.from_pretrained(model_id)\n",
    "# model.save_pretrained(\"gpt-j-6B\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# tokenizer.save_pretrained(\"gpt-j-6B\")\n",
    "\n",
    "# bucket = session.default_bucket()      # bucket to house artifacts\n",
    "# s3_location = f\"s3://{bucket}/djl-serving/gpt-j-6B\"\n",
    "# S3Uploader.upload(\"gpt-j-6B\", s3_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39747c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For demo purposes, we already have a copy of this model available in S3 that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_location = f\"s3://sagemaker-examples-files-prod-{region}/models/gpt-j-6b-model/\"\n",
    "print(f\"Pretrained model will be downloaded from ---- > {pretrained_model_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebc47f",
   "metadata": {},
   "source": [
    "### Deploy the model to SageMaker\n",
    "\n",
    "The following code is all that is needed to host this model on SageMaker. We will use the `pretrained_model_location` pointing to artifacts in S3 to reduce the container startup time, but feel free to experiment with using `model_id` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.djl_inference import DJLModel\n",
    "\n",
    "model = DJLModel(\n",
    "    pretrained_model_location,  # C an also use model_id here\n",
    "    role,\n",
    "    task=\"text-generation\",\n",
    "    number_of_partitions=2,\n",
    "    data_type=\"fp16\",\n",
    ")\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf6a90",
   "metadata": {},
   "source": [
    "### Run inference using the endpoint\n",
    "\n",
    "Once the endpoint is created and in-service, we can issue inference requests like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748174f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"inputs\": [\n",
    "        \"My favorite thing about Math is\",\n",
    "        \"My least favorite thing about Math is\",\n",
    "    ],\n",
    "    \"parameters\": {\n",
    "        \"max_length\": 200,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    "}\n",
    "outputs = predictor.predict(data)\n",
    "for output in outputs:\n",
    "    print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc91a2",
   "metadata": {},
   "source": [
    "### Clean up resources after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58865f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete SageMaker endpoint and model\n",
    "predictor.delete_endpoint()\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1fb33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extensions\n",
    "\n",
    "In this notebook we demonstrated how to deploy the GPT-J-6B model for text generation on SageMaker. DJL Serving supports a wide variety of models and NLP tasks. This notebook is a great starting point to experiment with other models and NLP tasks.\n",
    "\n",
    "For example, we can host the [flan-t5-xl](https://huggingface.co/google/flan-t5-xl) model for translation by changing `model_id=google/flan-t5-xl` and `task=\"text2text-generation` in DJLModel.\n",
    "\n",
    "For more information on using DJL Serving on SageMaker with the Python SDK, please see our [documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/djl/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a2bfe8",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n",
    "\n",
    "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/inference|generativeai|deepspeed|GPT-J-6B_DJLServing_with_PySDK.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
