{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Built-in Algorithms with SageMaker (Part 4/4)\n",
    "Download | Structure | Preprocess | **Train**\n",
    "```\n",
    "\n",
    "```\n",
    "Note: this notebook should be used with the conda_amazonei_mxnet_p36 kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "___\n",
    "For this guide we'll use the SageMaker Python SDK version 2.9.2. By default, your SageMaker Notebook may come with an earlier version. Other guides provided by Amazon may be set up to work with other versions of the Python SDK so you may wish to roll-back to 1.72.0 which is currently the default version on most notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "original_sagemaker_version = !conda list | grep -E \"sagemaker\\s\" | awk '{print $2}'\n",
    "!{sys.executable} -m pip install -q \"sagemaker==2.9.2\" \"opencv-python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages and check SageMaker version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import urllib\n",
    "import pickle\n",
    "import pathlib\n",
    "import tarfile\n",
    "import subprocess\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker updated  1.72.1 -> 2.9.2\n"
     ]
    }
   ],
   "source": [
    "print(f'sagemaker updated  {original_sagemaker_version[0]} -> {sagemaker.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load S3 Bucket Name & Category Labels\n",
    "The `category_labels` file was generated from the first notebook in this series `01_download_data.ipynb`. You will need to run that notebook before running the code here. \n",
    "\n",
    "An S3 bucket for this guide was created in Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Name:  sagemaker-prebuilt-ic-2a789e07-853b-4b89-b0eb-8ea33550520e\n"
     ]
    }
   ],
   "source": [
    "with open('pickled_data/prebuilt_bucket_name.pickle', 'rb') as f:\n",
    "    bucket_name = pickle.load(f)\n",
    "    print('Bucket Name: ', bucket_name)\n",
    "    \n",
    "with open('pickled_data/category_labels.pickle', 'rb') as f:\n",
    "    category_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Algorithm\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SageMaker Training and Validation Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket_name}/data/train',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "val_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket_name}/data/val',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': val_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Algorithm's Hyperparameters\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html\n",
    "* **num_layers** - The built-in image classification algrorithm is based off the ResNet architecture. There are many different versions of this architecture differing by how many layers they use. We'll use the smallest one for this guide to speed up training. If the algorithm's accuracy is hitting a plateau and you need better accuracy, increasing the number of layers may help.\n",
    "* **use_pretrained_model** - This will initialize the weights from a pre-trained model for transfer learning. Otherwise weights are initialized randomly.\n",
    "* **augmentation_type** - Allows you to add augmentations to your trainingset to help your model generalize better. For small datasets, augmentation can greatly imporve training.\n",
    "* **image_shape** -  The channel, height, width of all the images\n",
    "* **num_classes** - Number of classes in your dataset\n",
    "* **num_training_samples** - Total number of images in your training set (used to help calculate progres)\n",
    "* **mini_batch_size** - The batch size you would like to use during training. \n",
    "* **epochs** - An epoch refers to one cycle through the training set and having more epochs to train means having more oppotunities to improve accracy. Suitable values range from 5 to 25 epochs depending on your time and budget constraints. Ideally, the right number of epochs is right before your validation accuracy plateaus.\n",
    "* **learning_rate**: After each batch of training we update the model's weights to give us the best possible results for that batch. The learning rate controls by how much we should update the weights. Best practices dictate a value between 0.2 and .001, typically never going higher than 1. The higher the learning rate, the faster your training will converge to the optimal weights, but going too fast can lead you to overshoot the target. In this example, we're using the weights from a pre-trained model so we'd want to start with a lower learning rate because the weights have already been optimized and we don't want move too far away from them.\n",
    "* **precision_dtype** -  Whether you want to use a 32-bit float data type for the model's weights or 16-bit. 16-bit can be used if you're running into memory management issues. However, weights can grow or shrink rapidly so having 32-bit weights make your training more robust to these issues and is typically the default in most frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(category_labels)\n",
    "num_training_samples = len(set(pathlib.Path('data_structured/train').rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'num_layers': 18,\n",
    "    'use_pretrained_model': 1,\n",
    "    'augmentation_type': 'crop_color_transform',\n",
    "    'image_shape': \"3,224,224\",\n",
    "    'num_classes': num_classes,\n",
    "    'num_training_samples': num_training_samples,\n",
    "    'mini_batch_size': 64,\n",
    "    'epochs': 5,\n",
    "    'learning_rate': 0.001,\n",
    "    'precision_dtype': 'float32'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Type of Aglorithm and Resources to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = sagemaker.image_uris.retrieve('image-classification', sagemaker.Session().boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_config = {\n",
    "    'hyperparameters': hyperparameters,\n",
    "    'image_uri': training_image,\n",
    "    'role': sagemaker.get_execution_role(), \n",
    "    'instance_count': 1, \n",
    "    'instance_type': 'ml.p3.2xlarge',\n",
    "    'volume_size': 100,\n",
    "    'max_run': 360000,\n",
    "    'output_path': f's3://{bucket_name}/data/output'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = sagemaker.estimator.Estimator(**algo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-05 05:41:32 Starting - Starting the training job...\n",
      "2020-10-05 05:41:33 Starting - Launching requested ML instances......\n",
      "2020-10-05 05:42:33 Starting - Preparing the instances for training...\n",
      "2020-10-05 05:43:32 Downloading - Downloading input data...\n",
      "2020-10-05 05:43:43 Training - Downloading the training image......\n",
      "2020-10-05 05:45:03 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'precision_dtype': u'float32', u'epochs': u'5', u'augmentation_type': u'crop_color_transform', u'num_layers': u'18', u'image_shape': u'3,224,224', u'mini_batch_size': u'64', u'use_pretrained_model': u'1', u'num_classes': u'11', u'num_training_samples': u'2200'}\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.001', u'epochs': u'5', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'num_classes': u'11', u'precision_dtype': u'float32', u'mini_batch_size': u'64', u'augmentation_type': u'crop_color_transform', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'2200'}\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] multi_label: 0\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] num_layers: 18\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] epochs: 5\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] learning_rate: 0.001\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] num_training_samples: 2200\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] mini_batch_size: 64\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] num_classes: 11\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] augmentation_type: crop_color_transform\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] kv_store: device\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] --------------------\u001b[0m\n",
      "\u001b[34m[05:45:06] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.3437.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[05:45:06] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.3437.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:06 INFO 140481505945408] Setting number of threads: 7\u001b[0m\n",
      "\u001b[34m[05:45:12] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.3437.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:14 INFO 140481505945408] Epoch[0] Batch [20]#011Speed: 456.397 samples/sec#011accuracy=0.248512\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:16 INFO 140481505945408] Epoch[0] Train-accuracy=0.333640\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:16 INFO 140481505945408] Epoch[0] Time cost=3.987\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:16 INFO 140481505945408] Epoch[0] Validation-accuracy=0.453125\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:16 INFO 140481505945408] Storing the best model with validation accuracy: 0.453125\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:16 INFO 140481505945408] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\n",
      "2020-10-05 05:45:33 Uploading - Uploading generated training model\u001b[34m[10/05/2020 05:45:19 INFO 140481505945408] Epoch[1] Batch [20]#011Speed: 566.977 samples/sec#011accuracy=0.616071\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:20 INFO 140481505945408] Epoch[1] Train-accuracy=0.630055\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:20 INFO 140481505945408] Epoch[1] Time cost=3.598\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:20 INFO 140481505945408] Epoch[1] Validation-accuracy=0.587500\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:20 INFO 140481505945408] Storing the best model with validation accuracy: 0.587500\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:20 INFO 140481505945408] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:22 INFO 140481505945408] Epoch[2] Batch [20]#011Speed: 641.844 samples/sec#011accuracy=0.717262\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:24 INFO 140481505945408] Epoch[2] Train-accuracy=0.731618\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:24 INFO 140481505945408] Epoch[2] Time cost=3.194\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:24 INFO 140481505945408] Epoch[2] Validation-accuracy=0.640625\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:24 INFO 140481505945408] Storing the best model with validation accuracy: 0.640625\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:24 INFO 140481505945408] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:26 INFO 140481505945408] Epoch[3] Batch [20]#011Speed: 636.940 samples/sec#011accuracy=0.775298\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:27 INFO 140481505945408] Epoch[3] Train-accuracy=0.778493\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:27 INFO 140481505945408] Epoch[3] Time cost=3.193\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:28 INFO 140481505945408] Epoch[3] Validation-accuracy=0.668750\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:28 INFO 140481505945408] Storing the best model with validation accuracy: 0.668750\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:28 INFO 140481505945408] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:30 INFO 140481505945408] Epoch[4] Batch [20]#011Speed: 630.140 samples/sec#011accuracy=0.796875\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:31 INFO 140481505945408] Epoch[4] Train-accuracy=0.795496\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:31 INFO 140481505945408] Epoch[4] Time cost=3.200\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:31 INFO 140481505945408] Epoch[4] Validation-accuracy=0.687500\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:32 INFO 140481505945408] Storing the best model with validation accuracy: 0.687500\u001b[0m\n",
      "\u001b[34m[10/05/2020 05:45:32 INFO 140481505945408] Saved checkpoint to \"/opt/ml/model/image-classification-0005.params\"\u001b[0m\n",
      "\n",
      "2020-10-05 05:45:45 Completed - Training job completed\n",
      "Training seconds: 133\n",
      "Billable seconds: 133\n"
     ]
    }
   ],
   "source": [
    "algorithm.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Training Output\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[09/14/2020 05:37:38 INFO 139869866030912] Epoch[0] Batch [20]#011Speed: 111.811 samples/sec#011accuracy=0.452381\n",
    "[09/14/2020 05:37:54 INFO 139869866030912] Epoch[0] Batch [40]#011Speed: 131.393 samples/sec#011accuracy=0.570503\n",
    "[09/14/2020 05:38:10 INFO 139869866030912] Epoch[0] Batch [60]#011Speed: 139.540 samples/sec#011accuracy=0.617700\n",
    "[09/14/2020 05:38:27 INFO 139869866030912] Epoch[0] Batch [80]#011Speed: 144.003 samples/sec#011accuracy=0.644483\n",
    "[09/14/2020 05:38:43 INFO 139869866030912] Epoch[0] Batch [100]#011Speed: 146.600 samples/sec#011accuracy=0.664991\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training has begun:\n",
    "* Epoch[0]: One epoch corresponds to one training cycle through all the data. Stochastic optimizers like SGD and Adam improve accuracy by running multiple epochs. Random data augmentations is also applied with each new epoch allowing the training algorithm to learn on modified data.\n",
    "* Batch: The number of batches processed by the training algorithm. We specified one batch to be 64 images in the `mini_batch_size` hyperparameter. For algorithms like SGD, the model get a chance to update itself every batch.  \n",
    "* Speed: the number of images sent to the training algorithm per second. This information is important in determining how changes in your dataset affect the speed of training.\n",
    "* Accuracy: the training accuracy achieved at each interval (in this case, 20 batches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "[09/14/2020 05:38:58 INFO 139869866030912] Epoch[0] Train-accuracy=0.677083\n",
    "[09/14/2020 05:38:58 INFO 139869866030912] Epoch[0] Time cost=102.745\n",
    "[09/14/2020 05:39:02 INFO 139869866030912] Epoch[0] Validation-accuracy=0.729492\n",
    "[09/14/2020 05:39:02 INFO 139869866030912] Storing the best model with validation accuracy: 0.729492\n",
    "[09/14/2020 05:39:02 INFO 139869866030912] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first epoch of training has ended (for this example we only train for one epoch). The final training accuracy is reported as well as the accuracy on the validation set. Comparing these two number is important in determining if your model is overfit or underfit as well as the bais/variance trade-off. The saved model uses the learned weights from the epoch with the best validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "2020-09-14 05:39:03 Uploading - Uploading generated training model\n",
    "2020-09-14 05:39:15 Completed - Training job completed\n",
    "Training seconds: 235\n",
    "Billable seconds: 235\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model parameters are saved as a `.tar.gz` in S3 to the directory specified in the `output_path` of `algo_config`. Total billable seconds is also reported to help compute the cost of training since you are only charged for the time the EC2 instance is training on the data. Other costs such as S3 storage also apply, but are not included here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollback to default version of SDK\n",
    "Only do this if you're done with this guide and want to use the same kernel for other notebooks with an incompatible version of the SageMaker SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Original version: {original_sagemaker_version[0]}')\n",
    "# print(f'Current version:  {sagemaker.__version__}')\n",
    "# print('')\n",
    "# print(f'Rolling back to {original_sagemaker_version[0]}. Restart notebook kernel to use this version.')\n",
    "# print('')\n",
    "# s = f'sagemaker=={original_sagemaker_version[0]}'\n",
    "# !{sys.executable} -m pip install {s}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
