{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeef4885-a6e6-41af-b6e0-9efd5894e86c",
   "metadata": {},
   "source": [
    "# Build and deploy a serial inference application to SageMaker real-time endpoints\n",
    "\n",
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "- We build a fully custom ML serial inference application that encapsulates the following:\n",
    "  1. A [\"featurizer\"](./featurizer/) model (data pre-processing container) built using `SKLearn` column transformer\n",
    "     - The model transforms raw csv input data to features and returns the transformed data as output\n",
    "  1. A [predictor](./predictor/) `XGBoost` model trained on UCI Abalone dataset that accepts transformed features (generated by \"featurizer\" model) and returns predictions in JSON format.\n",
    "\n",
    "![ Abalone Predictor Pipeline ](./images/serial-inference-pipeline.png)\n",
    "\n",
    "## Building Custom inference containers\n",
    "\n",
    "1. To build, test and host \"featurizer\" container locally Refer to [`featurizer.ipynb`](./featurizer/featurizer.ipynb) Notebook\n",
    "1.  To build, test and host \"predictor\" container locally - Refer to [`predictor.ipynb`](./predictor/predictor.ipynb) Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd608469-ee3e-4086-9793-019e71057226",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisite\n",
    "\n",
    "**NOTE:** Ensure both [featurizer.ipynb](./featurizer/featurizer.ipynb) and [predictor.ipynb](./predictor/predictor.ipynb) are completed before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592c5e55-8ee4-4d9c-a830-5891ef29c0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awscli      : 1.29.25\n",
      "boto3       : 1.28.25\n",
      "sagemaker   : 2.177.0\n",
      "scikit-learn: 1.3.0\n",
      "tqdm        : 4.66.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -U awscli boto3 sagemaker watermark scikit-learn tqdm --quiet\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -p awscli,boto3,sagemaker,scikit-learn,tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4cacad-d445-4312-98b1-5b7ed992de65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/abalone.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from sagemaker import session, get_execution_role\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader, s3_path_join\n",
    "\n",
    "# account id for constructing ECR repo uri\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "\n",
    "sm_session = session.Session()\n",
    "region = sm_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "bucket = sm_session.default_bucket()\n",
    "\n",
    "prefix = \"sagemaker/abalone/models/byoc\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "abalone_s3uri = (\n",
    "    f\"s3://sagemaker-example-files-prod-{region}/datasets/tabular/uci_abalone/abalone.csv\"\n",
    ")\n",
    "\n",
    "pretrained_xgboost_model_s3uri = (\n",
    "    f\"s3://sagemaker-example-files-prod-{region}/models/xgb-abalone/xgboost-model\"\n",
    ")\n",
    "\n",
    "\n",
    "base_dir = Path(\"./data\")\n",
    "featurizer_dir = Path(\"./featurizer\").absolute()\n",
    "predictor_dir = Path(\"./predictor\").absolute()\n",
    "\n",
    "S3Downloader.download(s3_uri=abalone_s3uri, local_path=base_dir, sagemaker_session=sm_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8768bc6-4bb7-4403-b493-6178986e4b32",
   "metadata": {},
   "source": [
    "### Build \"featurizer\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8564f79d-20b1-4e56-8c3b-f2258cc50b54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/falcon-xgboost/featurizer\n"
     ]
    }
   ],
   "source": [
    "os.chdir(featurizer_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4b4b81-c22d-4947-a934-3292604be85c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting raw dataset to train and test datasets..\n",
      "Test dataset written to /home/ec2-user/SageMaker/falcon-xgboost/data/abalone_test.csv\n",
      "Saved preprocessor model to /home/ec2-user/SageMaker/falcon-xgboost/featurizer/models\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "featurizer_model_dir = featurizer_dir.joinpath(\"models\")\n",
    "\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "DATA_FILE = DATA_DIR.joinpath(\"abalone.csv\")\n",
    "\n",
    "if not DATA_FILE.exists():\n",
    "    raise ValueError(f\"{DATA_FILE} doesn't exist\")\n",
    "\n",
    "if not featurizer_model_dir.exists():\n",
    "    featurizer_model_dir.mkdir(parents=True)\n",
    "\n",
    "# As we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    DATA_FILE,\n",
    "    header=None,\n",
    "    names=feature_columns_names + [label_column],\n",
    "    dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    ")\n",
    "\n",
    "print(\"Splitting raw dataset to train and test datasets..\")\n",
    "\n",
    "(df_train_val, df_test) = train_test_split(df, random_state=42, test_size=0.1)\n",
    "\n",
    "\n",
    "df_test.to_csv(f\"{DATA_DIR.joinpath('abalone_test.csv')}\", index=False)\n",
    "\n",
    "print(f\"Test dataset written to {str(DATA_DIR.resolve())}/abalone_test.csv\")\n",
    "\n",
    "\n",
    "numeric_features = list(feature_columns_names)\n",
    "numeric_features.remove(\"sex\")\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_features = [\"sex\"]\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Call fit on ColumnTransformer to fit all transformers to X, y\n",
    "preprocessor = preprocess.fit(df_train_val)\n",
    "\n",
    "# Save the processor model to featurizer/models directory\n",
    "joblib.dump(preprocess, featurizer_model_dir.joinpath(\"preprocess.joblib\"))\n",
    "print(f\"Saved preprocessor model to {featurizer_model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fd088d-d633-4a69-907d-4c4a09dc7179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/falcon-xgboost/featurizer/models/model.tar.gz archive created successfully!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "os.chdir(featurizer_model_dir.absolute())\n",
    "\n",
    "featurizer_model_path = featurizer_model_dir.absolute().joinpath(\"model.tar.gz\")\n",
    "\n",
    "if featurizer_model_path.exists():\n",
    "    featurizer_model_path.unlink()\n",
    "\n",
    "tar_cmd = \"tar -czvf model.tar.gz preprocess.joblib ../code/\"\n",
    "result = subprocess.run(tar_cmd, shell=True, capture_output=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"{featurizer_model_path} archive created successfully!\")\n",
    "    os.chdir(featurizer_dir)\n",
    "else:\n",
    "    os.chdir(featurizer_dir)\n",
    "    print(\"An error occurred:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec80d6-674d-4a03-8d17-d00b911aefb4",
   "metadata": {},
   "source": [
    "### Build and push \"featurizer\" docker image to private ECR repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed485387-2e95-42ef-b711-b1658796a3ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  302.1kB\n",
      "Step 1/14 : FROM python:3.9-slim-buster\n",
      " ---> c84dbfe3b8de\n",
      "Step 2/14 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 76ae84aabc5c\n",
      "Step 3/14 : RUN apt-get update && apt-get install -y --no-install-recommends     build-essential     python3-dev     ca-certificates     wget     nginx     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 0ba37799969c\n",
      "Step 4/14 : RUN pip3 --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 871e413c7da8\n",
      "Step 5/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 1c7b74adc4ce\n",
      "Step 6/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 45506f932b56\n",
      "Step 7/14 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> c9740d7c49b1\n",
      "Step 8/14 : COPY requirements.txt /opt/program/requirements.txt\n",
      " ---> Using cache\n",
      " ---> fdcc84d4104f\n",
      "Step 9/14 : RUN pip3 install --no-cache-dir -r /opt/program/requirements.txt\n",
      " ---> Using cache\n",
      " ---> 46361382c9e6\n",
      "Step 10/14 : COPY code/ /opt/program/\n",
      " ---> Using cache\n",
      " ---> 692da4b4e80f\n",
      "Step 11/14 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 036955e19f34\n",
      "Step 12/14 : EXPOSE 8080\n",
      " ---> Using cache\n",
      " ---> 141dd0b8960c\n",
      "Step 13/14 : ENTRYPOINT [\"python\"]\n",
      " ---> Using cache\n",
      " ---> de0847f8852d\n",
      "Step 14/14 : CMD [ \"serve\" ]\n",
      " ---> Using cache\n",
      " ---> f47989a8a411\n",
      "Successfully built f47989a8a411\n",
      "Successfully tagged abalone/featurizer:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  302.1kB\n",
      "Step 1/14 : FROM python:3.9-slim-buster\n",
      " ---> c84dbfe3b8de\n",
      "Step 2/14 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 76ae84aabc5c\n",
      "Step 3/14 : RUN apt-get update && apt-get install -y --no-install-recommends     build-essential     python3-dev     ca-certificates     wget     nginx     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 0ba37799969c\n",
      "Step 4/14 : RUN pip3 --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 871e413c7da8\n",
      "Step 5/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 1c7b74adc4ce\n",
      "Step 6/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 45506f932b56\n",
      "Step 7/14 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> c9740d7c49b1\n",
      "Step 8/14 : COPY requirements.txt /opt/program/requirements.txt\n",
      " ---> Using cache\n",
      " ---> fdcc84d4104f\n",
      "Step 9/14 : RUN pip3 install --no-cache-dir -r /opt/program/requirements.txt\n",
      " ---> Using cache\n",
      " ---> 46361382c9e6\n",
      "Step 10/14 : COPY code/ /opt/program/\n",
      " ---> Using cache\n",
      " ---> 692da4b4e80f\n",
      "Step 11/14 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 036955e19f34\n",
      "Step 12/14 : EXPOSE 8080\n",
      " ---> Using cache\n",
      " ---> 141dd0b8960c\n",
      "Step 13/14 : ENTRYPOINT [\"python\"]\n",
      " ---> Using cache\n",
      " ---> de0847f8852d\n",
      "Step 14/14 : CMD [ \"serve\" ]\n",
      " ---> Using cache\n",
      " ---> f47989a8a411\n",
      "Successfully built f47989a8a411\n",
      "Successfully tagged abalone/featurizer:latest\n",
      "The push refers to repository [726793866085.dkr.ecr.us-west-2.amazonaws.com/abalone/featurizer]\n",
      "\n",
      "\u001b[1B2c01ab67: Preparing \n",
      "\u001b[1B102524ec: Preparing \n",
      "\u001b[1B6f9662ab: Preparing \n",
      "\u001b[1Ba9419eda: Preparing \n",
      "\u001b[1Bb8f9018e: Preparing \n",
      "\u001b[1Ba27560c1: Preparing \n",
      "\u001b[1B037e08b3: Preparing \n",
      "\u001b[1Beede8d6e: Preparing \n",
      "\u001b[1B55769c5e: Preparing \n",
      "\u001b[1B8a51359d: Layer already exists \u001b[5A\u001b[2Klatest: digest: sha256:32a1e3cc8cc81fb98bdcee9231f465afb7a0cd139235785b379aa876075360b0 size: 2423\n"
     ]
    }
   ],
   "source": [
    "featurizer_image_name = \"abalone/featurizer\"\n",
    "\n",
    "# build featurizer image\n",
    "!docker build -t $featurizer_image_name .\n",
    "\n",
    "# change file permissions\n",
    "!chmod +x build_n_push.sh\n",
    "\n",
    "# push image to ecr repo\n",
    "!./build_n_push.sh $featurizer_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423e538b-26ab-4918-9087-b6d3dfd327ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726793866085.dkr.ecr.us-west-2.amazonaws.com/abalone/featurizer\n",
      "featurizer model uploaded to to s3://sagemaker-us-west-2-726793866085/sagemaker/abalone/models/byoc/featurizer/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Full name of the ECR repository\n",
    "featurizer_ecr_repo_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{featurizer_image_name}\"\n",
    "\n",
    "print(featurizer_ecr_repo_uri)\n",
    "\n",
    "# Upload featurizer model to s3\n",
    "featurizer_s3_uri = s3_path_join(f\"s3://{bucket}/{prefix}\", \"featurizer\")\n",
    "\n",
    "if featurizer_model_path.exists():\n",
    "    featurizer_model_data = S3Uploader.upload(\n",
    "        local_path=str(featurizer_model_path),\n",
    "        desired_s3_uri=featurizer_s3_uri,\n",
    "        sagemaker_session=sm_session,\n",
    "    )\n",
    "else:\n",
    "    print(f\"{featurizer_model_path} not found!\")\n",
    "\n",
    "print(f\"featurizer model uploaded to to {featurizer_model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183dfc2-2812-4f8f-a298-f2bde597e0c4",
   "metadata": {},
   "source": [
    "### Build predictor model\n",
    "\n",
    "We downlaod and use the pre-trained `xgboost` model from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55562119-bf71-4a04-837a-1a4d65ee4bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/falcon-xgboost\n"
     ]
    }
   ],
   "source": [
    "# Step out of featurizer directory\n",
    "os.chdir(current_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "282f696b-9c90-4e37-88bb-c7e3eda31472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_model_dir = predictor_dir.joinpath(\"models\").absolute()\n",
    "if not predictor_model_dir.exists():\n",
    "    predictor_model_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba350d57-a807-44b2-bd64-65c2d9490c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/falcon-xgboost/predictor'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(predictor_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d172947-8006-4c4f-98bf-35f71f12e4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-example-files-prod-us-west-2/models/xgb-abalone/xgboost-model to models/xgboost-model\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $pretrained_xgboost_model_s3uri $predictor_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d44ee7-e56f-432a-b702-b3490946be05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tar archive created successfully!\n",
      "/home/ec2-user/SageMaker/falcon-xgboost/predictor/models/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "os.chdir(predictor_model_dir)\n",
    "predictor_model_path = predictor_model_dir.joinpath(\"model.tar.gz\")\n",
    "\n",
    "if predictor_model_path.exists():\n",
    "    predictor_model_path.unlink()\n",
    "\n",
    "tar_cmd = \"tar -czvf model.tar.gz xgboost-model ../code/\"\n",
    "result = subprocess.run(tar_cmd, shell=True, capture_output=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"Tar archive created successfully!\")\n",
    "    print(predictor_model_path)\n",
    "    os.chdir(predictor_dir)\n",
    "else:\n",
    "    os.chdir(predictor_model_dir)\n",
    "    print(\"An error occurred:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae225b1b-81e6-4ac8-b5a8-9161f5ec40a4",
   "metadata": {},
   "source": [
    "### Build and push \"predictor\" docker image to private ECR repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefad799-5bb5-4475-ba78-47ccbc75b7f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  532.5kB\n",
      "Step 1/19 : FROM ubuntu:18.04\n",
      " ---> f9a80a55f492\n",
      "Step 2/19 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> dbedbc2d1423\n",
      "Step 3/19 : RUN apt-get update && apt-get upgrade -y && apt-get clean\n",
      " ---> Using cache\n",
      " ---> 175c9a4b8b87\n",
      "Step 4/19 : RUN apt-get install -y curl python3.7 python3.7-dev python3.7-distutils\n",
      " ---> Using cache\n",
      " ---> 8cfddebe657f\n",
      "Step 5/19 : RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.7 1\n",
      " ---> Using cache\n",
      " ---> 89b55d971055\n",
      "Step 6/19 : RUN update-alternatives --set python /usr/bin/python3.7\n",
      " ---> Using cache\n",
      " ---> b223eb86412c\n",
      "Step 7/19 : RUN apt-get -y install --no-install-recommends     build-essential     ca-certificates     vim     nginx     && rm -rf /var/lib/apt/lists/*     && python --version     && curl -O https://bootstrap.pypa.io/get-pip.py     && python get-pip.py\n",
      " ---> Using cache\n",
      " ---> 43c3ab30203d\n",
      "Step 8/19 : RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1\n",
      " ---> Using cache\n",
      " ---> a7d7d7479f27\n",
      "Step 9/19 : RUN update-alternatives --install /usr/local/bin/pip pip /usr/local/bin/pip3 1\n",
      " ---> Using cache\n",
      " ---> 3e3a18c3030e\n",
      "Step 10/19 : RUN pip3 --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 43ae3b3b2564\n",
      "Step 11/19 : RUN pip3 --no-cache-dir install     flask     gunicorn     gevent     numpy     pandas     joblib     xgboost\n",
      " ---> Using cache\n",
      " ---> f109ee4c4994\n",
      "Step 12/19 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 5a788dc8ba97\n",
      "Step 13/19 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> e15b6f687329\n",
      "Step 14/19 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> d6406e34da7d\n",
      "Step 15/19 : COPY code /opt/program\n",
      " ---> Using cache\n",
      " ---> 00d5478befaa\n",
      "Step 16/19 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 2632cd843f5e\n",
      "Step 17/19 : EXPOSE 8080\n",
      " ---> Using cache\n",
      " ---> e0d75cb10baf\n",
      "Step 18/19 : ENTRYPOINT [\"python\"]\n",
      " ---> Using cache\n",
      " ---> 928a0d939176\n",
      "Step 19/19 : CMD [\"serve\"]\n",
      " ---> Using cache\n",
      " ---> adf29bce8d71\n",
      "Successfully built adf29bce8d71\n",
      "Successfully tagged abalone/predictor:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  532.5kB\n",
      "Step 1/19 : FROM ubuntu:18.04\n",
      " ---> f9a80a55f492\n",
      "Step 2/19 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> dbedbc2d1423\n",
      "Step 3/19 : RUN apt-get update && apt-get upgrade -y && apt-get clean\n",
      " ---> Using cache\n",
      " ---> 175c9a4b8b87\n",
      "Step 4/19 : RUN apt-get install -y curl python3.7 python3.7-dev python3.7-distutils\n",
      " ---> Using cache\n",
      " ---> 8cfddebe657f\n",
      "Step 5/19 : RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.7 1\n",
      " ---> Using cache\n",
      " ---> 89b55d971055\n",
      "Step 6/19 : RUN update-alternatives --set python /usr/bin/python3.7\n",
      " ---> Using cache\n",
      " ---> b223eb86412c\n",
      "Step 7/19 : RUN apt-get -y install --no-install-recommends     build-essential     ca-certificates     vim     nginx     && rm -rf /var/lib/apt/lists/*     && python --version     && curl -O https://bootstrap.pypa.io/get-pip.py     && python get-pip.py\n",
      " ---> Using cache\n",
      " ---> 43c3ab30203d\n",
      "Step 8/19 : RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1\n",
      " ---> Using cache\n",
      " ---> a7d7d7479f27\n",
      "Step 9/19 : RUN update-alternatives --install /usr/local/bin/pip pip /usr/local/bin/pip3 1\n",
      " ---> Using cache\n",
      " ---> 3e3a18c3030e\n",
      "Step 10/19 : RUN pip3 --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 43ae3b3b2564\n",
      "Step 11/19 : RUN pip3 --no-cache-dir install     flask     gunicorn     gevent     numpy     pandas     joblib     xgboost\n",
      " ---> Using cache\n",
      " ---> f109ee4c4994\n",
      "Step 12/19 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 5a788dc8ba97\n",
      "Step 13/19 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> e15b6f687329\n",
      "Step 14/19 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> d6406e34da7d\n",
      "Step 15/19 : COPY code /opt/program\n",
      " ---> Using cache\n",
      " ---> 00d5478befaa\n",
      "Step 16/19 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 2632cd843f5e\n",
      "Step 17/19 : EXPOSE 8080\n",
      " ---> Using cache\n",
      " ---> e0d75cb10baf\n",
      "Step 18/19 : ENTRYPOINT [\"python\"]\n",
      " ---> Using cache\n",
      " ---> 928a0d939176\n",
      "Step 19/19 : CMD [\"serve\"]\n",
      " ---> Using cache\n",
      " ---> adf29bce8d71\n",
      "Successfully built adf29bce8d71\n",
      "Successfully tagged abalone/predictor:latest\n",
      "The push refers to repository [726793866085.dkr.ecr.us-west-2.amazonaws.com/abalone/predictor]\n",
      "\n",
      "\u001b[1Bce4458df: Preparing \n",
      "\u001b[1B3f7e8a2c: Preparing \n",
      "\u001b[1Bbc30fc1d: Preparing \n",
      "\u001b[1Bce73dba9: Preparing \n",
      "\u001b[1B6ed861e6: Preparing \n",
      "\u001b[1B7f863d1b: Preparing \n",
      "\u001b[1B9181f870: Preparing \n",
      "\u001b[1Bdd7d83a3: Preparing \n",
      "\u001b[1Bfd581b6f: Preparing \n",
      "\u001b[1B7dbca955: Preparing \n",
      "\u001b[1B79621a42: Layer already exists \u001b[5A\u001b[2K\u001b[4A\u001b[2Klatest: digest: sha256:e78cbec4244e678a594b103be016effeccc57f97bf252beec28dc48b699b0e61 size: 2624\n"
     ]
    }
   ],
   "source": [
    "predictor_image_name = \"abalone/predictor\"\n",
    "\n",
    "!docker build -t $predictor_image_name .\n",
    "\n",
    "!chmod +x build_n_push.sh\n",
    "\n",
    "!./build_n_push.sh $predictor_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa1ecfc-aa0d-4558-8cbf-33a880475e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726793866085.dkr.ecr.us-west-2.amazonaws.com/abalone/predictor\n",
      "Uploading predictor model to s3://sagemaker-us-west-2-726793866085/sagemaker/abalone/models/byoc/predictor\n"
     ]
    }
   ],
   "source": [
    "# Full name of the ECR repository\n",
    "predictor_ecr_repo_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{predictor_image_name}\"\n",
    "\n",
    "print(predictor_ecr_repo_uri)\n",
    "\n",
    "# Upload featurizer model to s3\n",
    "predictor_s3_uri = s3_path_join(f\"s3://{bucket}/{prefix}\", \"predictor\")\n",
    "\n",
    "if predictor_model_path.exists():\n",
    "    print(f\"Uploading predictor model to {predictor_s3_uri}\")\n",
    "    predictor_model_data = S3Uploader.upload(\n",
    "        local_path=str(predictor_model_path),\n",
    "        desired_s3_uri=predictor_s3_uri,\n",
    "        sagemaker_session=sm_session,\n",
    "    )\n",
    "else:\n",
    "    print(f\"{predictor_model_path} not found!\")\n",
    "\n",
    "os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afca977-3f3d-4676-b339-ee19e1cd1025",
   "metadata": {},
   "source": [
    "### Create Models and Pipeline Model\n",
    "\n",
    "Now, we create two model objects to be combined later to a Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "616caf67-66f6-4333-aef5-b9e7f0740bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Featurizer model: AbaloneXGB-featurizer-d55dc-12Aug2023\n",
      "Creating Predictor model: AbaloneXGB-Predictor-d55dc-12Aug2023\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from sagemaker.model import Model\n",
    "\n",
    "suffix = f\"{str(uuid4())[:5]}-{datetime.now().strftime('%d%b%Y')}\"\n",
    "\n",
    "# Featurizer Model (SKLearn Model)\n",
    "image_name = \"abalone/featurizer\"\n",
    "sklearn_image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "featurizer_model_name = f\"AbaloneXGB-featurizer-{suffix}\"\n",
    "print(f\"Creating Featurizer model: {featurizer_model_name}\")\n",
    "sklearn_model = Model(\n",
    "    image_uri=featurizer_ecr_repo_uri,\n",
    "    name=featurizer_model_name,\n",
    "    model_data=featurizer_model_data,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Predictor Model (XGBoost Model)\n",
    "predictor_model_name = f\"AbaloneXGB-Predictor-{suffix}\"\n",
    "print(f\"Creating Predictor model: {predictor_model_name}\")\n",
    "xgboost_model = Model(\n",
    "    image_uri=predictor_ecr_repo_uri,\n",
    "    name=predictor_model_name,\n",
    "    model_data=predictor_model_data,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a43ba0-b6c7-448e-9723-407363b7f54e",
   "metadata": {},
   "source": [
    "### Create Pipeline Model\n",
    "\n",
    "1. Create a Pipeline model with `sklearn_model` and `xgboost_model` to act a serial inference pipeline.\n",
    "1. Deploy Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d113217c-e048-4f16-b645-504c82f310ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying pipeline model Abalone-pipeline-d55dc-12Aug2023...\n",
      "----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "pipeline_model_name = f\"Abalone-pipeline-{suffix}\"\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=pipeline_model_name,\n",
    "    role=role,\n",
    "    models=[sklearn_model, xgboost_model],\n",
    "    sagemaker_session=sm_session,\n",
    ")\n",
    "\n",
    "print(f\"Deploying pipeline model {pipeline_model_name}...\")\n",
    "predictor = pipeline_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e90fac-cae7-4a9c-a4ed-90a7a9fe4f09",
   "metadata": {},
   "source": [
    "### Test inference on Endpoint with Pipeline Model\n",
    "\n",
    "- Instantiate a `Predictor` class from `sagemaker.predictor` module\n",
    "- Use `CSVSerialzier` to serialize payload\n",
    "- and `JSONDeSerializer` for deserializing output (JSON) from the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae5d6992-4f0d-461b-bd66-0c12d99b6ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 9.0 | Predicted: 9.620622634887695\n",
      "True: 8.0 | Predicted: 7.7064619064331055\n",
      "True: 16.0 | Predicted: 10.882061004638672\n",
      "True: 9.0 | Predicted: 9.000561714172363\n",
      "True: 14.0 | Predicted: 9.393890380859375\n",
      "True: 11.0 | Predicted: 8.286240577697754\n",
      "True: 7.0 | Predicted: 7.742858409881592\n",
      "True: 6.0 | Predicted: 6.912567615509033\n",
      "True: 7.0 | Predicted: 5.272202014923096\n",
      "True: 10.0 | Predicted: 8.214031219482422\n",
      "True: 22.0 | Predicted: 9.155113220214844\n",
      "True: 7.0 | Predicted: 5.6337432861328125\n",
      "True: 15.0 | Predicted: 10.531659126281738\n",
      "True: 9.0 | Predicted: 5.540441989898682\n",
      "True: 8.0 | Predicted: 6.859899997711182\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Use the endpoint_name you specified when deploying the pipeline\n",
    "endpoint_name = pipeline_model_name\n",
    "\n",
    "# Let's use the test dataset in featurizer/data directory\n",
    "local_test_dataset = DATA_DIR.joinpath(\"abalone_test.csv\").resolve()\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sm_session,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "\n",
    "limit = 15\n",
    "i = 0\n",
    "\n",
    "with open(local_test_dataset, \"r\") as _f:\n",
    "    for row in _f:\n",
    "        # Skip headers row\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "        elif i <= limit:\n",
    "            row = row.rstrip(\"\\n\")\n",
    "            splits = row.split(\",\")\n",
    "            # Remove the target column (last column)\n",
    "            label = splits.pop(-1)\n",
    "            input_cols = \",\".join(s for s in splits)\n",
    "            prediction = None\n",
    "            try:\n",
    "                response = predictor.predict(input_cols)\n",
    "                print(f\"True value: {label} | Predicted: {response['result'][0]}\")\n",
    "                i += 1\n",
    "                sleep(0.15)\n",
    "            except Exception as e:\n",
    "                print(f\"Prediction error: {e}\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f4b74-6cb0-4020-8cdf-6c36b1d665b7",
   "metadata": {},
   "source": [
    "### (Optional) Verify Logs emitted by the endpoint in CloudWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eadc7226-f527-4e94-984e-37836d5cc8a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-12 07:38:17: Starting the inference server with 4 workers.\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [10] [INFO] Starting gunicorn 21.2.0\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [10] [INFO] Using worker: sync\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [16] [INFO] Booting worker with pid: 16\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [20] [INFO] Booting worker with pid: 20\n",
      "2023-08-12 07:38:17: [2023-08-12 07:38:11 +0000] [21] [INFO] Booting worker with pid: 21\n",
      "2023-08-12 07:38:17: Featurizer model loaded\n",
      "2023-08-12 07:38:21: 169.254.178.2 - - [12/Aug/2023:07:38:16 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:21: Featurizer model loaded\n",
      "2023-08-12 07:38:26: 169.254.178.2 - - [12/Aug/2023:07:38:21 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:26: Featurizer model loaded\n",
      "2023-08-12 07:38:31: 169.254.178.2 - - [12/Aug/2023:07:38:26 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:31: Featurizer model loaded\n",
      "2023-08-12 07:38:36: 169.254.178.2 - - [12/Aug/2023:07:38:31 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:36: Featurizer model loaded\n",
      "2023-08-12 07:38:41: 169.254.178.2 - - [12/Aug/2023:07:38:36 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:41: Featurizer model loaded\n",
      "2023-08-12 07:38:46: 169.254.178.2 - - [12/Aug/2023:07:38:41 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:46: Featurizer model loaded\n",
      "2023-08-12 07:38:51: 169.254.178.2 - - [12/Aug/2023:07:38:46 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:51: Featurizer model loaded\n",
      "2023-08-12 07:38:56: 169.254.178.2 - - [12/Aug/2023:07:38:51 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:38:56: Featurizer model loaded\n",
      "2023-08-12 07:39:01: 169.254.178.2 - - [12/Aug/2023:07:38:56 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:01: Featurizer model loaded\n",
      "2023-08-12 07:39:06: 169.254.178.2 - - [12/Aug/2023:07:39:01 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:06: Featurizer model loaded\n",
      "2023-08-12 07:39:11: 169.254.178.2 - - [12/Aug/2023:07:39:06 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:11: Featurizer model loaded\n",
      "2023-08-12 07:39:16: 169.254.178.2 - - [12/Aug/2023:07:39:11 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:16: Featurizer model loaded\n",
      "2023-08-12 07:39:21: 169.254.178.2 - - [12/Aug/2023:07:39:16 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:21: Featurizer model loaded\n",
      "2023-08-12 07:39:26: 169.254.178.2 - - [12/Aug/2023:07:39:21 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:26: Featurizer model loaded\n",
      "2023-08-12 07:39:31: 169.254.178.2 - - [12/Aug/2023:07:39:26 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:31: Featurizer model loaded\n",
      "2023-08-12 07:39:33: 169.254.178.2 - - [12/Aug/2023:07:39:31 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:33: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:33: Featurizer model loaded\n",
      "2023-08-12 07:39:33: Featurizer model loaded\n",
      "2023-08-12 07:39:34: 169.254.178.2 - - [12/Aug/2023:07:39:33 +0000] \"POST /invocations HTTP/1.1\" 200 158 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:34: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: 169.254.178.2 - - [12/Aug/2023:07:39:33 +0000] \"POST /invocations HTTP/1.1\" 200 163 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:34: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: 169.254.178.2 - - [12/Aug/2023:07:39:34 +0000] \"POST /invocations HTTP/1.1\" 200 159 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:34: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: 169.254.178.2 - - [12/Aug/2023:07:39:34 +0000] \"POST /invocations HTTP/1.1\" 200 156 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:34: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: 169.254.178.2 - - [12/Aug/2023:07:39:34 +0000] \"POST /invocations HTTP/1.1\" 200 166 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:34: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:34: Featurizer model loaded\n",
      "2023-08-12 07:39:35: 169.254.178.2 - - [12/Aug/2023:07:39:34 +0000] \"POST /invocations HTTP/1.1\" 200 166 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:35: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: 169.254.178.2 - - [12/Aug/2023:07:39:34 +0000] \"POST /invocations HTTP/1.1\" 200 166 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:35: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: 169.254.178.2 - - [12/Aug/2023:07:39:35 +0000] \"POST /invocations HTTP/1.1\" 200 168 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:35: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: 169.254.178.2 - - [12/Aug/2023:07:39:35 +0000] \"POST /invocations HTTP/1.1\" 200 160 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:35: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: 169.254.178.2 - - [12/Aug/2023:07:39:35 +0000] \"POST /invocations HTTP/1.1\" 200 160 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:35: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: 169.254.178.2 - - [12/Aug/2023:07:39:35 +0000] \"POST /invocations HTTP/1.1\" 200 162 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:35: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:35: Featurizer model loaded\n",
      "2023-08-12 07:39:36: 169.254.178.2 - - [12/Aug/2023:07:39:35 +0000] \"POST /invocations HTTP/1.1\" 200 162 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:36: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:36: 169.254.178.2 - - [12/Aug/2023:07:39:36 +0000] \"POST /invocations HTTP/1.1\" 200 170 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:36: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:36: 169.254.178.2 - - [12/Aug/2023:07:39:36 +0000] \"POST /invocations HTTP/1.1\" 200 161 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:36: Featurizer: received content type: text/csv\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:36: 169.254.178.2 - - [12/Aug/2023:07:39:36 +0000] \"POST /invocations HTTP/1.1\" 200 167 \"-\" \"AHC/2.0\"\n",
      "2023-08-12 07:39:36: Featurizer model loaded\n",
      "2023-08-12 07:39:41: 169.254.178.2 - - [12/Aug/2023:07:39:36 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"AHC/2.0\"\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "logs_client = boto3.client(\"logs\")\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(minutes=15)\n",
    "\n",
    "log_group_name = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "log_streams = logs_client.describe_log_streams(logGroupName=log_group_name)\n",
    "log_stream_name = log_streams[\"logStreams\"][0][\"logStreamName\"]\n",
    "\n",
    "# Retrieve the logs\n",
    "logs = logs_client.get_log_events(\n",
    "    logGroupName=log_group_name,\n",
    "    logStreamName=log_stream_name,\n",
    "    startTime=int(start_time.timestamp() * 1000),\n",
    "    endTime=int(end_time.timestamp() * 1000),\n",
    ")\n",
    "\n",
    "# Print the logs\n",
    "for event in logs[\"events\"]:\n",
    "    print(f\"{datetime.fromtimestamp(event['timestamp'] // 1000)}: {event['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3865d9-7743-4841-aa21-68fe011db86a",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaba487c-5606-4d4d-879f-f1c6512a768a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting model: Abalone-pipeline-d55dc-12Aug2023\n",
      "Deleting endpoint: Abalone-pipeline-d55dc-12Aug2023\n"
     ]
    }
   ],
   "source": [
    "# Delete model, endpoint\n",
    "try:\n",
    "    print(f\"Deleting model: {pipeline_model_name}\")\n",
    "    predictor.delete_model()\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting model: {pipeline_model_name}\\n{e}\")\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    print(f\"Deleting endpoint: {endpoint_name}\")\n",
    "    predictor.delete_endpoint()\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting EP: {endpoint_name}\\n{e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f37039",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/inference|structured|realtime|byoc|byoc-nginx-python|serial-inference-pipeline.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
