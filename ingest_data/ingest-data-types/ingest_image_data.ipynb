{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Image Data\n",
    "When working on computer vision tasks, you may be using a common library such as OpenCV, matplotlib, or pandas. Once we are moving to cloud and start your machine learning journey in Amazon Sagemaker, you will encounter new challenges of loading, reading, and writing files from S3 to a Sagemaker Notebook, and we will discuss several approaches in this section. Due to the size of the data we are dealing with, copying data into the instance is not recommended; you do not need to download data to the Sagemaker to train a model either. But if you want to take a look at a few samples from the image dataset and decide whether any transformation/pre-processing is needed, here are ways to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data: COCO (Common Objects in Context)\n",
    " **COCO** is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:\n",
    "\n",
    "* Object segmentation\n",
    "* Recognition in context\n",
    "* Superpixel stuff segmentation\n",
    "* 330K images (>200K labeled)\n",
    "* 1.5 million object instances\n",
    "* 80 object categories\n",
    "* 91 stuff categories\n",
    "* 5 captions per image\n",
    "* 250,000 people with keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU 'sagemaker>=2.15.0' 's3fs==0.4.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "import glob\n",
    "import tempfile\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix = \"image_coco/coco_val/val2017\"\n",
    "filename = \"000000086956.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download image data and write to S3\n",
    "**Note**: COCO data size is large so this could take around one minute or two. You can download partial files by using [COCOAPI](https://github.com/cocodataset/cocoapi). We recommend to go with a bigger storage instance when you start your notebook instance if you are experimenting with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to upload data to s3\n",
    "def write_to_s3(bucket, prefix, filename):\n",
    "    key = \"{}/{}\".format(prefix, filename)\n",
    "    return boto3.Session().resource(\"s3\").Bucket(bucket).upload_file(filename, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are in SageMaker Studio notebook\n",
    "#!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/zips/val2017.zip -O coco_val.zip\n",
    "# Uncompressing\n",
    "!unzip -qU -o coco_val.zip -d coco_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the files to the S3 bucket, we only upload 20 images to S3 bucket to showcase how ingestion works\n",
    "csv_files = glob.glob(\"coco_val/val2017/*.jpg\")\n",
    "for filename in csv_files[:20]:\n",
    "    write_to_s3(bucket, prefix, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Streaming data from S3 to the SageMaker instance-memory \n",
    "\n",
    "  **Use AWS compatible Python Packages with io Module** \n",
    " \n",
    "The easiest way to access your files in S3 without copying files into your instance storage is to use pre-built packages that already have implemented options to access data with a specified path string. Streaming means to read the object directly to memory instead of writing it to a file. As an example, the `matplotlib` library has a pre-built function `imread` that usually an URL or path to an image, but here we use S3 objects and BytesIO method to read the image. You can also go with `PIL` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "key = \"{}/{}\".format(prefix, filename)\n",
    "image_object = boto3.resource(\"s3\").Bucket(bucket).Object(key)\n",
    "image = mpimage.imread(io.BytesIO(image_object.get()[\"Body\"].read()), \"jpg\")\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open(image_object.get()[\"Body\"])\n",
    "plt.figure(0)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Using temporary files on the SageMaker instance\n",
    "Another way to work with your usual methods is to create temporary files on your SageMaker instance and feed them into the standard methods as a file path. Tempfiles provides automatic cleanup, meaning that creates temporary files that will be deleted as the file is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tempfile.NamedTemporaryFile()\n",
    "with open(tmp.name, \"wb\") as f:\n",
    "    image_object.download_fileobj(f)\n",
    "    f.seek(\n",
    "        0, 2\n",
    "    )  # the file will be downloaded in a lazy fashion, so add this to the file descriptor\n",
    "    img = plt.imread(tmp.name)\n",
    "    print(img.shape)\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Use AWS native methods\n",
    "#### s3fs \n",
    "[S3Fs](https://s3fs.readthedocs.io/en/latest/) is a Pythonic file interface to S3. It builds on top of botocore. The top-level class S3FileSystem holds connection information and allows typical file-system style operations like cp, mv, ls, du, glob, etc., as well as put/get of local files to/from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "data_s3fs_location = \"s3://{}/{}/\".format(bucket, prefix)\n",
    "# To List first file in your accessible bucket\n",
    "fs.ls(data_s3fs_location)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open it directly with s3fs\n",
    "data_s3fs_location = \"s3://{}/{}/{}\".format(bucket, prefix, filename)  # S3 URL\n",
    "with fs.open(data_s3fs_location) as f:\n",
    "    display(Image.open(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "Lin, Tsung-Yi, Maire, Michael, Belongie, Serge, Bourdev, Lubomir, Girshick, Ross, Hays, James, Perona, Pietro, Ramanan, Deva, Zitnick, C. Lawrence and Doll√°r, Piotr Microsoft COCO: Common Objects in Context. (2014). , cite arxiv:1405.0312Comment: 1) updated annotation pipeline description and figures; 2) added new section describing datasets splits; 3) updated author list ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
