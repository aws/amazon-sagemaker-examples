{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an TensorFlow model with a SageMaker Training Job and track it using SageMaker Experiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook shows how you can use the SageMaker SDK to track a Machine Learning experiment. \n",
    "\n",
    "We introduce two concepts in this notebook -\n",
    "\n",
    "* *Experiment:* An experiment is a collection of runs. When you initialize a run in your training loop, you include the name of the experiment that the run belongs to. Experiment names must be unique within your AWS account. \n",
    "* *Run:* A run consists of all the inputs, parameters, configurations, and results for one iteration of model training. Initialize an experiment run for tracking a training job with Run(). \n",
    "\n",
    "In this notebook we train a Keras model using the MNIST dataset on a remote SageMaker instance using a training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** To run this notebook, use the `Python 3 (Data Science) Image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update boto3 and sagemaker to ensure latest SDK version\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade boto3\n",
    "!{sys.executable} -m pip install --upgrade sagemaker\n",
    "!{sys.executable} -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.utils import unique_name_from_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "boto_sess = boto3.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "\n",
    "sm = boto_sess.client(\"sagemaker\")\n",
    "region = boto_sess.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the training script\n",
    "\n",
    "Here we use a SageMaker Training job to train the model on a remote instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./script/train.py\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(\"pip install -U sagemaker\")\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments import load_run\n",
    "\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.session.Session(region_name=os.environ[\"REGION\"])\n",
    "sagemaker_session = Session(boto_session=boto_session)\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.01)\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "class ExperimentCallback(keras.callbacks.Callback):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, run, model, x_test, y_test):\n",
    "        \"\"\"Save params in constructor\"\"\"\n",
    "        self.run = run\n",
    "        self.model = model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" \"\"\"\n",
    "        keys = list(logs.keys())\n",
    "        for key in keys:\n",
    "            self.run.log_metric(name=key, value=logs[key], step=epoch)\n",
    "            print(\"{} -> {}\".format(key, logs[key]))\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "    train_path = \"input_train.npy\"\n",
    "    test_path = \"input_test.npy\"\n",
    "    train_labels_path = \"input_train_labels.npy\"\n",
    "    test_labels_path = \"input_test_labels.npy\"\n",
    "\n",
    "    # Load the data and split it between train and test sets\n",
    "    s3.download_file(\n",
    "        \"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_train.npy\", train_path\n",
    "    )\n",
    "    s3.download_file(\n",
    "        \"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_test.npy\", test_path\n",
    "    )\n",
    "    s3.download_file(\n",
    "        \"sagemaker-sample-files\",\n",
    "        \"datasets/image/MNIST/numpy/input_train_labels.npy\",\n",
    "        train_labels_path,\n",
    "    )\n",
    "    s3.download_file(\n",
    "        \"sagemaker-sample-files\",\n",
    "        \"datasets/image/MNIST/numpy/input_test_labels.npy\",\n",
    "        test_labels_path,\n",
    "    )\n",
    "\n",
    "    x_train = np.load(train_path)\n",
    "    x_test = np.load(test_path)\n",
    "    y_train = np.load(train_labels_path)\n",
    "    y_test = np.load(test_labels_path)\n",
    "\n",
    "    # Reshape the arrays\n",
    "    x_train = np.reshape(x_train, (60000, 28, 28))\n",
    "    x_test = np.reshape(x_test, (10000, 28, 28))\n",
    "    y_train = np.reshape(y_train, (60000,))\n",
    "    y_test = np.reshape(y_test, (10000,))\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(x_train.shape[0], \"train samples\")\n",
    "    print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\" \"\"\"\n",
    "    args, _ = parse_args()\n",
    "    print(\"Args are : \", args)\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(args.dropout),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    ###\n",
    "    # `load_run` will use the run defined when calling the estimator\n",
    "    ###\n",
    "    with load_run(sagemaker_session=sagemaker_session) as run:\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[ExperimentCallback(run, model, x_test, y_test)],\n",
    "        )\n",
    "\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(\"Test loss:\", score[0])\n",
    "        print(\"Test accuracy:\", score[1])\n",
    "\n",
    "        run.log_metric(name=\"Final Test Loss\", value=score[0])\n",
    "        run.log_metric(name=\"Final Test Accuracy\", value=score[1])\n",
    "\n",
    "        model.save(\"/opt/ml/model\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment and launch a training job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.experiments.run import Run\n",
    "\n",
    "exp_name = \"tensorflow-script-mode-experiment\"\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "dropout = 0.1\n",
    "\n",
    "with Run(\n",
    "    experiment_name=exp_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    run.log_parameter(\"batch_size\", batch_size)\n",
    "    run.log_parameter(\"epochs\", epochs)\n",
    "    run.log_parameter(\"dropout\", dropout)\n",
    "\n",
    "    est = TensorFlow(\n",
    "        entry_point=\"./script/train.py\",\n",
    "        role=role,\n",
    "        model_dir=False,\n",
    "        hyperparameters={\"epochs\": epochs, \"batch_size\": batch_size, \"dropout\": dropout},\n",
    "        framework_version=\"2.8\",\n",
    "        py_version=\"py39\",\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        instance_count=1,\n",
    "        keep_alive_period_in_seconds=3600,\n",
    "        environment={\"REGION\": region},\n",
    "    )\n",
    "\n",
    "    est.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the trained model in the Model Registry\n",
    "\n",
    "This is an optional step users can take if they want to keep track of their models in a central model catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "\n",
    "model = TensorFlowModel(model_data=est.model_data, role=role, framework_version=\"2.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.register(\n",
    "    model_package_group_name=\"tensorflow-script-mode-model\",\n",
    "    content_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}