{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Edge Manager Example\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Demo Setup](#Demo-Setup)\n",
    "    1. [Launch EC2 Instance](#Launch-EC2-Instance)\n",
    "3. [Compile Model using SageMaker Neo](#Compile-Model-using-SageMaker-Neo)\n",
    "    1. [Load pretrained model](#Load-pretrained-model)\n",
    "6. [Deploy Model using Sagemaker Edge Manager](#Deploy-Model-using-Sagemaker-Edge-Manager)\n",
    "    1. [Package Model](#Package-Model)\n",
    "    2. [Create AWS IoT thing](#Create-AWS-IoT-thing)\n",
    "    3. [Create Device Fleet](#Create-Device-Fleet)\n",
    "    4. [Create and register client certificate with AWS IoT](#Create-and-register-client-certificate-with-AWS-IoT)\n",
    "7. [Inference on Edge](#Inference-on-Edge)\n",
    "    1. [Setup Sagemaker Edge Manager Agent](#Setup-Sagemaker-Edge-Manager-Agent) \n",
    "    2. [Load Model](#Load-Model)\n",
    "    3. [List Models](#List-Models)\n",
    "    4. [Run Predict](#Run-Predict)\n",
    "    5. [Capture Data](#Capture-Data)\n",
    "    6. [Unload Model](#Unload-Model)\n",
    "8. [Clean Up](#Clean-Up)\n",
    "9. [Appendix](#Appendix)\n",
    "    1. [(Optional)Install CloudWatch Agent](#(Optional)Install-CloudWatch-Agent )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "SageMaker Edge Manager is a service from Amazon SageMaker that lets you:\n",
    "\n",
    "+ prepares custom models for edge device hardware\n",
    "+ includes a runtime for running machine learning inference efficiently on edge devices\n",
    "+ enables the device to send samples of data from each model securely to SageMaker for relabeling and retraining.\n",
    "\n",
    "There are two main components to this service:\n",
    "+ SageMaker Edge Manager in the Cloud \n",
    "+ SageMaker Edge Agent on the Edge device\n",
    "\n",
    "This nootebook demonstrates the end-to-end workflow for getting a running Sagemaker Edge on the edge device. This will involve the following steps:\n",
    "\n",
    "+ Compile the model using SageMaker Neo\n",
    "+ Package the compiled model with Sagemaker Edge Manager\n",
    "+ Deploy with Sagemaker Edge Manager Agent\n",
    "+ Run inference with the model\n",
    "+ Capture model's input and output data to S3\n",
    "\n",
    "**Note**:\n",
    "Typically, the SageMaker Edge Agent is run on an Edge device. For the sake of this notebook, we will run the Agent on an EC2 instance. We show how to package the compiled model and then load it to the Agent on the Edge Device to make predictions with. Finally, we show how to capture model's input and output to S3 via the Agent.\n",
    "\n",
    "This notebook is intented only for notebook instances. When you run this notebook, choose the kernel: `conda_tensorflow_p36`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note**: There are pricing implications to the use of this notebook. Please refer to [Edge Manager](https://aws.amazon.com/sagemaker/edge-manager/pricing) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an AWS account role with SageMaker access. This role is used to give SageMaker access to S3, launch an EC2 instance and create components and deployments in Greengrass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::699391019698:role/Admin\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the above printed sagemaker role from [IAM console](https://console.aws.amazon.com/iam), find and attach the following policies to role:\n",
    "\n",
    "- AmazonEC2FullAccess \n",
    "- AmazonEC2RoleforSSM \n",
    "- AmazonSSMManagedInstanceCore \n",
    "- AmazonSSMFullAccess \n",
    "- AWSGreengrassFullAccess\n",
    "- AWSIoTFullAccess \n",
    "\n",
    "You can find more information about how to attach policies to role [here](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-attach-detach.html#add-policies-console).\n",
    "\n",
    "**If you try this example with a real device, only attach AWSIoTFullAccess to create certificates on AWS IoT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need an S3 bucket that would be used for storing the model artifacts generated after compilation and packaged artifacts generated after edge packaging job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket and folders for saving model artifacts.\n",
    "# Feel free to specify different bucket/folders here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "folder = \"DEMO-Sagemaker-Edge\"\n",
    "compilation_output_sub_folder = folder + \"/compilation-output\"\n",
    "iot_folder = folder + \"/iot\"\n",
    "\n",
    "# S3 Location to save the model artifact after compilation\n",
    "s3_compilation_output_location = \"s3://{}/{}\".format(bucket, compilation_output_sub_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we upload the test image to S3 bucket. This image will be used in inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_img_path = sess.upload_data(\"darknet.bmp\", bucket, iot_folder)\n",
    "keras_img_path = sess.upload_data(\"keras.bmp\", bucket, iot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch EC2 Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, this EC2 instance is used in place of an Edge device for running the agent software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_client = boto3.client(\"ec2\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate key pair for EC2 instance, save the key pem file. We can use this key with SSH to connect to the instance. But in this notebook example, we will not use SSH, instead, we will use AWS Systems Manager to send commands to the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pairs = ec2_client.describe_key_pairs()\n",
    "key_names = list(map(lambda x: x[\"KeyName\"], key_pairs[\"KeyPairs\"]))\n",
    "\n",
    "key_name = \"ec2-key-pair\"\n",
    "\n",
    "if key_name in key_names:\n",
    "    ec2_key_pair = ec2_client.delete_key_pair(\n",
    "        KeyName=key_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_key_pair = ec2_client.create_key_pair(\n",
    "    KeyName=key_name,\n",
    ")\n",
    "\n",
    "key_pair = str(ec2_key_pair[\"KeyMaterial\"])\n",
    "key_pair_file = open(\"ec2-key-pair.pem\", \"w\")\n",
    "key_pair_file.write(key_pair)\n",
    "key_pair_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a role for the EC2 instance we are going to use. Read for detailed information about [IAM roles for Amazon EC2](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html).\n",
    "\n",
    "Following steps here to [create an IAM role](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html#create-iam-role). Note down the role name and role ARN, role name will be used when we launch the EC2 instance, and role ARN will be needed to create inline policy.\n",
    "\n",
    "After creation, make sure the following policies are attached to role:\n",
    "\n",
    "- AmazonS3FullAccess \n",
    "- AmazonSSMManagedInstanceCore \n",
    "- CloudWatchAgentAdminPolicy \n",
    "\n",
    "\n",
    "Locate the same sagemaker role used for this notebook in [Demo Setup](#Demo-Setup) in [IAM console](https://console.aws.amazon.com/iam), click `Add inline policy` button on the role summary page, choose JSON format and replace the content with below statement:\n",
    "\n",
    "Before copy the following content, make sure you use the EC2 role ARN you just created in the `Resource` field for `iam:PassRole` action.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"iam:PassRole\",\n",
    "            \"Resource\": \"arn:aws:iam::<account>:role/<role-name>\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iot:AddThingToThingGroup\",\n",
    "                \"iot:AttachPolicy\",\n",
    "                \"iot:AttachThingPrincipal\",\n",
    "                \"iot:CreateKeysAndCertificate\",\n",
    "                \"iot:CreatePolicy\",\n",
    "                \"iot:CreateRoleAlias\",\n",
    "                \"iot:CreateThing\",\n",
    "                \"iot:CreateThingGroup\",\n",
    "                \"iot:DescribeEndpoint\",\n",
    "                \"iot:DescribeRoleAlias\",\n",
    "                \"iot:DescribeThingGroup\",\n",
    "                \"iot:GetPolicy\",\n",
    "                \"iam:GetRole\",\n",
    "                \"iam:CreateRole\",\n",
    "                \"iam:PassRole\",\n",
    "                \"iam:CreatePolicy\",\n",
    "                \"iam:AttachRolePolicy\",\n",
    "                \"iam:GetPolicy\",\n",
    "                \"sts:GetCallerIdentity\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"DeployDevTools\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"greengrass:CreateDeployment\",\n",
    "                \"iot:CancelJob\",\n",
    "                \"iot:CreateJob\",\n",
    "                \"iot:DeleteThingShadow\",\n",
    "                \"iot:DescribeJob\",\n",
    "                \"iot:DescribeThing\",\n",
    "                \"iot:DescribeThingGroup\",\n",
    "                \"iot:GetThingShadow\",\n",
    "                \"iot:UpdateJob\",\n",
    "                \"iot:UpdateThingShadow\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch an EC2 C5 instance. In this example we will use aws deep learning ami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_map = {\n",
    "    \"us-east-1\": \"ami-063585f0e06d22308\",\n",
    "    \"us-east-2\": \"ami-01bd6a1621a6968d7\",\n",
    "    \"us-west-2\": \"ami-0bc87a16c757a7f07\",\n",
    "    \"eu-central-1\": \"ami-01227276a4e5a4a31\",\n",
    "    \"ap-northeast-1\": \"ami-03b8cfea5460e4881\",\n",
    "    \"eu-west-1\": \"ami-006ff58f5247c50eb\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_profile_name = \"SMEdgeManageExampleRole\"  # the name of the role created for EC2\n",
    "\n",
    "ec2_instance = ec2_client.run_instances(\n",
    "     ImageId=ami_map[region],\n",
    "     MinCount=1,\n",
    "     MaxCount=1,\n",
    "     InstanceType='c5.large',\n",
    "     KeyName='ec2',\n",
    "     IamInstanceProfile={\n",
    "        'Name': ec2_profile_name}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id = ec2_instance[\"Instances\"][0][\"InstanceId\"]  # will used for running inference later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model using SageMaker Neo\n",
    "\n",
    "Create Sagemaker client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pretrained darknet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-23 16:11:00--  https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg?raw=true\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/pjreddie/darknet/raw/master/cfg/yolov3-tiny.cfg [following]\n",
      "--2021-06-23 16:11:00--  https://github.com/pjreddie/darknet/raw/master/cfg/yolov3-tiny.cfg\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg [following]\n",
      "--2021-06-23 16:11:01--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1915 (1,9K) [text/plain]\n",
      "Saving to: ‘yolov3-tiny.cfg’\n",
      "\n",
      "yolov3-tiny.cfg     100%[===================>]   1,87K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-06-23 16:11:01 (25,7 MB/s) - ‘yolov3-tiny.cfg’ saved [1915/1915]\n",
      "\n",
      "--2021-06-23 16:11:01--  https://pjreddie.com/media/files/yolov3-tiny.weights\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35434956 (34M) [application/octet-stream]\n",
      "Saving to: ‘yolov3-tiny.weights.1’\n",
      "\n",
      "yolov3-tiny.weights 100%[===================>]  33,79M  1,77MB/s    in 26s     \n",
      "\n",
      "2021-06-23 16:11:28 (1,29 MB/s) - ‘yolov3-tiny.weights.1’ saved [35434956/35434956]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O yolov3-tiny.cfg \"https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg?raw=true\"\n",
    "!wget https://pjreddie.com/media/files/yolov3-tiny.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"yolov3-tiny.tar.gz\", mode=\"w:gz\") as archive:\n",
    "    archive.add(\"yolov3-tiny.cfg\")\n",
    "    archive.add(\"yolov3-tiny.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_model_path = sess.upload_data(\"yolov3-tiny.tar.gz\", bucket, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When calling ``create_compilation_job()`` user is expected to provide all the correct input shapes required by the model for successful compilation. If we are using a different model, we need to specify the framework and data shape correctly.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_model_data_shape = '{\"data\":[1,3,416,416]}'\n",
    "darknet_model_framework = \"darknet\"\n",
    "target_device = \"ml_c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation job for Sagemaker-Edge-1624459072 started\n",
      "{'CompilationJobArn': 'arn:aws:sagemaker:eu-west-1:699391019698:compilation-job/Sagemaker-Edge-1624459072', 'ResponseMetadata': {'RequestId': '33f964ae-d423-4175-bfba-bf506b2babd0', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '33f964ae-d423-4175-bfba-bf506b2babd0', 'content-type': 'application/x-amz-json-1.1', 'content-length': '106', 'date': 'Wed, 23 Jun 2021 14:37:52 GMT'}, 'RetryAttempts': 0}}\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "role = \"arn:aws:iam::699391019698:role/service-role/AmazonSageMaker-ExecutionRole-20190424T105861\"\n",
    "darknet_compilation_job_name = \"Sagemaker-Edge-\" + str(time.time()).split(\".\")[0]\n",
    "print(\"Compilation job for %s started\" % darknet_compilation_job_name)\n",
    "\n",
    "response = sagemaker_client.create_compilation_job(\n",
    "    CompilationJobName=darknet_compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        \"S3Uri\": darknet_model_path,\n",
    "        \"DataInputConfig\": darknet_model_data_shape,\n",
    "        \"Framework\": darknet_model_framework.upper(),\n",
    "    },\n",
    "    OutputConfig={\n",
    "        \"S3OutputLocation\": s3_compilation_output_location,\n",
    "        \"TargetDevice\": target_device,\n",
    "    },\n",
    "    StoppingCondition={\"MaxRuntimeInSeconds\": 900},\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Poll every 30 sec\n",
    "while True:\n",
    "    response = sagemaker_client.describe_compilation_job(\n",
    "        CompilationJobName=darknet_compilation_job_name\n",
    "    )\n",
    "    if response[\"CompilationJobStatus\"] == \"COMPLETED\":\n",
    "        break\n",
    "    elif response[\"CompilationJobStatus\"] == \"FAILED\":\n",
    "        print(response)\n",
    "        raise RuntimeError(\"Compilation failed\")\n",
    "    print(\"Compiling ...\")\n",
    "    time.sleep(10)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Model using Sagemaker Edge Manager\n",
    "\n",
    "In this section, we will walk through packaging two models that achieve different goals. One is an Image Classification model (from Keras framework) and another is an Object Detection Model from DarkNet framework. This showcases the versatility of SageMaker Edge Manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Darknet Model\n",
    "\n",
    "Before we can deploy the compiled model to edge devices, we need to package the model with Sagemaker Edge Manager cloud service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_packaged_model_name = \"darknet-model\"\n",
    "darknet_model_version = \"1.0.0\"\n",
    "darknet_component_name = \"com.model.darknet\"\n",
    "darknet_model_package = \"{}-{}.tar.gz\".format(darknet_packaged_model_name, darknet_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '7f076c23-e040-4a8b-8b2f-233dd131870f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7f076c23-e040-4a8b-8b2f-233dd131870f', 'content-type': 'application/x-amz-json-1.1', 'content-length': '0', 'date': 'Wed, 23 Jun 2021 15:29:58 GMT'}, 'RetryAttempts': 0}}\n",
      "Packaging ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "darknet_packaging_job_name = darknet_compilation_job_name + \"-packaging\"\n",
    "response = sagemaker_client.create_edge_packaging_job(\n",
    "    RoleArn=role,\n",
    "    OutputConfig={\n",
    "        \"PresetDeploymentType\": \"GreengrassV2Component\",\n",
    "        \"PresetDeploymentConfig\": json.dumps({\"ComponentName\":darknet_component_name, \"ComponentVersion\":darknet_model_version}),\n",
    "        \"S3OutputLocation\": s3_compilation_output_location,\n",
    "    },\n",
    "    ModelName=darknet_packaged_model_name,\n",
    "    ModelVersion=darknet_model_version,\n",
    "    EdgePackagingJobName=darknet_packaging_job_name,\n",
    "    CompilationJobName=darknet_compilation_job_name,\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Poll every 30 sec\n",
    "while True:\n",
    "    job_status = sagemaker_client.describe_edge_packaging_job(\n",
    "        EdgePackagingJobName=darknet_packaging_job_name\n",
    "    )\n",
    "    if job_status[\"EdgePackagingJobStatus\"] == \"COMPLETED\":\n",
    "        break\n",
    "    elif job_status[\"EdgePackagingJobStatus\"] == \"FAILED\":\n",
    "        raise RuntimeError(\"Edge Packaging failed\")\n",
    "    print(\"Packaging ...\")\n",
    "    time.sleep(30)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_model_data = job_status[\"ModelArtifact\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pretrained Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f669c11771a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mobilenet_v2.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.applications.MobileNetV2()\n",
    "model.save(\"mobilenet_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"mobilenet_v2.tar.gz\", mode=\"w:gz\") as archive:\n",
    "    archive.add(\"mobilenet_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = sess.upload_data(\"mobilenet_v2.tar.gz\", bucket, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When calling ``create_compilation_job()`` user is expected to provide all the correct input shapes required by the model for successful compilation. If we are using a different model, we need to specify the framework and data shape correctly.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_data_shape = '{\"input_1\":[1,3,224,224]}'\n",
    "keras_model_framework = \"keras\"\n",
    "target_device = \"ml_c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "keras_compilation_job_name = \"Sagemaker-Edge-\" + str(time.time()).split(\".\")[0]\n",
    "print(\"Compilation job for %s started\" % keras_compilation_job_name)\n",
    "\n",
    "response = sagemaker_client.create_compilation_job(\n",
    "    CompilationJobName=keras_compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        \"S3Uri\": keras_model_path,\n",
    "        \"DataInputConfig\": keras_model_data_shape,\n",
    "        \"Framework\": keras_model_framework.upper(),\n",
    "    },\n",
    "    OutputConfig={\n",
    "        \"S3OutputLocation\": s3_compilation_output_location,\n",
    "        \"TargetDevice\": target_device,\n",
    "    },\n",
    "    StoppingCondition={\"MaxRuntimeInSeconds\": 900},\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Poll every 30 sec\n",
    "while True:\n",
    "    response = sagemaker_client.describe_compilation_job(\n",
    "        CompilationJobName=keras_compilation_job_name\n",
    "    )\n",
    "    if response[\"CompilationJobStatus\"] == \"COMPLETED\":\n",
    "        break\n",
    "    elif response[\"CompilationJobStatus\"] == \"FAILED\":\n",
    "        raise RuntimeError(\"Compilation failed\")\n",
    "    print(\"Compiling ...\")\n",
    "    time.sleep(30)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_packaged_model_name = \"keras-model\"\n",
    "keras_model_version = \"1.0.0\"\n",
    "keras_component_name = \"com.model.keras\"\n",
    "keras_model_package = \"{}-{}.tar.gz\".format(keras_packaged_model_name, keras_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_packaging_job_name = keras_compilation_job_name + \"-packaging\"\n",
    "response = sagemaker_client.create_edge_packaging_job(\n",
    "    RoleArn=role,\n",
    "    OutputConfig={\n",
    "        \"PresetDeploymentType\": \"GreengrassV2Component\",\n",
    "        \"PresetDeploymentConfig\": json.dumps({\"ComponentName\":keras_component_name, \"ComponentVersion\":keras_model_version}),\n",
    "        \"S3OutputLocation\": s3_compilation_output_location,\n",
    "    },\n",
    "    ModelName=keras_packaged_model_name,\n",
    "    ModelVersion=keras_model_version,\n",
    "    EdgePackagingJobName=keras_packaging_job_name,\n",
    "    CompilationJobName=keras_compilation_job_name,\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Poll every 30 sec\n",
    "while True:\n",
    "    job_status = sagemaker_client.describe_edge_packaging_job(\n",
    "        EdgePackagingJobName=keras_packaging_job_name\n",
    "    )\n",
    "    if job_status[\"EdgePackagingJobStatus\"] == \"COMPLETED\":\n",
    "        break\n",
    "    elif job_status[\"EdgePackagingJobStatus\"] == \"FAILED\":\n",
    "        raise RuntimeError(\"Edge Packaging failed\")\n",
    "    print(\"Packaging ...\")\n",
    "    time.sleep(30)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_data = job_status[\"ModelArtifact\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Install Greengrass\n",
    "\n",
    "SageMaker Edge Manager can use AWS IoT Greengrass to deploy the agent, the model and the inference application to the edge device.\n",
    "\n",
    "AWS IoT Greengrass provides all the necessary features to manage applications on remote devices in a secure and scalable way. To learn more about Greengrass, head to the [documentation](https://docs.aws.amazon.com/greengrass/v2/developerguide/what-is-iot-greengrass.html). \n",
    "\n",
    "The SageMaker Edge Manager agent leverages the AWS credentials provided by the [Token exchange service](https://docs.aws.amazon.com/greengrass/v2/developerguide/token-exchange-service-component.html) component to securely communicate with the SageMaker Edge Manager backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_client = boto3.client(\"ssm\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands to install Greengrass on the EC2 instance. \n",
    "\n",
    "> **Note**: If you are using a real device, connect to the device via SSH, ensure that you have both Java v8 or above and the Unzip command and then run the following commands (replace `<your_region>` with the correct value). To run this command on the device you also need to provide IAM credentials with at least the permissions listed [here](https://docs.aws.amazon.com/greengrass/v2/developerguide/provision-minimal-iam-policy.html).\n",
    "```bash\n",
    "curl -s https://d2s8p88vqu9w66.cloudfront.net/releases/greengrass-nucleus-latest.zip > greengrass-nucleus-latest.zip \\\n",
    "               && unzip greengrass-nucleus-latest.zip -d GreengrassCore,\n",
    "sudo -E java -Droot=\"/greengrass/v2\" -Dlog.store=FILE -jar ./GreengrassCore/lib/Greengrass.jar \\\n",
    "    --thing-name GreengrassSMEdgeManagerDevice -trn SageMakerTESRole -tra SageMakerTESRoleAlias \\ \n",
    "    --thing-group-name GreengrassSMEdgeManagerGroup \\ \n",
    "    --component-default-user ggc_user:ggc_group --provision true --setup-system-service true --deploy-dev-tools true \\\n",
    "    --aws-region <your_region>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ssm_client.send_command(\n",
    "    InstanceIds=[instance_id],\n",
    "    DocumentName=\"AWS-RunShellScript\",\n",
    "    OutputS3BucketName=bucket,\n",
    "    OutputS3KeyPrefix=folder,\n",
    "    Parameters={\n",
    "        \"commands\": [\n",
    "            \"#!/bin/bash\",\n",
    "            \"curl -s https://d2s8p88vqu9w66.cloudfront.net/releases/greengrass-nucleus-latest.zip > greengrass-nucleus-latest.zip && unzip greengrass-nucleus-latest.zip -d GreengrassCore\",\n",
    "            f'sudo -E java -Droot=\"/greengrass/v2\" -Dlog.store=FILE -jar ./GreengrassCore/lib/Greengrass.jar --aws-region {region} --thing-name GreengrassSMEdgeManagerDevice -trn SageMakerTESRole -tra SageMakerTESRoleAlias --thing-group-name GreengrassSMEdgeManagerGroup --component-default-user ggc_user:ggc_group --provision true --setup-system-service true --deploy-dev-tools true'\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CommandId': 'aeb69c81-c1a6-4d87-b87c-e8be50ad092a',\n",
       " 'InstanceId': 'i-086550044d97bdfaf',\n",
       " 'Comment': '',\n",
       " 'DocumentName': 'AWS-RunShellScript',\n",
       " 'DocumentVersion': '$DEFAULT',\n",
       " 'PluginName': 'aws:runShellScript',\n",
       " 'ResponseCode': -1,\n",
       " 'ExecutionEndDateTime': '',\n",
       " 'Status': 'InProgress',\n",
       " 'StatusDetails': 'InProgress',\n",
       " 'StandardOutputContent': '',\n",
       " 'StandardOutputUrl': '',\n",
       " 'StandardErrorContent': '',\n",
       " 'StandardErrorUrl': '',\n",
       " 'CloudWatchOutputConfig': {'CloudWatchLogGroupName': '',\n",
       "  'CloudWatchOutputEnabled': False},\n",
       " 'ResponseMetadata': {'RequestId': 'e076867a-be94-44ba-b175-1f983e270680',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Wed, 23 Jun 2021 15:07:45 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '479',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'e076867a-be94-44ba-b175-1f983e270680'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm_client.get_command_invocation(\n",
    "    CommandId=response[\"Command\"][\"CommandId\"],\n",
    "    InstanceId=instance_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Device Fleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the IAM role for device fleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure an IAM role in your AWS account that will be assumed by the credentials provider on behalf of the devices in your device fleet. \n",
    "\n",
    "\n",
    "Go to [IAM console](https://console.aws.amazon.com/iam/home?#/roles/SageMakerTESRole), and look for the role create role for IoT, attach the following policies:\n",
    "\n",
    "- AmazonSageMakerEdgeDeviceFleetPolicy\n",
    "\n",
    "Edit then the [trust relationship](https://console.aws.amazon.com/iam/home?#/roles/SageMakerTESRole?section=trust) as follow:\n",
    "```\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "      {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Principal\": {\"Service\": \"credentials.iot.amazonaws.com\"},\n",
    "        \"Action\": \"sts:AssumeRole\"\n",
    "      },\n",
    "      {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Principal\": {\"Service\": \"sagemaker.amazonaws.com\"},\n",
    "        \"Action\": \"sts:AssumeRole\"\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Note down the role ARN, it will be later used for creating the device fleet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn=\"<your role arn>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ce0c9193-3a31-47bb-bd70-c2a9775db3dd',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ce0c9193-3a31-47bb-bd70-c2a9775db3dd',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 23 Jun 2021 15:14:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_fleet_name =\"demo-device-fleet\" + str(time.time()).split('.')[0]\n",
    "\n",
    "sagemaker_client.create_device_fleet(\n",
    "    DeviceFleetName=device_fleet_name,\n",
    "    RoleArn=role_arn,\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': s3_compilation_output_location\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register device to the fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'aa668711-74f2-4002-a4a8-c7bcb624667f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'aa668711-74f2-4002-a4a8-c7bcb624667f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 23 Jun 2021 15:15:26 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_name = \"GreengrassSMEdgeManagerDevice\"\n",
    "\n",
    "sagemaker_client.register_devices(\n",
    "    DeviceFleetName=device_fleet_name,\n",
    "    Devices=[\n",
    "        {\n",
    "            \"DeviceName\": device_name,\n",
    "            \"IotThingName\": device_name,\n",
    "            \"Description\": \"this is a sample virtual device\",\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use [AWS Iot Greengrass](https://docs.aws.amazon.com/) to remotely deploy the agent, the model and the inference application.\n",
    "\n",
    "The [SageMaker Edge Manager component](https://docs.aws.amazon.com/greengrass/v2/developerguide/sagemaker-edge-manager-component.html) is already provided an will be used to deploy and run the agent on the device.\n",
    "\n",
    "The model component has been created for you by the packaging jobs you execute previsouly and in [your account](https://console.aws.amazon.com/iot/home?#/greengrass/v2/components) you should now have 2 models: `com.model.keras` and `com.model.darknet`. \n",
    "\n",
    "In order to be able to use the model, we also need an application component to load the model and invoke it. In the next section we are going to see how to create such component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the inference application component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Python application to load the model and perform the inference. The application is provided in the [inference.py](./inference.py) file. In addition to this file, you will also need to generate the Protobuf libraries that can be used with the gRPC API of the agent.\n",
    "\n",
    "First list the available releases from the S3 bucket. It does not matter which OS we are going to use since we only need the protobuf definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-02 08:31:22          0 \n",
      "                           PRE 1.20210512.96da6cc/\n",
      "                           PRE 1.20210305.a4bc999/\n",
      "                           PRE 1.20201218.81f481f/\n",
      "                           PRE 1.20201207.02d0e97/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://sagemaker-edge-release-store-us-west-2-linux-x64/Releases/ | sort -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the archive corresponding to the first item on the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-edge-release-store-us-west-2-linux-x64/Releases/1.20210512.96da6cc/1.20210512.96da6cc.tgz to ./sm_agent.tgz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-edge-release-store-us-west-2-linux-x64/Releases/1.20210512.96da6cc/1.20210512.96da6cc.tgz sm_agent.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the protobuf definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xf sm_agent.tgz docs/api/agent.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to generate the Python libraries to use the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# If you are running this on a personal computer you might want to create a Virtual Environment first\n",
    "python3 -m venv venv\n",
    ". venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install pip --upgrade\n",
    "pip install wheel\n",
    "pip install grpcio\n",
    "pip install grpcio-tools\n",
    "python3 -m grpc_tools.protoc --proto_path=. --python_out=. --grpc_python_out=. docs/api/agent.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, upload the `inference.py` and the protobuf libraries to an S3 bucket so that they can be referenced by the component recipe and from where they will be downloaded by Greengrass on the device. We can use the Sagemaker bucket for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export BUCKET=<bucket>\n",
    "aws s3 cp inference.py s3://$BUCKET/com.sagemaker.edgePythonExample/1.0.0/inference.py\n",
    "aws s3 cp agent_pb2.py s3://$BUCKET/com.sagemaker.edgePythonExample/1.0.0/agent_pb2.py\n",
    "aws s3 cp agent_pb2_grpc.py s3://$BUCKET/com.sagemaker.edgePythonExample/1.0.0/agent_pb2_grpc.py\n",
    "aws s3 cp keras.bmp s3://$BUCKET/com.sagemaker.edgePythonExample/1.0.0/keras.bmp\n",
    "aws s3 cp darknet.bmp s3://$BUCKET/com.sagemaker.edgePythonExample/1.0.0/darknet.bmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, create the component. You can use the [AWS Console](https://console.aws.amazon.com/iot/home?#/greengrass/v2/components/create) and copy paste the following YAML. Replace the `_BUCKET_` placeholder with the name of the bucket to which you have uploaded the artifacts.\n",
    "\n",
    "```yaml\n",
    "---\n",
    "RecipeFormatVersion: 2020-01-25\n",
    "ComponentName: com.sagemaker.edgePythonExample\n",
    "ComponentVersion: 1.0.0\n",
    "ComponentDescription: Sagemaker Edge Manager Python example\n",
    "ComponentPublisher: Amazon Web Services, Inc.\n",
    "ComponentDependencies:\n",
    "  aws.greengrass.SageMakerEdgeManager:\n",
    "    VersionRequirement: '>=1.0.0'\n",
    "    DependencyType: HARD\n",
    "  com.example.keras:\n",
    "    VersionRequirement: '~1.0.0'\n",
    "    DependencyType: HARD\n",
    "  com.example.darknet:\n",
    "    VersionRequirement: '~1.0.0'\n",
    "    DependencyType: HARD\n",
    "DefaultComponentConfiguration:\n",
    "  Demo: \"true\"\n",
    "  MLModel: keras\n",
    "  ImagePath: /absolute/path\n",
    "  CaptureData: \"true\"\n",
    "Manifests:\n",
    "  - Platform:\n",
    "      os: linux\n",
    "      architecture: \"/amd64|x86/\"\n",
    "    Lifecycle:\n",
    "      Install: |-\n",
    "        python3 -m venv venv\n",
    "        . venv/bin/activate\n",
    "        pip install pip --upgrade\n",
    "        pip install wheel      \n",
    "        pip3 install grpcio\n",
    "        pip3 install grpcio-tools\n",
    "        pip3 install protobuf\n",
    "        pip3 install Pillow\n",
    "      Run:\n",
    "        Setenv:\n",
    "          DEMO: \"{configuration:/Demo}\"\n",
    "          ML_MODEL: \"{configuration:/MLModel}\"\n",
    "          CAPTURE_DATA: \"{configuration:/CaptureData}\"\n",
    "        Script: |- \n",
    "          if [ $ML_MODEL == 'keras' ]; then\n",
    "            export MODEL_PATH=\"{com.example.keras:work}\"\n",
    "            export IMAGE_PATH={artifacts:path}/keras.bmp\n",
    "          else\n",
    "            export MODEL_PATH=\"{com.example.darknet:work}\"\n",
    "            export IMAGE_PATH={artifacts:path}/keras.bmp\n",
    "          fi\n",
    "          if [ $DEMO != 'true' ]; then\n",
    "            export IMAGE_PATH=\"{configuration:/ImagePath}\"\n",
    "          fi\n",
    "            \n",
    "          python3 -u {artifacts:path}/edge_manager_python_example.py \n",
    "    Artifacts:\n",
    "      - URI: s3://_BUCKET_/com.sagemaker.edgePythonExample/1.0.0/inference.py\n",
    "      - URI: s3://_BUCKET_/com.sagemaker.edgePythonExample/1.0.0/agent_pb2.py\n",
    "      - URI: s3://_BUCKET_/com.sagemaker.edgePythonExample/1.0.0/agent_pb2_grpc.py\n",
    "      - URI: s3://_BUCKET_/com.sagemaker.edgePythonExample/1.0.0/keras.bmp\n",
    "      - URI: s3://_BUCKET_/com.sagemaker.edgePythonExample/1.0.0/darknet.bmp      \n",
    "```"
   ]
  },
  {
   "source": [
    "# Deploy the application\n",
    "\n",
    "Once the application component has been created, it can be deployed to the device. In the AWS Console select the component, and click on **Deploy**.\n",
    "\n",
    "Next, select the a target thing group `GreengrassSMEdgeManagerGroup`, and click next until you reach the last screen. Click on **Deploy**.\n",
    "\n",
    "After few seconds the components will have been deployed to the EC2 instance and you should be able to see the results of the inference in the Greengrass logs by executing:\n",
    "```bash\n",
    "sudo cat /greengrass/v2/logs/com.sagemaker.edgePythonExample.log\n",
    "```\n",
    "\n",
    "If you are using another device, it might take longer depending on the network speed.\n",
    "\n",
    "As you noticed there is no need to install the agent separately or download the model: these tasks are performed by Greengrass based on the fact that the application recipe defined the dependencies on SageMagerEdge manager component and the model component created by the packaging job.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_log_out = ssm_client.send_command(\n",
    "    InstanceIds=[instance_id],\n",
    "    DocumentName=\"AWS-RunShellScript\",\n",
    "    OutputS3BucketName=bucket,\n",
    "    OutputS3KeyPrefix=folder,\n",
    "    Parameters={\n",
    "        \"commands\": [\n",
    "            \"sudo cat /greengrass/v2/logs/com.sagemaker.edgePythonExample.log\",\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_client.get_command_invocation(\n",
    "    CommandId=cat_log_out[\"Command\"][\"CommandId\"],\n",
    "    InstanceId=instance_id,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Customizing the application\n",
    "\n",
    "The application component is configured to run in demo mode by default, meaning it will use a pre-loaded image to perform the prediction. In case you want to provide your own image, you can change the component configuration during the deployment passing the following values:\n",
    "```json\n",
    "{\n",
    "    \"Demo\": \"false\",\n",
    "    \"ImagePath\": \"/absolute/host/path/to/the/image.bmp\"\n",
    "}\n",
    "```\n",
    "\n",
    "Note that the image must be in BMP format and 416x416 pixels if using Darknet and 224x224 pixels if using keras. If you want to provide images in other format and sizes you need to preprocess the image to obtain the above format and encoding.\n",
    "\n",
    "The code will:\n",
    "\n",
    "1. Load the model in SageMager Edge Manager agent\n",
    "2. List the models\n",
    "3. Perform the prediction\n",
    "4. Unload the model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undeploy the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_client.cancel_command(CommandId=agent_out[\"Command\"][\"CommandId\"], InstanceIds=[instance_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the EC2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_client.stop_instances(InstanceIds=[instance_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detach and delete policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iot_client.detach_policy(policyName=policy_name, target=iot_cert[\"certificateArn\"])\n",
    "\n",
    "iot_client.delete_policy(policyName=policy_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deregister device and delete device fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client.deregister_devices(DeviceFleetName=device_fleet_name, DeviceNames=[device_name])\n",
    "\n",
    "sagemaker_client.delete_device_fleet(DeviceFleetName=device_fleet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Use LogManager component to upload logs to CloudWatch"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}