{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this solution we build the core of a credit card fraud detection system using SageMaker. We start by training an unsupervised anomaly detection algorithm [Random Cut Forecast](https://docs.aws.amazon.com/sagemaker/latest/dg/randomcutforest.html), then proceed to train two [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) models for supervised training. To deal with the highly imbalanced data common in fraud detection, our first model uses XGBoost's weighting schema, and the second uses a re-sampling technique, SMOTE for oversampling the rare fraudulent examples. Lastly, we train an optimal XGBoost model with Hyper-parameter Optimization (HPO) to further improve the model performance. \n",
    "\n",
    "You can select Run->Run All from the menu to run all cells in Studio (or Cell->Run All in a SageMaker Notebook Instance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When running this notebook on SageMaker Classic notebooko, you should make sure the 'conda_python3' image/kernel is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credit card fraud detector solution contains five stages.\n",
    "\n",
    "* Stage I: Investigate and process the data (time duration: ~0.5 min)\n",
    "* Stage II: Train an unsupervised RandomCutForest model (time duration: ~6 min)\n",
    "* Stage III: Train a XGBoost model with the built-in weighting schema (time duration: ~7.5 min)\n",
    "* Stage IV: Train a XGBoost model with the over-sampling technique SMOTE (time duration: ~9 min)\n",
    "* Stage V: Train an optimal XGBoost model with hyper-parameter optimization (HPO) (time duration: ~15 min)\n",
    "* Stage VI: Evaluate and compare all model performance on the same test data (time duration: ~0.5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage I: Investigate and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"./src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U seaborn aws_requests_auth imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in the credit card fraud data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from package import config\n",
    "import uuid\n",
    "\n",
    "instance_type_train = \"ml.m5.4xlarge\"\n",
    "instance_type_inference = \"ml.g4dn.2xlarge\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\", region_name=config.AWS_REGION)\n",
    "s3.Object(\n",
    "    f\"{config.SOLUTIONS_S3_BUCKET}-{config.AWS_REGION}\",\n",
    "    f\"{config.SOLUTION_NAME}/data/creditcardfraud.zip\",\n",
    ").download_file(\"creditcardfraud.zip\")\n",
    "unique_hash = str(uuid.uuid4())[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"creditcardfraud.zip\", \"r\") as zf:\n",
    "    zf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"creditcard.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at our data (we only show a subset of the columns in the table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "data[[\"Time\", \"V1\", \"V2\", \"V27\", \"V28\", \"Amount\", \"Class\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains\n",
    "only numerical features, because the original features have been transformed using PCA, to protect user privacy. As a result,\n",
    "the dataset contains 28 PCA components, V1-V28, and two features that haven't been transformed, _Amount_ and _Time_.\n",
    "_Amount_ refers to the transaction amount, and _Time_ is the seconds elapsed between any transaction in the data\n",
    "and the first transaction.\n",
    "\n",
    "The class column corresponds to whether or not a transaction is fraudulent. We see that the majority of data is non-fraudulent with only $492$ ($0.173\\%$) of the data corresponding to fraudulent examples, out of the total of 284,807 examples in the data. This corresponds to the extreme class imbalance scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonfrauds, frauds = data.groupby(\"Class\").size()\n",
    "print(\"Number of frauds: \", frauds)\n",
    "print(\"Number of non-frauds: \", nonfrauds)\n",
    "print(\"Percentage of fradulent data:\", 100.0 * frauds / (frauds + nonfrauds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that the columns $V_i$ have been normalized to have $0$ mean and unit standard deviation as the result of a PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_columns = data.columns[:-1]\n",
    "label_column = data.columns[-1]\n",
    "\n",
    "features = data[feature_columns].values.astype(\"float32\")\n",
    "labels = (data[label_column].values).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare our data for loading and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset into a train and test to evaluate the performance of our models. It's important to do so _before_ any techniques meant to alleviate the class imbalance are used. This ensures that we don't leak information from the test set into the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(y_test), np.mean(y_train), X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If you are bringing your own data to this solution and they include categorical data, that have strings as values, you'd need to one-hot encode these values first using for example sklearn's [OneHotEncoder](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features), as XGBoost only supports numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage II: Train an unsupervised RandomCutForest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a fraud detection scenario, commonly we have very few labeled examples, and it's possible that labeling fraudulent examples takes a very long time. We would like then to extract information from the unlabeled data we have at hand as well. _Anomaly detection_ is a form of unsupervised learning where we try to identify anomalous examples based solely on their feature characteristics. [Random Cut Forest](https://docs.aws.amazon.com/sagemaker/latest/dg/randomcutforest.html) is a state-of-the-art anomaly detection algorithm that is both accurate and scalable. We train such a model on our training data and evaluate its performance on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from package import config\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = config.MODEL_DATA_S3_BUCKET\n",
    "prefix = \"fraud-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import RandomCutForest\n",
    "\n",
    "training_job_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-rcf\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Training -> Training jobs -> a job name started with {training_job_name} to monitor training status and details.\"\n",
    ")\n",
    "\n",
    "# specify general training job information\n",
    "rcf = RandomCutForest(\n",
    "    role=config.SAGEMAKER_IAM_ROLE,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type_train,\n",
    "    data_location=\"s3://{}/{}/\".format(bucket, prefix),\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    base_job_name=training_job_name,\n",
    "    num_samples_per_tree=512,\n",
    "    num_trees=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to fit the model. The below cell should take around 5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcf.fit(rcf.record_set(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host Random Cut Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once we have a trained model we can deploy it and get some predictions for our test set. SageMaker spins up an instance for us and deploy the model, the whole process should take around 10 minutes, you can see progress being made with each `-` and an exclamation point when the process is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-rcf\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Inference -> Endpoints --> an endpoint with name {endpoint_name} to monitor the deployment status.\"\n",
    ")\n",
    "\n",
    "rcf_predictor = rcf.deploy(\n",
    "    model_name=f\"{config.SOLUTION_PREFIX}-{unique_hash}-rcf\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type_inference,  # use a smaller instance for endpoint deployment\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Random Cut Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With the model deployed, let's see how it performs in terms of separating fraudulent from legitimate transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_rcf(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        array_preds = [s[\"score\"] for s in current_predictor.predict(array)[\"scores\"]]\n",
    "        predictions.append(array_preds)\n",
    "\n",
    "    return np.concatenate([np.array(batch) for batch in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each data example, RCF associates an anomaly score. Low score values indicate that the data point is considered \"normal\" (non-fraudulent in our case). High values indicate the presence of an anomaly in the data (fraudulent). The definitions of \"low\" and \"high\" depend on the application but common practice suggests that scores beyond three standard deviations from the mean score are considered anomalous.\n",
    "\n",
    "We get the predictions of anomaly scores for the test examples by querying the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = predict_rcf(rcf_predictor, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we examine the anomaly scores for positive (fraudulent) and negative (non-fraudulent) examples separately. The expectation is that positive (fraudulent) example has relatively high score, and negative (non-fraudulent) example has relatively low score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_samples_scores = scores[y_test == 1]\n",
    "negative_samples_scores = scores[y_test == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot histograms for scores of positive (left histogram) and negative examples (right histogram). Because the number of positive and negative examples differs significantly (which you can tell from the y axis of each histogram), we plot them separately. \n",
    "From the histograms, we can see following patterns:\n",
    "\n",
    "1. Almost half of positive examples (left histogram) have scores more than 0.9, while most of the negative examples (right histogram) have anomaly scores less than 0.85.\n",
    "2. Because of not using label information, the unsupervised learning method RCF has limitations to identify fraudulent and non-fraudulent examples accurately. This issue can be resolved by collecting label information and using a supervised learning method, as demonstrated in the following stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "plot1 = sns.histplot(positive_samples_scores, label=\"fraud\", bins=20, color=\"red\", ax=axes[0])\n",
    "plot2 = sns.histplot(negative_samples_scores, label=\"not-fraud\", bins=20, color=\"blue\", ax=axes[1])\n",
    "axes[0].set_xlim(0.5, 1.5)\n",
    "axes[0].set_xlabel(\"Anomaly Score\")\n",
    "axes[1].set_xlim(0.5, 1.5)\n",
    "axes[1].set_xlabel(\"Anomaly Score\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's assume in a real-world scenario where we want to classify each test example into either positive (fraudulent) or negative (non-fraudulent) example based on its anomaly score. We plot the histogram of scores for all the test examples as below. Then we choose a cutoff score `1.0` (based on the pattern shown in the histogram) for classification. Specifically, if the anomaly score is less than or equal to `1.0`, the example is classified as negative (non-fraudulent) example. Otherwise, the example is classified as positive (fraudulent) example. Next, we compare the classification result with the ground truth labels and compute the evaluation metrics. The evaluation metrics are [Balanced Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html), [Cohen's Kappa score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html), [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), and [ROC_AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html). For all of the metrics, a large value indicates a better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(scores, 50, density=False, facecolor=\"g\", alpha=0.75)\n",
    "\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of Scores for Test Examples\")\n",
    "plt.xlim(0.8, 1.4)\n",
    "plt.grid(True)\n",
    "plt.axvline(x=1.0, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_preds_rcf = np.where(scores > 1.0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. Because there is no estimated probability for positive and negative classes from the RCF model on each example, we cannot compute the [ROC_AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) score. This metric is computed in following stages using supervised learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score, roc_auc_score\n",
    "\n",
    "result_rcf = [\n",
    "    balanced_accuracy_score(y_test, y_preds_rcf),\n",
    "    cohen_kappa_score(y_test, y_preds_rcf),\n",
    "    f1_score(y_test, y_preds_rcf),\n",
    "]\n",
    "result_rcf.append(\"-\")\n",
    "result_rcf = pd.DataFrame(\n",
    "    result_rcf, index=[\"Balanced accuracy\", \"Cohen's Kappa\", \"F1\", \"ROC_AUC\"], columns=[\"RCF\"]\n",
    ")\n",
    "\n",
    "print(result_rcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unsupervised model already can achieve some separation between the classes, with higher anomaly scores being correlated to fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage III: Train a XGBoost model with the built-in weighting schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have gathered an adequate amount of labeled training data, we can use a supervised learning algorithm that discovers relationships between the features and the dependent class.\n",
    "\n",
    "We use Gradient Boosted Trees as our model, as they have a proven track record, are highly scalable and can deal with missing data, reducing the need to pre-process datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data and Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we copy the data to an in-memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import sklearn\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "buf = io.BytesIO()\n",
    "\n",
    "sklearn.datasets.dump_svmlight_file(X_train, y_train, buf)\n",
    "buf.seek(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we upload the data to S3 using boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = \"fraud-dataset\"\n",
    "subdir = \"base\"\n",
    "boto3.resource(\"s3\", region_name=config.AWS_REGION).Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train\", subdir, key)\n",
    ").upload_fileobj(buf)\n",
    "\n",
    "s3_train_data = \"s3://{}/{}/train/{}/{}\".format(bucket, prefix, subdir, key)\n",
    "print(\"Uploaded training data location: {}\".format(s3_train_data))\n",
    "\n",
    "output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "print(\"Training artifacts are uploaded to: {}\".format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now train using SageMaker's built-in XGBoost algorithm. To specify the XGBoost algorithm, we use a utility function to obtain its URI. A complete list of built-in algorithms is found here: https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html\n",
    "\n",
    "Moving onto training, first we need to specify the locations of the XGBoost algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SageMaker abstracts training via Estimators. We can pass the classifier and parameters along with hyperparameters to the estimator, and fit the estimator to the data in S3. An important parameter here is `scale_pos_weight` which scales the weights of the positive vs. negative class examples. This is crucial to do in an imbalanced dataset like the one we are using here, otherwise the majority class would dominate the learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Because the data set is so highly skewed, we set the scale position weight conservatively,\n",
    "# as sqrt(num_nonfraud/num_fraud).\n",
    "# Other recommendations for the scale_pos_weight are setting it to (num_nonfraud/num_fraud).\n",
    "scale_pos_weight = sqrt(np.count_nonzero(y_train == 0) / np.count_nonzero(y_train))\n",
    "hyperparams = {\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"num_round\": 100,\n",
    "    \"eta\": 0.9,\n",
    "    \"gamma\": 10,\n",
    "    \"min_child_weight\": 16,\n",
    "    \"silent\": 0,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explain the hyper-parameters used above. The one that's very relevant for learning from skewed data is `scale_pos_weight`. This is a ratio that weighs the examples of the positive class (fraud) against the negative class (legitimate). Commonly this is set to `(num_nonfraud/num_fraud)`, but our data is exteremely skewed so we set it to `sqrt(num_nonfraud/num_fraud)`.  For the data in this example, this would be `sqrt(284,807/492)` which would give our fraud examples a weight of ~24.\n",
    "\n",
    "The rest of the hyper-parameters are as follows:\n",
    "\n",
    "* `max_depth`: This is the maximum depth of the trees that are built for our ensemble. A max depth of 5 gives us trees with up to 32 leaves. Note that tree size grows exponentially when increasing this parameter (`num_leaves=2^max_depth`), so a max depth of 10 would give us trees with 1024 leaves, which are likely to overfit.\n",
    "* `subsample`: The subsample ratio that we use to select a subset of the complete data to train each tree in the ensemble. With a value of 0.8, each tree is trained on a random sample containing 80% of the complete data. This is used to prevent overfitting.\n",
    "* `num_round`: This is the size of the ensemble. We use 100 \"rounds\", each training round adding a new tree to the ensemble.\n",
    "* `eta`: This is the step size shrinkage applied at each update. This value shrinks the weights of new features to prevent overfitting.\n",
    "* `gamma`: This is the minimum loss reduction to reach before splitting a leaf. Splitting a leaf can sometimes have a small benefit, and splitting such leaves can lead to overfitting. By setting `gamma` to values larger than zero, we ensure that there should be at least some non-negligible amount of accuracy gain before splitting a leaf.\n",
    "* `min_child_weight`: This parameter has a similar effect to gamma, setting it to higher values means we wait until enough gain is possible before splitting a leaf.\n",
    "* `objective`: We are doing binary classification, so we use a logistic loss objective.\n",
    "* `eval_metric`: Having a good evaluation metric is crucial when dealing with imbalanced data (see discussion below). We use AUC here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Training -> Training jobs -> a job name started with {training_job_name} to monitor training status and details.\"\n",
    ")\n",
    "\n",
    "clf = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role=config.SAGEMAKER_IAM_ROLE,\n",
    "    hyperparameters=hyperparams,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type_train,\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=training_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit our supervised training model, the call to fit below should take around 5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit({\"train\": s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Host Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we deploy the estimator to and endpoint. As before progress are indicated by `-`, and the deployment should be done after 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Inference -> Endpoints --> an endpoint with name {endpoint_name} to monitor the deployment status.\"\n",
    ")\n",
    "\n",
    "predictor = clf.deploy(\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type=instance_type_inference,  # use a smaller instance for endpoint deployment\n",
    "    serializer=CSVSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the model we can use it to make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Because we have a large test set, we call predict on smaller batches\n",
    "def predict(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = \"\"\n",
    "    for array in split_array:\n",
    "        predictions = \",\".join([predictions, current_predictor.predict(array).decode(\"utf-8\")])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_preds = predict(predictor, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use a few measures from the scikit-learn package to evaluate the performance of our model. When dealing with an imbalanced dataset, we need to choose metrics that take into account the frequency of each class in the data.\n",
    "\n",
    "Four such metrics are the [balanced accuracy score](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score), [Cohen's Kappa](https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa), [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), [ROC_AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score, roc_auc_score\n",
    "\n",
    "# scikit-learn expects 0/1 predictions, so we threshold our raw predictions\n",
    "y_preds = np.where(raw_preds > 0.5, 1, 0)\n",
    "result_xgboost = [\n",
    "    balanced_accuracy_score(y_test, y_preds),\n",
    "    cohen_kappa_score(y_test, y_preds),\n",
    "    f1_score(y_test, y_preds),\n",
    "]\n",
    "result_xgboost.append(roc_auc_score(y_test, raw_preds))\n",
    "result_xgboost = pd.DataFrame(\n",
    "    result_xgboost, index=[\"Balanced accuracy\", \"Cohen's Kappa\", \"F1\", \"ROC_AUC\"], columns=[\"XGB\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_rcf_xgboost = result_rcf.join(result_xgboost)\n",
    "print(result_rcf_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a supervised learning method XGBoost with the weighting schema (using `scale_pos_weight` to scale the weights of the positive vs. negative class examples) achieves significantly better performance than the unsupervised learning method RCF. We can also see that there still are rooms to improve the model performance. In particular, Cohen's Kappa scores above 0.8 are generally very favorable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from single-value metrics, it's also useful to look at metrics that indicate performance per class. A confusion matrix, and per-class precision, recall and f1-score can also provide more information about the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_predicted):\n",
    "    cm = confusion_matrix(y_true, y_predicted)\n",
    "    # Get the per-class normalized value for each cell\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # We color each cell according to its normalized value, annotate with exact counts.\n",
    "    ax = sns.heatmap(cm_norm, annot=cm, fmt=\"d\")\n",
    "    ax.set(xticklabels=[\"non-fraud\", \"fraud\"], yticklabels=[\"non-fraud\", \"fraud\"])\n",
    "    ax.set_ylim([0, 2])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"Real Classes\")\n",
    "    plt.xlabel(\"Predicted Classes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage IV: Train a XGBoost model with the over-sampling technique SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline model using XGBoost, we can try to see if sampling techniques that are designed specifically for imbalanced problems can improve the performance of the model.\n",
    "\n",
    "For that purpose we use the [imbalanced-learn](https://imbalanced-learn.readthedocs.io/en/stable/index.html) package that works well with scikit-learn. We have pre-installed the package for this kernel, but if you need it for a different Jupyter kernel you can install it by running `pip install --upgrade imbalanced-learn` within the conda environment you need.\n",
    "\n",
    "We use [Sythetic Minority Over-sampling](https://arxiv.org/abs/1106.1813) (SMOTE), which oversamples the minority class by interpolating new data points between existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that SMOTE has now balanced the two classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(sorted(Counter(y_smote).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that this is a case of extreme oversampling of the the minority class, we went from ~0.17% to 50%. An alternative would be to use a smaller resampling ratio, such as having one minority cl\n",
    "ass sample for every `sqrt(non_fraud/fraud)` majority samples, or using more advanced resampling techniques. See the [comparison](https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html#sphx-glr-auto-examples-over-sampling-plot-comparison-over-sampling-py) provided by imbalanced-learn for more over-sampling options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In our case we use the SMOTE dataset we just created and upload it to S3 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smote_buf = io.BytesIO()\n",
    "\n",
    "# Dump the SMOTE data into a buffer\n",
    "sklearn.datasets.dump_svmlight_file(X_smote, y_smote, smote_buf)\n",
    "smote_buf.seek(0)\n",
    "\n",
    "# Upload from the buffer to S3\n",
    "key = \"fraud-dataset-smote\"\n",
    "subdir = \"smote\"\n",
    "boto3.resource(\"s3\", region_name=config.AWS_REGION).Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train\", subdir, key)\n",
    ").upload_fileobj(smote_buf)\n",
    "\n",
    "s3_smote_train_data = \"s3://{}/{}/train/{}/{}\".format(bucket, prefix, subdir, key)\n",
    "print(\"Uploaded training data location: {}\".format(s3_smote_train_data))\n",
    "\n",
    "smote_output_location = \"s3://{}/{}/smote-output\".format(bucket, prefix)\n",
    "print(\"Training artifacts are uploaded to: {}\".format(smote_output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No need to scale weights after SMOTE resampling, so we remove that parameter\n",
    "hyperparams.pop(\"scale_pos_weight\", None)\n",
    "\n",
    "training_job_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb-smote\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Training -> Training jobs -> a job name started with {training_job_name} to monitor training status and details.\"\n",
    ")\n",
    "\n",
    "smote_xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role=config.SAGEMAKER_IAM_ROLE,\n",
    "    hyperparameters=hyperparams,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type_train,\n",
    "    output_path=smote_output_location,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=training_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are now ready to fit the model, which should take around 5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smote_xgb.fit({\"train\": s3_smote_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model we can check its performance to compare it against the base XGBoost model. The deployment takes around 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb-smote\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Inference -> Endpoints --> an endpoint with name {endpoint_name} to monitor the deployment status.\"\n",
    ")\n",
    "\n",
    "smote_predictor = smote_xgb.deploy(\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type=instance_type_inference,  # use a smaller instance for endpoint deployment\n",
    "    serializer=CSVSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smote_raw_preds = predict(smote_predictor, X_test)\n",
    "smote_preds = np.where(\n",
    "    smote_raw_preds > 0.5, 1, 0\n",
    ")  # generate predicted labels using a cutoff threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_xgboost_smote = [\n",
    "    balanced_accuracy_score(y_test, smote_preds),\n",
    "    cohen_kappa_score(y_test, smote_preds),\n",
    "    f1_score(y_test, smote_preds),\n",
    "]\n",
    "result_xgboost_smote.append(roc_auc_score(y_test, smote_raw_preds))\n",
    "result_xgboost_smote = pd.DataFrame(\n",
    "    result_xgboost_smote,\n",
    "    index=[\"Balanced accuracy\", \"Cohen's Kappa\", \"F1\", \"ROC_AUC\"],\n",
    "    columns=[\"XGB_SMOTE\"],\n",
    ")\n",
    "\n",
    "result_rcf_xgboost_all = result_rcf_xgboost.join(result_xgboost_smote)\n",
    "print(result_rcf_xgboost_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with over-sampling technique SMOTE, XGBoost achieves a better performance on [Balanced Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html), but not on [Cohen's Kappa](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html) and [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) scores. We present the confusion matrix to examine the results in details and explain the reason as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, smote_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, smote_preds, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the randomness of XGBoost your results may vary, but overall, you should see a large increase in non-fraud cases being classified as fraud (false positives). The reason this happens is because SMOTE has oversampled the fraud class so much that it's increased its overlap in feature space with the non-fraud cases.\n",
    "Since Cohen's Kappa gives more weight to false positives than balanced accuracy does, the metric drops significantly, as does the precision and F1 score for fraud cases. However, we can bring a balance between the metrics again by adjusting our classification threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been using 0.5 as the threshold between labeling a point as fraudulent or not. We can try different thresholds to see if they affect the result of the classification. To evaluate, we use the balanced accuracy and Cohen's Kappa metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for thres in np.linspace(0.1, 0.9, num=9):\n",
    "    smote_thres_preds = np.where(smote_raw_preds > thres, 1, 0)\n",
    "    print(\"Threshold: {:.1f}\".format(thres))\n",
    "    print(\"Balanced accuracy = {:.3f}\".format(balanced_accuracy_score(y_test, smote_thres_preds)))\n",
    "    print(\"Cohen's Kappa = {:.3f}\\n\".format(cohen_kappa_score(y_test, smote_thres_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Cohen's Kappa keeps increasing along with the threshold, without a significant loss in balanced accuracy. This adds a useful knob to our model: We can keep a low threshold if we care more about not missing any fraudulent cases, or we can increase the threshold to try to minimize the number of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage V: Train an optimal XGBoost model with hyper-parameter optimization (HPO)\n",
    "\n",
    "In this stage, we demonstrate that model performance can be further improved by training an optimal XGBoost model with Hyper-parameter Optimization (HPO). To overcome the highly imbalance data problem, we use the XGBoost's weighting schema with hyper-parameter`scale_pos_weight` to scale the weights of the positive vs. negative class examples.\n",
    "\n",
    "First, we further split the training data into training and validation data using the stratified sampling. The HPO process selects an optimal model that has the best performance on the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_hpo, X_valid_hpo, y_train_hpo, y_valid_hpo = train_test_split(\n",
    "    X_train, y_train, test_size=0.4, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_hpo.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last few stages, we prepare the input data as the `libsvm` format to train a XGBoost model. In this stage, we demonstrate how to prepare the training and validation data as the `csv` format. The input formats supported by XGBoost are documented in [SageMaker XGBoost Document](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html).\n",
    "\n",
    "We combine the target variable (label) with the features variables for both training and validation data, save them into `csv` formats, and upload them to S3 buckets.\n",
    ">Note. The algorithm assumes that the target variable is in the first column.\n",
    "\n",
    "A standard approach for creating training and validation data is to make sure that the training and validation data are disjoint (i.e., they don't have any example in common). As a result, the model can be evaluated on the hold-out validation data, and thus the optimal model, which performs the best on the validation data, is selected by the HPO process. \n",
    "\n",
    "In our experiment, however, we found that using entire data (`X_train` and `y_train` instead of `X_train_hpo` and `y_train_hpo`) as the training set gave a significantly better performance (i.e., the validation data are subset of the training data). The reason is that due to highly imbalance data, there are very few number of positive (fraudulent) examples for model to learn their underlying pattern. If we use the standard approach to split the training data into two disjoint training and validation subsets, there are even smaller number of training examples for the model to learn. On the other hand, having the training and validation data non-disjoint can make the model trained with more iterations, which allows the model to learn the underlying pattern deeper. The reason is that the evaluation score on the validation data is similar to that on the training data, and tends to become better when iteration increases. Under such scenario, the early stopping are likely not be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_combine = np.concatenate((np.reshape(y_train, (-1, 1)), X_train), axis=1)\n",
    "# X_train_combine = np.concatenate((np.reshape(y_train_hpo, (-1, 1)), X_train_hpo), axis=1) # this is the standard approach to create disjoint training and validation data\n",
    "X_valid_combine = np.concatenate((np.reshape(y_valid_hpo, (-1, 1)), X_valid_hpo), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p xgboost_hpo_input\n",
    "np.savetxt(\"xgboost_hpo_input/X_train_hpo.csv\", X_train_combine, delimiter=\",\")\n",
    "np.savetxt(\"xgboost_hpo_input/X_valid_hpo.csv\", X_valid_combine, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "prefix = \"fraud-classifier-hpo\"\n",
    "\n",
    "s3_train_data = S3Uploader.upload(\n",
    "    \"xgboost_hpo_input/X_train_hpo.csv\", \"s3://{}/{}/{}\".format(bucket, prefix, \"train\")\n",
    ")\n",
    "print(\"Uploaded training data location: {}\".format(s3_train_data))\n",
    "\n",
    "s3_validation_data = S3Uploader.upload(\n",
    "    \"xgboost_hpo_input/X_valid_hpo.csv\", \"s3://{}/{}/{}\".format(bucket, prefix, \"validation\")\n",
    ")\n",
    "print(\"Uploaded training data location: {}\".format(s3_validation_data))\n",
    "\n",
    "output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "print(\"Training artifacts are uploaded to: {}\".format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're training with the `csv` file format, we create TrainingInputs that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_input_train = TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/train/\".format(bucket, prefix), content_type=\"csv\"\n",
    ")\n",
    "s3_input_validation = TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/validation/\".format(bucket, prefix), content_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "# Because the data set is so highly skewed, we set the scale position weight conservatively,\n",
    "# as sqrt(num_nonfraud/num_fraud).\n",
    "# Other recommendations for the scale_pos_weight are setting it to (num_nonfraud/num_fraud).\n",
    "scale_pos_weight = sqrt(\n",
    "    np.count_nonzero(y_train == 0) / np.count_nonzero(y_train)\n",
    ")  # sqrt(np.count_nonzero(y_train==0)/np.count_nonzero(y_train))\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    config.SAGEMAKER_IAM_ROLE,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type_train,\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    eval_metric=\"auc\",\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=1000,\n",
    "    early_stopping_rounds=10,\n",
    "    silent=0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the hyper-parameters search ranges.\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 0.5),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"gamma\": ContinuousParameter(2, 7),\n",
    "    # \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"subsample\": ContinuousParameter(0.6, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objective metric name and objective type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_metric_name = \"validation:auc\"\n",
    "objective_type = \"Maximize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-tuning\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Training -> Hyperparameter tuning jobs -> a job name started with {tuning_job_name} to monitor HPO tuning status and details.\\n\"\n",
    "    f\"Note. You are unable to successfully run the following cells until the tuning job completes. This step may take around 15 min.\"\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=30,\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=objective_type,\n",
    "    base_tuning_job_name=tuning_job_name,\n",
    ")\n",
    "\n",
    "tuner.fit({\"train\": s3_input_train, \"validation\": s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Status of HPO tuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the tuning job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_result = sm_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "\n",
    "status = tuning_job_result[\"HyperParameterTuningJobStatus\"]\n",
    "if status != \"Completed\":\n",
    "    print(\"Reminder: the tuning job has not been completed.\")\n",
    "\n",
    "job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "is_maximize = (\n",
    "    tuning_job_result[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"][\"Type\"]\n",
    "    != \"Maximize\"\n",
    ")\n",
    "objective_name = tuning_job_result[\"HyperParameterTuningJobConfig\"][\n",
    "    \"HyperParameterTuningJobObjective\"\n",
    "][\"MetricName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\", ascending=False)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy endpoint of the best tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb-tuning\"\n",
    "print(\n",
    "    f\"You can go to SageMaker -> Inference -> Endpoints --> an endpoint with name {endpoint_name} to monitor the deployment status.\"\n",
    ")\n",
    "\n",
    "predictor_hpo = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type_train,\n",
    "    serializer=CSVSerializer(),\n",
    "    endpoint_name=endpoint_name,\n",
    ")  # Note. Because of csv-format input takes larger memory than the libsvm-format input,\n",
    "# we use the large instance type `instance_type_train` for deploying an endpoint to avoid out-of-memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_preds_hpo = predict(predictor_hpo, X_test)\n",
    "preds_hpo = np.where(raw_preds_hpo > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_xgboost_hpo = [\n",
    "    balanced_accuracy_score(y_test, preds_hpo),\n",
    "    cohen_kappa_score(y_test, preds_hpo),\n",
    "    f1_score(y_test, preds_hpo),\n",
    "]\n",
    "result_xgboost_hpo.append(roc_auc_score(y_test, raw_preds_hpo))\n",
    "result_xgboost_hpo = pd.DataFrame(\n",
    "    result_xgboost_hpo,\n",
    "    index=[\"Balanced accuracy\", \"Cohen's Kappa\", \"F1\", \"ROC_AUC\"],\n",
    "    columns=[\"XGB_HPO\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage VI: Evaluate and compare all model performance on the same test data\n",
    "\n",
    "We present the evaluation results from four models, Random Cut Forest (RCF), XGBoost (XGB), XGBoost with over-sampling method SMOTE, and XGBoost with HPO. The evaluations are conducted on the same test data, which are created at the beginning of the notebook. The evaluation metrics are [Balanced Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html), [Cohen's Kappa score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html), [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), and [ROC_AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html). For all of the metrics, a large value indicates a better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_xgboost_all_hpo = result_rcf_xgboost_all.join(result_xgboost_hpo)\n",
    "print(result_xgboost_all_hpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that XGBoost with HPO achieves even better performance than that with SMOTE method. In particular, Cohen's Kappa scores and F1 are over 0.8, indicating optimal model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "We leave the unsupervised and base XGBoost endpoints running at the end of this notebook so we can handle incoming event streams using the Lambda function. The solution automatically cleans up the endpoints when deleted, however, don't forget to ensure the prediction endpoints are deleted when you're done. You can do that at the Amazon SageMaker console in the Endpoints page. Or you can run `predictor_name.delete_endpoint()` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to clean up endpoints\n",
    "# rcf_predictor.delete_model()\n",
    "# rcf_predictor.delete_endpoint()\n",
    "# predictor.delete_model()\n",
    "# predictor.delete_endpoint()\n",
    "# smote_predictor.delete_model()\n",
    "# smote_predictor.delete_endpoint()\n",
    "# predictor_hpo.delete_model()\n",
    "# predictor_hpo.delete_endpoint()\n",
    "# sm_client = boto3.client(\"sagemaker\", region_name=config.AWS_REGION)\n",
    "# waiter = sm_client.get_waiter(\"endpoint_deleted\")\n",
    "# waiter.wait(EndpointName=f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb-smote\")\n",
    "# waiter.wait(EndpointName=f\"{config.SOLUTION_PREFIX}-{unique_hash}-xgb\")\n",
    "# waiter.wait(EndpointName=f\"{config.SOLUTION_PREFIX}-{unique_hash}-rcf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Acknowledgements\n",
    "\n",
    "The dataset used to demonstrated the fraud detection solution has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the [DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) project\n",
    "We cite the following works:\n",
    "* Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
    "* Dal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n",
    "* Dal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n",
    "* Dal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n",
    "* Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n",
    "* Carcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/introduction_to_applying_machine_learning|credit_card_fraud_detector|credit_card_fraud_detector.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
