{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Customer Churn Model for Music Streaming App Users: Model Selection and Model Explainability\n",
    "\n",
    "In this demo, you are going to learn how to use various SageMaker functionalities to build, train, and deploy the model from end to end, including data pre-processing steps like ingestion, cleaning and processing, feature engineering, training and hyperparameter tuning, model explainability, and eventually deploy the model. There are two parts of the demo: in part 1: Prepare Data, you will process the data with the help of Data Wrangler, then create features from the cleaned data. By the end of part 1, you will have a complete feature data set that contains all attributes built for each user, and it is ready for modeling. Then in part 2: Modeling and Reference, you will use the data set built from part 1 to find an optimal model for the use case, then test the model predictability with the test data. To start with Part 2, you can either read in data from the output of your Part 1 results, or use the provided 'data/full_feature_data.csv' as the input for the next steps.\n",
    "\n",
    "\n",
    "For how to set up the SageMaker Studio Notebook environment, please check the [onboarding video]( https://www.youtube.com/watch?v=wiDHCWVrjCU&feature=youtu.be). And for a list of services covered in the use case demo, please check the documentation linked in each section.\n",
    "\n",
    "\n",
    "## Content\n",
    "* [Overview](#Overview)\n",
    "* [Data Selection](#2)\n",
    "* [Ingest Data](#4)\n",
    "* [Data Cleaning and Data Exploration](#5)\n",
    "* [Pre-processing with SageMaker Data Wrangler](#7)\n",
    "* [Feature Engineering with SageMaker Processing](#6)\n",
    "* [Data Splitting](#8)\n",
    "* [Model Selection](#9)\n",
    "* [Training with SageMaker Estimator and Experiment](#10)\n",
    "* [Hyperparameter Tuning with SageMaker Hyperparameter Tuning Job](#11)\n",
    "* [Deploy the model with SageMaker Batch-transform](#12)\n",
    "* [Model Explainability with SageMaker Clarify](#15)\n",
    "* [Optional: Automate your training and model selection with SageMaker Autopilot (Console)](#13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### What is Customer Churn and why is it important for businesses?\n",
    "\n",
    "Customer churn, or customer retention/attrition, means a customer has the tendency to leave and stop paying for a business. It is one of the primary metrics companies want to track to get a sense of their customer satisfaction, especially for a subscription-based business model. The company can track churn rate (defined as the percentage of customers churned during a period) as a health indicator for the business, but we would love to identify the at-risk customers before they churn and offer appropriate treatment to keep them with the business, and this is where machine learning comes into play.\n",
    "### Use Cases for Customer Churn\n",
    "\n",
    "Any subscription-based business would track customer churn as one of the most critical Key Performance Indicators (KPIs). Such companies and industries include Telecom companies (cable, cell phone, internet, etc.), digital subscriptions of media (news, forums, blogposts platforms, etc.), music and video streaming services, and other Software as a Service (SaaS) providers (e-commerce, CRM, Mar-Tech, cloud computing, video conference provider, and visualization and data science tools, etc.)\n",
    "\n",
    "### Define Business problem\n",
    "\n",
    "To start with, here are some common business problems to consider depending on your specific use cases and your focus:\n",
    "\n",
    " * Will this customer churn (cancel the plan, cancel the subscription)?\n",
    " * Will this customer downgrade a pricing plan?\n",
    " * For a subscription business model, will a customer renew his/her subscription?\n",
    "\n",
    "### Machine learning problem formulation\n",
    "\n",
    "#### Classification: will this customer churn?\n",
    "\n",
    "To goal of classification is to identify the at-risk customers and sometimes their unusual behavior, such as: will this customer churn or downgrade their plan? Is there any unusual behavior for a customer? The latter question can be formulated as an anomaly detection problem.\n",
    "\n",
    "#### Time Series: will this customer churn in the next X months? When will this customer churn?\n",
    "\n",
    "You can further explore your users by formulating the problem as a time series one and detect when will the customer churn.\n",
    "\n",
    "### Data Requirements\n",
    "\n",
    "#### Data collection Sources\n",
    "\n",
    "Some most common data sources used to construct a data set for churn analysis are:\n",
    "* Customer Relationship Management platform (CRM), \n",
    "* engagement and usage data (analytics services), \n",
    "* passive feedback (ratings based on your request), and active feedback (customer support request, feedback on social media and review platforms).\n",
    "\n",
    "#### Construct a Data Set for Churn Analysis\n",
    "\n",
    "Most raw data collected from the sources mentioned above are huge and often needs a lot of cleaning and pre-processing. For example, usage data is usually event-based log data and can be more than a few gigabytes every day; you can aggregate the data to user-level daily for further analysis. Feedback and review data are mostly text data, so you would need to clean and pre-process the natural language data to be normalized, machine-readable data. If you are joining multiple data sources (especially from different platforms) together, you would want to make sure all data points are consistent, and the user identity can be matched across different platforms.\n",
    "           \n",
    "#### Challenges with Customer Churn\n",
    "\n",
    "* Business related\n",
    "    * Importance of domain knowledge: this is critical when you start building features for the machine learning model. It is important to understand the business enough to decide which features would trigger retention.\n",
    "* Data issues\n",
    "    * fewer churn data available (imbalanced classes): data for churn analysis is often very imbalanced as most of the customers of a business are happy customers (usually).\n",
    "    * User identity mapping problem: if you are joining data from different platforms (CRM, email, feedback, mobile app, and website usage data), you would want to make sure user A is recognized as the same user across multiple platforms. There are third-party solutions that help you tackle this problem.\n",
    "    * Not collecting the right data for the use case or Lacking enough data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "You can experiment with all your model choices and see which one gives better results. A few things to note when you choose algorithms:\n",
    "* **Start with simple ones**: Usually for tabular data classification that does not contain complex unstructured data (text, audio, image, etc.), you can start with logistic regression to see how your data performs, as sometimes the simplest model gives great results if your data have a strong linear pattern.\n",
    "\n",
    "* **Think about your data structure**: For imbalanced class data like churn analysis, you can experiment with tree-based models like the random forest, gradient boosting, or XGboost since they are less sensitive to class imbalance.\n",
    "\n",
    "* **Interpretability**: logistic regression model generally has better interpretability because of its linearity. You can also use feature importance from tree-based models or Support Vector Machines as an overall observation, but not to your predicting instance level. Instead, you can utilize tools like SHAP or the SageMaker new feature SageMaker Clarify to better visualize which feature contributing more to your prediction results.\n",
    "\n",
    "In this use case, a tree-based model XGBoost is chosen due to consideration of imbalanced class, and in the family of tree based models, XGBoost usually gives best results as its built for model performance and computational speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='10'></a>\n",
    "\n",
    "## Training with SageMaker Estimator and Experiment\n",
    "\n",
    "Once you decide on a range of models you want to experiment with, you can start training and comparing model results to choose the best one. A few things left for you to make a decision:\n",
    "* SageMaker estimator configuration\n",
    "  * to initialize your training job, you would need to config your SageMaker estimator and SageMaker training image by specifying the model choice, instance size, and type.\n",
    "* Choose evaluation methods\n",
    "    * You can check the [model parameter documentation page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst#learning-task-parameters) for all the evaluation metrics you can choose for a model. For a imbalanced classification problem, you can choose F1 as your evaluation especially for comparing different models;  area under curve (auc) is also a good choice when your output is probability.\n",
    "* Hyper-parameters\n",
    "    * You can look at the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) for a complete list of hyper-parameters tunable for the model (The XGBoost model here was given as an example). For best performances, you can experiment with a range of combinations for the hyper-parameters and compare the validation results.\n",
    "   \n",
    "### How to create a training job as a trial in SageMaker Experiment    \n",
    "\n",
    "#### Get ECR image URIs for pre-built SageMaker Docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import s3fs\n",
    "import boto3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3 = sagemaker_session.boto_session.resource(\"s3\")\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"music-streaming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\n",
    "    \"xgboost\", region, version=\"1.0-1\", instance_type=\"ml.m4.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"12\",\n",
    "    \"eta\": \"0.08\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"7\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"800\",\n",
    "    \"early_stopping_rounds\": \"50\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SageMaker estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 µs, sys: 0 ns, total: 102 µs\n",
      "Wall time: 309 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}/\".format(bucket, prefix, \"train\"), content_type=content_type\n",
    ")\n",
    "validation_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}/\".format(bucket, prefix, \"validation\"), content_type=content_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-29 21:58:04 Starting - Starting the training job...\n",
      "2022-04-29 21:58:28 Starting - Preparing the instances for trainingProfilerReport-1651269483: InProgress\n",
      ".........\n",
      "2022-04-29 21:59:56 Downloading - Downloading input data...\n",
      "2022-04-29 22:00:31 Training - Downloading the training image......\n",
      "2022-04-29 22:01:27 Training - Training image download completed. Training in progress..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:01:32] 708x25 matrix with 17700 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:01:32] 204x25 matrix with 5100 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 708 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 204 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.91768#011validation-auc:0.94514\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.92026#011validation-auc:0.95180\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.93830#011validation-auc:0.95534\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.93852#011validation-auc:0.95507\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.95391#011validation-auc:0.96667\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.95654#011validation-auc:0.96758\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.95694#011validation-auc:0.96468\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.96200#011validation-auc:0.96473\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.96468#011validation-auc:0.96720\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.96311#011validation-auc:0.96699\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.96290#011validation-auc:0.96871\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.96521#011validation-auc:0.97434\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.96481#011validation-auc:0.97182\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.96483#011validation-auc:0.97386\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.96442#011validation-auc:0.97375\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.96458#011validation-auc:0.97418\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.96498#011validation-auc:0.97563\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.96619#011validation-auc:0.97724\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.96492#011validation-auc:0.97681\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.96406#011validation-auc:0.97584\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.96365#011validation-auc:0.97584\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.96428#011validation-auc:0.97381\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.96540#011validation-auc:0.97348\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.96511#011validation-auc:0.97445\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.96481#011validation-auc:0.97450\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.96465#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.96503#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.96627#011validation-auc:0.97364\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.96733#011validation-auc:0.97289\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.96781#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.96757#011validation-auc:0.97300\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.96827#011validation-auc:0.97300\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.96887#011validation-auc:0.97332\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.96900#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.96905#011validation-auc:0.97332\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.96980#011validation-auc:0.97440\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.96945#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.96924#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.96936#011validation-auc:0.97418\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.96936#011validation-auc:0.97418\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.96933#011validation-auc:0.97407\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.96896#011validation-auc:0.97343\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.96899#011validation-auc:0.97348\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.96945#011validation-auc:0.97359\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.96924#011validation-auc:0.97391\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.96974#011validation-auc:0.97423\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.97061#011validation-auc:0.97477\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.97083#011validation-auc:0.97467\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.97080#011validation-auc:0.97467\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.97067#011validation-auc:0.97456\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.97121#011validation-auc:0.97456\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.97121#011validation-auc:0.97456\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.97181#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.97159#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.97159#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.97246#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.97246#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.97246#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.97333#011validation-auc:0.97515\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.97349#011validation-auc:0.97515\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.97359#011validation-auc:0.97515\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.97353#011validation-auc:0.97525\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.97353#011validation-auc:0.97525\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.97353#011validation-auc:0.97525\u001b[0m\n",
      "\n",
      "2022-04-29 22:01:57 Uploading - Uploading generated training model\n",
      "2022-04-29 22:01:57 Completed - Training job completed\n",
      "Training seconds: 113\n",
      "Billable seconds: 113\n",
      "CPU times: user 465 ms, sys: 20.3 ms, total: 485 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit(inputs={\"train\": train_input, \"validation\": validation_input}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SageMaker Experiment and Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom trial name\n",
    "experiment_name = \"music-streaming-churn-exp-{}\".format(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "trial_name_xgb = \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment creation music-streaming-churn-exp: SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2022-04-29-22-02-17-343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create trial xgboost: SUCCESSFUL\n",
      "2022-04-29 22:02:17 Starting - Starting the training job...\n",
      "2022-04-29 22:02:44 Starting - Preparing the instances for trainingProfilerReport-1651269737: InProgress\n",
      ".........\n",
      "2022-04-29 22:04:14 Downloading - Downloading input data...\n",
      "2022-04-29 22:04:45 Training - Downloading the training image......\n",
      "2022-04-29 22:05:46 Training - Training image download completed. Training in progress...\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:05:50] 708x25 matrix with 17700 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:05:50] 204x25 matrix with 5100 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 708 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 204 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.91768#011validation-auc:0.94514\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.92026#011validation-auc:0.95180\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.93830#011validation-auc:0.95534\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.93852#011validation-auc:0.95507\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.95391#011validation-auc:0.96667\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.95654#011validation-auc:0.96758\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.95694#011validation-auc:0.96468\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.96200#011validation-auc:0.96473\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.96468#011validation-auc:0.96720\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.96311#011validation-auc:0.96699\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.96290#011validation-auc:0.96871\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.96521#011validation-auc:0.97434\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.96481#011validation-auc:0.97182\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.96483#011validation-auc:0.97386\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.96442#011validation-auc:0.97375\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.96458#011validation-auc:0.97418\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.96498#011validation-auc:0.97563\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.96619#011validation-auc:0.97724\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.96492#011validation-auc:0.97681\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.96406#011validation-auc:0.97584\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.96365#011validation-auc:0.97584\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.96428#011validation-auc:0.97381\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.96540#011validation-auc:0.97348\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.96511#011validation-auc:0.97445\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.96481#011validation-auc:0.97450\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.96465#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.96503#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.96627#011validation-auc:0.97364\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.96733#011validation-auc:0.97289\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.96781#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.96757#011validation-auc:0.97300\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.96827#011validation-auc:0.97300\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.96887#011validation-auc:0.97332\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.96900#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.96905#011validation-auc:0.97332\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.96980#011validation-auc:0.97440\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.96945#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.96924#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.96936#011validation-auc:0.97418\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.96936#011validation-auc:0.97418\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.96933#011validation-auc:0.97407\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.96896#011validation-auc:0.97343\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.96899#011validation-auc:0.97348\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.96945#011validation-auc:0.97359\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.96924#011validation-auc:0.97391\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.96974#011validation-auc:0.97423\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.97061#011validation-auc:0.97477\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.97083#011validation-auc:0.97467\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.97080#011validation-auc:0.97467\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.97067#011validation-auc:0.97456\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.97121#011validation-auc:0.97456\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.97121#011validation-auc:0.97456\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.97181#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.97159#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.97159#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.97246#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.97246#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.97246#011validation-auc:0.97504\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.97323#011validation-auc:0.97493\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.97333#011validation-auc:0.97515\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.97349#011validation-auc:0.97515\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.97359#011validation-auc:0.97515\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.97353#011validation-auc:0.97525\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.97353#011validation-auc:0.97525\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.97353#011validation-auc:0.97525\u001b[0m\n",
      "\n",
      "2022-04-29 22:06:07 Uploading - Uploading generated training model\n",
      "2022-04-29 22:06:07 Completed - Training job completed\n",
      "Training seconds: 113\n",
      "Billable seconds: 113\n",
      "CPU times: user 994 ms, sys: 74.8 ms, total: 1.07 s\n",
      "Wall time: 4min 13s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>early_stopping_rounds</th>\n",
       "      <th>eta</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>...</th>\n",
       "      <th>train:auc - Last</th>\n",
       "      <th>train:auc - Count</th>\n",
       "      <th>train - MediaType</th>\n",
       "      <th>train - Value</th>\n",
       "      <th>validation - MediaType</th>\n",
       "      <th>validation - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sagemaker-xgboost-2022-04-29-22-02-17-343-aws-...</td>\n",
       "      <td>churn-xgboost</td>\n",
       "      <td>arn:aws:sagemaker:us-west-2:688520471316:train...</td>\n",
       "      <td>246618743249.dkr.ecr.us-west-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m4.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>auc</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96905</td>\n",
       "      <td>35</td>\n",
       "      <td>csv</td>\n",
       "      <td>s3://sagemaker-us-west-2-688520471316/music-st...</td>\n",
       "      <td>csv</td>\n",
       "      <td>s3://sagemaker-us-west-2-688520471316/music-st...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-west-2-688520471316/music-st...</td>\n",
       "      <td>[xgboost]</td>\n",
       "      <td>[music-streaming-churn-exp]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName    DisplayName  \\\n",
       "0  sagemaker-xgboost-2022-04-29-22-02-17-343-aws-...  churn-xgboost   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0  arn:aws:sagemaker:us-west-2:688520471316:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0  246618743249.dkr.ecr.us-west-2.amazonaws.com/s...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB  early_stopping_rounds  \\\n",
       "0           ml.m4.xlarge                      30.0                   50.0   \n",
       "\n",
       "    eta eval_metric  ...  train:auc - Last  train:auc - Count  \\\n",
       "0  0.08         auc  ...           0.96905                 35   \n",
       "\n",
       "   train - MediaType                                      train - Value  \\\n",
       "0                csv  s3://sagemaker-us-west-2-688520471316/music-st...   \n",
       "\n",
       "  validation - MediaType                                 validation - Value  \\\n",
       "0                    csv  s3://sagemaker-us-west-2-688520471316/music-st...   \n",
       "\n",
       "   SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                 None   \n",
       "\n",
       "                     SageMaker.ModelArtifact - Value     Trials  \\\n",
       "0  s3://sagemaker-us-west-2-688520471316/music-st...  [xgboost]   \n",
       "\n",
       "                   Experiments  \n",
       "0  [music-streaming-churn-exp]  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from smexperiments import experiment, trial\n",
    "from sagemaker import analytics\n",
    "\n",
    "# create experiment if it doesn't exist\n",
    "try:\n",
    "    my_experiment = experiment.Experiment.load(experiment_name=experiment_name)\n",
    "    print(f\"Experiment loaded {experiment_name}: SUCCESS\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_experiment = experiment.Experiment.create(experiment_name=experiment_name)\n",
    "        print(f\"Experiment creation {experiment_name}: SUCCESS\")\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    my_trial = trial.Trial.load(trial_name=trial_name_xgb)\n",
    "    print(f\"Trial loaded {trial_name_xgb}: SUCCESS\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_trial = trial.Trial.create(experiment_name=experiment_name, trial_name=trial_name_xgb)\n",
    "        print(f\"Create trial {my_trial.trial_name}: SUCCESSFUL\")\n",
    "\n",
    "\n",
    "xgb.fit(\n",
    "    inputs={\"train\": train_input, \"validation\": validation_input},\n",
    "    wait=True,\n",
    "    experiment_config={\n",
    "        \"ExperimentName\": my_experiment.experiment_name,\n",
    "        \"TrialName\": my_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"churn-xgboost\",\n",
    "    },\n",
    "    logs=True,\n",
    ")\n",
    "\n",
    "trial_component_analytics = analytics.ExperimentAnalytics(\n",
    "    experiment_name=my_experiment.experiment_name\n",
    ")\n",
    "\n",
    "analytic_table = trial_component_analytics.dataframe()\n",
    "analytic_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11'></a>\n",
    "\n",
    "## Hyperparameter Tuning with SageMaker Hyperparameter Tuning Job\n",
    "\n",
    "Now that you understand how training one model works and how to create a SageMaker experiment, and selected the XGBoost model as the final model, you will need to fine-tune the hyperparameters for the best model performances. For a xgboost model, you can start with defining ranges for the eta, alpha, min_child_weight, and max_depth. You can check the [documentation when considering what haperparameter to tune](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-considerations.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the Hyperparameter Tuning Job Settings\n",
    "\n",
    "To specify settings for the hyperparameter tuning job, you define a JSON object. You pass the object as the value of the HyperParameterTuningJobConfig parameter to CreateHyperParameterTuningJob when you create the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "        \"CategoricalParameterRanges\": [],\n",
    "        \"ContinuousParameterRanges\": [\n",
    "            {\"MaxValue\": \"1\", \"MinValue\": \"0\", \"Name\": \"eta\"},\n",
    "            {\"MaxValue\": \"2\", \"MinValue\": \"0\", \"Name\": \"alpha\"},\n",
    "            {\"MaxValue\": \"10\", \"MinValue\": \"1\", \"Name\": \"min_child_weight\"},\n",
    "        ],\n",
    "        \"IntegerParameterRanges\": [{\"MaxValue\": \"10\", \"MinValue\": \"1\", \"Name\": \"max_depth\"}],\n",
    "    },\n",
    "    \"ResourceLimits\": {\"MaxNumberOfTrainingJobs\": 20, \"MaxParallelTrainingJobs\": 3},\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"TrainingJobEarlyStoppingType\": \"Auto\",\n",
    "    \"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:auc\", \"Type\": \"Maximize\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Training Jobs\n",
    "\n",
    "To configure the training jobs that the tuning job launches, define a JSON object that you pass as the value of the TrainingJobDefinition parameter of the CreateHyperParameterTuningJob call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = \"s3://{}/{}/train\".format(bucket, prefix)\n",
    "s3_input_validation = \"s3://{}/{}/validation\".format(bucket, prefix)\n",
    "\n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"ContentType\": \"csv\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_input_train,\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"ContentType\": \"csv\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_input_validation,\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/output\".format(bucket, prefix)},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 2, \"InstanceType\": \"ml.c4.2xlarge\", \"VolumeSizeInGB\": 10},\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"num_round\": \"100\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"rate_drop\": \"0.3\",\n",
    "        \"tweedie_variance_power\": \"1.4\",\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 43200},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name and Launch the Hyperparameter Tuning Job\n",
    "\n",
    "Now you can provide a name for the hyperparameter tuning job and then launch it by calling the CreateHyperParameterTuningJob API. Pass tuning_job_config, and training_job_definition that you created in previous steps as the values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tuning_job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# custom a tuner job name\n",
    "tuning_job_name = \"ChurnPrediction-Tuning-Job-{}\".format(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tuner job has been created\n",
    "list_tuning_job = smclient.list_hyper_parameter_tuning_jobs(NameContains=tuning_job_name)\n",
    "job_results = [[i for i in list_tuning_job[x]] for x in list_tuning_job.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobSummaries': [],\n",
       " 'NextToken': 'cIws2QhTXUIa8bi8W47LEKvF+FCR8eCxw7lm05/6M4GEnbWgUtoUJdlQBSv7kOsUKyeD3vlHXjc+jwuuBpymNWHzVbJTQRgpv3gKfmL4gypEQUDRwvEqhJzEDswtvI3HovY77Q4w795ItXG+PyA0eT/CNgcnCrkGC1ZBCjvUDG3ik8HgfI2+WPs8rSJrNtI86VXlB+tKqBzfn6e0wkIVyMjnAtA653gJLJ6HYJjCA4wq7Q5HqeZyUP62UPhU2KKXNbvdlD2x/3WC9Z37Re53/rYLhSnzqCBH0BVz1OS0vsRuL4QUzHmrVw/b6rngygpW57lbB2WQkZJqB9yyBXjOO/G3BELqDX7SKGDYEQw6j3jklpEwBM//HEqMOppRWmDr7bpGrVFs1aWy/a79jjTWTMe2916jd/I5RWvegPXL1o5E6lfkb+7ZbMelxH2Idtj8LF6B38/DNdYEDXnjeNoXRTjUTPBb5ay0ExcwPqHQs3wSax6Js7KazMxNQBDSVOcFJ7FfjGA/CTd71ya/S6l23g5PtLj8bPbn97oJn2Xej6tvFumWLATRDxWFTQIgE9mZylxrQEYM3kVymvSvzVg42WJdbtFzikOsFPjzyaO/T7lll9K2XUY7SWsybD+NQ/JNBSimd73sbOfy',\n",
       " 'ResponseMetadata': {'RequestId': '86f3a2ff-4ab7-40af-9262-0c8034a1347f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '86f3a2ff-4ab7-40af-9262-0c8034a1347f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '706',\n",
       "   'date': 'Fri, 29 Apr 2022 22:06:30 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.list_hyper_parameter_tuning_jobs(NameContains=tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create tuning job ChurnPrediction-Tuning-Job: SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# create the tuning job if it doesn't exist\n",
    "try:\n",
    "    if tuning_job_name == job_results[0][0][\"HyperParameterTuningJobName\"]:\n",
    "        print(f\"Tuning job exists\")\n",
    "except Exception as ex:\n",
    "    # create hyperparameter tuning job\n",
    "    smclient.create_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuning_job_name,\n",
    "        HyperParameterTuningJobConfig=tuning_job_config,\n",
    "        TrainingJobDefinition=training_job_definition,\n",
    "    )\n",
    "    print(f\"Create tuning job {tuning_job_name}: SUCCESSFUL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Progress of a Hyperparameter Tuning Job\n",
    "\n",
    "To monitor the progress of a hyperparameter tuning job and the training jobs that it launches, you can use the Amazon SageMaker console.\n",
    "\n",
    "<div>\n",
    "<img src=\"image/hp1.PNG\" width=\"600\"/>\n",
    "   </div>\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='12'></a>\n",
    "## Deploy the model with SageMaker Batch-transform\n",
    "\n",
    "You can directly deploy the best model from your hyperparameter tuning job by getting the best training job from your tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "CPU times: user 556 ms, sys: 53.8 ms, total: 610 ms\n",
      "Wall time: 25min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# check status\n",
    "import time\n",
    "\n",
    "status = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(60)\n",
    "    status = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuning_job_name\n",
    "    )[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChurnPrediction-Tuning-Job-010-f4b35971\n",
      "\n",
      "2022-04-29 22:19:24 Starting - Preparing the instances for training\n",
      "2022-04-29 22:19:24 Downloading - Downloading input data\n",
      "2022-04-29 22:19:24 Training - Training image download completed. Training in progress.\n",
      "2022-04-29 22:19:24 Uploading - Uploading generated training model\n",
      "2022-04-29 22:19:24 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2022-04-29-22-31-36-166\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2022-04-29-22-31-36-813\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2022-04-29-22-31-36-813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!CPU times: user 306 ms, sys: 12.4 ms, total: 318 ms\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Attach to an existing hyperparameter tuning job.\n",
    "tuning_job_details = smclient.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "xgb_tuner = HyperparameterTuner.attach(\n",
    "    tuning_job_name,\n",
    "    job_details=tuning_job_details,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    estimator_cls=None,\n",
    ")\n",
    "\n",
    "# Get the best XGBoost training job name from the HPO job\n",
    "xgb_best_training_job = xgb_tuner.best_training_job()\n",
    "print(xgb_best_training_job)\n",
    "# Attach estimator to the best training job name\n",
    "best_estimator = sagemaker.estimator.Estimator.attach(xgb_best_training_job)\n",
    "\n",
    "# Create model to be passed to the inference pipeline\n",
    "best_model = sagemaker.model.Model(\n",
    "    model_data=best_estimator.model_data,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri=best_estimator.image_uri,\n",
    ")\n",
    "\n",
    "predictor = best_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following code to find and deploy the best model. Replace with your best model output path. Go to SageMaker Console $\\rightarrow$ Hyperparameter Tuning Job $\\rightarrow$ [Your hyperparameter Tuning Job] $\\rightarrow$ Best model $\\rightarrow$ Output. You can also choose to **create a model** from the console under **best training job**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your best model output path\n",
    "# model_artifacts = 's3://{}/{}/output/ChurnPrediction-TuningJob-020-20eee831/output/model.tar.gz'.format(bucket, prefix)\n",
    "# best_model = sagemaker.model.Model(\n",
    "#    model_data= model_artifacts,\n",
    "#    image_uri =container,\n",
    "#    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The location of the test dataset\n",
    "test_data = pd.read_csv(\"data/test_w_header.csv\")\n",
    "test_set = test_data.drop(columns=[\"user_churned\"])\n",
    "test_set.to_csv(\"data/test.csv\", index=False, header=False)\n",
    "s3_input_validation = (\n",
    "    boto3.Session()\n",
    "    .resource(\"s3\")\n",
    "    .Bucket(bucket)\n",
    "    .Object(os.path.join(prefix, \"test/testdata/test.csv\"))\n",
    "    .upload_file(\"data/test.csv\")\n",
    ")\n",
    "\n",
    "batch_input = \"s3://{}/{}/test/testdata\".format(bucket, prefix)\n",
    "\n",
    "batch_output = \"s3://{}/{}/batch-inference\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2022-04-29-22-34-07-950\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2022-04-29-22-34-08-567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................\n",
      ".\u001b[34m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:30:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:30:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"POST /invocations HTTP/1.1\" 200 2006 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"POST /invocations HTTP/1.1\" 200 2006 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-04-29T22:39:37.156:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:30:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:30:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[34m[2022-04-29 22:39:31 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[35m[2022-04-29 22:39:31 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-04-29:22:39:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"POST /invocations HTTP/1.1\" 200 2006 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-04-29:22:39:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2022:22:39:37 +0000] \"POST /invocations HTTP/1.1\" 200 2006 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-04-29T22:39:37.156:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer = best_model.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m4.xlarge\", output_path=batch_output\n",
    ")\n",
    "transformer.transform(\n",
    "    data=batch_input, data_type=\"S3Prefix\", content_type=\"text/csv\", split_type=\"Line\"\n",
    ")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the previous step to be completed. Once done, you can download the prediction results to your instance for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket).download_file(prefix + \"/batch-inference/test.csv.out\", \"batch_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_results\") as f:\n",
    "    results = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model results to actual\n",
    "\n",
    "You can evaluate your model results with the test data you left out earlier and check the precision and recall. In customer churn problem, precision and recall means:\n",
    "\n",
    "* Precision – Of all the users that the algorithm predicts will churn, how many of them do actually churn?\n",
    "* Recall – What percentage of users that end up churning does the algorithm successfully find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_churned</th>\n",
       "      <th>predicted_results</th>\n",
       "      <th>predicted_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_churned  predicted_results  predicted_binary\n",
       "0             0.0           0.069090                 0\n",
       "1             0.0           0.026726                 0\n",
       "2             0.0           0.027686                 0\n",
       "3             0.0           0.080675                 0\n",
       "4             0.0           0.017445                 0\n",
       "..            ...                ...               ...\n",
       "97            1.0           0.986643                 1\n",
       "98            1.0           0.964494                 1\n",
       "99            1.0           0.106448                 0\n",
       "100           1.0           0.975653                 1\n",
       "101           1.0           0.989780                 1\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"predicted_results\"] = pd.to_numeric(results)\n",
    "# define a threshold to convert probability to class, you can set as 0.5 by default\n",
    "test_data[\"predicted_binary\"] = [1 if x >= 0.5 else 0 for x in test_data[\"predicted_results\"]]\n",
    "test_data[[\"user_churned\", \"predicted_results\", \"predicted_binary\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You did a good job and your model can detect 85% of the users who are going to churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Evaluation: \n",
      "Average F1 Score:  0.8861607142857144\n",
      "Precision Score:  0.9310344827586207\n",
      "Recall Score:  0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "test_labels = test_data[\"user_churned\"]\n",
    "test_pred = test_data[\"predicted_binary\"]\n",
    "\n",
    "test_f1 = metrics.f1_score(test_labels, test_pred, average=None)\n",
    "# fbeta_test= metrics.f1_score(mtest_labels, mpreds_test_xgb, average=None)\n",
    "prec, rec, fbeta_test, support = metrics.precision_recall_fscore_support(\n",
    "    test_labels, test_pred, average=None\n",
    ")\n",
    "metrics.precision_recall_fscore_support(test_labels, test_pred, average=None)\n",
    "print(\"Test Evaluation: \")\n",
    "print(\"Average F1 Score: \", (test_f1[0] + test_f1[1]) / 2)\n",
    "print(\"Precision Score: \", (prec[1]))\n",
    "print(\"Recall Score: \", (rec[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='15'></a>\n",
    "\n",
    "## Model Explainability with SageMaker Clarify\n",
    "\n",
    "You can visualize which feature contributes most to your prediction results by using the new SageMaker feature SageMaker Clarify. It  will provide SHAP values which measures the importance of a feature by replacing it with a dummy and seeing how it affects the prediciton. (In reality, SHAP is smart about the choice of dummy and also takes into account feature interactions.)  For a more general overview of model interpretability, see [this post](https://towardsdatascience.com/guide-to-interpretable-machine-learning-d40e8a64b6cf). For other capabilities of SageMaker Clarify, please see the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-fairness-and-explainability.html) and the [example notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.0.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, instance_count=1, instance_type=\"ml.c4.xlarge\", sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_uri = \"s3://{}/{}/train/train.csv\".format(bucket, prefix).format(bucket, prefix)\n",
    "train_input = TrainingInput(train_uri, content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "xgb_endpoint_name = smclient.list_endpoints()[\"Endpoints\"][0][\"EndpointName\"]\n",
    "xgb_model_name = smclient.list_models()[\"Models\"][0][\"ModelName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_binary', 'predicted_results', 'user_churned'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_data.columns) - set(test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:DataConfig will be deprecated on 15 Mar 2022.s3_data_distribution_type parameter will no longer be supported. Everything else will remain as is in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=[test_set.iloc[0].values.tolist()], num_samples=100, agg_method=\"mean_abs\"\n",
    ")\n",
    "\n",
    "explainability_output_path = \"s3://{}/{}/clarify-explainability\".format(bucket, prefix)\n",
    "\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_uri,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label=\"user_churned\",\n",
    "    headers=test_data.drop([\"predicted_results\", \"predicted_binary\"], axis=1).columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=xgb_model_name,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name Clarify-Explainability-2022-04-29-22-39-55-756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Explainability-2022-04-29-22-39-55-756\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-688520471316/music-streaming/train/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-688520471316/music-streaming/clarify-explainability/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-688520471316/music-streaming/clarify-explainability', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".....................................\u001b[34m2022-04-29 22:45:55,125 logging.conf not found when configuring logging, using default logging configuration.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,125 Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,126 Analysis config path: /opt/ml/processing/input/config/analysis_config.json\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,126 Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,127 This host is algo-1.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,127 This host is the leader.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,127 Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,287 Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,288 Dataset type: text/csv uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,296 Loading dataset...\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,314 Loaded dataset. Dataset info:\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mRangeIndex: 708 entries, 0 to 707\u001b[0m\n",
      "\u001b[34mData columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \u001b[0m\n",
      "\u001b[34m---  ------                   --------------  -----  \n",
      " 0   average_events_weekend   708 non-null    float64\n",
      " 1   average_events_weekday   708 non-null    float64\n",
      " 2   num_songs_played_7d      708 non-null    int64  \n",
      " 3   num_ads_7d               708 non-null    int64  \n",
      " 4   num_error_7d             708 non-null    int64  \n",
      " 5   num_songs_played_30d     708 non-null    int64  \n",
      " 6   num_songs_played_90d     708 non-null    int64  \n",
      " 7   num_sessions             708 non-null    int64  \n",
      " 8   avg_time_per_session     708 non-null    float64\n",
      " 9   avg_events_per_session   708 non-null    float64\n",
      " 10  avg_gap_between_session  708 non-null    float64\n",
      " 11  num_events               708 non-null    int64  \n",
      " 12  num_songs                708 non-null    int64  \n",
      " 13  num_artists              708 non-null    int64  \n",
      " 14  num_thumbs_down          708 non-null    int64  \n",
      " 15  num_thumbs_up            708 non-null    int64  \n",
      " 16  num_add_to_playlist      708 non-null    int64  \n",
      " 17  num_ads                  708 non-null    int64  \n",
      " 18  num_add_friend           708 non-null    int64  \n",
      " 19  num_downgrade            708 non-null    int64  \n",
      " 20  num_upgrade              708 non-null    int64  \n",
      " 21  num_error                708 non-null    int64  \n",
      " 22  percentage_ad            708 non-null    float64\n",
      " 23  days_since_active        708 non-null    int64  \n",
      " 24  repeats_ratio            708 non-null    float64\u001b[0m\n",
      "\u001b[34mdtypes: float64(7), int64(18)\u001b[0m\n",
      "\u001b[34mmemory usage: 138.4 KB\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,482 Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,483 Creating endpoint-config with name sm-clarify-config-1651272355-5750\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,567 Creating endpoint: 'sm-clarify-sagemaker-xgboost-2022-04-29-22-34-0-1651272355-86d1'\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,831 Using endpoint name: sm-clarify-sagemaker-xgboost-2022-04-29-22-34-0-1651272355-86d1\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,832 Waiting for endpoint ...\u001b[0m\n",
      "\u001b[34m2022-04-29 22:45:55,832 Checking endpoint status:\u001b[0m\n",
      "\u001b[34mLegend:\u001b[0m\n",
      "\u001b[34m(OutOfService: x, Creating: -, Updating: -, InService: !, RollingBack: <, Deleting: o, Failed: *)\u001b[0m\n",
      "\u001b[34m2022-04-29 22:49:56,323 Endpoint is in service after 240 seconds\u001b[0m\n",
      "\u001b[34m2022-04-29 22:49:56,323 Endpoint ready.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:49:56,326 SHAP n_samples 100\u001b[0m\n",
      "\u001b[34m2022-04-29 22:49:56,480 =====================================================\u001b[0m\n",
      "\u001b[34m2022-04-29 22:49:56,480 Shap analyzer: explaining 708 rows, 25 columns...\u001b[0m\n",
      "\u001b[34m2022-04-29 22:49:56,480 =====================================================\n",
      "  0% (0 of 708) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--\u001b[0m\n",
      "\u001b[34m100% (708 of 708) |######################| Elapsed Time: 0:00:16 Time:  0:00:16\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,201 getting explanations took 16.72 seconds.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,201 ===================================================\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,271 converting explanations to tabular took 0.07 seconds.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,271 ===================================================\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,274 Wrote baseline used to compute explanations to: /opt/ml/processing/output/explanations_shap/baseline.csv\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,298 Wrote 708 local explanations to: /opt/ml/processing/output/explanations_shap/out.csv\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,299 writing local explanations took 0.03 seconds.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,299 ===================================================\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,301 aggregating local explanations took 0.00 seconds.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,301 ===================================================\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,301 Shap analysis finished.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,302 Stop using endpoint: sm-clarify-sagemaker-xgboost-2022-04-29-22-34-0-1651272355-86d1\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,302 Deleting endpoint configuration with name: sm-clarify-config-1651272355-5750\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,407 Deleting endpoint with name: sm-clarify-sagemaker-xgboost-2022-04-29-22-34-0-1651272355-86d1\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:13,528 Model endpoint delivered 41.81825 requests per second and a total of 710 requests over 17 seconds\u001b[0m\n",
      "\u001b[34m2022-04-29 22:50:17,557 Stop using endpoint: None\u001b[0m\n",
      "\n",
      "\u001b[34m2022-04-29 22:51:24,009 jupyter nbconvert --to html --output /opt/ml/processing/output/report.html /opt/ml/processing/output/report.ipynb --template sagemaker-xai\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 534585 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34m2022-04-29 22:51:25,148 HTML report '/opt/ml/processing/output/report.html' generated successfully.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:51:25,148 wkhtmltopdf -q /opt/ml/processing/output/report.html /opt/ml/processing/output/report.pdf\u001b[0m\n",
      "\u001b[34m2022-04-29 22:51:25,809 PDF report '/opt/ml/processing/output/report.pdf' generated successfully.\u001b[0m\n",
      "\u001b[34m2022-04-29 22:51:25,810 Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"explanations\": {\n",
      "        \"kernel_shap\": {\n",
      "            \"label0\": {\n",
      "                \"global_shap_values\": {\n",
      "                    \"average_events_weekend\": 0.0021496041898171037,\n",
      "                    \"average_events_weekday\": 0.016587702435219898,\n",
      "                    \"num_songs_played_7d\": 0.0017402863783950045,\n",
      "                    \"num_ads_7d\": 0.00868551809925556,\n",
      "                    \"num_error_7d\": 0.0027734162552485904,\n",
      "                    \"num_songs_played_30d\": 0.0011722262443900576,\n",
      "                    \"num_songs_played_90d\": 0.0012286071144514484,\n",
      "                    \"num_sessions\": 0.0011579425530513692,\n",
      "                    \"avg_time_per_session\": 0.010029593923214982,\n",
      "                    \"avg_events_per_session\": 0.003897350916100629,\n",
      "                    \"avg_gap_between_session\": 0.0448815105461223,\n",
      "                    \"num_events\": 0.0010721354650824332,\n",
      "                    \"num_songs\": 0.0010824064811915818,\n",
      "                    \"num_artists\": 0.0011435948826397841,\n",
      "                    \"num_thumbs_down\": 0.0022934530809684047,\n",
      "                    \"num_thumbs_up\": 0.0010034211293590313,\n",
      "                    \"num_add_to_playlist\": 0.001163952744967679,\n",
      "                    \"num_ads\": 0.0010789208860291896,\n",
      "                    \"num_add_friend\": 0.005465492600682657,\n",
      "                    \"num_downgrade\": 0.001048377920399092,\n",
      "                    \"num_upgrade\": 0.002673292801161779,\n",
      "                    \"num_error\": 0.0011517907319294842,\n",
      "                    \"percentage_ad\": 0.02861671713801823,\n",
      "                    \"days_since_active\": 0.29080317686448776,\n",
      "                    \"repeats_ratio\": 0.001010326307543725\n",
      "                },\n",
      "                \"expected_value\": 0.06909029185771942\n",
      "            }\n",
      "        }\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-04-29 22:51:25,810 exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\u001b[34m----!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='13'></a>\n",
    "\n",
    "## Optional: Automate your training and model selection with SageMaker Autopilot (Console)\n",
    "\n",
    "With [SageMaker Autopilot](https://aws.amazon.com/blogs/aws/amazon-sagemaker-autopilot-fully-managed-automatic-machine-learning/), you can skip all the steps above and let it automatically tracks the inputs, parameters, configurations, and results of your iterations as trials. Go to SageMaker Experiments List on the left navigation pane, then choose **Create Experiment**. You will be directed to the experiment creating page. All you need to do is do give the Experiment job a name, specify your input and output data location, specify your target variable, and choose your ML problem type (classification or regression), or leave it as auto.\n",
    "\n",
    "<div>\n",
    "<img src=\"image/sm1.PNG\" width=\"400\"/>\n",
    "   </div>\n",
    "<div>\n",
    "<img src=\"image/sm2.PNG\" width=\"400\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_w_header.csv\")\n",
    "validation_data = pd.read_csv(\"data/validation_w_header.csv\")\n",
    "\n",
    "data_for_experiment = pd.concat([train_data, validation_data])\n",
    "data_for_experiment.to_csv(\"full_feature_data_temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Reference\n",
    "\n",
    "Now that you have created the complete feature set, you can start to explore and find a best-working model for your churn use case. By the end of part 2, you will select an algorithm, find the best sets of hyperparameter for the model, examine how well the model performs, and finally find the top influential features.\n",
    "\n",
    "To start with Part 2, you can either read in data from the output of your Part 1 results, or use the provided 'data/full_feature_data.csv' as the input (variable dataframe `processed_data`) for the next steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read(\"full_feature_data.csv\")\n",
    "# s3_input_full_set = (\n",
    "#     boto3.Session()\n",
    "#     .resource(\"s3\")\n",
    "#     .Bucket(bucket)\n",
    "#     .Object(os.path.join(prefix, \"full/fullset.csv\"))\n",
    "#     .upload_file(\"full_feature_data.csv\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment job will take some time to run (for the default 250 trials). It will go through data exploration, feature engineering, model selection and hyperparameter tuning. It will create a **data exploration notebook** that describes the data (missing values, numerical feature distributions, etc.), and a **candidate generation notebook** that describes the AutoML job. At the end of the Experiment job, the best model chosen is highlighted, and you can directly deploy the model for real-time prediction from the SageMaker Experiment Console. \n",
    "<div>\n",
    "<img src=\"image/sm3.PNG\" width=\"800\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: deploy model created from SageMaker Autopilot\n",
    "\n",
    "#### From Console\n",
    "\n",
    "You can navigate to the SageMaker Hyperparameter Tuning Job from the console to find the best model by go to **SageMaker  $\\rightarrow$ Hyperparameter tuning jobs  $\\rightarrow$ \\<your most recent job name marked as complete\\> $\\rightarrow$ Best training job** then choose **Create model**.\n",
    "<div>\n",
    "<img src=\"image/sm4.PNG\" width=\"800\"/>\n",
    "\n",
    "</div>\n",
    "\n",
    "#### With Code\n",
    "\n",
    "Alternatively, you can take look at the candidate generation notebook that describes the AutoML job. As part of the job, the input dataset has been randomly split into two pieces, one for training and one for validation. The notebook helps you inspect and modify the data transformation approaches proposed by Amazon SageMaker Autopilot. You can interactively train the data transformation models and use them to transform the data. Finally, you can execute a multiple algorithm hyperparameter optimization (multi-algo HPO) job that helps you find the best model for your dataset by jointly optimizing the data transformations and machine learning algorithms. Note that with the data transformation pipeline created by the AutoML job, the final model may contain more features than what you already created in this notebook, hence it would be better to test the models created by the AutoML job in the **Candidate generation notebook** to make sure your test data is also processed by the data transformation pipeline and has all the feature needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "The data used in this notebook is synthetic and does not contain real user data. The results (all the names, emails, IP addresses, and browser information) of this simulation are fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "\n",
    "The data used in this notebook is simulated using the [EventSim](https://github.com/Interana/eventsim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
