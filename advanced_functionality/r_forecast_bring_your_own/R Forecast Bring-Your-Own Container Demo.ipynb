{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Forecastig Bring-Your-Own Container Demo\n",
    "\n",
    "This notebook demonstrates how to use the container to create an endpoint serving\n",
    "forecasts made by the [R forecast package](https://cran.r-project.org/web/packages/forecast/index.html) using Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to the ECR image url of the container, returned by build_and_push.sh\n",
    "# e.g. 123456789.dkr.ecr.us-east-1.amazonaws.com/r_forecast_bring_your_own:latest\n",
    "CONTAINER_IMAGE = \"to_be_set\" \n",
    "\n",
    "EXECUTION_ROLE_ARN = sagemaker.get_execution_role()  # or set manually\n",
    "\n",
    "INSTANCE_TYPE = \"ml.c5.xlarge\"\n",
    "INSTANCE_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = sagemaker_session.sagemaker_client\n",
    "sagemaker_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "# Region for SageMaker calls -- should be the same as your ECR\n",
    "print(\"Region: \" + sagemaker_session.boto_region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create endpoint from container image\n",
    "\n",
    "name = 'r-forecast-test-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "primary_container = {\n",
    "    'Image': CONTAINER_IMAGE,\n",
    "}\n",
    "\n",
    "# Create the Model\n",
    "# Note that we are not providing a ModelDataUrl in the primary_container, as there is no training step \n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = name,\n",
    "    ExecutionRoleArn = EXECUTION_ROLE_ARN,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(\"ModelArn: \" + create_model_response['ModelArn'])\n",
    "\n",
    "time.sleep(5)  # wait for model creation to finish\n",
    "\n",
    "# Create the EndpointConfig\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName = name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': INSTANCE_TYPE,\n",
    "        'InitialInstanceCount': INSTANCE_COUNT,\n",
    "        'ModelName': name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"EndpointConfigArn: \" + create_endpoint_config_response['EndpointConfigArn'])\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Create the Endpoint\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=name,\n",
    "    EndpointConfigName=name)\n",
    "\n",
    "print(\"EndpointArn: \" + create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query endpoint status\n",
    "# The status needs to change to 'InService' before continuing\n",
    "\n",
    "describe_endpoint_response = sagemaker_client.describe_endpoint(EndpointName=name)\n",
    "\n",
    "print(\"Creating endpoint\", end=\"\")\n",
    "while describe_endpoint_response['EndpointStatus'] == 'Creating':\n",
    "    time.sleep(10)\n",
    "    describe_endpoint_response = sagemaker_client.describe_endpoint(EndpointName=name)\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "print(\" done\")\n",
    "    \n",
    "assert describe_endpoint_response['EndpointStatus'] == 'InService'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Forecast Request / Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a basic request. The request format is the same as the one used\n",
    "# used by the DeepAR algorithm,\n",
    "# see https://docs.aws.amazon.com/sagemaker/latest/dg/deepar-in-formats.html\n",
    "\n",
    "toy_time_series = [1, 2, 3, 4, 5]\n",
    "\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "                \"start\": \"2018-01-01\",\n",
    "                \"target\": toy_time_series\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain a response from the endpoint\n",
    "response = sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(request)\n",
    ")\n",
    "\n",
    "forecasts = json.loads(response['Body'].read().decode())[\"predictions\"]\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 4))\n",
    "ax.plot(range(0, len(toy_time_series)), toy_time_series, 'x')\n",
    "ax.plot(\n",
    "    range(len(toy_time_series), len(toy_time_series) + len(forecasts[0][\"mean\"])),\n",
    "    forecasts[0][\"mean\"], 'kx')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Milk Production Data Example\n",
    "\n",
    "Now we'll try a more interesting data set, namely the \"Monthly milk production: pounds per cow. Jan 62 â€“ Dec 75\" data set from\n",
    "[Rob Hyndman's Time Series Data Library](https://robjhyndman.com/hyndsight/tsdl/)\n",
    "available from [here](https://datamarket.com/data/set/22ox)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the data from the DataMarket API\n",
    "URL = \"https://datamarket.com/api/v1/series.json?ds=22ox\"\n",
    "response = urllib.request.urlopen(URL).read()\n",
    "data = json.loads(response[18:-1])[0]['data']\n",
    "milk_production = pd.Series([x[1] for x in data], index=pd.date_range(data[0][0], periods=len(data), freq=\"1M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve the last two years for testing\n",
    "milk_production_train = milk_production[:-24]\n",
    "milk_production_test = milk_production[-24:]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 4))\n",
    "milk_production_train.plot(ax=ax)\n",
    "milk_production_test.plot(ax=ax)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, we define a function for retrieving forecasts from the endpoint\n",
    "def get_forecast(start, target, method, frequency, prediction_length):\n",
    "    request = {\n",
    "        \"configuration\": {\n",
    "            \"frequency\": frequency,\n",
    "            \"method\": method,\n",
    "            \"output_types\": [\"mean\", \"quantiles\"],\n",
    "            \"prediction_length\": prediction_length,\n",
    "            \"quantiles\": [\"0.1\", \"0.5\", \"0.9\"]\n",
    "        },\n",
    "        \"instances\": [\n",
    "            {\n",
    "                    \"start\": start,\n",
    "                    \"target\": target\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # obtain a response from the endpoint\n",
    "    response = sagemaker_runtime_client.invoke_endpoint(\n",
    "        EndpointName=name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(request)\n",
    "    )\n",
    "\n",
    "    return json.loads(response['Body'].read().decode())[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecasts\n",
    "fig, axs = plt.subplots(4, 1, sharey=True, figsize=(14, 16))\n",
    "axs = axs.ravel()\n",
    "for i, method in enumerate(['ets', 'ets_additive', 'arima', 'tbats']):\n",
    "    forecasts = get_forecast(\n",
    "        start=str(milk_production_train.index[0]), \n",
    "        target=milk_production_train.values.tolist(), \n",
    "        method=method, frequency=12, prediction_length=24\n",
    "    )\n",
    "    milk_production_train.plot(ax=axs[i])\n",
    "    milk_production_test.plot(ax=axs[i])\n",
    "    pd.Series(forecasts[0]['mean'], milk_production_test.index).plot(ax=axs[i])\n",
    "    axs[i].fill_between(\n",
    "        milk_production_test.index,\n",
    "        forecasts[0]['quantiles']['0.1'],\n",
    "        forecasts[0]['quantiles']['0.9']\n",
    "    )\n",
    "    axs[i].set_title(method)\n",
    "    axs[i].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to make a large number of forecast requests, you can increase the number of instances (and the number of cores per instance) to achieve the desired throughput. Note, however, that the parallelism is on a per-request basis, i.e. instead of sending a single request containing a large number instances, requests containing a few instances each should be made in parallel (e.g. using Python's multiprocessing module). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
