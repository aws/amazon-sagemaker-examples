{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='04-nb'></a>\n",
    "\n",
    "# Music Recommender Part 4: Deploy Model & Inference using Online Feature Store\n",
    "\n",
    "----\n",
    "\n",
    "In this notebook, we'll deploy our chosen model as an endpoint so that we can make predictions/inferences against it. \n",
    "Under the hood the *model.deploy* function creates a model, an endpoint configuration and an endpoint. \n",
    "\n",
    "Then we'll make music recommendations for a single user by inferencing against our model. We'll query our Feature Store to get some data to use for inferencing and show you how [SageMaker Clarify](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.html) can explain which features were most useful in making the recommended music predictions using SHAP values.\n",
    "\n",
    "Amazon SageMaker Clarify provides tools to help explain how machine learning models make predictions. These tools can help ML modelers and developers and other internal stakeholders understand model characteristics as a whole prior to deployment and to debug predictions provided by the model after it's deployed. Transparency about how ML models arrive at their predictions is also critical to consumers and regulators who need to trust the model predictions if they are going to accept the decisions based on them.\n",
    "\n",
    "----\n",
    "### Contents\n",
    "- [Overview](00_overview_arch_data.ipynb)\n",
    "- [Part 1: Data Prep using Data Wrangler](01_music_dataprep.flow)\n",
    "- [Part 2a: Feature Store Creation - Tracks](02a_export_fg_tracks.ipynb)\n",
    "- [Part 2b: Feature Store Creation - User Preferences](02b_export_fg_5star_features.ipynb)\n",
    "- [Part 2c: Feature Store Creation - Ratings](02c_export_fg_ratings.ipynb)\n",
    "- [Part 3: Train Model with Debugger Hooks. Set Artifacts and Register Model.](03_train_model_lineage_registry_debugger.ipynb)\n",
    "- [Part 4: Deploy Model & Inference using Online Feature Store](04_deploy_inference_explainability.ipynb)\n",
    "    - [Deploy model](#04-deploy)\n",
    "    - [Create predictor](#04-predictor)\n",
    "    - [Infer new songs](#04-infer)\n",
    "    - [Explain model predictions](#04-explain)\n",
    "- [Part 5: Model Monitor](05_model_monitor.ipynb)\n",
    "- [Part 6: SageMaker Pipelines](06_pipeline.ipynb)\n",
    "- [Part 7: Resource Cleanup](07_clean_up.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    !pip install -U awswrangler\n",
    "except ModuleNotFoundError:\n",
    "    !pip install --no-input awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pandas to avoid data type issues in older 1.0 version\n",
    "!pip install -qU pandas==1.2.0\n",
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import argparse\n",
    "import pathlib\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.estimator import Estimator\n",
    "import awswrangler as wr\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pprint\n",
    "sys.path.insert(1, './code')\n",
    "from parameter_store import ParameterStore\n",
    "ps = ParameterStore(verbose=False)\n",
    "\n",
    "parameters = ps.read('music-rec')\n",
    "\n",
    "bucket = parameters['bucket']\n",
    "dw_ecrlist = parameters['dw_ecrlist']\n",
    "fg_name_ratings = parameters['fg_name_ratings']\n",
    "fg_name_tracks = parameters['fg_name_tracks']\n",
    "fg_name_user_preferences = parameters['fg_name_user_preferences']\n",
    "\n",
    "flow_export_id = parameters['flow_export_id']\n",
    "flow_s3_uri = parameters['flow_s3_uri']\n",
    "pretrained_model_path = parameters['pretrained_model_path']\n",
    "prefix = parameters['prefix']\n",
    "ratings_data_source = parameters['ratings_data_source']\n",
    "tracks_data_source = parameters['tracks_data_source']\n",
    "model_name = parameters['model_name']\n",
    "training_job_name = parameters['training_job_name']\n",
    "mpg_name = parameters['mpg_name']\n",
    "model_name = parameters['model_name']\n",
    "feature_names = parameters['feature_names']\n",
    "train_data_uri = parameters['train_data_uri']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client\n",
    ")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role(sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='04-deploy'></a>\n",
    "\n",
    "## Deploy Model\n",
    "\n",
    "##### [back to top](#04-nb)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = '{}-endpoint-notebooks'.format(model_name)\n",
    "print(endpoint_name)\n",
    "\n",
    "ps.add({'endpoint_name':endpoint_name}, namespace='music-rec')\n",
    "ps.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use a pretrained model, set use_pretrained = True\n",
    "## else use_pretrained = False to use the model you trained in the previous notebook\n",
    "use_pretrained = False\n",
    "\n",
    "if use_pretrained:\n",
    "    # or use a pretrained model if you skipped model training in the last notebook\n",
    "    xgb_estimator = sagemaker.model.Model(\n",
    "        image_uri=sagemaker.image_uris.retrieve(\"xgboost\", region, \"0.90-2\"),\n",
    "        model_data=pretrained_model_path,\n",
    "        role=sagemaker_role\n",
    "    )\n",
    "else:\n",
    "    print(training_job_name)\n",
    "    # reinstantiate the estimator we trained in the previous notebook\n",
    "    xgb_estimator = Estimator.attach(training_job_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_list = sagemaker_client.list_endpoints(\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    "    NameContains=endpoint_name,\n",
    "    StatusEquals='InService'\n",
    ")\n",
    "endpoint_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(endpoint_list['Endpoints']) > 0:\n",
    "    print(f\"Using existing endpoint: {endpoint_list['Endpoints'][0]['EndpointName']}\")\n",
    "else:\n",
    "    # deploy endpoint for model if it doesn't already exist\n",
    "    xgb_estimator.deploy(initial_instance_count=1,\n",
    "                         instance_type='ml.m4.xlarge',\n",
    "                         model_name=model_name,\n",
    "                         endpoint_name=endpoint_name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package = sagemaker_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList'][0]\n",
    "model_package_update = {\n",
    "    'ModelPackageArn': model_package['ModelPackageArn'],\n",
    "    'ModelApprovalStatus': 'Approved'\n",
    "}\n",
    "\n",
    "update_response = sagemaker_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='04-predictor'> </a>\n",
    "\n",
    "## Create a predictor\n",
    "\n",
    "##### [back to top](#04-nb)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull user data from feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random user ID. You can try any other ID\n",
    "sample_user_id = 11005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the sample user's 5 star preferences record from the feature store\n",
    "fg_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=fg_name_user_preferences, \n",
    "    RecordIdentifierValueAsString=str(sample_user_id)\n",
    ")\n",
    "\n",
    "record = fg_response['Record']\n",
    "df_user = pd.DataFrame(record).set_index('FeatureName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull sample of 1000 tracks from feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a sample of the tracks data (multiple records) from the feature store using athena query\n",
    "fg_name_tracks_obj = FeatureGroup(name=fg_name_tracks, sagemaker_session=feature_store_session)\n",
    "tracks_query = fg_name_tracks_obj.athena_query()\n",
    "tracks_table = tracks_query.table_name\n",
    "\n",
    "# use escaped quotes aound table name since it contains '-' symbols\n",
    "query_string = (\"SELECT * FROM \\\"{}\\\" LIMIT 1000\".format(tracks_table))\n",
    "print(\"Running \" + query_string)\n",
    "\n",
    "# run Athena query. The output is loaded to a Pandas dataframe.\n",
    "tracks_query.run(query_string=query_string, output_location=f\"s3://{bucket}/{prefix}/query_results/\")\n",
    "tracks_query.wait()\n",
    "df_tracks = tracks_query.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_tracks.merge(pd.DataFrame(df_user['ValueAsString']).T, how='cross')\n",
    "data.columns = [c.lower() for c in data.columns]\n",
    "inference_df = data[feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "The datapoint must match the exact input format as the model was trained--with all features in the correct order. In this example, the `col_order` variable was saved when you created the train and test datasets earlier in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputs = [','.join([str(i) for i in row]) for row in inference_df.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='04-infer'> </a>\n",
    "\n",
    "## Infer (predict) new songs using model\n",
    "\n",
    "##### [back to top](#04-nb)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for data_input in data_inputs:\n",
    "    results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    predictions.append(prediction)\n",
    "print(f'Predicted rating for user {int(sample_user_id)}:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv in S3 without headers and index column.\n",
    "inference_df['rating'] = predictions\n",
    "inference_df = inference_df[['rating']+feature_names]\n",
    "inference_df.to_csv('data/prediction_data.csv', header=False, index=False)\n",
    "\n",
    "s3_client.upload_file('data/prediction_data.csv', bucket, f'{prefix}/data/pred/prediction_data.csv')\n",
    "\n",
    "pred_data_uri = f's3://{bucket}/{prefix}/data/pred/prediction_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_data_uri)\n",
    "\n",
    "label = 'rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='04-explain'> </a>\n",
    "\n",
    "## Explain model predictions\n",
    "\n",
    "##### [back to top](#04-nb)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability_output_path = f's3://{bucket}/{prefix}/clarify-output/explainability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    instance_count=1,\n",
    "    accept_type='text/csv')\n",
    "\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[df_train.median().values[1:].tolist()],  # ignore the first column since that is that target\n",
    "    num_samples=100,\n",
    "    agg_method='mean_abs')\n",
    "\n",
    "explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=pred_data_uri,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label=label,\n",
    "    headers=[label]+feature_names,\n",
    "    dataset_type='text/csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    s3_client.download_file(\n",
    "        Bucket   = bucket, \n",
    "        Key      = f'{prefix}/clarify-output/explainability/explanations_shap/out.csv', \n",
    "        Filename = 'data/shap_output.csv'\n",
    "    )\n",
    "    print('Downloaded output from previous explainability job')\n",
    "except Exception as e:\n",
    "    error = e.response.get('Error').get('Code')\n",
    "    if error == '404':\n",
    "        print('Running explainability job')\n",
    "        clarify_processor.run_explainability(\n",
    "            data_config=explainability_data_config,\n",
    "            model_config=model_config,\n",
    "            explainability_config=shap_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df['trackid'] = data['trackid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_length = 10  # number of songs to recommend in playlist\n",
    "playlist = inference_df.sort_values(by='rating', ascending=False).head(playlist_length)\n",
    "print('Curated Playlist:\\n', playlist['trackid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_explanations_out = pd.read_csv(explainability_output_path+'/explanations_shap/out.csv')\n",
    "local_explanations_out.columns = feature_names\n",
    "\n",
    "print(\"Model prediction:\", playlist.iloc[0, 0])\n",
    "plt.figure(figsize=(12,6))\n",
    "local_explanations_out.iloc[0].sort_values().plot.barh(title='Local explanation for prediction')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
