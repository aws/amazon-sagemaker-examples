{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and Explainability with Amazon SageMaker Clarify\n",
    "\n",
    "## Overview\n",
    "Biases are imbalances in the training data, or the prediction behavior of the model across different groups. Sometimes these biases can cause harms to demographic subgroups, e.g. based age or income bracket. The field of machine learning provides an opportunity to address biases by detecting them and measuring them in your data and model.\n",
    "\n",
    "![ Bias and Explainability with SageMaker Clarify ](clarify_explainability_arch.png)\n",
    "\n",
    "Amazon SageMaker Clarify provides machine learning developers with greater visibility into their training data and models, so they can identify and limit bias and explain predictions.\n",
    "\n",
    "In this notebook, we are going to go through each stage of the ML lifecycle, and show where you can include Clarify.\n",
    "\n",
    "## Problem Formation\n",
    "\n",
    "In this notebook, we are looking to predict the final grade for students in a math class, from the popular [Student Performance dataset](https://archive.ics.uci.edu/ml/datasets/Student+Performance) courtesy of UC Irvine.\n",
    "\n",
    "For this dataset, final grades range from 0-20, where 15-20 are the most favorable outcomes. This is a multi-class classification problem, where we want to predict which grade a given student will get from 0 to 20. \n",
    "\n",
    "The benefit of using ML to predict this, is to be able to provide an accurate grade for the student if they aren't able to attend the final exam, due to circumstances outside their control.\n",
    "\n",
    "The notebook will take 90 minutes to execute and will cost approximately $2.\n",
    "\n",
    "## Prerequisites\n",
    "1. This notebook works in the following environments.\n",
    "   - Notebook Instances: Jupyter\n",
    "   - Notebook Instances: JupyterLab\n",
    "   - Studio\n",
    "1. Use Python 3 Data Science Kernel on ml.m5.large instance.\n",
    "1. This is a standalone notebook, and it does not depend on other notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = \"sagemaker/student-data-xgb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Dataset Construction\n",
    "\n",
    "Data Construction is certainly a stage where bias can be introduced. We need to consider the following:\n",
    "\n",
    "- Is the training data representative of different groups?\n",
    "- Are there biases in labels or features?\n",
    "- Does the data need to be modified to mitigate bias?\n",
    "\n",
    "\n",
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup files from previous partial runs\n",
    "!rm -rf student.zip student-merge.R student-por.csv student.txt student-mat.csv\n",
    "\n",
    "!wget -O student.zip http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\n",
    "!unzip student.zip\n",
    "!rm -rf student.zip student-merge.R student-por.csv student.txt\n",
    "!ls\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_path = \"./student-mat.csv\"\n",
    "data = pd.read_csv(local_data_path, sep=\";\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "This dataset is anonymized, with some encoding. We now need to encode various categorical variables.\n",
    "We will not be including First Grade (G1) or Second Grade (G2), as these are strong predictors of the final grade - we want to understand how the other grades contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_data(students):\n",
    "\n",
    "    students.columns = [\n",
    "        \"School\",  # 1. (binary)      student's school\n",
    "        \"Gender\",  # 2. (binary)      student's gender\n",
    "        \"Age\",  # 3. (numerical)   student's age\n",
    "        \"Address\",  # 4. (binary)      student's home address type\n",
    "        \"FamilySize\",  # 5. (binary)      family size\n",
    "        \"ParentCohabStatus\",  # 6. (binary)      parent's cohabitation status\n",
    "        \"MotherEducation\",  # 7. (numeric)     mother's education\n",
    "        \"FatherEducation\",  # 8. (numeric)     father's education\n",
    "        \"MotherJob\",  # 9. (nominal)     mother's job\n",
    "        \"FatherJob\",  # 10.(nominal)     father's job\n",
    "        \"SchoolChoiceReason\",  # 11.(nominal)     reason to choose this school\n",
    "        \"Guardian\",  # 12.(nominal)     student's guardian\n",
    "        \"TravelTime\",  # 13.(numerical)   home to school travel time\n",
    "        \"StudyTime\",  # 14.(numerical)   weekly study time\n",
    "        \"Failures\",  # 15.(numerical)   number of past class failures\n",
    "        \"SchoolSup\",  # 16.(binary)      extra educational support\n",
    "        \"FamilySup\",  # 17.(binary)      family educational support\n",
    "        \"ExtraPaidClasses\",  # 18.(binary)      extra paid classes within the course subject\n",
    "        \"ExtraActivities\",  # 19.(binary)      extra-curricular activities\n",
    "        \"Nursery\",  # 20.(binary)      attended nursery school\n",
    "        \"WantsHigherEdu\",  # 21.(binary)      wants to take higher education\n",
    "        \"HasInternet\",  # 22.(binary)      Internet access at home\n",
    "        \"Romantic\",  # 23.(binary)      with a romantic relationship\n",
    "        \"FamilyRelQuality\",  # 24.(numerical)   quality of family relationships\n",
    "        \"FreeTime\",  # 25.(numerical)   free time after school\n",
    "        \"GoOut\",  # 26.(numerical)   going out with friends\n",
    "        \"WorkdayAlcohol\",  # 27.(numerical)   workday alcohol consumption\n",
    "        \"WeekendAlcohol\",  # 28.(numerical)   workday alcohol consumption\n",
    "        \"HealthStatus\",  # 39.(numerical)   current health status\n",
    "        \"Absences\",  # 30.(numerical)   number of school absences\n",
    "        \"FirstGrade\",  # 31.(numerical)   G1 - first period grade\n",
    "        \"SecondGrade\",  # 32.(numerical)   G2 - second period grade\n",
    "        \"FinalGrade\",  # 33.(numerical)   G3 - final grade (TARGET)\n",
    "    ]\n",
    "\n",
    "    # For xgboost, we need to put target variable in the first column.\n",
    "    df = pd.DataFrame(students.FinalGrade)\n",
    "\n",
    "    # Encode the Attributes.\n",
    "    res = students.School.map({\"GP\": 1, \"MS\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.Gender.map({\"F\": 1, \"M\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.Age], axis=1, sort=False)\n",
    "\n",
    "    res = students.Address.map({\"U\": 1, \"R\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.FamilySize.map({\"LE3\": 1, \"GT3\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.ParentCohabStatus.map({\"T\": 1, \"A\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.MotherEducation], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.FatherEducation], axis=1, sort=False)\n",
    "\n",
    "    res = pd.get_dummies(students.MotherJob, prefix=\"MotherJob\")\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = pd.get_dummies(students.FatherJob, prefix=\"FatherJob\")\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = pd.get_dummies(students.SchoolChoiceReason, prefix=\"SchoolChoiceReason\")\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.TravelTime], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.StudyTime], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.Failures], axis=1, sort=False)\n",
    "\n",
    "    res = students.SchoolSup.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.FamilySup.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.ExtraPaidClasses.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.Nursery.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.WantsHigherEdu.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.HasInternet.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    res = students.Romantic.map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.concat([df, res], axis=1, sort=False)\n",
    "\n",
    "    df = pd.concat([df, students.FamilyRelQuality], axis=1, sort=False)\n",
    "    df = pd.concat([df, students.FreeTime], axis=1, sort=False)\n",
    "    df = pd.concat([df, students.GoOut], axis=1, sort=False)\n",
    "    df = pd.concat([df, students.WorkdayAlcohol], axis=1, sort=False)\n",
    "    df = pd.concat([df, students.WeekendAlcohol], axis=1, sort=False)\n",
    "    df = pd.concat([df, students.HealthStatus], axis=1, sort=False)\n",
    "    df = pd.concat([df, students.Absences], axis=1, sort=False)\n",
    "\n",
    "    # We will not be including G1 or G2, as these are strong predictors\n",
    "    # of the final grade - we want to understand how the other grades contribute.\n",
    "    print(\"DF Shape: {}\".format(df.shape))\n",
    "    print(\"DF columns: {}\".format(df.columns))\n",
    "\n",
    "    # X will be our dataframe of attributes only, without the target:\n",
    "    X = df.drop([\"FinalGrade\"], axis=1)\n",
    "\n",
    "    # y will be our array of target values, the final grades.\n",
    "    y = df.FinalGrade\n",
    "\n",
    "    return X, y, df\n",
    "\n",
    "\n",
    "X, y, df = _preprocess_data(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets\n",
    "\n",
    "We are going to use the **train_test_split** from sklearn which will randomize the rows and split into two groups for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, validation_data = train_test_split(df, test_size=0.3, random_state=300)\n",
    "print(train_data.shape)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload training and validation sets to S3\n",
    "\n",
    "Before we can create a pre-training bias report for Clarify, we need to upload our data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "train_data_s3_path = S3Uploader.upload(\n",
    "    \"train_data.csv\", \"s3://{}/{}\".format(bucket, prefix + \"/train\")\n",
    ")\n",
    "print(\"Train data uploaded to: \" + train_data_s3_path)\n",
    "\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False)\n",
    "validation_data_s3_path = S3Uploader.upload(\n",
    "    \"validation_data.csv\", \"s3://{}/{}\".format(bucket, prefix + \"/validation\")\n",
    ")\n",
    "print(\"Validation data uploaded to: \" + validation_data_s3_path)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "url = \"https://s3.console.aws.amazon.com/s3/buckets/{}?region={}&prefix={}/&showversions=false\".format(\n",
    "    bucket, session.boto_region_name, prefix\n",
    ")\n",
    "HTML('<a target=\"_blank\" href=\"{}\">Click here to view datasets in S3</a>'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Clarify - Pre-training Bias Report\n",
    "\n",
    "This step takes around 12 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "pretraining_bias_instance_count = 1\n",
    "pretraining_bias_instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role,\n",
    "    instance_count=pretraining_bias_instance_count,\n",
    "    instance_type=pretraining_bias_instance_type,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_pretrain_report_output_path = \"s3://{}/{}/clarify-pretrain-bias\".format(bucket, prefix)\n",
    "\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_s3_path,\n",
    "    s3_output_path=bias_pretrain_report_output_path,\n",
    "    label=\"FinalGrade\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Bias Configuration\n",
    "\n",
    "Now we can run pre-bias training over the favorable values, or the top final grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    facet_name=\"Gender\",\n",
    "    group_name=\"Age\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pre-training Bias Job\n",
    "\n",
    "Run the SageMaker Analyzer job - this takes about 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "clarify_processor.run_pre_training_bias(\n",
    "    data_config=bias_data_config, data_bias_config=bias_config, methods=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the report has been generated, we can inspect what our values are looking like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "url = \"https://s3.console.aws.amazon.com/s3/buckets/{}?region={}&prefix={}/clarify-bias/&showversions=false\".format(\n",
    "    bucket, session.boto_region_name, prefix\n",
    ")\n",
    "HTML(\n",
    "    '<a target=\"_blank\" href=\"{}\">Click here to view pre-training bias reports in S3</a>'.format(\n",
    "        url\n",
    "    )\n",
    ")\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "local_databias_report_path = \"./pretraining_bias_reports\"\n",
    "\n",
    "S3Downloader.download(\n",
    "    local_path=local_databias_report_path,\n",
    "    s3_uri=bias_pretrain_report_output_path,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Pretraining Bias Report\n",
    "\n",
    "You can view the report [here](./pretraining_bias_reports/report.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection\n",
    "\n",
    "During algorithm selection we need to consider the following:\n",
    "\n",
    "- Do fairness constraints need to be included in the objective function?\n",
    "\n",
    "For the model, we will use the [XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html). It can handle a variety of data types, relationships, and distributions, and has a number of hyperparameters that you can fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(train_data_s3_path, content_type=\"csv\")\n",
    "validation_input = TrainingInput(validation_data_s3_path, content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process\n",
    "\n",
    "For this demo, we will train 10 models and pick the best one to deploy, based on the lowest **Root Mean Square Error (RMSE).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "container = retrieve(\"xgboost\", session.boto_region_name, version=\"1.2-1\")\n",
    "\n",
    "training_instance_count = 1\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "xgb = Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=training_instance_count,\n",
    "    instance_type=training_instance_type,\n",
    "    disable_profiler=True,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    eval_metric=\"rmse\",\n",
    "    objective=\"reg:squarederror\",\n",
    "    num_round=100,\n",
    "    rate_drop=0.3,\n",
    "    tweedie_variance_power=1.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"subsample\": ContinuousParameter(0, 1),\n",
    "}\n",
    "objective_metric_name = \"validation:rmse\"\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=5,\n",
    "    objective_type=\"Minimize\",\n",
    ")\n",
    "\n",
    "%time\n",
    "tuner.fit({\"train\": train_input, \"validation\": validation_input}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tuning job will take around 8 minutes on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model, and grab the model name for passing to post-training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_name = \"xgb-student-model\"\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "xgb_predictor = tuner.deploy(\n",
    "    initial_instance_count=predictor_instance_count,\n",
    "    instance_type=predictor_instance_type,\n",
    "    model_name=xgb_model_name,\n",
    ")\n",
    "\n",
    "print(f\"Model is sucessfully deployed.\")\n",
    "xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Process\n",
    "\n",
    "This is where we can do some post-training testing with Clarify - both for bias and explain-ability.\n",
    "\n",
    "### Post training bias report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_posttrain_report_output_path = \"s3://{}/{}/clarify-posttrain-bias\".format(bucket, prefix)\n",
    "\n",
    "bias_posttrain_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_s3_path,\n",
    "    s3_output_path=bias_posttrain_report_output_path,\n",
    "    label=\"FinalGrade\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "posttraining_bias_instance_count = 1\n",
    "posttraining_bias_instance_type = \"ml.c5.2xlarge\"\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=xgb_model_name,\n",
    "    instance_type=posttraining_bias_instance_type,\n",
    "    instance_count=posttraining_bias_instance_count,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "predictions_config = clarify.ModelPredictedLabelConfig()\n",
    "\n",
    "clarify_processor.run_post_training_bias(\n",
    "    data_config=bias_posttrain_data_config,\n",
    "    data_bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    methods=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Post-Training Bias Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "local_posttrain_bias_report_path = \"./posttraining_bias_reports\"\n",
    "\n",
    "S3Downloader.download(\n",
    "    local_path=local_posttrain_bias_report_path,\n",
    "    s3_uri=bias_posttrain_report_output_path,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Post-Training Bias Report\n",
    "\n",
    "If the report has been successfully downloaded, you can view the report [here](./posttraining_bias_reports/report.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explainability report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to establish a baseline with our data\n",
    "test_features = validation_data.drop([\"FinalGrade\"], axis=1)\n",
    "explainability_report_output_path = \"s3://{}/{}/clarify-explainability\".format(bucket, prefix)\n",
    "\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_s3_path,\n",
    "    s3_output_path=explainability_report_output_path,\n",
    "    label=\"FinalGrade\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=[test_features.iloc[0].values.tolist()], num_samples=50, agg_method=\"mean_abs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run explain-ability job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Explainability Report\n",
    "\n",
    "We can use the [SageMaker S3 Downloader utility](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html#sagemaker.s3.S3Downloader) to download files to inspect them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_explainability_report_path = \"./explainability_reports\"\n",
    "\n",
    "S3Downloader.download(\n",
    "    local_path=local_explainability_report_path,\n",
    "    s3_uri=explainability_report_output_path,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "We need to consider:\n",
    "\n",
    "- Is the model deployed on a population for which it was not trained or evaluated?\n",
    "- Are there unequal effects across users?\n",
    "\n",
    "Tuner.deploy will deploy the best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the report has been successfully downloaded, you can view the report [here](./explainability_reports/report.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring & Feedback\n",
    "\n",
    "- Does the model encourage feedback loops that can produce increasingly unfair outcomes?\n",
    "\n",
    "To address this, we can look at including Model Monitor with Clarify Bias and Explainability, but we've run out of time for this demo.\n",
    "\n",
    "#### Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "You can keep your endpoint running to continue capturing data. If you do not plan to collect more data or use this endpoint further, you should delete the endpoint to avoid incurring additional charges. Note that deleting your endpoint does not delete the data that was captured during the model invocations. That data persists in Amazon S3 until you delete it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up model endpoints\n",
    "xgb_predictor.delete_model()\n",
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "\n",
    "# clean up local files\n",
    "!rm -rf student-mat.csv train_data.csv validation_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "In this session we reviewed the machine learning techniques and AWS services you can use to understand and reduce these risks.\n",
    "\n",
    "AI services and machine learning are helping organizations to build data driven applications that are innovative and can be highly attuned to their customers’ needs, but AI applications require crucial customer data to train machine learning models. Application logic is delegated to these models, which can introduce unfairness and biases into an application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Pauline Kelly - [Building AI applications that avoid bias and maintain privacy and fairness](https://anz-resources.awscloud.com/aws-summit-online-anz-2021-data-scientist/building-ai-applications-that-avoid-bias-and-maintain-privacy-and-fairness-1)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:111111111111:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
