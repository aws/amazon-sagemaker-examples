{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fleet Predictive Maintenance: Part 4. Training, Hyperparameter Tuning, and Prediction\n",
    "\n",
    "1. [Architecure](0_usecase_and_architecture_predmaint.ipynb#0_Architecture)\n",
    "1. [Data Prep: Processing Job from Data Wrangler Output](./1_dataprep_dw_job_predmaint.ipynb)\n",
    "1. [Data Prep: Featurization](./2_dataprep_predmaint.ipynb)\n",
    "1. [Train, Tune and Predict using Batch Transform](./3_train_tune_predict_predmaint.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View stored variables from previous session\n",
    "\n",
    "If you ran this notebook before, you may want to re-use the resources you aready created with AWS. Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything you may need to create them again or it may be your first time running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : <font color=red> dw_output_path_prm </font> should appear above as a stored (restored) variable, whose value was set when you ran notebook 1_datapred_predmaint.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any missing dependencies\n",
    "!pip install -qU 'sagemaker-experiments==0.1.24' 'sagemaker>=2.16.1' 'boto3' 'awswrangler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import collections\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SageMaker dependencies\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "import awswrangler as wr\n",
    "\n",
    "# This instantiates a SageMaker session that we will be operating in.\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# This object represents the IAM role that we are assigned.\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# prefix is the path within the bucket where SageMaker stores the output from training jobs.\n",
    "prefix_prm = \"predmaint\"  # place to upload training files within the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "### SageMaker Estimator and Experiments\n",
    "\n",
    "Once you have selected some models that you would like to try out, SageMaker Experiments can be a great tool to track and compare all of the models before selecting the best model to deploy. We will set up an experiment using SageMaker experiments to track all the model training iterations for the Linear Learner Estimator we will try. You can read more about [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) to learn about experiment features, tracking and comparing outputs.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "# import dependencies\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'create_date' not in locals():\n",
    "    create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    %store create_date\n",
    "\n",
    "    # location within S3 for outputs\n",
    "    exp_prefix = f'sagemaker-experiments/linear-learner-{create_date}'\n",
    "    %store exp_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used the storemagic previously, you can pick up from here using the `create_date` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the experiment\n",
    "experiment_name = f\"ll-failure-classification-{create_date}\"\n",
    "%store experiment_name\n",
    "\n",
    "try:\n",
    "    my_experiment = Experiment.load(experiment_name=experiment_name)\n",
    "    print(f\"Experiment loaded {experiment_name}: SUCCESS\")\n",
    "except Exception as e:\n",
    "    if \"ResourceNotFound\" in str(e):\n",
    "        my_experiment = Experiment.create(\n",
    "            experiment_name=experiment_name,\n",
    "            description=\"Classification PrM Experiment\",\n",
    "            tags=[{\"Key\": \"my-experiments\", \"Value\": \"exp\"}],\n",
    "            sagemaker_boto_client=smclient,\n",
    "        )\n",
    "        print(f\"Experiment creation {experiment_name}: SUCCESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The tags parameter is optional. You can search for the tag using Studio, the SageMaker console, and the SDK. Tags can also be applied to trials and trial components. For information on how to search tags using Studio, see [Search by Tag](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-search-studio.html#experiments-search-studio-tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"training\", sagemaker_boto_client=smclient) as tracker:\n",
    "    tracker.log_input(name=\"prm-dataset\", media_type=\"s3/uri\", value=path_to_train_data_prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin to specify our linear model from the Amazon SageMaker Linear Learner Estimator. For this binary classification problem, we have the option of selecting between logistic regression or hinge loss (Support Vector Machines). Here are additional resources to [learn more about Linear Learner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html#ll-input_output) and the [loss functions available](https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html). One piece to note is that Amazon SageMaker's Linear Learner actually fits many models in parallel, each with slightly different hyperparameters, and then returns the one with the best fit.  This functionality is automatically enabled.  There are a number of additional parameters available for the Linear Learner Estimator, so we will start be using the default features as well as:\n",
    "\n",
    "- `loss` which controls how we penalize mistakes in our model estimates.  For this case, we will start with logistic and move to using hinge loss if necessary for model improvement.\n",
    "- `predictor_type` is set to 'binary_classifier' since we are trying to predict whether a failure occurs or it doesn't.\n",
    "- `mini_batch_size` is set to 99.  This value can be tuned for relatively minor improvements in fit and speed, but selecting a reasonable value relative to the dataset is appropriate in most cases.\n",
    "- `wd` or `l1` which control regularization.  Regularization can prevent model overfitting by preventing our estimates from becoming too finely tuned to the training data, which can actually hurt generalizability.  In this case, we'll leave these parameters as their default \"auto\" though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by first building a logistic regression Linear Learner Estimator, setting the hyperparameters and configuring the SageMaker Experiment with the trial created above. We will then evaluate the results of the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set output path\n",
    "lr_output_path = f\"s3://{bucket}/{exp_prefix}/output/lr_default\"\n",
    "\n",
    "# with SageMaker v2.0, Image URI function get_image_uri has been replaced with sagemaker.image_uris.retrieve()\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    framework=\"linear-learner\", region=region, version=\"1\", image_scope=\"training\"\n",
    ")\n",
    "\n",
    "# create the trail component and the first experiment for linear learner\n",
    "training_trail_component = tracker.trial_component\n",
    "trial_name_1 = trial_name = f\"linear-learner-lr-training-job-{create_date}\"\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    my_trial = Trial.load(trial_name=trial_name_1)\n",
    "    print(f\"Loaded existing trial: {trial_name_1}\")\n",
    "except Exception as e:\n",
    "    if \"ResourceNotFound\" in str(e):\n",
    "        my_trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name_1)\n",
    "        print(f\"Create trial {my_trial.trial_name}: SUCCESSFUL \\n\")\n",
    "\n",
    "        print(f\"Creating logistic regression estimator. \\n\")\n",
    "        lr = sagemaker.estimator.Estimator(\n",
    "            container,\n",
    "            role,\n",
    "            instance_count=1,\n",
    "            instance_type=\"ml.c4.xlarge\",\n",
    "            output_path=lr_output_path,\n",
    "            sagemaker_session=sess,\n",
    "            enable_sagemaker_metrics=True,\n",
    "        )\n",
    "\n",
    "        lr.set_hyperparameters(\n",
    "            predictor_type=\"binary_classifier\",\n",
    "            loss=\"logistic\",  # default for auto is logistic regression\n",
    "            epochs=20,  # high number of epochs as early stopping feature will stop training\n",
    "            mini_batch_size=99,\n",
    "        )\n",
    "\n",
    "        lr.fit(\n",
    "            inputs=data_channels,\n",
    "            experiment_config={\n",
    "                \"ExperimentName\": my_experiment.experiment_name,\n",
    "                \"TrialName\": my_trial.trial_name,\n",
    "                \"TrialComponentDisplayName\": \"ll-lr-training-job\",\n",
    "            },\n",
    "            logs=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train a Linear Learner model with hinge loss, i.e. Support Vector Machines, and use the default hyperparmeters listed below. We will add this trial to the experiment for later comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_output_path = f\"s3://{bucket}/{exp_prefix}/output/svm_default\"\n",
    "trial_name_2 = f\"linear-learner-svm-{create_date}\"\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    my_trial = Trial.load(trial_name=trial_name_2)\n",
    "    print(f\"Loaded existing trial: {trial_name_2}\")\n",
    "except Exception as e:\n",
    "    if \"ResourceNotFound\" in str(e):\n",
    "        my_trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name_2)\n",
    "        print(f\"Create trial {my_trial.trial_name}: SUCCESSFUL\")\n",
    "\n",
    "        svm = sagemaker.estimator.Estimator(\n",
    "            container,\n",
    "            role,\n",
    "            instance_count=1,\n",
    "            instance_type=\"ml.c4.xlarge\",\n",
    "            output_path=svm_output_path,\n",
    "            sagemaker_session=sess,\n",
    "            enable_sagemaker_metrics=True,\n",
    "        )\n",
    "        svm.set_hyperparameters(\n",
    "            predictor_type=\"binary_classifier\", loss=\"hinge_loss\", epochs=20, mini_batch_size=99\n",
    "        )\n",
    "\n",
    "        svm.fit(\n",
    "            inputs=data_channels,\n",
    "            experiment_config={\n",
    "                \"ExperimentName\": my_experiment.experiment_name,\n",
    "                \"TrialName\": my_trial.trial_name,\n",
    "                \"TrialComponentDisplayName\": \"ll-svm-training-job\",\n",
    "            },\n",
    "            logs=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add in a selection for the hyperparameter `binary_classifier_model_selection_criteria` which allows us to define which metric we would like our model to optimize for (auto threshold tuning). We can choose between percision, recall, F1 and accuracy among other metric choices. \n",
    "\n",
    "It's important to note here that for PrM, we must carefully select our evaluation metric based on domain knowlege. For example, recall increases the chance of catching all failures even false ones. Whereas, precision decreases the chance of catching false failures along with real failures. It is not hard to see that these metrics do not always incorporate the business needs, especially the dollar costs and benefits associated with machinery failures. \n",
    "\n",
    "With this in mind, we will select F1 as the evaluation metric as it is generally a good evaluation metric for imbalanced classification proglems. If you would like to learn more about selecting a custom cost sensitive evaluation metric for your business use case, you can review the article listen in the *Additional Resources* section below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_output_path = f\"s3://{bucket}/{exp_prefix}/output/svm_threshold\"\n",
    "trial_name_3 = f\"linear-learner-svm-thresh-{create_date}\"\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    my_trial = Trial.load(trial_name=trial_name_3)\n",
    "    print(f\"Loaded existing trial: {trial_name_3}\")\n",
    "except Exception as e:\n",
    "    if \"ResourceNotFound\" in str(e):\n",
    "        my_trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name_3)\n",
    "        print(f\"Create trial {my_trial.trial_name}: SUCCESSFUL\")\n",
    "\n",
    "        svm_thresh = sagemaker.estimator.Estimator(\n",
    "            container,\n",
    "            role,\n",
    "            instance_count=1,\n",
    "            instance_type=\"ml.c4.xlarge\",\n",
    "            output_path=svm_output_path,\n",
    "            sagemaker_session=sess,\n",
    "        )\n",
    "\n",
    "        svm_thresh.set_hyperparameters(\n",
    "            predictor_type=\"binary_classifier\",\n",
    "            loss=\"hinge_loss\",\n",
    "            binary_classifier_model_selection_criteria=\"f_beta\",\n",
    "            epochs=20,\n",
    "            mini_batch_size=99,\n",
    "        )\n",
    "\n",
    "        # linear.fit({'train': path_to_train_data_prm})\n",
    "        svm_thresh.fit(\n",
    "            inputs=data_channels,\n",
    "            experiment_config={\n",
    "                \"ExperimentName\": my_experiment.experiment_name,\n",
    "                \"TrialName\": my_trial.trial_name,\n",
    "                \"TrialComponentDisplayName\": \"ll-svm-thresh-training-job\",\n",
    "            },\n",
    "            logs=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try dealing with class imbalances to try to improve precision and recall\n",
    "\n",
    "We will set the hyperparameter `positive_example_weight_mult` to *balanced* in order to use weighting by class to address the class imbalance issue. Since we have only 19% failures compared to non-failures, we can leverage this built-in hyperparameter to try to improve model performnce. Read about [linear learner hyperparameters here](https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training a binary classifier with hinge loss and balanced class weights\n",
    "\n",
    "# set output path\n",
    "svm_output_path = f\"s3://{bucket}/{exp_prefix}/output/svm_balanced\"\n",
    "trial_name_4 = f\"linear-learner-svm-balanced-{create_date}\"\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    my_trial = Trial.load(trial_name=trial_name_4)\n",
    "    print(f\"Loaded existing trial: {trial_name_4}\")\n",
    "except Exception as e:\n",
    "    if \"ResourceNotFound\" in str(e):\n",
    "        my_trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name_4)\n",
    "        print(f\"Create trial {my_trial.trial_name}: SUCCESSFUL\")\n",
    "\n",
    "        # specify algorithm containers and instantiate an Estimator with hyperparams\n",
    "        svm_balanced = sagemaker.estimator.Estimator(\n",
    "            container,\n",
    "            role,\n",
    "            instance_count=1,\n",
    "            instance_type=\"ml.c4.xlarge\",\n",
    "            output_path=svm_output_path,\n",
    "            sagemaker_session=sess,\n",
    "            enable_sagemaker_metrics=True,\n",
    "        )\n",
    "\n",
    "        svm_balanced.set_hyperparameters(\n",
    "            predictor_type=\"binary_classifier\",\n",
    "            loss=\"hinge_loss\",\n",
    "            positive_example_weight_mult=\"balanced\",  # this is for dealing with class imbalances\n",
    "            epochs=20,\n",
    "            mini_batch_size=99,\n",
    "        )\n",
    "        # fit model to data\n",
    "        svm_balanced.fit(\n",
    "            inputs=data_channels,\n",
    "            experiment_config={\n",
    "                \"ExperimentName\": my_experiment.experiment_name,\n",
    "                \"TrialName\": my_trial.trial_name,\n",
    "                \"TrialComponentDisplayName\": \"ll-svm-bal-training-job\",\n",
    "            },\n",
    "            logs=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>positive_example_weight_mult</th>\n",
       "      <th>validation:recall - Avg</th>\n",
       "      <th>validation:binary_classification_accuracy - Avg</th>\n",
       "      <th>validation:roc_auc_score - Avg</th>\n",
       "      <th>train:objective_loss - Avg</th>\n",
       "      <th>validation:objective_loss:final - Avg</th>\n",
       "      <th>validation:objective_loss - Avg</th>\n",
       "      <th>validation:binary_f_beta - Avg</th>\n",
       "      <th>validation:precision - Avg</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear-learner-2021-04-07-15-32-16-116-aws-tra...</td>\n",
       "      <td>ll-svm-training-job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.847778</td>\n",
       "      <td>0.726823</td>\n",
       "      <td>0.215480</td>\n",
       "      <td>0.230429</td>\n",
       "      <td>0.244350</td>\n",
       "      <td>0.583587</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>[linear-learner-svm-2021-04-07-15-16-22]</td>\n",
       "      <td>[ll-failure-classification-2021-04-07-15-16-22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear-learner-2021-04-07-15-27-01-989-aws-tra...</td>\n",
       "      <td>ll-lr-training-job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>0.422724</td>\n",
       "      <td>0.454241</td>\n",
       "      <td>0.463627</td>\n",
       "      <td>0.616216</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>[linear-learner-lr-training-job-2021-04-07-15-...</td>\n",
       "      <td>[ll-failure-classification-2021-04-07-15-16-22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear-learner-2021-04-07-15-42-43-638-aws-tra...</td>\n",
       "      <td>ll-svm-bal-training-job</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.352041</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.777452</td>\n",
       "      <td>0.531280</td>\n",
       "      <td>1.552268</td>\n",
       "      <td>0.574314</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>[linear-learner-svm-balanced-2021-04-07-15-16-22]</td>\n",
       "      <td>[ll-failure-classification-2021-04-07-15-16-22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear-learner-2021-04-07-15-37-30-147-aws-tra...</td>\n",
       "      <td>ll-svm-thresh-training-job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.733592</td>\n",
       "      <td>0.215480</td>\n",
       "      <td>0.229230</td>\n",
       "      <td>0.244350</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>[linear-learner-svm-thresh-2021-04-07-15-16-22]</td>\n",
       "      <td>[ll-failure-classification-2021-04-07-15-16-22]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName  \\\n",
       "2  linear-learner-2021-04-07-15-32-16-116-aws-tra...   \n",
       "3  linear-learner-2021-04-07-15-27-01-989-aws-tra...   \n",
       "0  linear-learner-2021-04-07-15-42-43-638-aws-tra...   \n",
       "1  linear-learner-2021-04-07-15-37-30-147-aws-tra...   \n",
       "\n",
       "                  DisplayName positive_example_weight_mult  \\\n",
       "2         ll-svm-training-job                          NaN   \n",
       "3          ll-lr-training-job                          NaN   \n",
       "0     ll-svm-bal-training-job                     balanced   \n",
       "1  ll-svm-thresh-training-job                          NaN   \n",
       "\n",
       "   validation:recall - Avg  validation:binary_classification_accuracy - Avg  \\\n",
       "2                 0.489796                                         0.847778   \n",
       "3                 0.581633                                         0.842222   \n",
       "0                 0.352041                                         0.830000   \n",
       "1                 0.642857                                         0.820000   \n",
       "\n",
       "   validation:roc_auc_score - Avg  train:objective_loss - Avg  \\\n",
       "2                        0.726823                    0.215480   \n",
       "3                        0.784895                    0.422724   \n",
       "0                        0.777452                    0.531280   \n",
       "1                        0.733592                    0.215480   \n",
       "\n",
       "   validation:objective_loss:final - Avg  validation:objective_loss - Avg  \\\n",
       "2                               0.230429                         0.244350   \n",
       "3                               0.454241                         0.463627   \n",
       "0                               1.552268                         0.574314   \n",
       "1                               0.229230                         0.244350   \n",
       "\n",
       "   validation:binary_f_beta - Avg  validation:precision - Avg  \\\n",
       "2                        0.583587                    0.721805   \n",
       "3                        0.616216                    0.655172   \n",
       "0                        0.474227                    0.726316   \n",
       "1                        0.608696                    0.577982   \n",
       "\n",
       "                                              Trials  \\\n",
       "2           [linear-learner-svm-2021-04-07-15-16-22]   \n",
       "3  [linear-learner-lr-training-job-2021-04-07-15-...   \n",
       "0  [linear-learner-svm-balanced-2021-04-07-15-16-22]   \n",
       "1    [linear-learner-svm-thresh-2021-04-07-15-16-22]   \n",
       "\n",
       "                                       Experiments  \n",
       "2  [ll-failure-classification-2021-04-07-15-16-22]  \n",
       "3  [ll-failure-classification-2021-04-07-15-16-22]  \n",
       "0  [ll-failure-classification-2021-04-07-15-16-22]  \n",
       "1  [ll-failure-classification-2021-04-07-15-16-22]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we can look at all the trials together to evaluate the performance\n",
    "trial_component_analytics = ExperimentAnalytics(experiment_name=my_experiment.experiment_name)\n",
    "analytic_table = trial_component_analytics.dataframe()\n",
    "analytic_table = analytic_table[\n",
    "    [\n",
    "        \"TrialComponentName\",\n",
    "        \"DisplayName\",\n",
    "        \"positive_example_weight_mult\",\n",
    "        \"validation:recall - Avg\",\n",
    "        \"validation:binary_classification_accuracy - Avg\",\n",
    "        \"validation:roc_auc_score - Avg\",\n",
    "        \"train:objective_loss - Avg\",\n",
    "        \"validation:objective_loss:final - Avg\",\n",
    "        \"validation:objective_loss - Avg\",\n",
    "        \"validation:binary_f_beta - Avg\",\n",
    "        \"validation:precision - Avg\",\n",
    "        \"Trials\",\n",
    "        \"Experiments\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "analytic_table.sort_values(\n",
    "    [\"validation:binary_classification_accuracy - Avg\", \"validation:binary_f_beta - Avg\"],\n",
    "    ascending=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Balancing class weights improved precision, but decreased recall significantly \n",
    "* Accuracy for all the models is relatively consistent at around 84%\n",
    "* Across all the metrics, SVM with auto hyperparameters performed the best cumulatively\n",
    "\n",
    "We will move forward with with the auto SMV model, labeled as `svm-default`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option to deploy a predictor here and make predictions against this endpoint\n",
    "\n",
    "# # initialize the deserializer and serializer\n",
    "# serializer = sagemaker.serializers.CSVSerializer()\n",
    "# deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "# svm_predictor = svm.deploy(initial_instance_count=1,\n",
    "#                            instance_type='local'\n",
    "#                            instance_type='ml.m4.xlarge',\n",
    "#                            serializer=serializer,\n",
    "#                            deserializer=deserializer,\n",
    "#                            endpoint_name='svm',\n",
    "#                            model_name='svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamter Tuning \n",
    "\n",
    "### Next, we set up the hyperparmeter tuning job using SageMaker Automatic Tuning\n",
    "\n",
    "*Note, with the settings below, the hyperparameter tuning job can take about 30 minutes to complete.*\n",
    "\n",
    "Hyperparameters can dramtically affect the performance of trained models. Thus, we need to pick the right values to achieve the best model result. Since model results are also affected by the data set as well, it is important to select the best hyperparmateters by searching for them using an algorithmic approach that can be automated and perform efficiently.\n",
    "\n",
    "Using Automatic Tuning, we will specify a range, or a list of possible values in the case of categorical hyperparameters, for each of the hyperparameter that we plan to tune. SageMaker hyperparameter tuning will automatically launch multiple training jobs with different hyperparameter settings, evaluate results of those training jobs based on a predefined \"objective metric\", and select the hyperparameter settings for future attempts based on previous results. For each hyperparameter tuning job, we will give it a budget (max number of training jobs) and it will complete once that many training jobs have been executed.\n",
    "\n",
    "In this example, we are using SageMaker Python SDK to set up and manage the hyperparameter tuning job. We first configure the training jobs the hyperparameter tuning job will launch by initiating an estimator, which includes the following configuration:\n",
    "\n",
    "* hyperparameters that SageMaker Automatic Model Tuning will tune: `learning_rate` \n",
    "* the maximum number of training jobs it will run to optimize the objective metric: 20\n",
    "* the number of parallel training jobs that will run in the tuning job: 2\n",
    "* the objective metric that Automatic Model Tuning will use: validation:accuracy\n",
    "\n",
    "We will also demonstrates how to associate trial components created by a hyperparameter tuning job with an experiment management trial.\n",
    "\n",
    "Read the following link more information on [tuning linear learner hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html) and [automatic tuning with SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom job name\n",
    "prm_tuning_job_name = f\"ll-svm-tuning-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output path\n",
    "svm_output_path = f\"s3://{bucket}/{exp_prefix}/output/tuning/svm_default\"\n",
    "\n",
    "# create the tuning job if it doesn't exist\n",
    "try:\n",
    "    svm_tune = sagemaker.estimator.Estimator(\n",
    "        container,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.c4.xlarge\",\n",
    "        output_path=svm_output_path,\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "\n",
    "    svm_tune.set_hyperparameters(\n",
    "        predictor_type=\"binary_classifier\", loss=\"hinge_loss\", epochs=20, mini_batch_size=99\n",
    "    )\n",
    "\n",
    "    hyperparameter_ranges = {\n",
    "        \"learning_rate\": ContinuousParameter(0.01, 0.5, scaling_type=\"Logarithmic\")\n",
    "    }\n",
    "\n",
    "    # configure HyperparameterTuner\n",
    "    my_tuner = HyperparameterTuner(\n",
    "        estimator=svm_tune,  # previously-configured Estimator object\n",
    "        objective_metric_name=\"validation:binary_classification_accuracy\",\n",
    "        hyperparameter_ranges=hyperparameter_ranges,\n",
    "        max_jobs=20,\n",
    "        max_parallel_jobs=2,\n",
    "        strategy=\"Random\",\n",
    "    )\n",
    "\n",
    "    # start hyperparameter tuning job\n",
    "    my_tuner.fit(inputs=data_channels, include_cls_metadata=False, job_name=prm_tuning_job_name)\n",
    "    print(f\"Create tuning job {prm_tuning_job_name}: SUCCESSFUL\")\n",
    "except ClientError as e:\n",
    "    if \"ResourceInUse\" in str(e):\n",
    "        my_tuner = HyperparameterTuner.attach(prm_tuning_job_name)\n",
    "        print(f\"Attach tuning job {prm_tuning_job_name}: SUCCESSFUL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check status\n",
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=my_tuner.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_analytics = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    my_tuner.latest_tuning_job.job_name\n",
    ").dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tuning jobs.\n",
      "Stored 'tune_trial_name' (str)\n",
      "Associate all training jobs created by ll-svm-tuning-job with trial ll-svm-tuning-job-trial\n"
     ]
    }
   ],
   "source": [
    "# get the most recently created tuning jobs\n",
    "list_tuning_jobs_response = smclient.list_hyper_parameter_tuning_jobs(\n",
    "    SortBy=\"CreationTime\", SortOrder=\"Descending\"\n",
    ")\n",
    "\n",
    "# inspect output\n",
    "print(f'Found {len(list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"])} tuning jobs.')\n",
    "tuning_jobs = list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"]\n",
    "most_recently_created_tuning_job = tuning_jobs[0]\n",
    "tuning_job_name = most_recently_created_tuning_job[\"HyperParameterTuningJobName\"]\n",
    "experiment_name = my_experiment.experiment_name\n",
    "tune_trial_name = tuning_job_name + \"-trial\"\n",
    "%store tune_trial_name\n",
    "\n",
    "print(f\"Associate all training jobs created by {tuning_job_name} with trial {tune_trial_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    tune_trial = Trial.load(trial_name=tune_trial_name)\n",
    "    print(f\"Loaded existing trial: {tune_trial_name}\")\n",
    "except Exception as e:\n",
    "    if \"ResourceNotFound\" in str(e):\n",
    "        tune_trial = Trial.create(experiment_name=experiment_name, trial_name=tune_trial_name)\n",
    "        print(f\"Create trial {tune_trial.trial_name}: SUCCESSFUL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import HyperparameterTuningJobAnalytics, Session\n",
    "from smexperiments.search_expression import Filter, Operator, SearchExpression\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "\n",
    "# get the training jobs associated with the tuning job\n",
    "tuning_analytics = HyperparameterTuningJobAnalytics(tuning_job_name, sess)\n",
    "\n",
    "training_job_summaries = tuning_analytics.training_job_summaries()\n",
    "training_job_arns = list(map(lambda x: x[\"TrainingJobArn\"], training_job_summaries))\n",
    "print(\n",
    "    f\"Found {len(training_job_arns)} training jobs for hyperparameter tuning job {tuning_job_name}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 trial components.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# get the trial components derived from the training jobs\n",
    "creation_time = most_recently_created_tuning_job[\"CreationTime\"]\n",
    "creation_time = creation_time.astimezone(timezone.utc)\n",
    "creation_time = creation_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "created_after_filter = Filter(\n",
    "    name=\"CreationTime\",\n",
    "    operator=Operator.GREATER_THAN_OR_EQUAL,\n",
    "    value=str(creation_time),\n",
    ")\n",
    "\n",
    "# the training job names contain the tuning job name (and the training job name is in the source arn)\n",
    "source_arn_filter = Filter(\n",
    "    name=\"Source.SourceArn\", operator=Operator.CONTAINS, value=tuning_job_name\n",
    ")\n",
    "source_type_filter = Filter(\n",
    "    name=\"Source.SourceType\", operator=Operator.EQUALS, value=\"SageMakerTrainingJob\"\n",
    ")\n",
    "\n",
    "search_expression = SearchExpression(\n",
    "    filters=[created_after_filter, source_arn_filter, source_type_filter]\n",
    ")\n",
    "\n",
    "# search iterates over every page of results by default\n",
    "trial_component_search_results = list(\n",
    "    TrialComponent.search(search_expression=search_expression, sagemaker_boto_client=smclient)\n",
    ")\n",
    "print(f\"Found {len(trial_component_search_results)} trial components.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate the trial components with the trial\n",
    "for tc in trial_component_search_results:\n",
    "    print(\n",
    "        f\"Associating trial component {tc.trial_component_name} with trial {tune_trial.trial_name}.\"\n",
    "    )\n",
    "    tune_trial.add_trial_component(tc.trial_component_name)\n",
    "    # sleep to avoid throttling\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094162</td>\n",
       "      <td>ll-svm-tuning-job-020-de38493c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.807778</td>\n",
       "      <td>2021-03-16 02:48:13+00:00</td>\n",
       "      <td>2021-03-16 02:49:25+00:00</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018556</td>\n",
       "      <td>ll-svm-tuning-job-019-b5e9ee8d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>2021-03-16 02:48:17+00:00</td>\n",
       "      <td>2021-03-16 02:49:38+00:00</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108048</td>\n",
       "      <td>ll-svm-tuning-job-018-e720402b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>2021-03-16 02:44:49+00:00</td>\n",
       "      <td>2021-03-16 02:46:02+00:00</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105569</td>\n",
       "      <td>ll-svm-tuning-job-017-ee995315</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.798889</td>\n",
       "      <td>2021-03-16 02:43:54+00:00</td>\n",
       "      <td>2021-03-16 02:45:16+00:00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256796</td>\n",
       "      <td>ll-svm-tuning-job-016-f023d0fb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.792222</td>\n",
       "      <td>2021-03-16 02:40:53+00:00</td>\n",
       "      <td>2021-03-16 02:42:17+00:00</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.368504</td>\n",
       "      <td>ll-svm-tuning-job-015-e97dc476</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>2021-03-16 02:39:49+00:00</td>\n",
       "      <td>2021-03-16 02:41:15+00:00</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018072</td>\n",
       "      <td>ll-svm-tuning-job-014-fcf45964</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>2021-03-16 02:36:51+00:00</td>\n",
       "      <td>2021-03-16 02:38:03+00:00</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.234124</td>\n",
       "      <td>ll-svm-tuning-job-013-a1f86f0f</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.837778</td>\n",
       "      <td>2021-03-16 02:35:57+00:00</td>\n",
       "      <td>2021-03-16 02:37:24+00:00</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027784</td>\n",
       "      <td>ll-svm-tuning-job-012-e5277482</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>2021-03-16 02:33:05+00:00</td>\n",
       "      <td>2021-03-16 02:34:08+00:00</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.187483</td>\n",
       "      <td>ll-svm-tuning-job-011-cc73e5e8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>2021-03-16 02:32:16+00:00</td>\n",
       "      <td>2021-03-16 02:33:26+00:00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.099079</td>\n",
       "      <td>ll-svm-tuning-job-010-07005361</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>2021-03-16 02:29:00+00:00</td>\n",
       "      <td>2021-03-16 02:30:17+00:00</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.017746</td>\n",
       "      <td>ll-svm-tuning-job-009-e77521ff</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>2021-03-16 02:28:39+00:00</td>\n",
       "      <td>2021-03-16 02:29:47+00:00</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.020755</td>\n",
       "      <td>ll-svm-tuning-job-008-6ed6082e</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>2021-03-16 02:25:19+00:00</td>\n",
       "      <td>2021-03-16 02:26:12+00:00</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.048608</td>\n",
       "      <td>ll-svm-tuning-job-007-692a0a7d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>2021-03-16 02:24:51+00:00</td>\n",
       "      <td>2021-03-16 02:26:38+00:00</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.027099</td>\n",
       "      <td>ll-svm-tuning-job-006-99d391aa</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>2021-03-16 02:20:51+00:00</td>\n",
       "      <td>2021-03-16 02:21:53+00:00</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.282473</td>\n",
       "      <td>ll-svm-tuning-job-005-06ecccfa</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.795556</td>\n",
       "      <td>2021-03-16 02:20:34+00:00</td>\n",
       "      <td>2021-03-16 02:22:21+00:00</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.026969</td>\n",
       "      <td>ll-svm-tuning-job-004-329ec538</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>2021-03-16 02:16:39+00:00</td>\n",
       "      <td>2021-03-16 02:17:53+00:00</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010212</td>\n",
       "      <td>ll-svm-tuning-job-003-a889d04c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.845556</td>\n",
       "      <td>2021-03-16 02:16:56+00:00</td>\n",
       "      <td>2021-03-16 02:17:46+00:00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.051641</td>\n",
       "      <td>ll-svm-tuning-job-002-9f9f727b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.824444</td>\n",
       "      <td>2021-03-16 02:12:43+00:00</td>\n",
       "      <td>2021-03-16 02:14:05+00:00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.022299</td>\n",
       "      <td>ll-svm-tuning-job-001-1694f3c9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>2021-03-16 02:13:00+00:00</td>\n",
       "      <td>2021-03-16 02:14:03+00:00</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate                 TrainingJobName TrainingJobStatus  \\\n",
       "0        0.094162  ll-svm-tuning-job-020-de38493c         Completed   \n",
       "1        0.018556  ll-svm-tuning-job-019-b5e9ee8d         Completed   \n",
       "2        0.108048  ll-svm-tuning-job-018-e720402b         Completed   \n",
       "3        0.105569  ll-svm-tuning-job-017-ee995315         Completed   \n",
       "4        0.256796  ll-svm-tuning-job-016-f023d0fb         Completed   \n",
       "5        0.368504  ll-svm-tuning-job-015-e97dc476         Completed   \n",
       "6        0.018072  ll-svm-tuning-job-014-fcf45964         Completed   \n",
       "7        0.234124  ll-svm-tuning-job-013-a1f86f0f         Completed   \n",
       "8        0.027784  ll-svm-tuning-job-012-e5277482         Completed   \n",
       "9        0.187483  ll-svm-tuning-job-011-cc73e5e8         Completed   \n",
       "10       0.099079  ll-svm-tuning-job-010-07005361         Completed   \n",
       "11       0.017746  ll-svm-tuning-job-009-e77521ff         Completed   \n",
       "12       0.020755  ll-svm-tuning-job-008-6ed6082e         Completed   \n",
       "13       0.048608  ll-svm-tuning-job-007-692a0a7d         Completed   \n",
       "14       0.027099  ll-svm-tuning-job-006-99d391aa         Completed   \n",
       "15       0.282473  ll-svm-tuning-job-005-06ecccfa         Completed   \n",
       "16       0.026969  ll-svm-tuning-job-004-329ec538         Completed   \n",
       "17       0.010212  ll-svm-tuning-job-003-a889d04c         Completed   \n",
       "18       0.051641  ll-svm-tuning-job-002-9f9f727b         Completed   \n",
       "19       0.022299  ll-svm-tuning-job-001-1694f3c9         Completed   \n",
       "\n",
       "    FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0              0.807778 2021-03-16 02:48:13+00:00 2021-03-16 02:49:25+00:00   \n",
       "1              0.817778 2021-03-16 02:48:17+00:00 2021-03-16 02:49:38+00:00   \n",
       "2              0.803333 2021-03-16 02:44:49+00:00 2021-03-16 02:46:02+00:00   \n",
       "3              0.798889 2021-03-16 02:43:54+00:00 2021-03-16 02:45:16+00:00   \n",
       "4              0.792222 2021-03-16 02:40:53+00:00 2021-03-16 02:42:17+00:00   \n",
       "5              0.810000 2021-03-16 02:39:49+00:00 2021-03-16 02:41:15+00:00   \n",
       "6              0.822222 2021-03-16 02:36:51+00:00 2021-03-16 02:38:03+00:00   \n",
       "7              0.837778 2021-03-16 02:35:57+00:00 2021-03-16 02:37:24+00:00   \n",
       "8              0.835556 2021-03-16 02:33:05+00:00 2021-03-16 02:34:08+00:00   \n",
       "9              0.826667 2021-03-16 02:32:16+00:00 2021-03-16 02:33:26+00:00   \n",
       "10             0.797778 2021-03-16 02:29:00+00:00 2021-03-16 02:30:17+00:00   \n",
       "11             0.816667 2021-03-16 02:28:39+00:00 2021-03-16 02:29:47+00:00   \n",
       "12             0.846667 2021-03-16 02:25:19+00:00 2021-03-16 02:26:12+00:00   \n",
       "13             0.797778 2021-03-16 02:24:51+00:00 2021-03-16 02:26:38+00:00   \n",
       "14             0.816667 2021-03-16 02:20:51+00:00 2021-03-16 02:21:53+00:00   \n",
       "15             0.795556 2021-03-16 02:20:34+00:00 2021-03-16 02:22:21+00:00   \n",
       "16             0.808889 2021-03-16 02:16:39+00:00 2021-03-16 02:17:53+00:00   \n",
       "17             0.845556 2021-03-16 02:16:56+00:00 2021-03-16 02:17:46+00:00   \n",
       "18             0.824444 2021-03-16 02:12:43+00:00 2021-03-16 02:14:05+00:00   \n",
       "19             0.827778 2021-03-16 02:13:00+00:00 2021-03-16 02:14:03+00:00   \n",
       "\n",
       "    TrainingElapsedTimeSeconds  \n",
       "0                         72.0  \n",
       "1                         81.0  \n",
       "2                         73.0  \n",
       "3                         82.0  \n",
       "4                         84.0  \n",
       "5                         86.0  \n",
       "6                         72.0  \n",
       "7                         87.0  \n",
       "8                         63.0  \n",
       "9                         70.0  \n",
       "10                        77.0  \n",
       "11                        68.0  \n",
       "12                        53.0  \n",
       "13                       107.0  \n",
       "14                        62.0  \n",
       "15                       107.0  \n",
       "16                        74.0  \n",
       "17                        50.0  \n",
       "18                        82.0  \n",
       "19                        63.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the output of all of the hyperparameter tuning trial runs\n",
    "tuning_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict\n",
    "\n",
    "### Deploy Model with Batch Transform and Get Inferences for the Test Dataset\n",
    "\n",
    "Let's predict on our test dataset to understand how accurate our model is. We will create batch inferences and use a helper function to evaludate the results. \n",
    "\n",
    "Use batch transform when you:\n",
    "- Want to get inferences for an entire dataset and index them to serve inferences in real time\n",
    "- Don't need a persistent endpoint that applications (for example, web or mobile apps) can call to get inferences\n",
    "- Don't need the subsecond latency that SageMaker hosted endpoints provide\n",
    "\n",
    "Read more about [Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a `sagemaker.transformer.Transformer` object from the model that was trained in the sections above. Then it calls that object's transform method to create a transform job. When you create the `sagemaker.transformer.Transformer` object, you specify the number and type of ML instances to use to perform the batch transform job, and the location in Amazon S3 where you want to store the inferences.For more information, see [SageMaker Transformer](https://sagemaker.readthedocs.io/en/stable/transformer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best model, deploy and get batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get best model\n",
    "best_model = my_tuner.best_estimator()\n",
    "\n",
    "# the location of the test dataset\n",
    "batch_input = path_to_test_x_data_prm\n",
    "\n",
    "# the location to store the results of the batch transform job\n",
    "batch_output = f\"s3://{bucket}/transform/batch-inference\"\n",
    "\n",
    "# create transformer for best model\n",
    "transformer = best_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=batch_output,\n",
    "    accept=\"application/json\",\n",
    ")\n",
    "\n",
    "# get batch inferences\n",
    "transformer.transform(data=batch_input, content_type=\"text/csv\", split_type=\"Line\")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that our Batch Transform job is complete, we can download the predictions and evaluate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the endpoint returned JSON which contains `predictions`, including the `score` and `predicted_label`.  In this case, `score` will be a continuous value between [0, 1] representing the probability there will be a failure in the window. `predicted_label` will take a value of either `0` or `1` where `1` denotes that we predict a failure within the next designated time window, while `0` denotes that we are predicting that there is not a failure within the next time window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(batch_file_path, test_labels, model_name, metrics=True):\n",
    "    \"\"\"\n",
    "    Download batch predictions and iterate through results. Evaluate model results by comparing to actuals from test data.\n",
    "    Return binary classification metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # open batch prediction file and parse json to exctract predicted label\n",
    "    with open(batch_file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            result = json.loads(line)\n",
    "            predictions = pd.Series(\n",
    "                [\n",
    "                    result[\"predictions\"][i][\"predicted_label\"]\n",
    "                    for i in range(len(result[\"predictions\"]))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, predictions).sum()\n",
    "    fp = np.logical_and(1 - test_labels, predictions).sum()\n",
    "    tn = np.logical_and(1 - test_labels, 1 - predictions).sum()\n",
    "    fn = np.logical_and(test_labels, 1 - predictions).sum()\n",
    "\n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    if metrics:\n",
    "        print(pd.crosstab(test_labels, predictions, rownames=[\"actuals\"], colnames=[\"predictions\"]))\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"F1: {f1}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"TN\": tn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1\": f1,\n",
    "        \"Model\": model_name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call evaluation function and inspect results\n",
    "test = pd.read_csv(path_to_test_data_prm, header=None)\n",
    "test_y = test[0]\n",
    "evaluate_model(\"test_x.csv.out\", test_y, \"PrM-Classification-SVM\", metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up  (Optional)\n",
    "\n",
    "Once we're done don't forget to clean up the endpoint and experiments to prevent unnecessary billing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(predictor):\n",
    "    try:\n",
    "        boto3.client(\"sagemaker\").delete_endpoint(EndpointName=predictor.endpoint)\n",
    "        print(\"Deleted {}\".format(predictor.endpoint))\n",
    "    except:\n",
    "        print(\"Already deleted: {}\".format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run this cell if you deployed your estimator instead of doing Batch Transform\n",
    "# delete_endpoint(svm_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) In order to delete the experiments created, you can `delete_all` or use the `cleanup_boto3` helper function to delete individual experiments by passing the experiment name to the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to delete the experiment and all its related trials and trial components\n",
    "# my_experiment.delete_all(action='--force')\n",
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def cleanup_boto3(experiment_name):\n",
    "    trials = sm.list_trials(ExperimentName=experiment_name)[\"TrialSummaries\"]\n",
    "    print(\"TrialNames:\")\n",
    "    for trial in trials:\n",
    "        trial_name = trial[\"TrialName\"]\n",
    "        print(f\"\\n{trial_name}\")\n",
    "\n",
    "        components_in_trial = sm.list_trial_components(TrialName=trial_name)\n",
    "        print(\"\\tTrialComponentNames:\")\n",
    "        for component in components_in_trial[\"TrialComponentSummaries\"]:\n",
    "            component_name = component[\"TrialComponentName\"]\n",
    "            print(f\"\\t{component_name}\")\n",
    "            sm.disassociate_trial_component(TrialComponentName=component_name, TrialName=trial_name)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                sm.delete_trial_component(TrialComponentName=component_name)\n",
    "            except:\n",
    "                # component is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(0.5)\n",
    "        sm.delete_trial(TrialName=trial_name)\n",
    "    sm.delete_experiment(ExperimentName=experiment_name)\n",
    "    print(f\"\\nExperiment {experiment_name} deleted\")\n",
    "\n",
    "\n",
    "# Call cleanup_boto3\n",
    "\n",
    "# Use experiment name not display name\n",
    "experiment_name = my_experiment.experiment_name\n",
    "# cleanup_boto3(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "---\n",
    "## Extensions\n",
    "\n",
    "* Our linear model does a relatively good job of predicting if a failure will occur in the next window of time and has an overall accuracy of close to 84%, but we can re-run the model with different values of the hyperparameters, loss functions etc and see if we get improved prediction\n",
    "    * Re-running the model with further tweaks to these hyperparameters may provide more accurate out-of-sample predictions\n",
    "* We also did not do much feature engineering\n",
    "    * We can create additional features by considering cross-product/intreaction of multiple features, squaring or raising higher powers of the features to induce non-linear effects, etc. \n",
    "    * If we expand the features using non-linear terms and interactions, we can then tweak the regulaization parameter to optimize the expanded model and hence generate improved forecasts\n",
    "* As a further extension, we can experiment with many tree-based models such as XGBoost, Random Forest, or gradient boosting to address the class imbalance as these models are less sensitive to class imbalances \n",
    "* Once the model performance has met the business's desired output, it can be deployed at the edge using [AWS IoT Greengrass](https://aws.amazon.com/greengrass/)\n",
    "    * Here is an additional example of [Predictive Maintenance Deployed at the Edge](https://github.com/aws-samples/amazon-sagemaker-predictive-maintenance-deployed-at-edge) using SageMaker and Greengrass for guidance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additonal Resources\n",
    "\n",
    "- [A Survey of Predictive Maintenance: Systems, Purposes and Approaches](https://arxiv.org/pdf/1912.07383.pdf)\n",
    "-[Cost-Sensitive Learning for Predictive Maintenance](https://arxiv.org/pdf/1809.10979.pdf)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
