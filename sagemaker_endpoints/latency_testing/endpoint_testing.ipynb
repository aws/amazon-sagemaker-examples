{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9373624e-e98e-4647-adfe-909c807c88e6",
   "metadata": {},
   "source": [
    "# Comparing Inference Latency of Models Served with Flask and FastAPI on SageMaker Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8461a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec9835-9d01-4752-a320-1a766e81bfe5",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This notebook will demontrate how the inference latency of the same model varies when one model is served with [Python Flask](https://flask.palletsprojects.com/en/2.3.x/), [FastAPI](https://fastapi.tiangolo.com/) and [SageMaker pre-built container](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html). In all cases, we use a [decision tree](https://scikit-learn.org/stable/modules/tree.html) algorithm from [scikit-learn](https://scikit-learn.org/stable/) package which is trained on the famous [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). \n",
    "\n",
    "The scripts and this notebook can be used to load test and compare latency for any endpoint that you deploy on SageMaker. You can either test a [pre-built SageMaker container](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html) or [bring your own container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-byoc-containers.html). [This GitHub repo](https://github.com/aws/amazon-sagemaker-examples/tree/main/advanced_functionality/scikit_bring_your_own) provides a more detailed example on how to bring your own container to SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841ed5e-bd78-4972-92da-9d821b7da453",
   "metadata": {},
   "source": [
    "## Pre-requisities\n",
    "\n",
    "### Permissions\n",
    "\n",
    "Running this notebook requires `SageMakerFullAccess` permissions. Additionally you will need permissions to publish to Amazon ECR. You can achieve this by adding the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately.\n",
    "\n",
    "### Python Version\n",
    "This notebook example was run using python 3.10. If you are using SageMaker notebook instance to execute this notebook, please use `Amazon Linux 2, Jupyter Lab 3(notebook-al2-v2)` platform identifier.\n",
    "\n",
    "### Docker\n",
    "\n",
    "Docker is required to build and push model images to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current python version\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86868f-fe43-44f4-a462-1bfe2f0e4234",
   "metadata": {},
   "source": [
    "## The experiment\n",
    "\n",
    "Load testing is carried out on `ml.c5d.18xlarge` SageMaker Notebook Instance type. It is recommended to use a large instance type for load testing in order to be able to provide the adeqate load on the Inference Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36526e88",
   "metadata": {},
   "source": [
    "![Diagram](img/diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87961e89-de75-4db5-8e44-428d759dbcfd",
   "metadata": {},
   "source": [
    "# Part 1: Bundling and Pushing Models to Amazon ECR\n",
    "\n",
    "There is a script inside each model folder to build and push a model image to ECR. The script logs in to ECR, builds and tags an image and pushes the image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f314fd-accb-4b0b-8bd6-9f40c2ac1f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff01fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"flask-model\", \"fastapi-model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592759d7-2fc4-4a2f-b12b-e803d92d9642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x ./build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa763f-e8c2-4ad7-bd50-b7991b8a4421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_and_push(model):\n",
    "    try:\n",
    "        result = subprocess.run([\"./build_and_push.sh\", f\"{model}\"],\n",
    "                                    capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Successfully built and pushed {model} to Amazon ECR\")\n",
    "        else:\n",
    "            print(f\"Error building and pushing {model}\")\n",
    "            print(f\"stdout: {result.stdout}\")\n",
    "            print(f\"stderr: {result.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80afbf-4861-438e-8b19-51e196cce703",
   "metadata": {},
   "source": [
    "Below is the script for building and pushing our custom algorithm containers. It looks for an ECR repository in the account you're using and the current default region (if you're using a SageMaker notebook instance, this will be the region where the notebook instance was created). If the repository doesn't exist, the script will create it, build the image and push to the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b273a-cd68-4549-bbcf-d6fba485a36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat ./build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469ea96-eb94-4be6-8ef7-3a1a4d30a23b",
   "metadata": {},
   "source": [
    "The cell below executes the scrip and may take a few minutes to run (docker images are building here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd5e29-3796-48b3-98d4-1fbfe71e4f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for model in models:\n",
    "        futures.append(executor.submit(build_and_push, model=model))\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495029f",
   "metadata": {},
   "source": [
    "# Part 2: Training and Deploying models to SageMaker Inference Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072c5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = \"sagemaker-endpoint-testing-example\"\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1ddc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data location\n",
    "WORK_DIRECTORY = \"data\"\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41828ef5",
   "metadata": {},
   "source": [
    "## Train and deploy models in paralled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3aa06",
   "metadata": {},
   "source": [
    "### Define train and deploy code for custom containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f494e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_deploy_custom_container_models(endpoint):\n",
    "    image = f\"{account}.dkr.ecr.{region}.amazonaws.com/{endpoint}:latest\"\n",
    "    tree = sage.estimator.Estimator(\n",
    "        image,\n",
    "        role,\n",
    "        1,\n",
    "        \"ml.c4.2xlarge\",\n",
    "        output_path=f\"s3://{sess.default_bucket()}/output\",\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "\n",
    "    tree.fit(data_location)\n",
    "\n",
    "    tree.deploy(1, \"ml.m4.xlarge\", serializer=CSVSerializer(),\n",
    "                endpoint_name=endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd2ef2",
   "metadata": {},
   "source": [
    "### Define train and deploy code for SageMaker pre-built container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8d376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# A sample training component that trains a simple scikit-learn decision tree model.\n",
    "# This implementation works in File mode and makes no assumptions about the input file names.\n",
    "# Input is specified as CSV with a data point in each row and the labels in the first column.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "# These are the paths to where SageMaker mounts interesting things in your container.\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = prefix + 'input/data'\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "param_path = os.path.join(prefix, 'input/config/hyperparameters.json')\n",
    "\n",
    "# This algorithm has a single channel of input data called 'training'. Since we run in\n",
    "# File mode, the input files are copied to the directory specified here.\n",
    "channel_name='training'\n",
    "training_path = os.path.join(input_path, channel_name)\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    #Load Model\n",
    "    with open(os.path.join(model_dir, \"decision-tree-model.pkl\"), \"rb\") as inp:\n",
    "        clf = pickle.load(inp)\n",
    "    return clf\n",
    "\n",
    "\n",
    "# The function to execute the training.\n",
    "def train():\n",
    "    print('Starting the training.')\n",
    "    try:\n",
    "        # Read in any hyperparameters that the user passed with the training job\n",
    "        with open(param_path, 'r') as tc:\n",
    "            trainingParams = json.load(tc)\n",
    "\n",
    "        # Take the set of files and read them all into a single pandas dataframe\n",
    "        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]\n",
    "        if len(input_files) == 0:\n",
    "            raise ValueError(('There are no files in {}.\\n' +\n",
    "                              'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                              'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                              'does not have permission to access the data.').format(training_path, channel_name))\n",
    "        raw_data = [ pd.read_csv(file, header=None) for file in input_files if file.endswith(\".csv\")]\n",
    "        train_data = pd.concat(raw_data)\n",
    "\n",
    "        # labels are in the first column\n",
    "        train_y = train_data.iloc[:,0]\n",
    "        train_X = train_data.iloc[:,1:]\n",
    "\n",
    "        # Here we only support a single hyperparameter. Note that hyperparameters are always passed in as\n",
    "        # strings, so we need to do any necessary conversions.\n",
    "        max_leaf_nodes = trainingParams.get('max_leaf_nodes', None)\n",
    "        if max_leaf_nodes is not None:\n",
    "            max_leaf_nodes = int(max_leaf_nodes)\n",
    "\n",
    "        # Now use scikit-learn's decision tree classifier to train the model.\n",
    "        clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n",
    "        clf = clf.fit(train_X, train_y)\n",
    "        \n",
    "        model_dir = os.environ['SM_MODEL_DIR']\n",
    "\n",
    "        # save the model\n",
    "        with open(os.path.join(model_dir, 'decision-tree-model.pkl'), 'wb') as out:\n",
    "            pickle.dump(clf, out)\n",
    "        print('Training complete.')\n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(model_dir, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print('Exception during training: ' + str(e) + '\\n' + trc, file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434b720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_deploy_prebuilt_container_model(model_name):\n",
    "    FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point=\"script.py\",\n",
    "        role=get_execution_role(),\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.c5.xlarge\",\n",
    "        framework_version=FRAMEWORK_VERSION,\n",
    "        base_job_name=\"sagemaker-scikit-tree\",\n",
    "    )\n",
    "\n",
    "    sklearn_estimator.fit(data_location)\n",
    "\n",
    "    sklearn_estimator.deploy(1, \"ml.m4.xlarge\", serializer=CSVSerializer(),\n",
    "                endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d7d97",
   "metadata": {},
   "source": [
    "## Kick off parallel training and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa16e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_built_enpoint_name = 'sagemaker-scikit-pre-built'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef4504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for model in models:\n",
    "        futures.append(executor.submit(train_and_deploy_custom_container_models, endpoint=model))\n",
    "\n",
    "    futures.append(executor.submit(train_and_deploy_prebuilt_container_model, model_name=pre_built_enpoint_name))\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34d7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models.append(pre_built_enpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee4d3a-fc48-4a8d-b2b0-8a0bd95eaf83",
   "metadata": {},
   "source": [
    "# Part 3: Load Testing and Measuring Latency of Each Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec71076-79eb-48fc-a329-625ea9985cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install locust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ab561-4c23-42d1-9f04-0c049f13b416",
   "metadata": {},
   "source": [
    "## Launch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd3e04",
   "metadata": {},
   "source": [
    "### Locust Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead84ee",
   "metadata": {},
   "source": [
    "In our experiment, Locust was configured to simulate the behaviour of 200 users, with each user represented by a worker. We ran 30 workers concurrently to generate realistic traffic levels. Each load test point was executed for a duration of 5 minutes, providing sufficient time to capture latency metrics under varying levels of load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e6866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat ./load-testing/run_locust.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87809a8e",
   "metadata": {},
   "source": [
    "The locust script iteself is then cofigured to hit the SageMaker invoke endpoint API for each request thatis being made by locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa7bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat ./load-testing/locust_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7908a7d-1276-488e-819e-f2f0d5da701a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x ./load-testing/run_locust.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea4143-32a2-4a1c-98d5-b93b066b48cb",
   "metadata": {},
   "source": [
    "A test for each endpoint takes around 5 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb987c-92ad-4f3f-8d4d-7c234351388b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"./load-testing/run_locust.sh\", f\"{model}\", f\"{region}\"], capture_output=True, text=True\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Finished load testing for {model} endpoint\")\n",
    "        else:\n",
    "            print(f\"Error load testing {model} endpoint:\", result.stderr)\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b620e-e0fa-4c4e-b5ba-68f3980d2c79",
   "metadata": {},
   "source": [
    "# Part 4: Visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8dfa1a",
   "metadata": {},
   "source": [
    "Locust results are saved in csv files inside the load-testing folder. We load the cvs for each model into pandas and we are specifically interested in min, max and average response times from our endpoints. We build a dictionary with those values and plot a box-plot to visualise the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a90c36-fc36-4dae-b63c-bf2b6967fb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latency_dict = {}\n",
    "\n",
    "# for each endpoint get latency from the load test results\n",
    "for model in models:\n",
    "    df = pd.read_csv(f\"./load-testing/results_{model}_stats.csv\")\n",
    "\n",
    "    min_latency = round(df.tail(1)[\"Min Response Time\"].values[0] / 1000, 1)\n",
    "    avg_latency = round(df.tail(1)[\"Average Response Time\"].values[0] / 1000, 1)\n",
    "    max_latency = round(df.tail(1)[\"Max Response Time\"].values[0] / 1000, 1)\n",
    "\n",
    "    latency_dict.update({model: [min_latency, avg_latency, max_latency]})\n",
    "\n",
    "# generate a data frame of the results and plot a box plot\n",
    "results = pd.DataFrame(latency_dict)\n",
    "res_plot = results.plot(\n",
    "    legend=True,\n",
    "    figsize=(12, 7),\n",
    "    kind=\"box\",\n",
    "    title=\"Request Latency Across Model Types\",\n",
    "    xlabel=\"Model Type\",\n",
    "    ylabel=\"Latency in Seconds\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b1c09",
   "metadata": {},
   "source": [
    "# Part 5: Cleanup Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5c5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3df1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    try:\n",
    "        sm_client.delete_endpoint(\n",
    "            EndpointName=model\n",
    "        )\n",
    "        sm_client.delete_endpoint_config(\n",
    "            EndpointConfigName=model\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting endpoint {model}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24aaf1",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_endpoints|latency_testing|endpoint_testing.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
