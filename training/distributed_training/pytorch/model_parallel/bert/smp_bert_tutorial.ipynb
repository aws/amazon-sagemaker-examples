{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Amazon Sagemaker Distributed Model Parallel to Launch a BERT Training Job with Model Parallelization\n",
    "\n",
    "Sagemaker distributed model parallel (SMP) is a model parallelism library for training large deep learning models that were previously difficult to train due to GPU memory limitations. SMP automatically and efficiently splits a model across multiple GPUs and instances and coordinates model training, allowing you to increase prediction accuracy by creating larger models with more parameters.\n",
    "\n",
    "Use this notebook to configure SMP to train a model using PyTorch (version 1.6.0) and the [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#train-a-model-with-the-sagemaker-python-sdk).\n",
    "\n",
    "In this notebook, you will use a BERT example training script with SMP.\n",
    "The example script is based on [Nvidia Deep Learning Examples](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT) and requires you to download the datasets and upload them to Amazon Simple Storage Service (Amazon S3) as explained in the instructions below. This is a large dataset, and so depending on your connection speed, this process can take hours to complete. \n",
    "\n",
    "This notebook depends on the following files. You can find all files in the [bert directory](https://github.com/aws/amazon-sagemaker-examples/tree/master/training/distributed_training/pytorch/model_parallel/bert) in the model parllel section of the Amazon SageMaker Examples notebooks repo.\n",
    "\n",
    "* `bert_example/sagemaker_smp_pretrain.py`: This is an entrypoint script that is passed to the Pytorch estimator in the notebook instructions. This script is responsible for end to end training of the BERT model with SMP. The script has additional comments at places where the SMP API is used.\n",
    "\n",
    "* `bert_example/modeling.py`: This contains the model definition for the BERT model.\n",
    "\n",
    "* `bert_example/bert_config.json`: This allows for additional configuration of the model and is used by `modeling.py`. Additional configuration includes dropout probabilities, pooler and encoder sizes, number of hidden layers in the encoder, size of the intermediate layers in the encoder etc.\n",
    "\n",
    "* `bert_example/schedulers.py`: contains definitions for learning rate schedulers used in end to end training of the BERT model (`bert_example/sagemaker_smp_pretrain.py`).\n",
    "\n",
    "* `bert_example/utils.py`: This contains different helper utility functions used in end to end training of the BERT model (`bert_example/sagemaker_smp_pretrain.py`).\n",
    "\n",
    "* `bert_example/file_utils.py`: Contains different file utility functions used in model definition (`bert_example/modeling.py`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "If you are a new user of Amazon SageMaker, you may find the following helpful to learn more about SMP and using SageMaker with Pytorch. \n",
    "\n",
    "* To learn more about the SageMaker model parallelism library, see [Model Parallel Distributed Training with SageMaker Distributed](http://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html).\n",
    "\n",
    "* To learn more about using the SageMaker Python SDK with Pytorch, see [Using PyTorch with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html).\n",
    "\n",
    "* To learn more about launching a training job in Amazon SageMaker with your own training image, see [Use Your Own Training Algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html).\n",
    "\n",
    "\n",
    "### Prerequisites \n",
    "\n",
    "1. You must create an S3 bucket to store the input data to be used for training. This bucket must must be located in the same AWS Region you use to launch your training job. This is the AWS Region you use to run this notebook. To learn how, see [Creating a bucket](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html) in the Amazon S3 documentation.\n",
    "\n",
    "2. You must download the dataset that you use for training from [Nvidia Deep Learning Examples](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT) and upload it to the S3 bucket you created. To learn more about the datasets and scripts provided to preprocess and download it, see [Getting the data](https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/README.md#getting-the-data) in the Nvidia Deep Learning Examples repo README. You can also use the [Quick Start Guide](https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/README.md#quick-start-guide) to learn how to download the dataset. The repository consists of three datasets. Optionally, you can to use the `wiki_only` parameter to only download the Wikipedia dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrade Sagemaker SDK to the latest version.\n",
    "NOTE: This step may require a kernel restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.23.1.tar.gz (400 kB)\n",
      "\u001b[K     |████████████████████████████████| 400 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: attrs in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3>=1.16.32 in /home/ubuntu/.local/lib/python3.6/site-packages (from sagemaker) (1.16.36)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta in /home/ubuntu/.local/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: protobuf3-to-dict>=0.1.5 in /home/ubuntu/.local/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Collecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.4.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (20.1)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.20.0,>=1.19.36 in /home/ubuntu/.local/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.19.36)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.36->boto3>=1.16.32->sagemaker) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.36->boto3>=1.16.32->sagemaker) (1.25.10)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.23.1-py2.py3-none-any.whl size=559547 sha256=6274f6fa8840ba1f32775764529946ada47d35f46fbea623d4a3ba01c8d4e4c5\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/f6/ea/42/c6241b7aef8d2f4cbe4af5672ecb3889f95fc3df8c599239a4\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: smdebug-rulesconfig, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.0\n",
      "    Uninstalling smdebug-rulesconfig-1.0.0:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.19.0\n",
      "    Uninstalling sagemaker-2.19.0:\n",
      "      Successfully uninstalled sagemaker-2.19.0\n",
      "Successfully installed sagemaker-2.23.1 smdebug-rulesconfig-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "original_version = sagemaker.__version__\n",
    "%pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the notebook instance. Get the AWS Region, SageMaker execution role Amazon Resource Name (ARN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name RL to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role:arn:aws:iam::688520471316:role/RL\n",
      "AWS account:688520471316\n",
      "AWS region:us-west-2\n",
      "['', '/home/ubuntu/anaconda3/envs/python3/lib/python36.zip', '/home/ubuntu/anaconda3/envs/python3/lib/python3.6', '/home/ubuntu/anaconda3/envs/python3/lib/python3.6/lib-dynload', '/home/ubuntu/.local/lib/python3.6/site-packages', '/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages', '/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n",
      "CPU times: user 932 ms, sys: 95.6 ms, total: 1.03 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import boto3\n",
    "\n",
    "role = get_execution_role() # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "print(f'SageMaker Execution Role:{role}')\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "print(f'AWS account:{account}')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "print(f'AWS region:{region}')\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=session)\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from smdistributed.modelparallel.torch.optimizers import FusedLAMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare/Identify your Training Data in Amazon S3\n",
    "\n",
    "If you don't already have the BERT dataset in an S3 bucket, please see the instructions in [Nvidia BERT Example](https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/README.md) to download the dataset and upload it to a s3 bucket. See the prerequisites at the beginning of this notebook for more information.\n",
    "\n",
    "Uncomment and use the following cell to specify the Amazon S3 bucket and prefix that contains your training data. For example, if your training data is in s3://your-bucket/training, enter `'your-bucket'` for s3_bucket and `'training'` for prefix. Note that your output data will be stored in the same bucket, under the `output/` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = 'sagemaker-us-west-2-688520471316'\n",
    "prefix = 'data/bert/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en_abstract'\n",
    "#prefix = '<ADD PREFIX>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SageMaker Data Channels\n",
    "\n",
    "In this step, you define Amazon SageMaker training data channel and output data path. The training data channel identifies where your training data is located in S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3train = f's3://{s3_bucket}/{prefix}'\n",
    "train = sagemaker.session.TrainingInput(s3train, distribution='FullyReplicated', \n",
    "                                        s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your output data path. This is where model artifacts are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your output data will be stored in: s3://sagemaker-us-west-2-688520471316/output/bert\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = f's3://{s3_bucket}/output'\n",
    "print(f'your output data will be stored in: s3://{s3_bucket}/output/bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SageMaker Training Job\n",
    "\n",
    "Next, you will use SageMaker Estimator API to define a SageMaker Training Job. You will use a [`PyTorchEstimator`](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html) to define the number and type of EC2 instances Amazon SageMaker uses for training, as well as the size of the volume attached to those instances. \n",
    "\n",
    "You must update the following:\n",
    "* `instance_count`\n",
    "* `instance_type`\n",
    "* `volume_size`\n",
    "\n",
    "See the following sub-sections for more details. \n",
    "\n",
    "### Update the Type and Number of EC2 Instances Used\n",
    "\n",
    "The instance type and number of instances you specify in `instance_type` and `instance_count` respectively will determine the number of GPUs Amazon SageMaker uses during training. Explicitly, `instance_type` will determine the number of GPUs on a single instance and that number will be multiplied by `instance_count`. \n",
    "\n",
    "You must specify values for `instance_type` and `instance_count` so that the total number of GPUs available for training is equal to `partitions` in `config` of `smp.init` in your training script. \n",
    "\n",
    "If you set ddp to `True`, you must ensure that the total number of GPUs available is divisible by `partitions`. The result of the division is inferred to be the number of model replicas to be used for Horovod (data parallelism degree). \n",
    "\n",
    "See [Amazon SageMaker Pricing](https://aws.amazon.com/sagemaker/pricing/) for SageMaker supported instances and cost information. To look up GPUs for each instance types, see [Amazon EC2 Instance Types](https://aws.amazon.com/ec2/instance-types/). Use the section **Accelerated Computing** to see general purpose GPU instances. Note that an ml.p3.2xlarge has the same number of GPUs as an p3.2xlarge.\n",
    "\n",
    "### Update your Volume Size\n",
    "\n",
    "The volume size you specify in `volume_size` must be larger than your input data size.\n",
    "\n",
    "### Set your parameters dictionary for SMP and set custom mpioptions\n",
    "\n",
    "With the parameters dictionary you can configure: the number of microbatches, number of partitions, whether to use data parallelism with ddp, the pipelining strategy, the placement strategy and other BERT specific hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpi_options = \"-verbose --mca orte_base_help_aggregate 0 \"\n",
    "smp_parameters = {\"optimize\": \"speed\", \"microbatches\": 12, \"partitions\": 2, \"ddp\": True, \"pipeline\": \"interleaved\", \"overlapping_allreduce\": True, \"placement_strategy\": \"cluster\", \"memory_weight\": 0.3}\n",
    "timeout = 60 * 60\n",
    "metric_definitions = [{\"Name\": \"base_metric\", \"Regex\": \"<><><><><><>\"}]\n",
    "\n",
    "hyperparameters = {\"input_dir\": \"/opt/ml/input/data/train\",\n",
    "                   \"output_dir\": \"./checkpoints\", \n",
    "                   \"config_file\": \"bert_config.json\", \n",
    "                   \"bert_model\": \"bert-large-uncased\", \n",
    "                   \"train_batch_size\": 48, \n",
    "                   \"max_seq_length\": 128,\n",
    "                   \"max_predictions_per_seq\": 20,\n",
    "                   \"max_steps\": 7038,\n",
    "                   \"warmup_proportion\": 0.2843,\n",
    "                   \"num_steps_per_checkpoint\": 200,\n",
    "                   \"learning_rate\": 6e-3,\n",
    "                   \"seed\": 12439,\n",
    "                   \"steps_this_run\": 500,\n",
    "                   \"allreduce_post_accumulation\": 1,\n",
    "                   \"allreduce_post_accumulation_fp16\": 1,\n",
    "                   \"do_train\": 1,\n",
    "                   \"use_sequential\": 1,\n",
    "                   \"skip_checkpoint\": 1,\n",
    "                   \"smp\": 1,\n",
    "                   \"apply_optimizer\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Pytorch Estimator with SMP enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "local_session = LocalSession()\n",
    "local_session.config = {\n",
    "    'local' : {\n",
    "        'local_mode':True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator = PyTorch(\"sagemaker_smp_pretrain.py\",\n",
    "                            role=role,\n",
    "                            instance_type=\"ml.p3.16xlarge\",\n",
    "                            volume_size=200,\n",
    "                            instance_count=1,\n",
    "                            sagemaker_session=sagemaker_session,\n",
    "                            py_version=\"py36\",\n",
    "                            framework_version='1.6.0',\n",
    "                            distribution={\n",
    "                                \"smdistributed\": {\n",
    "                                    \"modelparallel\": {\n",
    "                                        \"enabled\": True,\n",
    "                                        \"parameters\": smp_parameters\n",
    "                                    }\n",
    "                                },\n",
    "                                \"mpi\": {\n",
    "                                    \"enabled\": True,\n",
    "                                    \"processes_per_host\": 8,\n",
    "                                    \"custom_mpi_options\": mpi_options,\n",
    "                                }\n",
    "                            },\n",
    "                            source_dir='bert_example',\n",
    "                            output_path=s3_output_location,\n",
    "                            max_run=timeout,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            metric_definitions=metric_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you will use the estimator to launch the SageMaker training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 00:48:36 Starting - Starting the training job...\n",
      "2020-12-30 00:49:00 Starting - Launching requested ML instancesProfilerReport-1609289316: InProgress\n",
      ".........\n",
      "2020-12-30 00:50:35 Starting - Preparing the instances for training.........\n",
      "2020-12-30 00:52:07 Downloading - Downloading input data\n",
      "2020-12-30 00:52:07 Training - Downloading the training image..................\n",
      "2020-12-30 00:55:06 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:07,379 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:07,459 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:10,528 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:10,995 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:10,995 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:10,999 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:10,999 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:8'] process_per_hosts: 8 num_processes: 8\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:11,002 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2020-12-30 00:55:11,081 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 8,\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": false,\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose --mca orte_base_help_aggregate 0 \",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_steps\": 7038,\n",
      "        \"seed\": 12439,\n",
      "        \"steps_this_run\": 500,\n",
      "        \"allreduce_post_accumulation_fp16\": 1,\n",
      "        \"allreduce_post_accumulation\": 1,\n",
      "        \"apply_optimizer\": 1,\n",
      "        \"use_sequential\": 1,\n",
      "        \"smp\": 1,\n",
      "        \"output_dir\": \"./checkpoints\",\n",
      "        \"max_seq_length\": 128,\n",
      "        \"input_dir\": \"/opt/ml/input/data/train\",\n",
      "        \"num_steps_per_checkpoint\": 200,\n",
      "        \"config_file\": \"bert_config.json\",\n",
      "        \"skip_checkpoint\": 1,\n",
      "        \"bert_model\": \"bert-large-uncased\",\n",
      "        \"do_train\": 1,\n",
      "        \"warmup_proportion\": 0.2843,\n",
      "        \"train_batch_size\": 48,\n",
      "        \"learning_rate\": 0.006,\n",
      "        \"mp_parameters\": {\n",
      "            \"optimize\": \"speed\",\n",
      "            \"microbatches\": 12,\n",
      "            \"partitions\": 2,\n",
      "            \"ddp\": true,\n",
      "            \"pipeline\": \"interleaved\",\n",
      "            \"overlapping_allreduce\": true,\n",
      "            \"placement_strategy\": \"cluster\",\n",
      "            \"memory_weight\": 0.3\n",
      "        },\n",
      "        \"max_predictions_per_seq\": 20\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-12-30-00-48-36-219\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sagemaker_smp_pretrain\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sagemaker_smp_pretrain.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sagemaker_smp_pretrain.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose --mca orte_base_help_aggregate 0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sagemaker_smp_pretrain\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose --mca orte_base_help_aggregate 0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_STEPS=7038\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=12439\u001b[0m\n",
      "\u001b[34mSM_HP_STEPS_THIS_RUN=500\u001b[0m\n",
      "\u001b[34mSM_HP_ALLREDUCE_POST_ACCUMULATION_FP16=1\u001b[0m\n",
      "\u001b[34mSM_HP_ALLREDUCE_POST_ACCUMULATION=1\u001b[0m\n",
      "\u001b[34mSM_HP_APPLY_OPTIMIZER=1\u001b[0m\n",
      "\u001b[34mSM_HP_USE_SEQUENTIAL=1\u001b[0m\n",
      "\u001b[34mSM_HP_SMP=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=./checkpoints\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIR=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_STEPS_PER_CHECKPOINT=200\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG_FILE=bert_config.json\u001b[0m\n",
      "\u001b[34mSM_HP_SKIP_CHECKPOINT=1\u001b[0m\n",
      "\u001b[34mSM_HP_BERT_MODEL=bert-large-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_DO_TRAIN=1\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_PROPORTION=0.2843\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=48\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.006\u001b[0m\n",
      "\u001b[34mSM_HP_MP_PARAMETERS={\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_PREDICTIONS_PER_SEQ=20\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8 -np 8 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose --mca orte_base_help_aggregate 0 -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TRAIN -x SM_HP_MAX_STEPS -x SM_HP_SEED -x SM_HP_STEPS_THIS_RUN -x SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16 -x SM_HP_ALLREDUCE_POST_ACCUMULATION -x SM_HP_APPLY_OPTIMIZER -x SM_HP_USE_SEQUENTIAL -x SM_HP_SMP -x SM_HP_OUTPUT_DIR -x SM_HP_MAX_SEQ_LENGTH -x SM_HP_INPUT_DIR -x SM_HP_NUM_STEPS_PER_CHECKPOINT -x SM_HP_CONFIG_FILE -x SM_HP_SKIP_CHECKPOINT -x SM_HP_BERT_MODEL -x SM_HP_DO_TRAIN -x SM_HP_WARMUP_PROPORTION -x SM_HP_TRAIN_BATCH_SIZE -x SM_HP_LEARNING_RATE -x SM_HP_MP_PARAMETERS -x SM_HP_MAX_PREDICTIONS_PER_SEQ -x PYTHONPATH /opt/conda/bin/python -m mpi4py sagemaker_smp_pretrain.py --allreduce_post_accumulation 1 --allreduce_post_accumulation_fp16 1 --apply_optimizer 1 --bert_model bert-large-uncased --config_file bert_config.json --do_train 1 --input_dir /opt/ml/input/data/train --learning_rate 0.006 --max_predictions_per_seq 20 --max_seq_length 128 --max_steps 7038 --mp_parameters ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster --num_steps_per_checkpoint 200 --output_dir ./checkpoints --seed 12439 --skip_checkpoint 1 --smp 1 --steps_this_run 500 --train_batch_size 48 --use_sequential 1 --warmup_proportion 0.2843\n",
      "\n",
      "\n",
      " Data for JOB [41213,1] offset 0 Total slots allocated 8\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: algo-1#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 3 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 4 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 5 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 6 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 7 Bound: N/A\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,3]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,4]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,1]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/01be0d87-4625-4e43-aecb-ed0a0593a716',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,0]<stdout>:'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,3]<stdout>:'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,4]<stdout>:'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,6]<stdout>:'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,1]<stdout>:'AWS_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'CMAKE_PREFIX_PATH': '$(dirname '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                      '$(which '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                      'conda))/../',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'CUDA_VERSION': '11.0.3',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'CUDNN_VERSION': '8.0.4.30',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,0]<stdout>:'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,3]<stdout>:'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,4]<stdout>:'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,7]<stdout>:'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,5]<stdout>:'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,1]<stdout>:'CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'DGLBACKEND': 'pytorch',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,0]<stdout>:'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,3]<stdout>:'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,4]<stdout>:'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,7]<stdout>:'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,4]<stdout>:'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,1]<stdout>:'DMLC_INTERFACE': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1cb3e33a-c6f9-4e1c-83ec-736b2cff1617',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,0]<stdout>:'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,3]<stdout>:'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,7]<stdout>:'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,4]<stdout>:'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        [1,5]<stdout>:'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        [1,1]<stdout>:'HFI_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'HOME': '/root',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,0]<stdout>:'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,7]<stdout>:'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              [1,4]<stdout>:'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              [1,5]<stdout>:'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              [1,1]<stdout>:'HOROVOD_VERSION': '0.20.3',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'HOSTNAME': 'ip-10-0-118-156.us-west-2.compute.internal',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'IPATH_NO_BACKTRACE': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'LANG': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'LC_ALL': 'C.UTF-8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,7]<stdout>:'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              [1,2]<stdout>:'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '0.006 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--max_steps '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '200 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              [1,0]<stdout>:'--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              [1,4]<stdout>:'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              [1,5]<stdout>:'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              [1,6]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              [1,1]<stdout>:'LD_LIBRARY_PATH': '/home/.openmpi/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'LD_PRELOAD': '/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              [1,1]<stdout>:'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'MANUAL_BUILD': '0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'./checkpoints '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--smp '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '500 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              [1,0]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '0.006 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--max_steps '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              [1,4]<stdout>:'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '0.006 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--max_steps '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              [1,5]<stdout>:'--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              [1,6]<stdout>:'--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '0.006 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--max_steps '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              [1,7]<stdout>:'0.006 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--max_steps '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              [1,6]<stdout>:'200 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              [1,1]<stdout>:'MASTER_ADDR': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'MASTER_PORT': '7777',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '200 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              [1,4]<stdout>:'7038 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '200 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              [1,5]<stdout>:'--input_dir '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '0.006 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              [1,7]<stdout>:'--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '200 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              [1,5]<stdout>:'--max_steps '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              [1,6]<stdout>:'--smp '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '500 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:              [1,1]<stdout>:'NCCL_DEBUG': 'INFO',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'NCCL_IB_DISABLE': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,3]<stdout>:'OMPI_COMM_WORLD_LOCAL_RANK': '3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_COMM_WORLD_NODE_RANK': '3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'--smp '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '500 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              [1,4]<stdout>:'--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--smp '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '500 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              [1,7]<stdout>:'--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--smp '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '500 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              [1,4]<stdout>:'--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_COMM_WORLD_LOCAL_RANK': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'200 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--smp '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              [1,6]<stdout>:'0.2843',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_COMM_WORLD_LOCAL_RANK': '6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_COMM_WORLD_NODE_RANK': '6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              [1,1]<stdout>:'NCCL_MIN_NRINGS': '4',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'NCCL_SOCKET_IFNAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'NCCL_VERSION': '2.7.8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,3]<stdout>:'OMPI_COMM_WORLD_RANK': '3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_COMM_WORLD_LOCAL_RANK': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,7]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_COMM_WORLD_LOCAL_RANK': '7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'OMPI_COMM_WORLD_NODE_RANK': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_COMM_WORLD_NODE_RANK': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'500 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'OMPI_COMM_WORLD_RANK': '6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--config_file '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              [1,1]<stdout>:'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,3]<stdout>:'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,7]<stdout>:'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_COMM_WORLD_NODE_RANK': '7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_ess_base_vpid': '3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_COMM_WORLD_RANK': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_COMM_WORLD_RANK': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_COMM_WORLD_LOCAL_RANK': '5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              [1,1]<stdout>:'NVIDIA_REQUIRE_CUDA': 'cuda>=11.0 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        'brand=tesla,driver>=418,driver<419 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        'brand=tesla,driver>=440,driver<441 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        'brand=tesla,driver>=450,driver<451',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'OMPI_COMM_WORLD_RANK': '7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,1]<stdout>:'NVIDIA_VISIBLE_DEVICES': 'all',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_APP_CTX_NUM_PROCS': '8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,3]<stdout>:'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_COMM_WORLD_NODE_RANK': '5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_COMM_WORLD_RANK': '5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'0.006 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--max_steps '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              [1,7]<stdout>:'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,2]<stdout>:'200 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              [1,3]<stdout>:'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_ess_base_vpid': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_ess_base_vpid': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'OMPI_MCA_ess_base_vpid': '6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_ess_base_vpid': '7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,6]<stdout>:'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--smp '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '500 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              [1,3]<stdout>:'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_ess_node_rank': '3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,7]<stdout>:'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,5]<stdout>:'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_ARGV': '-m '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              'mpi4py '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              'sagemaker_smp_pretrain.py '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--allreduce_post_accumulation '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              [1,6]<stdout>:'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_ess_node_rank': '6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,7]<stdout>:'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,4]<stdout>:'OMPI_MCA_orte_ess_node_rank': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_ess_base_vpid': '5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'--allreduce_post_accumulation_fp16 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--apply_optimizer '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--bert_model '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              'bert-large-uncased '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              [1,6]<stdout>:'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_COMM_WORLD_LOCAL_RANK': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_orte_ess_node_rank': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,7]<stdout>:'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'--config_file '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              'bert_config.json '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--do_train '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--input_dir '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '/opt/ml/input/data/train '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--learning_rate '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '0.006 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--max_predictions_per_seq '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '20 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--max_seq_length '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '128 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              [1,6]<stdout>:'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_COMM_WORLD_NODE_RANK': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_COMM_WORLD_RANK': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,7]<stdout>:'OMPI_MCA_orte_ess_node_rank': '7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'--max_steps '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '7038 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--mp_parameters '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              'ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--num_steps_per_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '200 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--output_dir '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              './checkpoints '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--seed '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '12439 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              [1,6]<stdout>:'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,7]<stdout>:'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,2]<stdout>:'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_orte_ess_node_rank': '5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'--skip_checkpoint '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--smp '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--steps_this_run '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              [1,6]<stdout>:'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,6]<stdout>:'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'500 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--train_batch_size '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '48 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--use_sequential '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '--warmup_proportion '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:              '0.2843',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_COMMAND': 'python',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,1]<stdout>:'OMPI_COMM_WORLD_LOCAL_RANK': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_COMM_WORLD_LOCAL_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_ess_base_vpid': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_ID': '2700935169.3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,7]<stdout>:'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,5]<stdout>:'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_COMM_WORLD_NODE_RANK': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_RANK': '3',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,7]<stdout>:'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,4]<stdout>:'PMIX_ID': '2700935169.4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_COMM_WORLD_RANK': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_COMM_WORLD_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'PMIX_ID': '2700935169.6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'PMIX_ID': '2700935169.0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,7]<stdout>:'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_RANK': '0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_RANK': '4',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1.0/pid.27/0/0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_FIRST_RANKS': '0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'PMIX_RANK': '6',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,7]<stdout>:'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_ID': '2700935169.7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_btl': '^openib',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_btl_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_ess': '^singleton',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_orte_ess_node_rank': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,7]<stdout>:'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_RANK': '7',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,2]<stdout>:'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_ess_base_jobid': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_ess_base_vpid': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,6]<stdout>:'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'PMIX_ID': '2700935169.5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_hwloc_base_binding_policy': 'none',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_initial_wdir': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_mpi_yield_when_idle': '0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,1]<stdout>:'OMPI_MCA_oob_tcp_if_include': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_abort_on_non_zero_status': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        '0 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'PMIX_RANK': '5',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,7]<stdout>:'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,5]<stdout>:'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_orte_app_num': '0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_base_help_aggregate': '0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        [1,2]<stdout>:'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        [1,4]<stdout>:'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        [1,7]<stdout>:'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,4]<stdout>:'0 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_orte_ess_node_rank': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_ess_num_procs': '8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'0 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        '0 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,7]<stdout>:'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_orte_hnp_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,7]<stdout>:'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        '0 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_orte_launch': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_local_daemon_uri': '2700935168.0;tcp://10.0.118.156:40317',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,7]<stdout>:'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,2]<stdout>:'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_ID': '2700935169.2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_orte_num_nodes': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_precondition_transports': '3f58f5b9c9681df4-f07ea330992de6ed',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_tag_output': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_orte_tmpdir_base': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,6]<stdout>:'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_RANK': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        '0 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1.0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_plm_rsh_no_tree_spawn': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_pmix': '^s1,s2,cray,isolated',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,1]<stdout>:'OMPI_MCA_pml': 'ob1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_rmaps_base_display_map': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,7]<stdout>:'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,5]<stdout>:'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_MCA_rmaps_base_mapping_policy': 'slot',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,7]<stdout>:'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,4]<stdout>:'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'OMPI_NUM_APP_CTX': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'OMPI_UNIVERSE_SIZE': '8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,7]<stdout>:'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PATH': '/home/.openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,3]<stdout>:'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,7]<stdout>:'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds21_27',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1.0/pid.27/pmix_dstor_ds12_27',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,7]<stdout>:'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                    '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,2]<stdout>:'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,0]<stdout>:'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_GDS_MODULE': 'ds21,ds12,hash',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_ID': '2700935169.1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,7]<stdout>:'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,2]<stdout>:'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_MCA_mca_base_component_show_load_errors': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,6]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                    [1,1]<stdout>:'PMIX_NAMESPACE': '2700935169',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                         [1,0]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                    '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,4]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                    [1,5]<stdout>:'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,6]<stdout>:'\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,5]<stdout>:'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_PTL_MODULE': 'tcp,usock',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_RANK': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_SECURITY_MODE': 'native',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'6.0 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                         '6.1 '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: [1,0]<stdout>:'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,2]<stdout>:'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        '0 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,4]<stdout>:'\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,6]<stdout>:'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                         '6.0 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                         '6.1 '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,4]<stdout>:'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                         '6.0 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                         [1,5]<stdout>:'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1.0/pid.27',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_SERVER_URI2': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                    '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,3]<stdout>:'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: 'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: '_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                         '6.0 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                         '6.1 '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,2]<stdout>:'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,6]<stdout>:'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: 'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: [1,2]<stdout>:'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,4]<stdout>:'6.1 '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: [1,5]<stdout>:'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_SERVER_URI21': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PMIX_SERVER_URI3': '2700935168.0;tcp4://127.0.0.1:55143',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1,6]<stdout>:'_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,4]<stdout>:'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: 'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: '_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PMIX_SYSTEM_TMPDIR': '/tmp',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PWD': '/opt/ml/code',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                         '6.0 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                         '6.1 '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: 'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,0]<stdout>:'_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: [1,2]<stdout>:'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PYTHONDONTWRITEBYTECODE': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'PYTHONIOENCODING': 'UTF-8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,7]<stdout>:'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: '_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'PYTHONUNBUFFERED': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SAGEMAKER_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,5]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                    [1,2]<stdout>:'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SAGEMAKER_REGION': 'us-west-2',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,5]<stdout>:'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,2]<stdout>:'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SHLVL': '2',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_CHANNELS': '[\"train\"]',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                         '6.0 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                         [1,1]<stdout>:'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_CURRENT_HOST': 'algo-1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,5]<stdout>:'6.1 '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,2]<stdout>:'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,1]<stdout>:'SM_FRAMEWORK_PARAMS': '{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        '--mca '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        '0 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                        '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,5]<stdout>:'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: 'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: [1,2]<stdout>:'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_HOSTS': '[\"algo-1\"]',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HPS': '{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843}',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,5]<stdout>:'_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:'SM_HP_ALLREDUCE_POST_ACCUMULATION': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_ALLREDUCE_POST_ACCUMULATION_FP16': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_APPLY_OPTIMIZER': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                    [1,1]<stdout>:'SM_HP_BERT_MODEL': 'bert-large-uncased',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_CONFIG_FILE': 'bert_config.json',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                    '0 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                    '\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_HP_DO_TRAIN': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_INPUT_DIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_LEARNING_RATE': '0.006',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_HP_MAX_PREDICTIONS_PER_SEQ': '20',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_MAX_SEQ_LENGTH': '128',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                         [1,1]<stdout>:'SM_HP_MAX_STEPS': '7038',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_MP_PARAMETERS': '{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'6.0 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                         '6.1 '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: 'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_HP_NUM_STEPS_PER_CHECKPOINT': '200',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_OUTPUT_DIR': './checkpoints',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_HP_SEED': '12439',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: [1,1]<stdout>:'SM_HP_SKIP_CHECKPOINT': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_HP_SMP': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,2]<stdout>:'_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:'SM_HP_STEPS_THIS_RUN': '500',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_HP_TRAIN_BATCH_SIZE': '48',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_HP_USE_SEQUENTIAL': '1',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_HP_WARMUP_PROPORTION': '0.2843',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_INPUT_DIR': '/opt/ml/input',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_LOG_LEVEL': '20',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_MODEL_DIR': '/opt/ml/model',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_MODULE_NAME': 'sagemaker_smp_pretrain',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_NETWORK_INTERFACE_NAME': 'eth0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_NUM_CPUS': '64',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_NUM_GPUS': '8',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_OUTPUT_DIR': '/opt/ml/output',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                    '--mca '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                    'orte_base_help_aggregate '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                    [1,1]<stdout>:'0 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                    [1,1]<stdout>:'\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"allreduce_post_accumulation\":1,\"allreduce_post_accumulation_fp16\":1,\"apply_optimizer\":1,\"bert_model\":\"bert-large-uncased\",\"config_file\":\"bert_config.json\",\"do_train\":1,\"input_dir\":\"/opt/ml/input/data/train\",\"learning_rate\":0.006,\"max_predictions_per_seq\":20,\"max_seq_length\":128,\"max_steps\":7038,\"mp_parameters\":{\"ddp\":true,\"memory_weight\":0.3,\"microbatches\":12,\"optimize\":\"speed\",\"overlapping_allreduce\":true,\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num_steps_per_checkpoint\":200,\"output_dir\":\"./checkpoints\",\"seed\":12439,\"skip_checkpoint\":1,\"smp\":1,\"steps_this_run\":500,\"train_batch_size\":48,\"use_sequential\":1,\"warmup_proportion\":0.2843},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-12-30-00-48-36-219\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker_smp_pretrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker_smp_pretrain.py\"}',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_USER_ARGS': '[\"--allreduce_post_accumulation\",\"1\",\"--allreduce_post_accumulation_fp16\",\"1\",\"--apply_optimizer\",\"1\",\"--bert_model\",\"bert-large-uncased\",\"--config_file\",\"bert_config.json\",\"--do_train\",\"1\",\"--input_dir\",\"/opt/ml/input/data/train\",\"--learning_rate\",\"0.006\",\"--max_predictions_per_seq\",\"20\",\"--max_seq_length\",\"128\",\"--max_steps\",\"7038\",\"--mp_parameters\",\"ddp=True,memory_weight=0.3,microbatches=12,optimize=speed,overlapping_allreduce=True,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num_steps_per_checkpoint\",\"200\",\"--output_dir\",\"./checkpoints\",\"--seed\",\"12439\",\"--skip_checkpoint\",\"1\",\"--smp\",\"1\",\"--steps_this_run\",\"500\",\"--train_batch_size\",\"48\",\"--use_sequential\",\"1\",\"--warmup_proportion\",\"0.2843\"]',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'SM_USER_ENTRY_POINT': 'sagemaker_smp_pretrain.py',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'TORCH_CUDA_ARCH_LIST': '3.5 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                         '3.7 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                         '5.2 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                         [1,1]<stdout>:'6.0 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                         '6.1 '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                         '7.0+PTX '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                         '8.0',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'TORCH_NVCC_FLAGS': '-Xfatbin '\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:                     '-compress-all',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:688520471316:training-job/pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'TRAINING_JOB_NAME': 'pytorch-training-2020-12-30-00-48-36-219',\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: [1,1]<stdout>:'_': '/home/.openmpi/bin/mpirun.real'}\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:14.942: I smdistributed/modelparallel/torch/state_mod.py:114] [1] Finished initializing torch distributed process groups. mp_rank: 1, dp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:14.943: I smdistributed/modelparallel/torch/state_mod.py:114] [2] Finished initializing torch distributed process groups. mp_rank: 0, dp_rank: 1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:14.943: I smdistributed/modelparallel/torch/state_mod.py:114] [3] Finished initializing torch distributed process groups. mp_rank: 1, dp_rank: 1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:14.944: I smdistributed/modelparallel/torch/state_mod.py:114] [4] Finished initializing torch distributed process groups. mp_rank: 0, dp_rank: 2\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:14.944: I smdistributed/modelparallel/torch/state_mod.py:114] [5] Finished initializing torch distributed process groups. mp_rank: 1, dp_rank: 2\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:14.945: I smdistributed/modelparallel/torch/state_mod.py:114] [7] Finished initializing torch distributed process groups. mp_rank: 1, dp_rank: 3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:14.945: I smdistributed/modelparallel/torch/state_mod.py:114] [6] Finished initializing torch distributed process groups. mp_rank: 0, dp_rank: 3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:14.952: I smdistributed/modelparallel/torch/state_mod.py:114] [0] Finished initializing torch distributed process groups. mp_rank: 0, dp_rank: 0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,6]<stdout>:device: cuda:6 n_gpu: 1, mp_rank: 0, rank: 6, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:device: cuda:7 n_gpu: 1, mp_rank: 1, rank: 7, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:device: cuda:5 n_gpu: 1, mp_rank: 1, rank: 5, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:device: cuda:4 n_gpu: 1, mp_rank: 0, rank: 4, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:device: cuda:2 n_gpu: 1, mp_rank: 0, rank: 2, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:device: cuda:1 n_gpu: 1, mp_rank: 1, rank: 1, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:device: cuda:3 n_gpu: 1, mp_rank: 1, rank: 3, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:device: cuda:0 n_gpu: 1, mp_rank: 0, rank: 0, distributed training: False, 16-bits training: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.693: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.797 algo-1:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:25.912: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.930 algo-1:32 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.930 algo-1:32 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.931 algo-1:32 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.932 algo-1:32 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:25.932 algo-1:32 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:25.943: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:25.961: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:25.981: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:26.030 algo-1:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.065 algo-1:38 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.082: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.083: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:26.090 algo-1:39 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:26.091 algo-1:39 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:26.091 algo-1:39 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:26.092 algo-1:39 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:26.092 algo-1:39 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:26.096 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:26.111 algo-1:37 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.132 algo-1:38 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.132 algo-1:38 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.133 algo-1:38 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.134 algo-1:38 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.134 algo-1:38 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:26.160 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:26.161 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:26.161 algo-1:33 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:26.162 algo-1:33 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:26.162 algo-1:33 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:26.171 algo-1:37 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:26.172 algo-1:37 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.172: W smdistributed/modelparallel/torch/patches/moves.py:116] Model has not been partitioned yet, ignoring move of params and buffers to devices\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:26.172 algo-1:37 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:26.173 algo-1:37 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:26.173 algo-1:37 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.178: W smdistributed/modelparallel/backend/split.py:171] Object of type <class 'smdistributed.modelparallel.torch.optimizers.fused_lamb.FusedLAMB'> passed to smp.step. In normal use of SMP, this object should be used outside of smp.step. This might *potentially* be a bug.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.181: I smdistributed/modelparallel/torch/worker.py:285] Tracing on GPU. If the model parameters do not fit in a single GPU, you can set trace_device to `cpu`.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.199 algo-1:36 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.217 algo-1:35 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.262 algo-1:36 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.262 algo-1:36 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.263 algo-1:36 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.263 algo-1:36 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.264 algo-1:36 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.275 algo-1:35 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.276 algo-1:35 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.276 algo-1:35 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.277 algo-1:35 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:26.277 algo-1:35 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.305 algo-1:34 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:26.324: W smdistributed/modelparallel/backend/split.py:171] Object of type <class 'smdistributed.modelparallel.torch.optimizers.fused_lamb.FusedLAMB'> passed to smp.step. In normal use of SMP, this object should be used outside of smp.step. This might *potentially* be a bug.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.369 algo-1:34 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.370 algo-1:34 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.370 algo-1:34 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.371 algo-1:34 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.371 algo-1:34 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:26.449: W smdistributed/modelparallel/backend/split.py:171] Object of type <class 'smdistributed.modelparallel.torch.optimizers.fused_lamb.FusedLAMB'> passed to smp.step. In normal use of SMP, this object should be used outside of smp.step. This might *potentially* be a bug.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.466 algo-1:32 INFO hook.py:550] name:bert.embeddings.word_embeddings.weight count_params:31260672\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.embeddings.position_embeddings.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.embeddings.token_type_embeddings.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.embeddings.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.embeddings.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.467 algo-1:32 INFO hook.py:550] name:bert.encoder.0.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.0.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.468 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.469 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.470 algo-1:32 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.4.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.4.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.471 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.472 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.473 algo-1:32 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.8.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.8.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.474 algo-1:32 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.475 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.11.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.476 algo-1:32 INFO hook.py:550] name:bert.encoder.12.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.12.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.12.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.12.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.12.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.12.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.13.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.477 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.14.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.478 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.15.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.479 algo-1:32 INFO hook.py:550] name:bert.encoder.16.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.16.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.16.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.16.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.16.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.16.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.16.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.480 algo-1:32 INFO hook.py:550] name:bert.encoder.17.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.17.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.18.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.481 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.19.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.482 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.20.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.483 algo-1:32 INFO hook.py:550] name:bert.encoder.21.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.21.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.21.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.21.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.21.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.22.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.484 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.encoder.23.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.pooler.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:bert.pooler.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:cls.predictions.bias count_params:30528\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:cls.predictions.transform.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:cls.predictions.transform.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.485 algo-1:32 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.486 algo-1:32 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.486 algo-1:32 INFO hook.py:550] name:cls.seq_relationship.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.486 algo-1:32 INFO hook.py:550] name:cls.seq_relationship.bias count_params:2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.486 algo-1:32 INFO hook.py:552] Total Trainable Params: 336232258\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:26.486 algo-1:32 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:26.543: W smdistributed/modelparallel/backend/split.py:171] Object of type <class 'smdistributed.modelparallel.torch.optimizers.fused_lamb.FusedLAMB'> passed to smp.step. In normal use of SMP, this object should be used outside of smp.step. This might *potentially* be a bug.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.287: I smdistributed/modelparallel/torch/module_partition.py:274] Partition assignments:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.288: I smdistributed/modelparallel/torch/module_partition.py:278] main: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.288: I smdistributed/modelparallel/torch/module_partition.py:278] main/module: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.289: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.289: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/cls: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.289: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/embeddings: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/pooler: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/0: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/1: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/3: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.290: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/6: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/7: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/8: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/9: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/10: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/11: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/12: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.291: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/13: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/14: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/15: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/16: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/17: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/18: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/19: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/20: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/21: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.292: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/22: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:28.293: I smdistributed/modelparallel/torch/module_partition.py:278] main/module/bert/encoder/23: 1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:28.503: I smdistributed/modelparallel/torch/model.py:280] Number of parameters on partition 1 are 208. 208 require grads\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:33 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:33 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:33 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:33 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:NCCL version 2.4.8+cuda11.0\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:39 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:39 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:39 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:39 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:37 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:37 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:37 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:37 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:35 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:35 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:35 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:35 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Channel 00 :    0   1   3   2\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Channel 01 :    0   2   3   1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Channel 02 :    0   1   3   2\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Channel 03 :    0   2   3   1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO Ring 00 : 2[5] -> 0[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO Ring 00 : 1[3] -> 3[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO Ring 00 : 3[7] -> 2[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Ring 00 : 0[1] -> 1[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO Ring 01 : 2[5] -> 3[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO Ring 01 : 1[3] -> 0[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Ring 01 : 0[1] -> 2[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO Ring 01 : 3[7] -> 1[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO Ring 02 : 2[5] -> 0[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO Ring 02 : 1[3] -> 3[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Ring 02 : 0[1] -> 1[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO Ring 02 : 3[7] -> 2[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO Ring 03 : 2[5] -> 3[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO Ring 03 : 1[3] -> 0[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Ring 03 : 0[1] -> 2[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO Ring 03 : 3[7] -> 1[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:870 [5] NCCL INFO comm 0x7f3554003770 rank 2 nranks 4 cudaDev 5 nvmlDev 5 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:871 [3] NCCL INFO comm 0x7f9758003770 rank 1 nranks 4 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:868 [1] NCCL INFO comm 0x7fe388003770 rank 0 nranks 4 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:869 [7] NCCL INFO comm 0x7f3928003770 rank 3 nranks 4 cudaDev 7 nvmlDev 7 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:33 [1] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:29.124: I smdistributed/modelparallel/torch/model.py:324] Finished partitioning the model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:29.128: I smdistributed/modelparallel/torch/model.py:280] Number of parameters on partition 0 are 190. 190 require grads\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:32 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:32 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:32 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:32 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.4.8+cuda11.0\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:36 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:38 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:34 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:38 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:36 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:34 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:36 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:38 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:36 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:38 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:34 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:34 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.118.156<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Channel 00 :    0   1   3   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Channel 01 :    0   2   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Channel 02 :    0   1   3   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Channel 03 :    0   2   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Ring 00 : 0[0] -> 1[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO Ring 00 : 1[2] -> 3[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO Ring 00 : 2[4] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO Ring 00 : 3[6] -> 2[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Ring 01 : 0[0] -> 2[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO Ring 01 : 1[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO Ring 01 : 2[4] -> 3[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO Ring 01 : 3[6] -> 1[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Ring 02 : 0[0] -> 1[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO Ring 02 : 1[2] -> 3[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO Ring 02 : 2[4] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO Ring 02 : 3[6] -> 2[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Ring 03 : 0[0] -> 2[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO Ring 03 : 1[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO Ring 03 : 2[4] -> 3[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO Ring 03 : 3[6] -> 1[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:873 [0] NCCL INFO comm 0x7fc2cc003770 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:32 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:876 [2] NCCL INFO comm 0x7f2170003770 rank 1 nranks 4 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:874 [4] NCCL INFO comm 0x7f73c8003770 rank 2 nranks 4 cudaDev 4 nvmlDev 4 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:875 [6] NCCL INFO comm 0x7f0ccc003770 rank 3 nranks 4 cudaDev 6 nvmlDev 6 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2020-12-30 00:55:29.482: I smdistributed/modelparallel/torch/model.py:336] Broadcasted parameters and buffers for partition 0\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.482: I smdistributed/modelparallel/torch/model.py:336] Broadcasted parameters and buffers for partition 1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.491 algo-1:34 INFO hook.py:550] name:bert.embeddings.word_embeddings.weight count_params:31260672\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.embeddings.position_embeddings.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.embeddings.token_type_embeddings.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.embeddings.word_embeddings.weight count_params:31260672\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.embeddings.position_embeddings.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.embeddings.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.embeddings.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.embeddings.word_embeddings.weight count_params:31260672\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.embeddings.position_embeddings.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.embeddings.token_type_embeddings.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.embeddings.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.embeddings.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.embeddings.token_type_embeddings.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.embeddings.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.embeddings.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.492 algo-1:34 INFO hook.py:550] name:bert.encoder.0.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.0.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.492 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.492 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.0.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.493 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.493 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.493 algo-1:36 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.1.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.1.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.1.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.494 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.494 algo-1:36 INFO hook.py:550] name:bert.encoder.2.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.494 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.495 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.495 algo-1:38 INFO hook.py:550] name:bert.encoder.2.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.495 algo-1:34 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.4.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.4.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.496 algo-1:34 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.496 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.496 algo-1:38 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.3.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.497 algo-1:38 INFO hook.py:550] name:bert.encoder.4.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.4.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.497 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.497 algo-1:36 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.6.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.6.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.4.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.498 algo-1:36 INFO hook.py:550] name:bert.encoder.7.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.498 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.498 algo-1:38 INFO hook.py:550] name:bert.encoder.5.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.5.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.5.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.5.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.5.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.499 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.499 algo-1:34 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.499 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.9.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.9.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.6.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.500 algo-1:34 INFO hook.py:550] name:bert.encoder.10.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.500 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.500 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.501 algo-1:34 INFO hook.py:550] name:bert.encoder.10.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.501 algo-1:34 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.501 algo-1:34 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.501 algo-1:36 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.7.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.501 algo-1:34 INFO hook.py:550] name:bert.pooler.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.501 algo-1:34 INFO hook.py:550] name:bert.pooler.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.501 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.501 algo-1:34 INFO hook.py:550] name:cls.predictions.bias count_params:30528\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:550] name:cls.predictions.transform.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:550] name:cls.predictions.transform.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:550] name:cls.seq_relationship.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:550] name:cls.seq_relationship.bias count_params:2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:552] Total Trainable Params: 172481346\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:bert.pooler.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:bert.pooler.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.predictions.bias count_params:30528\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.predictions.transform.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.predictions.transform.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2020-12-30 00:55:29.502 algo-1:34 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.seq_relationship.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:550] name:cls.seq_relationship.bias count_params:2\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.502 algo-1:36 INFO hook.py:552] Total Trainable Params: 172481346\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.8.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.502 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2020-12-30 00:55:29.503 algo-1:36 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.503 algo-1:38 INFO hook.py:550] name:bert.encoder.9.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.attention.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.intermediate.dense_act.bias count_params:4096\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.output.dense.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.504 algo-1:38 INFO hook.py:550] name:bert.encoder.10.output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.505 algo-1:38 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.505 algo-1:38 INFO hook.py:550] name:bert.encoder.10.output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.505 algo-1:38 INFO hook.py:550] name:bert.pooler.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:bert.pooler.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.predictions.bias count_params:30528\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.predictions.transform.dense_act.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.predictions.transform.dense_act.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.predictions.transform.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.seq_relationship.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:550] name:cls.seq_relationship.bias count_params:2\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.506 algo-1:38 INFO hook.py:552] Total Trainable Params: 172481346\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2020-12-30 00:55:29.507 algo-1:38 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.541 algo-1:33 INFO hook.py:550] name:self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.541 algo-1:33 INFO hook.py:550] name:self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.541 algo-1:33 INFO hook.py:550] name:self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.541 algo-1:33 INFO hook.py:550] name:self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.541 algo-1:33 INFO hook.py:550] name:self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.541 algo-1:33 INFO hook.py:550] name:self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.542 algo-1:33 INFO hook.py:550] name:output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.542 algo-1:33 INFO hook.py:550] name:output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.542 algo-1:33 INFO hook.py:550] name:output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.542 algo-1:33 INFO hook.py:550] name:output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.542 algo-1:33 INFO hook.py:552] Total Trainable Params: 4200448\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2020-12-30 00:55:29.542 algo-1:33 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.140 algo-1:37 INFO hook.py:550] name:self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.141 algo-1:37 INFO hook.py:550] name:output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.142 algo-1:37 INFO hook.py:552] Total Trainable Params: 4200448\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2020-12-30 00:55:30.142 algo-1:37 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.204 algo-1:39 INFO hook.py:550] name:self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:550] name:output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.205 algo-1:39 INFO hook.py:552] Total Trainable Params: 4200448\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2020-12-30 00:55:30.206 algo-1:39 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:self.query.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:self.query.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:self.key.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:self.key.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:self.value.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:self.value.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:output.dense.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:output.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:output.LayerNorm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.229 algo-1:35 INFO hook.py:550] name:output.LayerNorm.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.230 algo-1:35 INFO hook.py:552] Total Trainable Params: 4200448\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2020-12-30 00:55:30.230 algo-1:35 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.58866024017334\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.466197967529297\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:Loss: 11.483488082885742\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.354116439819336\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.344836235046387\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.271285057067871\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.034238815307617\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 11.065356254577637\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.933156967163086\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.887144088745117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.813663482666016\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.789870262145996\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.63941764831543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.468856811523438\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.36077880859375\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.404821395874023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.454989433288574\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.200750350952148\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.270511627197266\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.147346496582031\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.087596893310547\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 10.141414642333984\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.986273765563965\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.997880935668945\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.804346084594727\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.738802909851074\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.649059295654297\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.746469497680664\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.767475128173828\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.880158424377441\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.665160179138184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.429483413696289\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.603195190429688\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.446172714233398\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.480104446411133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.36539363861084\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.510966300964355\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.27232551574707\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.178239822387695\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.175138473510742\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.313064575195312\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.313505172729492\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.21247673034668\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.063708305358887\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.001477241516113\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.022623062133789\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.762147903442383\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.851191520690918\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.711653709411621\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.76644229888916\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.655448913574219\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 9.044008255004883\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.938961029052734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.825202941894531\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.942047119140625\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.73330307006836\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.768453598022461\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.435140609741211\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.49358081817627\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.53357219696045\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.368295669555664\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.34306812286377\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.436805725097656\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.288023948669434\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.960469245910645\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.984335899353027\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.1729736328125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.870650291442871\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.556889533996582\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.365169525146484\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.913778305053711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.6738786697387695\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.203006744384766\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.073569297790527\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.219413757324219\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.983590602874756\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.013221740722656\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.875941753387451\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.855031490325928\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.020796775817871\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.622472286224365\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.198837280273438\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 8.16995906829834\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.758716583251953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.919240474700928\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.580506801605225\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.660910606384277\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.097476005554199\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.455193519592285\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.3720011711120605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.06884765625\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.007336616516113\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.026017665863037\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 7.144116401672363\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.826155662536621\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.685947418212891\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.878936290740967\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.845338344573975\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.521395683288574\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.815365791320801\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.815228462219238\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.39555549621582\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.359541893005371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.1122846603393555\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.854564666748047\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.314298629760742\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.182883262634277\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.2702813148498535\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.2495880126953125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.411725044250488\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.252353668212891\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 6.165230751037598\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.95259428024292\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.8193888664245605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.322872161865234\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.08919620513916\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.3060712814331055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 5.072564125061035\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.9591779708862305\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.562892913818359\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.133228302001953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.3638386726379395\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.461421966552734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.9876708984375\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.914297103881836\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.752697706222534\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.8436503410339355\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.7064528465271\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.026471138000488\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.597331523895264\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.7638347148895264\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.490504741668701\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.257674217224121\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.397731781005859\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.087201118469238\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.086761474609375\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.103680372238159\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 4.177191734313965\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.9161899089813232\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.2630467414855957\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.8448493480682373\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.7940940856933594\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.2475974559783936\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.99680233001709\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.48420786857605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.641695976257324\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.4740233421325684\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.3081488609313965\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.1957945823669434\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.9468783140182495\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.603452205657959\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.8279579877853394\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.5248212814331055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.1562459468841553\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.643749713897705\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.243535041809082\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.805079221725464\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.9384801387786865\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.6807942390441895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.5141355991363525\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.8885221481323242\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.73702335357666\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.707026720046997\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.483563780784607\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.3856730461120605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.3934593200683594\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.182342052459717\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.946887969970703\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.9445257186889648\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.5403332710266113\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.8859965801239014\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.235335350036621\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.5376495122909546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 3.503523349761963\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.6578774452209473\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.8962574005126953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.5381807088851929\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.21030592918396\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.1660680770874023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.3476002216339111\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.2008590698242188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.940092921257019\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.1121017932891846\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:Loss: 2.1427998542785645\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.0572926998138428\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.0085976123809814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.8136067390441895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.9908639192581177\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.7030866146087646\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.5312809944152832\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.6484192609786987\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.49187231063842773\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.779942512512207\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.5889333486557007\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.6668152809143066\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.5027334094047546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.5741355419158936\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3856635093688965\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3613825738430023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2412063479423523\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.197327122092247\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1985853910446167\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15104126930236816\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1478540152311325\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.6251105070114136\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.22580081224441528\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1421368420124054\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11143568158149719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.517599105834961\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.23970463871955872\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11425842344760895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.323866367340088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.2605232000350952\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.0481394529342651\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11619265377521515\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.119152307510376\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11463959515094757\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.1077702045440674\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0863708108663559\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.04690803214907646\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.8303983211517334\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.2529423236846924\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.9765486717224121\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.6862375736236572\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06563089042901993\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.6843879222869873\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.8092504739761353\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.30517834424972534\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.6878175735473633\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.022646427154541\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.37570926547050476\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3752788007259369\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1448456346988678\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12303970754146576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20149248838424683\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10980822145938873\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.3915987014770508\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.0742944478988647\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.9365305304527283\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.22744111716747284\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.8380298614501953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10645481199026108\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10310014337301254\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.9661109447479248\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15833985805511475\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.7638735175132751\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.43313178420066833\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2744516134262085\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12773889303207397\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08877428621053696\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3998517394065857\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3750864863395691\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4509681165218353\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.21622854471206665\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.31892597675323486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2958218455314636\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2274179756641388\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1625499427318573\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09906431287527084\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1479671597480774\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.13431672751903534\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09651385992765427\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.21355566382408142\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11328183114528656\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1244831532239914\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3886440694332123\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3546346127986908\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.21806880831718445\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.7670073509216309\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.40866348147392273\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2578984200954437\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.5078732967376709\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.23826520144939423\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.18122398853302002\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07315321266651154\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1159466952085495\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09503012895584106\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3717682957649231\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.23277121782302856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.33036983013153076\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 2.0954809188842773\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4892128109931946\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.29297375679016113\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.4527987241744995\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.5562877655029297\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2227151095867157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.570452094078064\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4382327198982239\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2982826828956604\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.25778728723526\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4153674840927124\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10280956327915192\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3591981828212738\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10146085917949677\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07626638561487198\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15206658840179443\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06958301365375519\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0487961620092392\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05659262090921402\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06307737529277802\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.060156457126140594\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0604986846446991\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05648390203714371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0764579176902771\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12520048022270203\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.32970553636550903\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3823915421962738\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1972135752439499\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2039031982421875\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3917538821697235\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1527465283870697\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.04951423034071922\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.28819581866264343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.22328415513038635\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4718494117259979\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15898090600967407\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06467371433973312\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.04979942366480827\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.04801850765943527\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.024408575147390366\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.7594678401947021\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4214421510696411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4068071246147156\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.31123825907707214\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10217686742544174\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20048782229423523\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10201030224561691\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3959459662437439\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15176990628242493\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09566151350736618\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07956562936306\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4605202078819275\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.24113145470619202\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09887546300888062\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09125509113073349\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1126222312450409\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.061052851378917694\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.35011622309684753\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07003384828567505\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.24823585152626038\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0750693753361702\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06591497361660004\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.19396424293518066\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10515600442886353\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07307117432355881\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.04607497900724411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.034914612770080566\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14935405552387238\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09776967763900757\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12321151793003082\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12326329201459885\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.17372147738933563\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15775439143180847\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.02509566955268383\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.022264165803790092\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:Loss: 0.14584039151668549\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4935380220413208\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.03370758146047592\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.014607151970267296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20980136096477509\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1187763661146164\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1161094456911087\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.19437524676322937\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05651412904262543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1647794544696808\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10710610449314117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14509719610214233\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14240017533302307\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07780162990093231\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05311121046543121\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05894014984369278\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1920362412929535\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.060521967709064484\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.03312932699918747\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.03796634078025818\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.22010265290737152\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.16726991534233093\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08598216623067856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.19841474294662476\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10753633081912994\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0571754090487957\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11720052361488342\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05669957026839256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.032659076154232025\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.054403193295001984\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08090893924236298\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.16368308663368225\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.037786126136779785\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20076274871826172\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10330706834793091\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09516959637403488\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15036894381046295\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05757148563861847\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.022275982424616814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12088878452777863\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10640454292297363\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.03772008791565895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15698954463005066\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09362482279539108\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0795733779668808\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.03793102130293846\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05594737082719803\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.40343090891838074\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.169942244887352\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15803426504135132\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1866462230682373\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05183672904968262\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.19541876018047333\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12957525253295898\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06207224354147911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1188942939043045\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05553816258907318\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.21442773938179016\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14316503703594208\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0992780476808548\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.35209184885025024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.12314523756504059\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.059420496225357056\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1797330379486084\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0644262433052063\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.049497853964567184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1529804766178131\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11477355659008026\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10495724529027939\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.19851844012737274\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1573430448770523\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08362790197134018\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.35080385208129883\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.34838318824768066\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.16960537433624268\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.13252905011177063\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.0811733603477478\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06281162798404694\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.16765257716178894\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08685916662216187\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.056635551154613495\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.051713064312934875\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.27089840173721313\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3042711615562439\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.24550604820251465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.3720309734344482\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.39631885290145874\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3919405937194824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 1.1232393980026245\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.25131475925445557\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06527286022901535\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.042366012930870056\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14768022298812866\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.13943608105182648\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08088826388120651\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.24456045031547546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08658011257648468\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1043541431427002\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2465699166059494\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10742954909801483\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.10618314146995544\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08154516667127609\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.6761495471000671\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.40340644121170044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.5169091820716858\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.18312180042266846\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4452756643295288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.11857426166534424\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.19083905220031738\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.2621918320655823\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20537421107292175\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.18613748252391815\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09286510944366455\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05062968283891678\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.04616164788603783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.02124474011361599\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.03955405205488205\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.4660796821117401\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20994818210601807\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.32655298709869385\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.08165000379085541\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.16202405095100403\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.16534855961799622\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.15424731373786926\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.07091551274061203\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.045011457055807114\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.030177827924489975\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1598556637763977\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06026517599821091\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.219047412276268\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.09272565692663193\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.057887520641088486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14773982763290405\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1191871389746666\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3247719407081604\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.14838199317455292\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.039268456399440765\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.20250993967056274\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.063375324010849\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06461802124977112\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.05004621669650078\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.3166428208351135\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.1518145501613617\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.06179049238562584\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Loss: 0.02221839502453804\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 00 :    0   1   2   3   7   5   6   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 01 :    0   2   6   7   4   5   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 02 :    0   3   1   5   4   7   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 03 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 04 :    0   4   6   5   7   3   2   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 05 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 06 :    0   1   2   3   7   5   6   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 07 :    0   2   6   7   4   5   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 08 :    0   3   1   5   4   7   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 09 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 10 :    0   4   6   5   7   3   2   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Channel 11 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 00 : 7[7] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 00 : 3[3] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 00 : 5[5] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 00 : 6[6] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 00 : 4[4] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 01 : 7[7] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 01 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 01 : 5[5] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 01 : 4[4] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 01 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 01 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 01 : 6[6] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 01 : 2[2] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 02 : 1[1] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 02 : 7[7] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 02 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 02 : 5[5] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 02 : 6[6] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 02 : 4[4] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 02 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 02 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 03 : 1[1] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 03 : 5[5] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 03 : 7[7] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 03 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 03 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 03 : 6[6] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 03 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 03 : 4[4] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 04 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 04 : 5[5] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 04 : 7[7] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 04 : 0[0] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 04 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 04 : 6[6] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 04 : 4[4] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 04 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 05 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 05 : 7[7] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 05 : 5[5] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 05 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 05 : 6[6] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 05 : 0[0] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 05 : 4[4] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 05 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 06 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 06 : 7[7] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 06 : 5[5] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 06 : 3[3] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 06 : 6[6] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 06 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 06 : 4[4] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 06 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 07 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 07 : 7[7] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 07 : 5[5] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 07 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 07 : 6[6] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 07 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 07 : 4[4] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 07 : 2[2] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 08 : 1[1] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 08 : 7[7] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 08 : 5[5] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 08 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 08 : 6[6] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 08 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 08 : 4[4] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 08 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 09 : 1[1] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 09 : 7[7] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 09 : 5[5] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 09 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 09 : 6[6] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 09 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 09 : 4[4] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 09 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 10 : 7[7] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 10 : 5[5] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 10 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 10 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 10 : 6[6] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 10 : 0[0] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 10 : 4[4] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 10 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO Ring 11 : 7[7] -> 6[6] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO Ring 11 : 5[5] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO Ring 11 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO Ring 11 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO Ring 11 : 6[6] -> 5[5] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Ring 11 : 0[0] -> 4[4] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO Ring 11 : 4[4] -> 7[7] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO Ring 11 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:39:48917 [7] NCCL INFO comm 0x7f394c007540 rank 7 nranks 8 cudaDev 7 nvmlDev 7 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:37:48915 [5] NCCL INFO comm 0x7f31b0006890 rank 5 nranks 8 cudaDev 5 nvmlDev 5 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:33:48916 [1] NCCL INFO comm 0x7fdfe4006ab0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:35:48919 [3] NCCL INFO comm 0x7f978c022c00 rank 3 nranks 8 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:38:48920 [6] NCCL INFO comm 0x7f0950005810 rank 6 nranks 8 cudaDev 6 nvmlDev 6 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:48913 [0] NCCL INFO comm 0x7fbf3c005b70 rank 0 nranks 8 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:32:32 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:36:48914 [4] NCCL INFO comm 0x7f6ff4005fb0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:34:48918 [2] NCCL INFO comm 0x7f1d940062b0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Start syncing model checkpoints to s3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Destination S3 Bucket which will store model artifacts: sagemaker-us-west-2-688520471316\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Syncing files from ./checkpoints to s3://sagemaker-us-west-2-688520471316/pytorch-training-2020-12-30-00-48-36-219/checkpoints/algo-1/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Time Taken to Sync:  0.9080119132995605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Finished syncing model checkpoints to s3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[SMP_METRIC]__Bert__Loss__0.022\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[SMP_METRIC]__Bert__Time_to_train__742.8262\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[SMP_METRIC]__Bert__Sequences/second__258.47\u001b[0m\n",
      "\u001b[34m2020-12-30 01:07:53,032 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-30 01:08:14 Uploading - Uploading generated training model\n",
      "2020-12-30 01:08:14 Completed - Training job completed\n",
      "ProfilerReport-1609289316: IssuesFound\n",
      "Training seconds: 967\n",
      "Billable seconds: 967\n"
     ]
    }
   ],
   "source": [
    "# local \n",
    "\n",
    "\n",
    "pytorch_estimator.fit(data_channels, logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
