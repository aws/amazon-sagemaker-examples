{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a524a4c-5a39-4b6b-abb1-1c8e1b2de84c",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify Model Bias Monitor - JSON Lines Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5511751",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaae7a8-2ab1-4f7c-8cb2-6b23606c58c1",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 60 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea223b4-8caa-47a6-a65d-d4e21c9d72e5",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [General Setup](#General-Setup)\n",
    "    * [Imports](#Imports)\n",
    "    * [Handful of configuration](#Handful-of-configuration)\n",
    "    * [Model file and data files](#Model-file-and-data-files)\n",
    "* [Real-time Inference Endpoint](#Real-time-Inference-Endpoint)\n",
    "    * [Deploy the model to an endpoint](#Deploy-the-model-to-an-endpoint)\n",
    "    * [Invoke the endpoint](#Invoke-the-endpoint)\n",
    "        * [Example: Single record](#Example:-Single-record)\n",
    "        * [Example: Two records](#Example:-Two-records)\n",
    "    * [View captured data](#View-captured-data)\n",
    "    * [Start generating some artificial traffic](#Start-generating-some-artificial-traffic)\n",
    "* [Ground Truth Data](#Ground-Truth-Data)\n",
    "* [Model Bias Monitor](#Model-Bias-Monitor)\n",
    "    * [Baselining job](#Baselining-job)\n",
    "        * [Configurations](#Configurations)\n",
    "        * [Kick off baselining job](#Kick-off-baselining-job)\n",
    "    * [Monitoring Schedule](#Monitoring-Schedule)\n",
    "        * [Wait for the first execution](#Wait-for-the-first-execution)\n",
    "        * [Wait for the execution to finish](#Wait-for-the-execution-to-finish)\n",
    "        * [Merged data](#Merged-data)\n",
    "        * [Inspect execution results](#Inspect-execution-results)\n",
    "* [Cleanup](#Cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2c6a4-a249-40bf-adbc-8bd00fb06cfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879bacd-fedd-434a-8094-40cd48f5f140",
   "metadata": {},
   "source": [
    "[Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) continuously monitors the quality of Amazon SageMaker machine learning models in production. It enables developers to set alerts for when there are deviations in the model quality. Early and pro-active detection of these deviations enables corrective actions, such as retraining models, auditing upstream systems, or fixing data quality issues without having to monitor models manually or build additional tooling. \n",
    "\n",
    "[Amazon SageMaker Clarify Model Bias Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html) is a model monitor that helps data scientists and ML engineers monitor predictions for bias on a regular basis. Bias can be introduced or exacerbated in deployed ML models when the training data differs from the data that the model sees during deployment (that is, the live data). These kinds of changes in the live data distribution might be temporary (for example, due to some short-lived, real-world events) or permanent. In either case, it might be important to detect these changes. For example, the outputs of a model for predicting home prices can become biased if the mortgage rates used to train the model differ from current, real-world mortgage rates. With bias drift detection capabilities in model monitor, when SageMaker detects bias beyond a certain threshold, it automatically generates metrics that you can view in SageMaker Studio and through Amazon CloudWatch alerts. \n",
    "\n",
    "This notebook demonstrates the process for setting up a model monitor for continuous monitoring of bias drift of the data and model of a [SageMaker real-time inference endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html). The model input and output are in [SageMaker JSON Lines dense format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#common-in-formats). SageMaker Clarify model monitor also supports analyzing CSV data, which is illustrated in [another notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.ipynb).\n",
    "\n",
    "In general, you can use the model bias monitor for real-time inference endpoint in this way,\n",
    "\n",
    "1. Enable the endpoint for data capture. Then, when the customer invokes the endpoint, the endpoint saves the invocations to a data capture S3 location. \n",
    "1. Schedule a model bias monitor to monitor the endpoint (to be more specific, the data capture S3 location) and a ground truth S3 location.\n",
    "1. You need to regularly fetch the captured data, label it, and then upload the ground truth labels to the ground truth S3 URI.\n",
    "\n",
    "The monitor executes processing jobs regularly to merge the captured data and ground truth data, do bias analysis for the merged data, and then generate analysis reports and publish metrics to CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eed2c2-4e67-49cd-8b16-01d10c0acdb0",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e754c8-d82a-49a3-9967-d7a487a42549",
   "metadata": {},
   "source": [
    "The notebook uses the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk). The following cell upgrades the SDK and its dependencies. Then you may need to restart the kernel and rerun the notebook to pick up the up-to-date APIs, if the notebook is executed in the SageMaker Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815029f-6166-40f6-a5dd-da2358f8b7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker\n",
    "!pip install -U boto3\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f20cf6-1672-45ab-966b-5db2d51aad53",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following cell imports the APIs to be used by the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f01570-2eee-46ef-b044-8b65569c26b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa9278-a1c9-427c-a9d9-5ddab19bcd49",
   "metadata": {},
   "source": [
    "### Handful of configuration\n",
    "\n",
    "To begin, ensure that these prerequisites have been completed.\n",
    "\n",
    "* Specify an AWS Region to host the model.\n",
    "* Specify an IAM role to execute jobs.\n",
    "* Define the S3 URIs that stores the model file, input data and output data. For demonstration purposes, this notebook uses the same bucket for them. In reality, they could be separated with different security policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b11f7c-e9cd-4321-8de5-27ca6dd85d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f\"AWS region: {region}\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"RoleArn: {role}\")\n",
    "\n",
    "# A different bucket can be used, but make sure the role for this notebook has\n",
    "# the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Demo Bucket: {bucket}\")\n",
    "prefix = sagemaker.utils.unique_name_from_base(\"sagemaker/DEMO-ClarifyModelMonitor\")\n",
    "print(f\"Demo Prefix: {prefix}\")\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "print(f\"Demo S3 key: {s3_key}\")\n",
    "\n",
    "data_capture_s3_uri = f\"{s3_key}/data-capture\"\n",
    "ground_truth_s3_uri = f\"{s3_key}/ground-truth\"\n",
    "baselining_output_s3_uri = f\"{s3_key}/baselining-output\"\n",
    "monitor_output_s3_uri = f\"{s3_key}/monitor-output\"\n",
    "\n",
    "print(f\"The endpoint will save the captured data to: {data_capture_s3_uri}\")\n",
    "print(f\"You should upload the ground truth data to: {ground_truth_s3_uri}\")\n",
    "print(f\"The baselining job will save the analysis results to: {baselining_output_s3_uri}\")\n",
    "print(f\"The monitor will save the analysis results to: {monitor_output_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da5265-858f-4478-978b-ad592464b61d",
   "metadata": {},
   "source": [
    "### Model file and data files\n",
    "\n",
    "This example includes a prebuilt [SageMaker Linear Learner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) model trained by [a SageMaker Clarify offline processing example notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability_jsonlines_format.ipynb). The model supports [SageMaker JSON Lines dense format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#common-in-formats) (MIME type `\"application/jsonlines\"`).\n",
    "\n",
    "* The model input can one or more lines, each line is a JSON object that has a \"features\" key pointing to a list of feature values concerning demographic characteristics of individuals. For example,\n",
    "\n",
    "```\n",
    "{\"features\":[28,2,133937,9,13,2,0,0,4,1,15024,0,55,37]}\n",
    "{\"features\":[43,2,72338,12,14,2,12,0,1,1,0,0,40,37]}\n",
    "```\n",
    "\n",
    "* The model output has the predictions of whether a person has a yearly income that is more than $50,000. Each prediction is a JSON object that has a \"predicted_label\" key pointing to the predicted label, and the \"score\" key pointing to the confidence score. For example,\n",
    "\n",
    "```\n",
    "{\"predicted_label\":1,\"score\":0.989977359771728}\n",
    "{\"predicted_label\":1,\"score\":0.504138827323913}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d26c9-0f0b-422d-97cb-b74efd5eacd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file = \"model/ll-adult-prediction-model.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d1d6a-c75c-4563-9699-33de88469093",
   "metadata": {},
   "source": [
    "This example includes two dataset files, both in the JSON Lines format. The data also originates from [the SageMaker Clarify offline processing example notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability_jsonlines_format.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaa4fe-622f-4745-a3cc-52d40db8ce9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_path = \"test_data/validation-dataset.jsonl\"\n",
    "test_dataset_path = \"test_data/test-dataset.jsonl\"\n",
    "dataset_type = \"application/jsonlines\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1001e-0b91-4133-8bce-6710aaa33270",
   "metadata": {},
   "source": [
    "The train dataset has the features and the ground truth label (pointed to by the key \"label\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c22c10-7ba8-417a-a0dc-1e152a0a3287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head -n 5 $train_dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebb1fd-d480-4700-8dd8-3143205331a6",
   "metadata": {},
   "source": [
    "The test dataset only has features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78d463-f1ff-4483-8cf3-562bccb98a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head -n 5 $test_dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b89b8d-5036-4bd9-8aa5-f5d638617aba",
   "metadata": {},
   "source": [
    "Here are the headers of the train dataset. \"Target\" is the header of the ground truth label, and the others are the feature headers. They will be used to beautify the analysis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a843093-0548-48dd-9f82-e80af07c357e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_headers = [\n",
    "    \"Age\",\n",
    "    \"Workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"Education\",\n",
    "    \"Education-Num\",\n",
    "    \"Marital Status\",\n",
    "    \"Occupation\",\n",
    "    \"Relationship\",\n",
    "    \"Ethnic group\",\n",
    "    \"Sex\",\n",
    "    \"Capital Gain\",\n",
    "    \"Capital Loss\",\n",
    "    \"Hours per week\",\n",
    "    \"Country\",\n",
    "    \"Target\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441fc17-0299-4b11-afe7-efdb167263ad",
   "metadata": {},
   "source": [
    "To verify that the execution role for this notebook has the necessary permissions to proceed, put a simple test object into the S3 bucket specified above. If this command fails, update the role to have `s3:PutObject` permission on the bucket and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe69a8c-9bf6-47c4-bb59-a775fd3b6934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker.s3.S3Uploader.upload_string_as_file_body(\n",
    "    body=\"hello\",\n",
    "    desired_s3_uri=f\"{s3_key}/upload-test-file.txt\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(\"Success! We are all set to proceed with uploading to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a099ef6-8d09-478d-854c-989758bad1c5",
   "metadata": {},
   "source": [
    "Then upload the files to S3 so that they can be used by SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fe183-4c83-4d22-bce5-65eba6a351e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_url = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=model_file,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Model file has been uploaded to {model_url}\")\n",
    "\n",
    "train_data_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=train_dataset_path,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Train data is uploaded to: {train_data_s3_uri}\")\n",
    "test_data_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=test_dataset_path,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Test data is uploaded to: {test_data_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11cc57-8ab4-422e-9492-4126f34ef4c5",
   "metadata": {},
   "source": [
    "## Real-time Inference Endpoint\n",
    "\n",
    "This section creates a SageMaker real-time inference endpoint to showcase the data capture capability in action. The model monitor will be scheduled for the endpoint and process the captured data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d295bc3-3a82-4f22-9768-29572c0ae4f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy the model to an endpoint\n",
    "\n",
    "Start with deploying the pre-trained model. Here, create a SageMaker `Model` object with the inference image and model file. Then deploy the model with the data capture configuration and wait until the endpoint is ready to serve traffic.\n",
    "\n",
    "[DataCaptureConfig](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.data_capture_config.DataCaptureConfig) enables capturing the request payload and the response payload of the endpoint. Payloads are typically treated as binary data and encoded in BASE64 by default, allowing them to be stored in capture data files. However, by specifying the data format in the `json_content_types` parameter as shown below, the payloads can be captured as plain text instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c565e0-051a-4f6c-bcb6-3dca8f4ec592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = sagemaker.utils.unique_name_from_base(\"DEMO-ll-adult-pred-model-monitor\")\n",
    "endpoint_name = model_name\n",
    "print(f\"SageMaker model name: {model_name}\")\n",
    "print(f\"SageMaker endpoint name: {endpoint_name}\")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"linear-learner\", region, \"1\")\n",
    "print(f\"SageMaker Linear Learner image: {image_uri}\")\n",
    "\n",
    "model = sagemaker.model.Model(\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_url,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "data_capture_config = sagemaker.model_monitor.DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,  # Capture 100% of the traffic\n",
    "    destination_s3_uri=data_capture_s3_uri,\n",
    "    json_content_types=[dataset_type],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86306f2-8f15-4d39-9cbb-2f6c0e7ee978",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell takes about 10 minutes to deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77330b34-0640-4b00-b3bb-4a8ea6e9a223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Deploying model {model_name} to endpoint {endpoint_name}\")\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf8504-bca2-4948-867a-cab4ca349bd9",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "Now send data to this endpoint to get inferences in real time. The model supports mini-batch predictions, so you can put one or more records to a single request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a908e5-c16f-41dc-b718-323ab5ed4268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_dataset_path, \"r\") as f:\n",
    "    test_data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc2ed6-355a-4cdb-a44e-1463c0d9ef9f",
   "metadata": {},
   "source": [
    "#### Example: Single record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e8368-37b1-41d2-b0da-0f22fee2b87e",
   "metadata": {},
   "source": [
    "Request payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbb63a-e1d8-414e-968a-20822305f23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_payload = test_data[0]\n",
    "print(request_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880886a-38cc-44c1-acc4-f3876956e2a8",
   "metadata": {},
   "source": [
    "Response payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87531e43-c9d1-4d9b-8019-19bec1a832eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sagemaker_session.sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=dataset_type,\n",
    "    Accept=dataset_type,\n",
    "    Body=request_payload,\n",
    ")\n",
    "response_payload = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe887e-ec0d-4b2a-9c32-28d93c2e25be",
   "metadata": {},
   "source": [
    "#### Example: Two records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094ad1c-55dd-40d1-b31f-8d47f21814c3",
   "metadata": {},
   "source": [
    "Request payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd41694-9e20-461f-ae85-5f792a521753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_payload = \"\\n\".join(test_data[:2])\n",
    "request_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab91982-67b4-4293-86cb-bb61be2f67aa",
   "metadata": {},
   "source": [
    "Response payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece49e7-38b9-4b33-91ca-f23fcd06dcbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sagemaker_session.sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=dataset_type,\n",
    "    Accept=dataset_type,\n",
    "    Body=request_payload,\n",
    ")\n",
    "response_payload = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243eac0c-a697-42b6-a56f-c0279cc7cd57",
   "metadata": {},
   "source": [
    "### View captured data\n",
    "\n",
    "Because data capture is enabled in the previous steps, the request and response payload, along with some additional metadata, are saved in the Amazon S3 location specified in the [DataCaptureConfig](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.data_capture_config.DataCaptureConfig).\n",
    "\n",
    "Now list the captured data files stored in Amazon S3. There should be different files from different time periods organized based on the hour in which the invocation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c649dd-40ef-4260-b499-0f3c371f970f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Waiting for captured data to show up\", end=\"\")\n",
    "for _ in range(120):\n",
    "    captured_data_files = sorted(\n",
    "        sagemaker.s3.S3Downloader.list(\n",
    "            s3_uri=f\"{data_capture_s3_uri}/{endpoint_name}\",\n",
    "            sagemaker_session=sagemaker_session,\n",
    "        )\n",
    "    )\n",
    "    if captured_data_files:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "print()\n",
    "print(\"Found capture data files:\")\n",
    "print(\"\\n \".join(captured_data_files[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b01fd-4df2-42ff-935e-8843f1bc568f",
   "metadata": {},
   "source": [
    "Next, view the content of a single capture file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad7021-4bcc-4fe1-880e-11a872941ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "captured_data = sagemaker.s3.S3Downloader.read_file(\n",
    "    s3_uri=captured_data_files[-1],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(captured_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09cffd-111a-43a1-8429-2fa3fbce9d2e",
   "metadata": {},
   "source": [
    "Finally, the contents of a single line is present below in formatted JSON to observe a little better.\n",
    "\n",
    "* `captureData` has two fields, `endpointInput` has the captured invocation request, and `endpointOutput` has the response.\n",
    "* `eventMetadata` has the inference ID and event ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14611944-0ae1-4f9f-ab6e-4b5c74ee7f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(captured_data.splitlines()[-1]), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b473f92-7142-4f79-8a27-86672682a5b2",
   "metadata": {},
   "source": [
    "### Start generating some artificial traffic\n",
    "The cell below starts a thread to send some traffic to the endpoint. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process.\n",
    "\n",
    "Notice the `InferenceId` attribute used to invoke, in this example, it will be used to join the captured data with the ground truth data. If it is not available, then the `eventId` will be used for the join operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af95cc5-9e1d-46fd-b373-16015c87be58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WorkerThread(threading.Thread):\n",
    "    def __init__(self, do_run, *args, **kwargs):\n",
    "        super(WorkerThread, self).__init__(*args, **kwargs)\n",
    "        self.__do_run = do_run\n",
    "        self.__terminate_event = threading.Event()\n",
    "\n",
    "    def terminate(self):\n",
    "        self.__terminate_event.set()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.__terminate_event.is_set():\n",
    "            self.__do_run(self.__terminate_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e832f7-8cc7-4044-b2aa-f22c93d2078d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_endpoint(terminate_event):\n",
    "    for index, record in enumerate(test_data):\n",
    "        response = sagemaker_session.sagemaker_runtime_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=dataset_type,\n",
    "            Accept=dataset_type,\n",
    "            Body=record,\n",
    "            InferenceId=str(index),  # unique ID per row\n",
    "        )\n",
    "        response[\"Body\"].read()\n",
    "        time.sleep(1)\n",
    "        if terminate_event.is_set():\n",
    "            break\n",
    "\n",
    "\n",
    "# Keep invoking the endpoint with test data\n",
    "invoke_endpoint_thread = WorkerThread(do_run=invoke_endpoint)\n",
    "invoke_endpoint_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c772d-0628-4b9f-843d-1cd631cbf99f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ground Truth Data\n",
    "\n",
    "Besides captured data, bias drift monitoring execution also requires ground truth data. In real use cases, you should regularly label the captured data, then upload the ground truth data (labels) to designated S3 location. For demonstration purpose, this example notebook generates fake ground truth data following [this schema](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html), and then uploads it to `ground_truth_s3_uri` which is another key input to the monitor. The bias drift monitoring execution will first merge the captured data and the ground truth data, and then do bias analysis for the merged data.\n",
    "\n",
    "Notice the value of the `data` field in `groundTruthData` **must be in the same format as how the ground truth labels are stored in the input dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e06d4-32d8-451c-81f2-be1f131a5ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    label = 1 if random.random() < 0.7 else 0  # randomly generate positive labels 70% of the time\n",
    "    # format required by the merge job and bias monitoring job\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": json.dumps(\n",
    "                {\"label\": label}  # Also use the \"label\" key, the same as in the input dataset.\n",
    "            ),\n",
    "            \"encoding\": \"JSON\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(upload_time):\n",
    "    records = [ground_truth_with_id(i) for i in range(len(test_data))]\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{ground_truth_s3_uri}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    sagemaker.s3.S3Uploader.upload_string_as_file_body(\n",
    "        body=data_to_upload,\n",
    "        desired_s3_uri=target_s3_uri,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49137517-172a-45ea-b139-ae78555b47e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate data for the last hour, in case the first monitoring execution is in this hour\n",
    "upload_ground_truth(datetime.datetime.utcnow() - datetime.timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573901f2-fbba-4bf0-b73c-807c44fe709b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate data once an hour\n",
    "def generate_fake_ground_truth(terminate_event):\n",
    "    upload_ground_truth(datetime.datetime.utcnow())\n",
    "    for _ in range(0, 60):\n",
    "        time.sleep(60)\n",
    "        if terminate_event.is_set():\n",
    "            break\n",
    "\n",
    "\n",
    "ground_truth_thread = WorkerThread(do_run=generate_fake_ground_truth)\n",
    "ground_truth_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d87f96-1ab6-4ad9-bd0d-f21b18ebcded",
   "metadata": {},
   "source": [
    "## Model Bias Monitor\n",
    "\n",
    "Similar to the other monitoring types, the standard procedure of creating a [bias drift monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html) is first run a baselining job, and then schedule the monitor.\n",
    "\n",
    "A bias drift monitoring execution starts a merge job that joins the captured data and ground truth data together using the inference ID. Then a SageMaker Clarify bias analysis job is started to compute all the [pre-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) and [post-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html). on the merged data. The max execution time is divided equally between two jobs, the notebook is scheduling an hourly model bias monitor, so the `max_runtime_in_seconds` parameter should not exceed 1800 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273af941-56ff-4a08-a1e1-023e2d4ec090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_monitor = sagemaker.model_monitor.ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a6f66-bdd8-4815-b3ed-286035f6e4ce",
   "metadata": {},
   "source": [
    "### Baselining job\n",
    "\n",
    "A baselining job runs predictions on training dataset and suggests constraints. The `suggest_baseline()` method of `ModelBiasMonitor` starts a SageMaker Clarify processing job to generate the constraints.\n",
    "\n",
    "The step is not mandatory, but providing constraints file to the monitor can enable violations file generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd931a-bacc-480b-8d2d-c363abe9943f",
   "metadata": {},
   "source": [
    "#### Configurations\n",
    "\n",
    "Information about the input data need to be provided to the processor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398d447-0ccf-4c79-a29d-8d6a54e1c034",
   "metadata": {},
   "source": [
    "`DataConfig` stores information about the dataset to be analyzed. For example, the dataset file and its format (like JSON Lines), where to store the analysis results. Some special things to note about this configuration for the JSON Lines dataset,\n",
    "\n",
    "* The parameter value `\"features\"` or `\"label\"` is **NOT** a header string. Instead, it is a `JMESPath` expression ([refer to its specification](https://jmespath.org/specification.html)) that is used to locate the features list or the ground truth label in the dataset. In this example notebook they happen to be the same as the keys in the dataset. But for example, if the dataset has records like below, then the `features` parameter should use value `\"data.features.values\"`, and the `label` parameter should use value `\"data.label\"`.\n",
    "\n",
    "  ```\n",
    "  {\"data\": {\"features\": {\"values\": [25, 2, 226802, 1, 7, 4, 6, 3, 2, 1, 0, 0, 40, 37]}, \"label\": 0}}\n",
    "  ```\n",
    "\n",
    "* SageMaker Clarify processing job will load the JSON Lines dataset into tabular representation for further analysis, and the parameter `headers` is the list of column names. **The label header shall be the last one in the headers list**, and the order of feature headers shall be the same as the order of features in a record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd146e26-a54c-4a31-acc9-5a406ddf8680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_jmespath = \"features\"\n",
    "ground_truth_label_jmespath = \"label\"\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_s3_uri,\n",
    "    s3_output_path=baselining_output_s3_uri,\n",
    "    features=features_jmespath,\n",
    "    label=ground_truth_label_jmespath,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9c98b-67a5-45e0-8aa5-a488e25a6de8",
   "metadata": {},
   "source": [
    "`ModelConfig` is configuration related to model to be used for inferencing. In order to compute post-training bias metrics, the computation needs to get inferences for the SageMaker model. To accomplish this, the processing job will use the model to create an ephemeral endpoint (also known as \"shadow endpoint\"). The processing job will delete the shadow endpoint after the computations are completed. One special thing to note about this configuration for the JSON Lines model input and output,\n",
    "\n",
    "* `content_template` is used by SageMaker Clarify processing job to convert the tabular data to the request payload acceptable to the shadow endpoint. To be more specific, the placeholder `$features` will be replaced by **the features list** from records. The request payload of a record from the testing dataset happens to be similar to the record itself, like `{\"features\":[28,2,133937,9,13,2,0,0,4,1,15024,0,55,37]}`, because both the dataset and the model input conform to the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49acc6-c6a9-46fa-aed7-e93e67fae373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_template = '{\"features\":$features}'\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_name,  # The name of the SageMaker model\n",
    "    instance_type=\"ml.m5.xlarge\",  # The instance type of the shadow endpoint\n",
    "    instance_count=1,  # The instance count of the shadow endpoint\n",
    "    content_type=dataset_type,  # The data format of the model input\n",
    "    accept_type=dataset_type,  # The data format of the model output\n",
    "    content_template=content_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c02c3-0238-48c9-8f21-73ddb317c506",
   "metadata": {},
   "source": [
    "`ModelPredictedLabelConfig` specifies how to extract predicted label from the model output. The example model returns the predicted label as well as the confidence score, so there are two ways to define this configuration,\n",
    "\n",
    "* Set the `label` parameter to \"predicted_label\" which is the `JMESPath` expression to locate the predicted label in the model output. This is the way used in this example.\n",
    "* Alternatively, you can set the `probability` parameter to \"score\" which is the `JMESPath` expression to locate the confidence score in the model output. And set the `probability_threshold` parameter to a floating number in between 0 and 1. The post-training analysis will use it to convert a score to binary predicted label (`0` or `1`). The default value is 0.5, which means a probability value > 0.5 indicates predicted label `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc6502-8a28-4cda-a135-2c687e9097b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_label_jmespath = \"predicted_label\"\n",
    "model_predicted_label_config = sagemaker.clarify.ModelPredictedLabelConfig(\n",
    "    label=predicted_label_jmespath,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b583a-f643-45dc-bdd3-ae29120734fa",
   "metadata": {},
   "source": [
    "`BiasConfig` is the configuration of the sensitive groups in the dataset. Typically, bias is measured by computing a metric and comparing it across groups. \n",
    "\n",
    "  * The group of interest is specified using the facet parameters. With the following configuration, the baselining job will check for bias in the model's predictions with respect to gender and income. Specifically, it is checking if the model is more likely to predict that males have an annual income of over $50,000 compared to females. Although not demonstrated in this example, a bias monitor can measure bias against multiple sensitive attributes, if you provide a list of facets.\n",
    "  * The `group_name` parameter is used to form subgroups for the measurement of [Conditional Demographic Disparity in Labels](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-data-bias-metric-cddl.html) (CDDL) and [Conditional Demographic Disparity in Predicted Labels](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-post-training-bias-metric-cddpl.html) (CDDPL) with regard to [Simpsonâ€™s paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead08ae-1867-41b9-8c0e-6202760c4175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1],  # the positive outcome is earning >$50,000\n",
    "    facet_name=\"Sex\",  # the sensitive attribute is the gender\n",
    "    facet_values_or_threshold=[0],  # the disadvantaged group is female\n",
    "    group_name=\"Age\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9417f1-b2b2-4c23-81ba-256ff4616c5c",
   "metadata": {},
   "source": [
    "#### Kick off baselining job\n",
    "\n",
    "Call the `suggest_baseline()` method to start the baselining job. The job computes all the [pre-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) and [post-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27e74b-31f6-435a-a0d4-bef52a4cdcdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_monitor.suggest_baseline(\n",
    "    bias_config=bias_config,\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=model_predicted_label_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf396d3-c7ab-4041-8820-64c5ebd15d46",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell waits until the baselining job is completed (in about 10 minutes). It then inspects the suggested constraints. This step can be skipped, because the monitor to be scheduled will automatically pick up baselining job name and wait for it before monitoring execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ece68-f130-4b66-b8ab-36d2916502c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_monitor.latest_baselining_job.wait(logs=False)\n",
    "print()\n",
    "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
    "print(f\"Suggested constraints: {model_bias_constraints.file_s3_uri}\")\n",
    "print(\n",
    "    sagemaker.s3.S3Downloader.read_file(\n",
    "        s3_uri=model_bias_constraints.file_s3_uri,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545f7e0-8256-4b33-8385-741c23b9acc6",
   "metadata": {},
   "source": [
    "### Monitoring Schedule\n",
    "\n",
    "With above constraints collected, now call `create_monitoring_schedule()` method to schedule an hourly model bias monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f1d50-d9ce-42c6-84da-a710bfb7b47a",
   "metadata": {},
   "source": [
    "If a baselining job has been submitted, then the monitor object will automatically pick up the analysis configuration from the baselining job. But if the baselining step is skipped, or if the capture dataset has different nature than the training dataset, then analysis configuration has to be provided.\n",
    "\n",
    "`BiasAnalysisConfig` is a subset of the configuration of the baselining job, many options are not needed because,\n",
    "\n",
    "* Model bias monitor will merge the captured data and the ground truth data, and then use the merged data as the dataset.\n",
    "* Capture data already includes predictions, so there is no need to create shadow endpoint.\n",
    "* Attributes like predicted label are provided as part of EndpointInput.\n",
    "\n",
    "Highlights,\n",
    "\n",
    "* From `endpoint_name` the monitor can figure out the location of data captured by the endpoint.\n",
    "* `ground_truth_s3_uri` is the location of ground truth data\n",
    "* `features_attribute` is the `JMESPath` expression to locate the features in model input, similar to the `features` parameter of `DataConfig`.\n",
    "* `inference_attribute` is the `JMESPath` expression to locate the predicted label in model output, similar to the `label` parameter of `ModelPredictedLabelConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d160d3e-0482-4c4b-a171-e62eddb38b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule_expression = sagemaker.model_monitor.CronExpressionGenerator.hourly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a1355-2997-46f2-ae02-cb00063e3661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_analysis_config = None\n",
    "if not model_bias_monitor.latest_baselining_job:\n",
    "    model_bias_analysis_config = sagemaker.model_monitor.BiasAnalysisConfig(\n",
    "        bias_config,\n",
    "        headers=all_headers,\n",
    "        label=ground_truth_label_jmespath,\n",
    "    )\n",
    "model_bias_monitor.create_monitoring_schedule(\n",
    "    analysis_config=model_bias_analysis_config,\n",
    "    endpoint_input=sagemaker.model_monitor.EndpointInput(\n",
    "        endpoint_name=endpoint_name,\n",
    "        destination=\"/opt/ml/processing/input/endpoint\",\n",
    "        features_attribute=features_jmespath,  # mandatory if no baselining job\n",
    "        inference_attribute=predicted_label_jmespath,  # mandatory if no baselining job\n",
    "        # look back 6 hour for captured data\n",
    "        start_time_offset=\"-PT6H\",\n",
    "        end_time_offset=\"-PT0H\",\n",
    "    ),\n",
    "    ground_truth_input=ground_truth_s3_uri,\n",
    "    output_s3_uri=monitor_output_s3_uri,\n",
    "    schedule_cron_expression=schedule_expression,\n",
    ")\n",
    "print(f\"Model bias monitoring schedule: {model_bias_monitor.monitoring_schedule_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22401a-4662-4063-b47f-5be6becf3c3b",
   "metadata": {},
   "source": [
    "#### Wait for the first execution\n",
    "\n",
    "The schedule starts jobs at the previously specified intervals. Code below waits until time crosses the hour boundary (in UTC) to see executions kick off.\n",
    "\n",
    "Note: Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule executions. The execution might start in anywhere from zero to ~20 minutes from the hour boundary. This is expected and done for load balancing in the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00eb31-bbc7-4cf9-9fae-b323b4d380b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_execution_to_start(model_monitor):\n",
    "    print(\n",
    "        \"An hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\"\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for the first execution to happen\", end=\"\")\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    while \"LastMonitoringExecutionSummary\" not in schedule_desc:\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(60)\n",
    "    print()\n",
    "    print(\"Done! Execution has been created\")\n",
    "\n",
    "    print(\"Now waiting for execution to start\", end=\"\")\n",
    "    while schedule_desc[\"LastMonitoringExecutionSummary\"][\"MonitoringExecutionStatus\"] in \"Pending\":\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(10)\n",
    "\n",
    "    print()\n",
    "    print(\"Done! Execution has started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fabf1c-8458-4186-9fb2-7bfa2462b705",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell waits until the first monitoring execution is started. As explained above, the wait could take more than 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512df1e-57cf-4ba3-9262-0c325c4a600e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wait_for_execution_to_start(model_bias_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210955ae-1709-423f-98c0-ca93476eebde",
   "metadata": {},
   "source": [
    "In real world, a monitoring schedule is supposed to be active all the time. But in this example, it can be stopped to avoid incurring extra charges. A stopped schedule will not trigger further executions, but the ongoing execution will continue. And if needed, the schedule can be restarted by `start_monitoring_schedule()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6980d31-c96d-4850-a7fb-c8583eeac54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_monitor.stop_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a4a1d-4410-4f60-b859-762f18f7370b",
   "metadata": {},
   "source": [
    "#### Wait for the execution to finish\n",
    "\n",
    "In the previous cell, the first execution has started. This section waits for the execution to finish so that its analysis results are available. Here are the possible terminal states and what each of them mean:\n",
    "\n",
    "* `Completed` - This means the monitoring execution completed, and no issues were found in the violations report.\n",
    "* `CompletedWithViolations` - This means the execution completed, but constraint violations were detected.\n",
    "* `Failed` - The monitoring execution failed, maybe due to client error (perhaps incorrect role permissions) or infrastructure issues. Further examination of `FailureReason` and `ExitMessage` is necessary to identify what exactly happened.\n",
    "* `Stopped` - job exceeded max runtime or was manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07426d-f805-4527-9863-1d3d664734fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Waits for the schedule to have last execution in a terminal status.\n",
    "def wait_for_execution_to_finish(model_monitor):\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "    if execution_summary is not None:\n",
    "        print(\"Waiting for execution to finish\", end=\"\")\n",
    "        while execution_summary[\"MonitoringExecutionStatus\"] not in [\n",
    "            \"Completed\",\n",
    "            \"CompletedWithViolations\",\n",
    "            \"Failed\",\n",
    "            \"Stopped\",\n",
    "        ]:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(60)\n",
    "            schedule_desc = model_monitor.describe_schedule()\n",
    "            execution_summary = schedule_desc[\"LastMonitoringExecutionSummary\"]\n",
    "        print()\n",
    "        print(f\"Done! Execution Status: {execution_summary['MonitoringExecutionStatus']}\")\n",
    "    else:\n",
    "        print(\"Last execution not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01434010-3c04-4ef5-acd2-21a3a0035fc8",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell takes about 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e36f00-f488-4a16-867f-92c53d819782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wait_for_execution_to_finish(model_bias_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c7bbd-0af7-44a1-bec9-a94f180f6892",
   "metadata": {},
   "source": [
    "#### Merged data\n",
    "\n",
    "Merged data is the intermediate results of bias drift monitoring execution. It is saved to JSON Lines files under the \"merge\" folder of `monitor_output_s3_uri`. Each line is a valid JSON object which combines the captured data and the ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df9816-63ad-4e44-b26d-b79fba785307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data_s3_uri = f\"{monitor_output_s3_uri}/merge\"\n",
    "merged_data_files = sagemaker.s3.S3Downloader.list(\n",
    "    s3_uri=merged_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(\"Found merged files:\")\n",
    "print(\"\\n \".join(merged_data_files[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71db78-5d65-4768-b5ff-461057c5f922",
   "metadata": {},
   "source": [
    "The following cell prints a single line of a merged data file.\n",
    "\n",
    "* `eventId` is the inference ID from the captured data and the ground truth data\n",
    "* `groundTruthData` is from the ground truth data\n",
    "* `captureData` is from the captured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581b300-4ee0-4884-aef7-bf94577c07aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data_file = sagemaker.s3.S3Downloader.read_file(\n",
    "    s3_uri=merged_data_files[-1],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "merged_record = merged_data_file.splitlines()[-1]\n",
    "print(json.dumps(json.loads(merged_record), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecf876-5999-4c2a-adcd-0a8537f082e6",
   "metadata": {},
   "source": [
    "#### Inspect execution results\n",
    "\n",
    "List the generated reports,\n",
    "\n",
    "* analysis.json includes all the bias metrics.\n",
    "* report.* files are static report files to visualize the bias metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c767cbd-78c5-433d-a850-e230cb5a55dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule_desc = model_bias_monitor.describe_schedule()\n",
    "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
    "    \"Completed\",\n",
    "    \"CompletedWithViolations\",\n",
    "]:\n",
    "    last_model_bias_monitor_execution = model_bias_monitor.list_executions()[-1]\n",
    "    last_model_bias_monitor_execution_report_uri = (\n",
    "        last_model_bias_monitor_execution.output.destination\n",
    "    )\n",
    "    print(f\"Report URI: {last_model_bias_monitor_execution_report_uri}\")\n",
    "    last_model_bias_monitor_execution_report_files = sorted(\n",
    "        sagemaker.s3.S3Downloader.list(\n",
    "            s3_uri=last_model_bias_monitor_execution_report_uri,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "        )\n",
    "    )\n",
    "    print(\"Found Report Files:\")\n",
    "    print(\"\\n \".join(last_model_bias_monitor_execution_report_files))\n",
    "else:\n",
    "    last_model_bias_monitor_execution = None\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a2ef3-4d6c-4d93-974e-77a679fc4757",
   "metadata": {},
   "source": [
    "If there are any violations compared to the baseline, they are listed here. See [Bias Drift Violations](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift-violations.html) for the schema of the file, and how violations are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7174d2e-9ee4-437f-be9a-c9d984318b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "violations = model_bias_monitor.latest_monitoring_constraint_violations()\n",
    "if violations is not None:\n",
    "    pprint.PrettyPrinter(indent=4).pprint(violations.body_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e3d97-27cc-4325-814d-04219d25ab76",
   "metadata": {},
   "source": [
    "By default, the analysis results are also published to CloudWatch, see [CloudWatch Metrics for Bias Drift Analysis](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift-cw.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6388287-b810-4522-bcc1-928228982388",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The endpoint can keep running and capturing data, but if there is no plan to collect more data or use this endpoint further, it should be deleted to avoid incurring additional charges. Note that deleting endpoint does not delete the data that was captured during the model invocations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e8db8-4918-420c-9b4d-5c7263a402e7",
   "metadata": {},
   "source": [
    "First stop the worker threads,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813097c-00cc-4ee4-91cc-d03b72915c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invoke_endpoint_thread.terminate()\n",
    "ground_truth_thread.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f971c4-c1ae-4766-ab44-a30d361df523",
   "metadata": {},
   "source": [
    "Then stop all monitors scheduled for the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b99289-3924-4d40-9860-75ccea76646b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_monitor.stop_monitoring_schedule()\n",
    "wait_for_execution_to_finish(model_bias_monitor)\n",
    "model_bias_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2442401-06c9-481a-a04c-e339d618af54",
   "metadata": {},
   "source": [
    "Finally, delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd0678-66d3-493d-bee4-7e2a9dab901e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name=endpoint_name)\n",
    "sagemaker_session.delete_model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400ee1b",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_model_monitor|fairness_and_explainability_jsonlines|SageMaker-Monitoring-Bias-Drift-for-Endpoint.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
