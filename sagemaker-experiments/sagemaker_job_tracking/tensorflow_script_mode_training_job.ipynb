{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track an experiment while training in a SageMaker Job\n",
    "\n",
    "This notebook shows how you can use the SageMaker SDK to track a Machine Learning experiment. \n",
    "\n",
    "We introduce two concepts in this notebook -\n",
    "\n",
    "* *Experiment:* An experiment is a collection of runs. When you initialize a run in your training loop, you include the name of the experiment that the run belongs to. Experiment names must be unique within your AWS account. \n",
    "* *Run:* A run consists of all the inputs, parameters, configurations, and results for one iteration of model training. Initialize an experiment run for tracking a training job with Run(). \n",
    "\n",
    "In this notebook we train a Keras model using the MNIST dataset on a remote SageMaker instance using a training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** To run this notebook, use the `Python 3 (Data Science) Image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.utils import unique_name_from_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "boto_sess = boto3.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "\n",
    "sm = boto_sess.client(\"sagemaker\")\n",
    "region = boto_sess.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the training script\n",
    "\n",
    "Here we use a SageMaker Training job to train the model on a remote instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./script/train.py\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(\"pip install -U sagemaker\")\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments import load_run\n",
    "\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.session.Session(region_name=os.environ[\"REGION\"])\n",
    "sagemaker_session = Session(boto_session=boto_session)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.01)\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "class ExperimentCallback(keras.callbacks.Callback):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, run, model, x_test, y_test):\n",
    "        \"\"\"Save params in constructor\"\"\"\n",
    "        self.run = run\n",
    "        self.model = model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" \"\"\"\n",
    "        keys = list(logs.keys())\n",
    "        for key in keys:\n",
    "            self.run.log_metric(name=key, value=logs[key], step=epoch)\n",
    "            print(\"Epoch: {}\\n{} -> {}\".format(epoch, key, logs[key]))\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "    # Load the data and split it between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(x_train.shape[0], \"train samples\")\n",
    "    print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\" \"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(args.dropout),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    ###\n",
    "    # `load_run` will use the run defined when calling the estimator\n",
    "    ###\n",
    "    with load_run(sagemaker_session=sagemaker_session) as run:\n",
    "\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[ExperimentCallback(run, model, x_test, y_test)],\n",
    "        )\n",
    "\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(\"Test loss:\", score[0])\n",
    "        print(\"Test accuracy:\", score[1])\n",
    "\n",
    "        run.log_metric(name=\"Final Test Loss\", value=score[0])\n",
    "        run.log_metric(name=\"Final Test Loss\", value=score[0])\n",
    "\n",
    "        model.save(\"/opt/ml/model\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment and launch a training job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.experiments.run import Run\n",
    "\n",
    "exp_name = \"tensorflow-script-mode-experiment\"\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "dropout = 0.1\n",
    "\n",
    "with Run(\n",
    "    experiment_name=exp_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    run.log_parameter(\"batch_size\", batch_size)\n",
    "    run.log_parameter(\"epochs\", epochs)\n",
    "\n",
    "    est = TensorFlow(\n",
    "        entry_point=\"./script/train.py\",\n",
    "        role=role,\n",
    "        model_dir=False,\n",
    "        hyperparameters={\"epochs\": epochs, \"batch_size\": batch_size, \"dropout\": dropout},\n",
    "        framework_version=\"2.8\",\n",
    "        py_version=\"py39\",\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        instance_count=1,\n",
    "        keep_alive_period_in_seconds=3600,\n",
    "        env={\"REGION\": region},\n",
    "    )\n",
    "\n",
    "    est.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "\n",
    "model = TensorFlowModel(model_data=est.model_data, role=role, framework_version=\"2.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.register(\n",
    "    model_package_group_name=\"tensorflow-script-mode-model\",\n",
    "    content_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
