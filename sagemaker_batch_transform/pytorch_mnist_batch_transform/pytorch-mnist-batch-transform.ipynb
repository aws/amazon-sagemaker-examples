{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f7253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-ml-py3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (7.352.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Found existing installation: torchvision 0.10.0\n",
      "Uninstalling torchvision-0.10.0:\n",
      "  Would remove:\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.10.0.dist-info/*\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libcudart.459720b2.so.10.2\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libnvjpeg.a6b52b54.so.10\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libz.1328edc3.so.1\n",
      "    /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/*\n",
      "Proceed (y/n)?   Successfully uninstalled torchvision-0.10.0\n",
      "yes: standard output: Broken pipe\n",
      "yes: write error\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.10.0-cp36-cp36m-manylinux1_x86_64.whl (22.1 MB)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: torch==1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.9.0->torchvision) (0.8)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.10.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-ml-py3\n",
    "!yes | pip uninstall torchvision\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3de83",
   "metadata": {
    "papermill": {
     "duration": 0.009489,
     "end_time": "2021-06-03T00:10:10.266437",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.256948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Batch Inference\n",
    "In this notebook, we'll examine how to do batch transform task with PyTorch in Amazon SageMaker. \n",
    "\n",
    "First, an image classification model is build on MNIST dataset. Then, we demonstrate batch transform by using SageMaker Python SDK PyTorch framework with different configurations\n",
    "- `data_type=S3Prefix`: uses all objects that match the specified S3 key name prefix for batch inference.\n",
    "- `data_type=ManifestFile`: a manifest file containing a list of object keys that you want to batch inference.\n",
    "- `instance_count>1`: distribute the batch inference dataset to multiple inference instance\n",
    "\n",
    "For batch transform in TensorFlow in Amazon SageMaker, you can follow other Jupyter notebooks [here](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc941a",
   "metadata": {
    "papermill": {
     "duration": 0.009319,
     "end_time": "2021-06-03T00:10:10.285106",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.275787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "We'll begin with some necessary imports, and get an Amazon SageMaker session to help perform certain tasks, as well as an IAM role with the necessary permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5698e15a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:10.310480Z",
     "iopub.status.busy": "2021-06-03T00:10:10.309977Z",
     "iopub.status.idle": "2021-06-03T00:10:11.972019Z",
     "shell.execute_reply": "2021-06-03T00:10:11.971547Z"
    },
    "papermill": {
     "duration": 1.677667,
     "end_time": "2021-06-03T00:10:11.972131",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.294464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:\n",
      "sagemaker-us-east-1-474422712127\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-batch-inference-script\"\n",
    "print(\"Bucket:\\n{}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad944550",
   "metadata": {
    "papermill": {
     "duration": 0.009748,
     "end_time": "2021-06-03T00:10:11.992188",
     "exception": false,
     "start_time": "2021-06-03T00:10:11.982440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed7695",
   "metadata": {
    "papermill": {
     "duration": 0.009924,
     "end_time": "2021-06-03T00:10:12.012090",
     "exception": false,
     "start_time": "2021-06-03T00:10:12.002166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since the main purpose of this notebook is to demonstrate SageMaker PyTorch batch transform, **we reuse this SageMaker Python SDK [PyTorch example](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_mnist) to train a PyTorch model**. It takes around 7 minutes to finish the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98a92ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:12.038135Z",
     "iopub.status.busy": "2021-06-03T00:10:12.037362Z",
     "iopub.status.idle": "2021-06-03T00:15:42.451109Z",
     "shell.execute_reply": "2021-06-03T00:15:42.449969Z"
    },
    "papermill": {
     "duration": 330.429296,
     "end_time": "2021-06-03T00:15:42.451328",
     "exception": true,
     "start_time": "2021-06-03T00:10:12.022032",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-474422712127/sagemaker/DEMO-pytorch-batch-inference-script\n",
      "2021-07-22 20:25:39 Starting - Starting the training job...\n",
      "2021-07-22 20:26:02 Starting - Launching requested ML instancesProfilerReport-1626985539: InProgress\n",
      "......\n",
      "2021-07-22 20:27:04 Starting - Preparing the instances for training............\n",
      "2021-07-22 20:29:05 Downloading - Downloading input data\n",
      "2021-07-22 20:29:05 Training - Downloading the training image...\n",
      "2021-07-22 20:29:24 Training - Training image download completed. Training in progress.\u001b[32mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[32mbash: no job control in this shell\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,020 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,022 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,031 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,246 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,642 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,654 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,665 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-07-22 20:29:22,674 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[32mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[32m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2021-07-22-20-25-39-426\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[32m}\n",
      "\u001b[0m\n",
      "\u001b[32mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[32mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[32mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[32mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[32mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[32mSM_RESOURCE_CONFIG={\"current_host\":\"algo-3\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[32mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[32mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[32mSM_CURRENT_HOST=algo-3\u001b[0m\n",
      "\u001b[32mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[32mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[32mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[32mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[32mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[32mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[32mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[32mSM_MODULE_DIR=s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[32mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-3\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2021-07-22-20-25-39-426\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-3\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[32mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[32mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[32mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[32mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[32mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[32mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[32m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mDistributed training - True\u001b[0m\n",
      "\u001b[32mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:22,200 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:22,202 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:22,211 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:22,217 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:21,892 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:21,894 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:21,902 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:22,520 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:22,825 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:22,838 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:22,849 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-07-22 20:29:22,858 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2021-07-22-20-25-39-426\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2021-07-22-20-25-39-426\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:54,011 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:54,022 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:54,033 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-07-22 20:29:54,042 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-07-22-20-25-39-426\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-07-22-20-25-39-426\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-474422712127/pytorch-training-2021-07-22-20-25-39-426/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[32mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 2. Number of gpus: 0\u001b[0m\n",
      "\u001b[32mGet train data loader\u001b[0m\n",
      "\u001b[32mGet test data loader\u001b[0m\n",
      "\u001b[32mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[32mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.447 algo-3:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.447 algo-1:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mGet train data loader\u001b[0m\n",
      "\u001b[35mGet test data loader\u001b[0m\n",
      "\u001b[35mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.431 algo-2:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.784 algo-3:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.784 algo-3:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.784 algo-3:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.785 algo-3:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.785 algo-3:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[32m[2021-07-22 20:29:56.832 algo-3:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.743 algo-1:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.743 algo-1:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.744 algo-1:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.744 algo-1:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.744 algo-1:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[34m[2021-07-22 20:29:56.788 algo-1:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.729 algo-2:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.730 algo-2:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.730 algo-2:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.730 algo-2:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.730 algo-2:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[35m[2021-07-22 20:29:56.770 algo-2:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [6400/20000 (32%)] Loss: 2.076494\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [6400/20000 (32%)] Loss: 1.944218\u001b[0m\n",
      "\n",
      "2021-07-22 20:30:09 Uploading - Uploading generated training model\u001b[34mTrain Epoch: 1 [6400/20000 (32%)] Loss: 1.830737\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [12800/20000 (64%)] Loss: 1.229461\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/20000 (64%)] Loss: 1.132146\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [12800/20000 (64%)] Loss: 0.970919\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.667853\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.892621\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.714048\u001b[0m\n",
      "\u001b[32mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 2. Number of gpus: 0\u001b[0m\n",
      "\u001b[32mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[32mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[32mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[32mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 2.076494\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 1.229461\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.667853\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[32mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2021-07-22 20:30:04,357 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 1.830737\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 1.132146\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.892621\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-22 20:30:04,458 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[35mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 1.944218\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 0.970919\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.714048\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[35mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-07-22 20:30:04,379 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-07-22 20:30:25 Completed - Training job completed\n",
      "Training seconds: 258\n",
      "Billable seconds: 258\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "local_dir = \"data\"\n",
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "MNIST(\n",
    "    local_dir,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=local_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"model-script/mnist.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        \"backend\": \"gloo\",\n",
    "    },  # set epochs to a more realistic number for real training\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361159b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Prepare batch inference data\n",
    "\n",
    "First, convert the test data into png image; second, upload to your default S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14e25ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls data/MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ee95b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# untar gz => png\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "with gzip.open(os.path.join(local_dir, \"MNIST/raw\", \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1137406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3cf193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 100 of test images and upload them to S3\n",
    "\n",
    "import random\n",
    "from PIL import Image as im\n",
    "\n",
    "ids = random.sample(range(len(images)), 100)\n",
    "ids = np.array(ids, dtype=np.int)\n",
    "selected_images = images[ids]\n",
    "\n",
    "image_dir = \"data/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "for i, img in enumerate(selected_images):\n",
    "    pngimg = im.fromarray(img)\n",
    "    pngimg.save(os.path.join(image_dir, f\"{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677d9641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23.png',\n",
       " '10.png',\n",
       " '48.png',\n",
       " '64.png',\n",
       " '52.png',\n",
       " '86.png',\n",
       " '70.png',\n",
       " '69.png',\n",
       " '65.png',\n",
       " '20.png',\n",
       " '14.png',\n",
       " '77.png',\n",
       " '57.png',\n",
       " '36.png',\n",
       " '71.png',\n",
       " '50.png',\n",
       " '60.png',\n",
       " '63.png',\n",
       " '73.png',\n",
       " '56.png',\n",
       " '95.png',\n",
       " '51.png',\n",
       " '98.png',\n",
       " '25.png',\n",
       " '54.png',\n",
       " '3.png',\n",
       " '8.png',\n",
       " '45.png',\n",
       " '6.png',\n",
       " '49.png',\n",
       " '37.png',\n",
       " '11.png',\n",
       " '75.png',\n",
       " '21.png',\n",
       " '74.png',\n",
       " '34.png',\n",
       " '92.png',\n",
       " '72.png',\n",
       " '96.png',\n",
       " '53.png',\n",
       " '31.png',\n",
       " '85.png',\n",
       " '0.png',\n",
       " '55.png',\n",
       " '2.png',\n",
       " '99.png',\n",
       " '80.png',\n",
       " '78.png',\n",
       " '29.png',\n",
       " '16.png',\n",
       " '24.png',\n",
       " '19.png',\n",
       " '13.png',\n",
       " '67.png',\n",
       " '30.png',\n",
       " '47.png',\n",
       " '4.png',\n",
       " '40.png',\n",
       " '39.png',\n",
       " '27.png',\n",
       " '91.png',\n",
       " '82.png',\n",
       " '1.png',\n",
       " '83.png',\n",
       " '32.png',\n",
       " '46.png',\n",
       " '5.png',\n",
       " '88.png',\n",
       " '79.png',\n",
       " '59.png',\n",
       " '38.png',\n",
       " '28.png',\n",
       " '17.png',\n",
       " '42.png',\n",
       " '41.png',\n",
       " '93.png',\n",
       " '33.png',\n",
       " '89.png',\n",
       " '61.png',\n",
       " '7.png',\n",
       " '90.png',\n",
       " '87.png',\n",
       " '66.png',\n",
       " '22.png',\n",
       " '84.png',\n",
       " '12.png',\n",
       " '68.png',\n",
       " '15.png',\n",
       " '9.png',\n",
       " '81.png',\n",
       " '94.png',\n",
       " '18.png',\n",
       " '43.png',\n",
       " '62.png',\n",
       " '58.png',\n",
       " '26.png',\n",
       " '35.png',\n",
       " '97.png',\n",
       " '44.png',\n",
       " '76.png']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73dfbd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-474422712127/batch_transform\n"
     ]
    }
   ],
   "source": [
    "inference_prefix = \"batch_transform\"\n",
    "inference_inputs = sagemaker_session.upload_data(\n",
    "    path=image_dir, bucket=bucket, key_prefix=inference_prefix\n",
    ")\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inference_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a40db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Create model transformer\n",
    "Now, we will create a transformer object for handling creating and interacting with Amazon SageMaker transform jobs. We can create the transformer in two ways as shown in the following notebook cells.\n",
    "- use fitted estimator directly\n",
    "- first create PyTorchModel from saved model artefect, then create transformer from PyTorchModel object\n",
    "\n",
    "\n",
    "Here, we implement the `model_fn`, `input_fn`, `predict_fn` and `output_fn` function to override the default [PyTorch inference handler](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_inference_handler.py). \n",
    "\n",
    "It is noted that in `input_fn` function, the inferenced images are encoded as a Python ByteArray. That's why we use `load_from_bytearray` function to load image from `io.BytesIO` then use `PIL.image` to read.\n",
    "\n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "    \n",
    "def load_from_bytearray(request_body):\n",
    "    image_as_bytes = io.BytesIO(request_body)\n",
    "    image = Image.open(image_as_bytes)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    # if set content_type as 'image/jpg' or 'applicaiton/x-npy', \n",
    "    # the input is also a python bytearray\n",
    "    if request_content_type == 'application/x-image': \n",
    "        image_tensor = load_from_bytearray(request_body)\n",
    "    else:\n",
    "        print(\"not support this type yet\")\n",
    "        raise ValueError(\"not support this type yet\")\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "def predict_fn(input_object, model):\n",
    "    output = model.forward(input_object)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    return {'predictions':pred.item()}\n",
    "\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "def output_fn(predictions, response_content_type):\n",
    "    return json.dumps(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccdbc781",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use fitted estimator directly\n",
    "transformer = estimator.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "490a574b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also create a Transformer object from saved model artefect\n",
    "\n",
    "# get model artefect location by estimator.model_data, or give a S3 key directly\n",
    "model_artefect_s3_location = estimator.model_data  #'s3://BUCKET/PREFIX/model.tar.gz'\n",
    "\n",
    "# create PyTorchModel from saved model artefect\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artefect_s3_location,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\"model-script/\",\n",
    "    entry_point=\"mnist.py\",\n",
    ")\n",
    "\n",
    "# then create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5659f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Batch inference\n",
    "Next, we will inference the sampled 100 MNIST images in a batch manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927369e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### input images directly from S3 location\n",
    "We set `S3DataType=S3Prefix` to uses all objects that match the specified S3 key name prefix for batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9b5b68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34m2021-07-22 20:11:22,659 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,659 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 948 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,689 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,708 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 542dc7064b21417a9e6abdd2a5fdb6b8\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,720 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,742 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,893 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,895 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]44\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,895 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35mMax heap size: 948 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,689 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,708 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 542dc7064b21417a9e6abdd2a5fdb6b8\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,720 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,742 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,893 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,895 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]44\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,895 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,896 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,914 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]43\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,916 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,920 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,952 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,952 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]42\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,953 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,953 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,953 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,964 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,992 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,992 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,994 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,999 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,999 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,999 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:22,999 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,741 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.240135192871094|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.675777435302734|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6410.94921875|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,744 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:936.54296875|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:23,744 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:15.9|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1075\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,162 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1432|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,896 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,914 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]43\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,916 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,920 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,952 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,952 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]42\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,953 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,953 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,953 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,964 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,970 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,992 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,992 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,994 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,999 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,999 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,999 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:22,999 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,741 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.240135192871094|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.675777435302734|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,743 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6410.94921875|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,744 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:936.54296875|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:23,744 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:15.9|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984683\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1075\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,162 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1432|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,163 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:66|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,163 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1039\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,163 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1432|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,163 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:100|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,220 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1089\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,220 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1492|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,220 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:110|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,234 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1115\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,234 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1503|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:24,234 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:100|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,163 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:66|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,163 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1039\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,163 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1432|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,163 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:100|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,220 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1089\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,220 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1492|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,220 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:110|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,234 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1115\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,234 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1503|#Level:Host|#hostname:dd32f2ad444b,timestamp:1626984684\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:24,234 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:100|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:28,990 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:57366 \"GET /ping HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:28,991 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,012 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:57374 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:28,990 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:57366 \"GET /ping HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:28,991 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,012 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:57374 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,013 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,093 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,094 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,094 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,093 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.7|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:46c13793-29e9-4152-8289-ddac7a64fb5e,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,095 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,095 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,179 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,179 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,179 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,182 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,182 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,185 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.06|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9a21984f-33c4-483b-b4b4-62efd7deea10,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,333 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,333 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.71|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b6d87825-fac8-4859-ad3a-8aa591743dca,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,013 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,093 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,094 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,094 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,093 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.7|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:46c13793-29e9-4152-8289-ddac7a64fb5e,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,095 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,095 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,179 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,179 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,179 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,182 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,182 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,185 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.06|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9a21984f-33c4-483b-b4b4-62efd7deea10,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,333 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,333 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.71|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b6d87825-fac8-4859-ad3a-8aa591743dca,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,334 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,445 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,446 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.68|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:7019e535-8294-45b9-af3e-7c098455bcba,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,447 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,447 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,448 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,448 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,445 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,446 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.68|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:7019e535-8294-45b9-af3e-7c098455bcba,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,447 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,447 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,448 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,448 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:187522ad-c6d3-4b28-a919-f313decb65e4,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,686 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:f8d64eb8-6af7-4297-9f13-aae641116ad5,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,834 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,834 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4621b924-f960-4cea-8b4d-e17f876cdb6b,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,926 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.0|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:079192e8-74c8-42c5-b72d-245765ff47a1,timestamp:1626984689\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,013 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c1d0606b-0c37-4ca9-95ab-a10bd545013b,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 8\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,221 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:88b21b6d-9dea-4b44-9ddc-f697ef11a3e1,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d7b67173-45f6-4914-ba02-1b6e195e184b,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:187522ad-c6d3-4b28-a919-f313decb65e4,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,686 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:f8d64eb8-6af7-4297-9f13-aae641116ad5,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,687 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,834 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,834 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4621b924-f960-4cea-8b4d-e17f876cdb6b,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,835 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,926 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.0|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:079192e8-74c8-42c5-b72d-245765ff47a1,timestamp:1626984689\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:29,927 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,013 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c1d0606b-0c37-4ca9-95ab-a10bd545013b,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 8\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,018 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,221 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:88b21b6d-9dea-4b44-9ddc-f697ef11a3e1,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,222 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d7b67173-45f6-4914-ba02-1b6e195e184b,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,321 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:724959dc-b73c-4021-8aa2-c15b4b3ac529,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,527 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,527 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c8898a97-771a-4abb-92d1-2765874ea30d,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:eb9151f5-955c-431b-a518-b8b48a967a0c,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,791 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,791 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.63|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d46ee65b-61f2-4ccf-a7b1-da7d46c149ef,timestamp:1626984690\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,180 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:1bcfc8a2-9a80-44fc-b265-9a102ad25805,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b47d7d62-974f-40dc-8dba-ef096e2fc3a2,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,328 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:724959dc-b73c-4021-8aa2-c15b4b3ac529,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,409 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,527 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,527 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c8898a97-771a-4abb-92d1-2765874ea30d,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:eb9151f5-955c-431b-a518-b8b48a967a0c,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,615 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,791 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,791 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.63|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d46ee65b-61f2-4ccf-a7b1-da7d46c149ef,timestamp:1626984690\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:30,792 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,180 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:1bcfc8a2-9a80-44fc-b265-9a102ad25805,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,181 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b47d7d62-974f-40dc-8dba-ef096e2fc3a2,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,327 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,328 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,464 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:28b46a00-4cfa-4bb6-b72a-a01c61ddf891,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:432496a2-c97f-4650-9c6f-0997f75a1cea,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,582 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,582 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cda04257-5ece-4fc5-9dfe-273768b53dd4,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,668 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,668 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0142595f-eca6-4dd3-87bd-150ececba990,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,754 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,840 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,840 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:217e9680-7281-4f32-ac4e-aa6fbfa5391d,timestamp:1626984691\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a5f1ee06-0fdf-4086-b060-3666b6766371,timestamp:1626984692\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,374 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cf1022e1-a3c0-485a-b7ba-2570173253a7,timestamp:1626984692\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,464 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:28b46a00-4cfa-4bb6-b72a-a01c61ddf891,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,465 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:432496a2-c97f-4650-9c6f-0997f75a1cea,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,581 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,582 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,582 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cda04257-5ece-4fc5-9dfe-273768b53dd4,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,667 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,668 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,668 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0142595f-eca6-4dd3-87bd-150ececba990,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,753 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,754 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,840 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,840 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:31,839 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:217e9680-7281-4f32-ac4e-aa6fbfa5391d,timestamp:1626984691\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a5f1ee06-0fdf-4086-b060-3666b6766371,timestamp:1626984692\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,169 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,374 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cf1022e1-a3c0-485a-b7ba-2570173253a7,timestamp:1626984692\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,375 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22T20:11:29.020:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,489 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,489 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:45e464d7-b113-4acc-a4ef-6862a5124f1b,timestamp:1626984692\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,599 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,599 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9629ec67-f87f-4e16-a34d-a5fb9386248f,timestamp:1626984692\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,489 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,490 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,489 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:45e464d7-b113-4acc-a4ef-6862a5124f1b,timestamp:1626984692\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,599 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,599 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9629ec67-f87f-4e16-a34d-a5fb9386248f,timestamp:1626984692\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ed4ea0d5-136d-42e4-92b5-7666131f8f84,timestamp:1626984692\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,943 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0596782f-666d-4ad5-8bfd-a2e6feed5ae8,timestamp:1626984692\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,600 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ed4ea0d5-136d-42e4-92b5-7666131f8f84,timestamp:1626984692\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,745 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,943 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0596782f-666d-4ad5-8bfd-a2e6feed5ae8,timestamp:1626984692\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,034 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9e47c183-22ca-4ab5-9eaa-5e24eb050c23,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,035 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:32,944 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,034 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9e47c183-22ca-4ab5-9eaa-5e24eb050c23,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,035 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,035 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,035 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:03d3b325-1778-47e5-9955-93630fb41d7e,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:e76f834a-e3c7-47df-9847-0abdfc5d1266,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,239 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,239 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,341 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,341 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c2fe35aa-7feb-414e-8d7e-6beab1459fb5,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,035 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,035 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:03d3b325-1778-47e5-9955-93630fb41d7e,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,140 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:e76f834a-e3c7-47df-9847-0abdfc5d1266,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,238 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,239 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,239 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,341 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,341 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c2fe35aa-7feb-414e-8d7e-6beab1459fb5,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,342 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,439 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,439 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4a83aec2-aa0c-4d9d-b6d1-be290a3f96d0,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,592 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,592 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:eb09f34f-88fb-4979-86fc-9a2923c76bb8,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,804 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,804 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:da86bc1b-239e-42cc-8b58-f62fe5126b28,timestamp:1626984693\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,804 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,805 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,805 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:33,805 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,148 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,148 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a33f9c5d-e650-4a7b-b02e-835ca8e700b1,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,148 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,149 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,149 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,149 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,439 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,439 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4a83aec2-aa0c-4d9d-b6d1-be290a3f96d0,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,440 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,592 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,592 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:eb09f34f-88fb-4979-86fc-9a2923c76bb8,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,593 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,804 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,804 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:da86bc1b-239e-42cc-8b58-f62fe5126b28,timestamp:1626984693\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,804 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,805 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,805 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:33,805 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,148 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,148 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a33f9c5d-e650-4a7b-b02e-835ca8e700b1,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,148 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,149 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,149 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,149 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,483 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,483 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c058ecc1-d4f9-464c-829f-f21b86490033,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,483 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,483 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:c058ecc1-d4f9-464c-829f-f21b86490033,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:30a7f66c-08a1-439a-8e46-88060e754145,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,590 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,590 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a84f52fb-6d46-49a9-964f-d553646eaf12,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ea96b6eb-db93-45d5-ab35-a98ed482464a,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,787 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,787 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,879 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,879 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:47f8556b-703b-44f8-8818-b0be8d4d1578,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,974 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0f6c11e6-9325-47e8-a1e9-b9d37c76b755,timestamp:1626984694\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a48aab70-693d-4e39-9e2b-20341b572c43,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,232 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:88e20ebe-e064-4a4a-b42a-7ecc69a6eed0,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,232 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:5db3a277-7abb-4493-ab39-51200a9abeaf,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,484 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:30a7f66c-08a1-439a-8e46-88060e754145,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,589 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,590 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,590 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a84f52fb-6d46-49a9-964f-d553646eaf12,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,682 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ea96b6eb-db93-45d5-ab35-a98ed482464a,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,786 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,787 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,787 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,879 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,879 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:47f8556b-703b-44f8-8818-b0be8d4d1578,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,974 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0f6c11e6-9325-47e8-a1e9-b9d37c76b755,timestamp:1626984694\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:34,975 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a48aab70-693d-4e39-9e2b-20341b572c43,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,138 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,232 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:88e20ebe-e064-4a4a-b42a-7ecc69a6eed0,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,232 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,233 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:5db3a277-7abb-4493-ab39-51200a9abeaf,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,328 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,439 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,439 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:acb02d6b-1fb5-4a4b-9128-b730b5a5c968,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,575 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,575 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:7bf1fcdd-f31f-4d5f-b03c-96d9bebbd362,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,667 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,667 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:bc8ebd0b-0ec2-4028-ad44-4c89d0c6ae00,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,763 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:6cac4212-b3c2-4550-b513-470b884ebe4a,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,763 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,921 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,921 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4c798da5-baa8-4289-81d5-12c8eec4ef44,timestamp:1626984695\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,009 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:06cf8ef2-4340-4e4a-99f5-516f26963954,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,439 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,439 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:acb02d6b-1fb5-4a4b-9128-b730b5a5c968,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,440 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,575 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,575 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:7bf1fcdd-f31f-4d5f-b03c-96d9bebbd362,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,576 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,667 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,667 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:bc8ebd0b-0ec2-4028-ad44-4c89d0c6ae00,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,668 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,763 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:6cac4212-b3c2-4550-b513-470b884ebe4a,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,763 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,764 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,921 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,921 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4c798da5-baa8-4289-81d5-12c8eec4ef44,timestamp:1626984695\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:35,922 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,009 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:06cf8ef2-4340-4e4a-99f5-516f26963954,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,010 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:8956db14-f4c5-428d-ba2d-1bac8b1e527b,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,253 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:08c634f6-e46b-419e-8da9-bc544e9e09b0,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:bb927e9e-0f08-40b5-91cf-78205eab86bb,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,340 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,340 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:8956db14-f4c5-428d-ba2d-1bac8b1e527b,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,115 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,253 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:08c634f6-e46b-419e-8da9-bc544e9e09b0,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,257 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:bb927e9e-0f08-40b5-91cf-78205eab86bb,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,339 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,340 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,340 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,476 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b0b3f3e5-a2e6-40f7-93cb-70a36579e857,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,476 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,560 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,560 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:64c05bae-fcf2-4f4e-ba16-53257340d217,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cee0f0d0-b063-4a2a-8f1d-adadea4e9c92,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,476 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b0b3f3e5-a2e6-40f7-93cb-70a36579e857,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,476 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,477 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,560 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,560 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:64c05bae-fcf2-4f4e-ba16-53257340d217,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,561 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cee0f0d0-b063-4a2a-8f1d-adadea4e9c92,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,648 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ce08e0f3-c1ae-490b-907a-92a7ec5f9e4e,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,885 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,885 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:42efe808-5899-4210-aabc-0a01408cdcab,timestamp:1626984696\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,885 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,886 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,886 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:36,886 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,064 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ef158a29-1565-423f-ad71-d38252a7cdd4,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,064 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,204 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,204 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:798a41fc-99a2-4391-8e8e-83565b2db897,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,204 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,205 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,205 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,205 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,296 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,296 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b7ee0cc1-e5e5-4c06-86c5-8c29159151d2,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,385 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,385 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:74f90def-949a-401b-a6e8-8281b5994358,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ce08e0f3-c1ae-490b-907a-92a7ec5f9e4e,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,783 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,885 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,885 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:42efe808-5899-4210-aabc-0a01408cdcab,timestamp:1626984696\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,885 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,886 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,886 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:36,886 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,064 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ef158a29-1565-423f-ad71-d38252a7cdd4,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,064 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,065 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,204 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,204 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:798a41fc-99a2-4391-8e8e-83565b2db897,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,204 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,205 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,205 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,205 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,296 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,296 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,297 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:b7ee0cc1-e5e5-4c06-86c5-8c29159151d2,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,385 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,385 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:74f90def-949a-401b-a6e8-8281b5994358,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,386 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,473 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a752382e-3b68-4f91-8fff-8b227139b1df,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,473 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a752382e-3b68-4f91-8fff-8b227139b1df,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,572 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,572 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.96|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:30b7db38-4971-4d02-9d73-2f235f4fa65a,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,572 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,573 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,573 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,573 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d4564a86-d61b-4b27-8d2b-4b37dbfb5621,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:bd638ba4-7d38-4dec-b0ca-aa1bce11489d,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:7925421e-d2c6-4e4f-991f-cce2c0bc470a,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,848 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,848 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,951 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,951 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:db1a8359-a6bf-44f1-a951-f56750866d1f,timestamp:1626984697\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,951 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,952 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,952 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:37,952 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:92fb7cc0-7588-4648-9941-4f75be2d7513,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,032 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,032 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,156 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:6f8bbb9a-2932-4a2f-b3b1-45224bb5d504,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,236 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9dc1b248-b74d-4af2-9408-c19cdcbb68d0,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:dafe32a9-c967-4e07-958e-6690dc3cebb1,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,474 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,572 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,572 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.96|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:30b7db38-4971-4d02-9d73-2f235f4fa65a,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,572 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,573 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,573 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,573 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d4564a86-d61b-4b27-8d2b-4b37dbfb5621,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:bd638ba4-7d38-4dec-b0ca-aa1bce11489d,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,747 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:7925421e-d2c6-4e4f-991f-cce2c0bc470a,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,847 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,848 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,848 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,951 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,951 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:db1a8359-a6bf-44f1-a951-f56750866d1f,timestamp:1626984697\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,951 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,952 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,952 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:37,952 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:92fb7cc0-7588-4648-9941-4f75be2d7513,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,031 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,032 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,032 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,156 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:6f8bbb9a-2932-4a2f-b3b1-45224bb5d504,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,157 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,235 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,236 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:9dc1b248-b74d-4af2-9408-c19cdcbb68d0,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:dafe32a9-c967-4e07-958e-6690dc3cebb1,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,326 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4443e3d1-606a-4c9d-a515-e70f879d5bbe,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,555 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4c31a6ad-f082-4f14-bfa9-6b16cf6128a1,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d52fe92b-6ea4-4faf-89bf-b8e5bfb82f0a,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,717 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,717 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:fd131789-2c31-44da-b533-ff3a6a3aec6a,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,888 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:fdb44c71-9c68-4f2c-9318-43a2e4105d67,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,888 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:099acb5e-badd-489a-9d84-ba8f0ec2deba,timestamp:1626984698\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:38,968 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,045 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,045 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:1e72b6dd-8743-450f-97ca-9ef55ac407e5,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4443e3d1-606a-4c9d-a515-e70f879d5bbe,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,462 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,555 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4c31a6ad-f082-4f14-bfa9-6b16cf6128a1,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,556 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:d52fe92b-6ea4-4faf-89bf-b8e5bfb82f0a,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,633 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,717 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,717 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:fd131789-2c31-44da-b533-ff3a6a3aec6a,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,718 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,888 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:fdb44c71-9c68-4f2c-9318-43a2e4105d67,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,888 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,889 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:099acb5e-badd-489a-9d84-ba8f0ec2deba,timestamp:1626984698\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,967 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:38,968 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,045 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,045 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:1e72b6dd-8743-450f-97ca-9ef55ac407e5,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:f474bfc1-9ac6-4333-a9d4-157e1b4d477b,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:32ff6d08-778f-4349-b21f-fa784332cdc2,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ffd4cf33-b636-4ce8-9164-91357fb4b451,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,046 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:f474bfc1-9ac6-4333-a9d4-157e1b4d477b,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,136 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:32ff6d08-778f-4349-b21f-fa784332cdc2,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,231 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.33|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:ffd4cf33-b636-4ce8-9164-91357fb4b451,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,364 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,480 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0a241620-23a9-48fd-8c45-6b896763a840,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:de0c13bc-a0b4-4202-9ee5-76f858d90848,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:606b39e1-258a-4904-a74f-ef5288080b50,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,480 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:0a241620-23a9-48fd-8c45-6b896763a840,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,481 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:de0c13bc-a0b4-4202-9ee5-76f858d90848,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,598 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:606b39e1-258a-4904-a74f-ef5288080b50,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,694 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:aba00606-0017-4e58-9a1e-1fafdfd32e7e,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,900 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,900 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,995 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,995 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4dcc8a75-1c8f-433b-bece-35ea65cd8134,timestamp:1626984699\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,091 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,091 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cce996ea-9deb-4935-b021-e483df1db197,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:6627e5f5-fe0a-420f-833b-67b48e6f13f1,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a241713c-b442-4719-bea0-502490a153ca,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:aba00606-0017-4e58-9a1e-1fafdfd32e7e,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,899 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,900 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,900 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,995 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,995 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4dcc8a75-1c8f-433b-bece-35ea65cd8134,timestamp:1626984699\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:39,996 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,091 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,091 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,092 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:cce996ea-9deb-4935-b021-e483df1db197,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:6627e5f5-fe0a-420f-833b-67b48e6f13f1,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,258 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a241713c-b442-4719-bea0-502490a153ca,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,340 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:5dea8a7e-d4ee-47de-97a0-b3a95ca05a0d,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,477 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:5dea8a7e-d4ee-47de-97a0-b3a95ca05a0d,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,477 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:f7363944-1b5d-45aa-892c-1daa9bc63464,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:046fb449-9b2e-4e59-b3c2-d9676befbd5b,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,655 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,658 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:af8f0d25-b9cf-4d79-ad4d-b33b1365e63d,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:8bd7c5b6-b0db-454e-9653-84b2edccf005,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,858 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,858 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4bf81838-4261-4f06-b7ff-fe3b580999d7,timestamp:1626984700\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a6bb2337-4f42-4874-b68c-bee8fe60b055,timestamp:1626984701\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,478 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:f7363944-1b5d-45aa-892c-1daa9bc63464,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:046fb449-9b2e-4e59-b3c2-d9676befbd5b,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,654 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,655 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,658 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:af8f0d25-b9cf-4d79-ad4d-b33b1365e63d,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,753 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:8bd7c5b6-b0db-454e-9653-84b2edccf005,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,857 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,858 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,858 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:4bf81838-4261-4f06-b7ff-fe3b580999d7,timestamp:1626984700\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:40,952 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:a6bb2337-4f42-4874-b68c-bee8fe60b055,timestamp:1626984701\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:28972074-4f3f-41d3-be33-02341394b479,timestamp:1626984701\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,311 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:11:41,311 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,189 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:dd32f2ad444b,requestID:28972074-4f3f-41d3-be33-02341394b479,timestamp:1626984701\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:57378 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,310 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,311 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:11:41,311 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:dd32f2ad444b,timestamp:null\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=inference_inputs, data_type=\"S3Prefix\", content_type=\"application/x-image\", wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5c9dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### input images by manifest file\n",
    "First, we generate a manifest file. Then we use the manifest file containing a list of object keys that you want to batch inference. Some key points:\n",
    "- content_type = 'application/x-image' (!!! here the content_type is for the actual object to be inference, not for the manifest file)\n",
    "- data_type = 'ManifestFile'\n",
    "- Manifest file format must follow the format as [this document](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html#SageMaker-Type-S3DataSource-S3DataType) pointed out. We create the manifest file by using jsonlines package.\n",
    "``` json\n",
    "[ {\"prefix\": \"s3://customer_bucket/some/prefix/\"},\n",
    "\"relative/path/to/custdata-1\",\n",
    "\"relative/path/custdata-2\",\n",
    "...\n",
    "\"relative/path/custdata-N\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b21a18a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dbf11ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_files\n",
      " ['23.png', '10.png', '48.png', '64.png', '52.png', '86.png', '70.png', '69.png', '65.png', '20.png', '14.png', '77.png', '57.png', '36.png', '71.png', '50.png', '60.png', '63.png', '73.png', '56.png', '95.png', '51.png', '98.png', '25.png', '54.png', '3.png', '8.png', '45.png', '6.png', '49.png', '37.png', '11.png', '75.png', '21.png', '74.png', '34.png', '92.png', '72.png', '96.png', '53.png', '31.png', '85.png', '0.png', '55.png', '2.png', '99.png', '80.png', '78.png', '29.png', '16.png', '24.png', '19.png', '13.png', '67.png', '30.png', '47.png', '4.png', '40.png', '39.png', '27.png', '91.png', '82.png', '1.png', '83.png', '32.png', '46.png', '5.png', '88.png', '79.png', '59.png', '38.png', '28.png', '17.png', '42.png', '41.png', '93.png', '33.png', '89.png', '61.png', '7.png', '90.png', '87.png', '66.png', '22.png', '84.png', '12.png', '68.png', '15.png', '9.png', '81.png', '94.png', '18.png', '43.png', '62.png', '58.png', '26.png', '35.png', '97.png', '44.png', '76.png']\n",
      "manifest_content\n",
      " [{'prefix': 's3://sagemaker-us-east-1-474422712127/sagemaker/DEMO-pytorch-batch-inference-script/images/'}, '23.png', '10.png', '48.png', '64.png', '52.png', '86.png', '70.png', '69.png', '65.png', '20.png', '14.png', '77.png', '57.png', '36.png', '71.png', '50.png', '60.png', '63.png', '73.png', '56.png', '95.png', '51.png', '98.png', '25.png', '54.png', '3.png', '8.png', '45.png', '6.png', '49.png', '37.png', '11.png', '75.png', '21.png', '74.png', '34.png', '92.png', '72.png', '96.png', '53.png', '31.png', '85.png', '0.png', '55.png', '2.png', '99.png', '80.png', '78.png', '29.png', '16.png', '24.png', '19.png', '13.png', '67.png', '30.png', '47.png', '4.png', '40.png', '39.png', '27.png', '91.png', '82.png', '1.png', '83.png', '32.png', '46.png', '5.png', '88.png', '79.png', '59.png', '38.png', '28.png', '17.png', '42.png', '41.png', '93.png', '33.png', '89.png', '61.png', '7.png', '90.png', '87.png', '66.png', '22.png', '84.png', '12.png', '68.png', '15.png', '9.png', '81.png', '94.png', '18.png', '43.png', '62.png', '58.png', '26.png', '35.png', '97.png', '44.png', '76.png']\n",
      "manifest_obj\n",
      " s3://sagemaker-us-east-1-474422712127/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "# build image list\n",
    "manifest_prefix = f\"s3://{bucket}/{prefix}/images/\"\n",
    "\n",
    "path = image_dir\n",
    "img_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "print(\"img_files\\n\", img_files)\n",
    "\n",
    "manifest_content = [{\"prefix\": manifest_prefix}]\n",
    "manifest_content.extend(img_files)\n",
    "\n",
    "print(\"manifest_content\\n\", manifest_content)\n",
    "\n",
    "# write jsonl file\n",
    "manifest_file = \"manifest.json\"\n",
    "with jsonlines.open(manifest_file, mode=\"w\") as writer:\n",
    "    writer.write(manifest_content)\n",
    "\n",
    "# upload to S3\n",
    "manifest_obj = sagemaker_session.upload_data(path=manifest_file, key_prefix=prefix)\n",
    "\n",
    "print(\"manifest_obj\\n\", manifest_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37156ff0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch transform with manifest file\n",
    "transform_job = transformer.transform(\n",
    "    data=manifest_obj, data_type=\"ManifestFile\", content_type=\"application/x-image\", wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "922302d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest transform job \n",
      " pytorch-inference-2021-07-22-20-14-20-565\n"
     ]
    }
   ],
   "source": [
    "print(\"latest transform job \\n\", transformer.latest_transform_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb552e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 7, 22, 20, 14, 20, 820000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2021-07-22-20-06-53-211',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '869',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Thu, 22 Jul 2021 20:14:25 GMT',\n",
      "                                      'x-amzn-requestid': 'c5ca42d2-8da0-477a-b79c-783aa989a2a4'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'c5ca42d2-8da0-477a-b79c-783aa989a2a4',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'ManifestFile',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-east-1-474422712127/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-inference-2021-07-22-20-14-20-565',\n",
      " 'TransformJobName': 'pytorch-inference-2021-07-22-20-14-20-565',\n",
      " 'TransformJobStatus': 'InProgress',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-east-1-474422712127/pytorch-inference-2021-07-22-20-14-20-565'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.c5.xlarge'}}\n"
     ]
    }
   ],
   "source": [
    "# look at the status of the transform job\n",
    "import boto3\n",
    "import pprint as pp\n",
    "\n",
    "sm_cli = boto3.client(\"sagemaker\")\n",
    "\n",
    "res = sm_cli.describe_transform_job(TransformJobName=transformer.latest_transform_job.name)\n",
    "\n",
    "pp.pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da88e37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "###  Multiple instance\n",
    "We use `instance_count > 1` to create multiple inference instances. When a batch transform job starts, Amazon SageMaker initializes compute instances and distributes the inference or preprocessing workload between them. Batch Transform partitions the Amazon S3 objects in the input by key and maps Amazon S3 objects to instances. When you have multiples files, one instance might process input1.csv, and another instance might process the file named input2.csv.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46cf170a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................\u001b[34m2021-07-22 20:19:59,198 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 910 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,239 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,265 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag dd3b07668d284a2f85e4dda3ff4651b7\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,278 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,309 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,492 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,499 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,499 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,499 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,514 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,516 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,525 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,526 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,526 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,526 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,551 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,555 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,555 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,555 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,556 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,563 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,565 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,573 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,573 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]44\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,574 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,574 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,574 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,575 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,594 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,595 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,595 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:19:59,598 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,196 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35mMax heap size: 908 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,236 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,258 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 3303e64e035c44f7825009d5a6e6063e\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,270 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,309 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,481 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,482 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,482 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,491 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,491 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,526 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,527 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]44\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,527 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,527 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,529 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,529 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,529 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,530 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,531 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,531 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,531 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,533 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,574 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,575 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,576 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,583 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,583 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,584 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:58,594 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,368 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,370 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.24013137817383|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,371 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.67578125|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,371 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,372 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6270.0625|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,373 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:928.19921875|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,374 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:16.1|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,768 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1065\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,769 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1488|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,771 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:108|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1088\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,788 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1508|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,789 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:100|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,942 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,942 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1664|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,942 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:134|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,970 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,970 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1689|#Level:Host|#hostname:939f53ea59d9,timestamp:1626985199\u001b[0m\n",
      "\u001b[35m2021-07-22 20:19:59,970 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:104|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,451 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,453 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.24012756347656|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,455 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.675785064697266|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,456 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,456 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6268.109375|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,456 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:928.6640625|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,457 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:16.1|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,823 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1079\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,824 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1538|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,824 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:136|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,883 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1154\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,884 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1595|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,884 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:121|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1205\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,921 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1632|#Level:Host|#hostname:a07f985830f0,timestamp:1626985200\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:00,921 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:109|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:01,111 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1381\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:01,112 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1823|#Level:Host|#hostname:a07f985830f0,timestamp:1626985201\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:01,112 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:124|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,419 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:47828 \"GET /ping HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,420 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,456 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:47836 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,457 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,557 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,558 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,558 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,558 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.17|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:9ad808e9-6264-46e7-9ba7-bd09d0249b4e,timestamp:1626985205\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,559 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,559 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,648 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,648 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,649 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,649 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,649 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,651 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.5|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:d5df181a-ab69-4320-8644-0f363a406a65,timestamp:1626985205\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,861 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,861 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.7|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:3dc81ce6-0af1-4ad8-a0f3-9a90f6f6cea8,timestamp:1626985205\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,861 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,862 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,862 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:05,862 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,046 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,046 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.35|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:1d7a3df2-298b-40c3-8ca1-3b9436d28290,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,046 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,046 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,047 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,047 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,124 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,124 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:7f678d50-3e1c-4086-a5e4-c509340762fe,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,125 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,125 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,125 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,125 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,252 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,252 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:d6bb41ed-28eb-47c3-8742-d073ad01d0fc,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,253 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,253 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,253 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,253 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,413 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,413 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,413 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,414 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:88b69fa8-84f5-4483-949b-b7581721feab,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,499 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,499 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:b8225028-ef38-423d-a043-5104c0d861da,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,500 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,500 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,500 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,500 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,583 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,583 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:a5ea0d93-dc06-4073-b8cc-371e7edf49f1,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,583 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,584 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,584 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,584 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,662 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:ce88caa8-4e52-42b8-a4e4-f6f6444ae815,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,662 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,663 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,663 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,663 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,664 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,767 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.09|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:250160bf-8f9c-4758-82b4-8a9f5ca98227,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,769 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,952 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,952 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:7789360b-ead0-4c96-b0e2-24c2ee9235fb,timestamp:1626985206\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,953 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,953 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,953 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:06,953 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,078 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,078 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:e473a600-02ef-4ccd-9ddf-7885c16db3d8,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,078 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,078 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,078 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,079 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,218 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,218 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.02|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:d3f0c46a-7c87-4959-a02e-9721041b1b07,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,218 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,218 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,218 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,219 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,349 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,349 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,349 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:9e759a9c-bb9b-4617-9ff0-b6e9a41d1b76,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,350 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,350 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,350 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,430 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:bffd0d12-af8f-486b-8142-1e4cdad59fb4,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,430 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,431 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,431 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,431 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,431 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,521 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,521 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:6075de9e-658f-499e-8601-e5fcdde04cf2,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,522 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,522 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,522 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,522 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,614 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,614 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.06|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:787c1bf1-d396-43c7-9bd7-86a234717f1e,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,614 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,614 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,615 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,615 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,788 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:f4436298-f5fc-47c1-aec1-deb9eeb45611,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,789 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,910 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,910 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:6896ae90-9fe5-41bb-a8e1-a3de38fd1450,timestamp:1626985207\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,911 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,911 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,911 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:07,911 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,017 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,017 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.24|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:da816ae5-9441-493c-8607-cf59e5fe10d7,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,018 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,018 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,018 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,018 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,249 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,249 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:cb6a0da4-6e0e-4fa4-bb79-049e422d179a,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,249 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,249 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,250 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,250 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,366 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,366 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:b573ea6b-9bdc-487a-871d-50f79b94d9b2,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,366 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,367 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,367 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,367 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,465 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,465 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:9a373594-a883-4ac1-9186-67905481addc,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,465 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,465 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,465 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,465 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,570 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,570 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.2|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:939ce063-fdf5-41c6-930e-fc1a2ede9cc4,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,570 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,570 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,570 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,571 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:42b116ea-e36c-4941-8525-18223a4d3bd4,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,676 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,676 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,676 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,676 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,676 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,770 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,770 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,770 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,771 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,771 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:08,771 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:a8c51065-9c4b-400d-9e6a-a513845e09a4,timestamp:1626985208\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,037 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:bfede8f3-e09c-4883-8dae-63680cc62654,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,037 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,037 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,038 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,038 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,038 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,175 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,175 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.13|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:a997e85c-dd3a-42c2-81e7-8b92b6fd2c1e,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,175 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,176 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,176 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,176 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:09,716 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:59426 \"GET /ping HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:09,717 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:09,751 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:59432 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:09,752 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,397 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,397 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,397 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:e5fbf65b-a49b-4705-8e7c-f9a240824e2e,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,397 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,398 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,398 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,531 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,531 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:5a6e3917-eaf1-4f83-b500-43bc9eeedc69,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,531 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,531 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,612 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:8b2a10c1-9ed3-4ca0-a471-0d3c4f3100d6,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,613 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,613 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,613 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,614 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,614 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,699 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,699 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.02|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:5d3eeed1-0367-4a74-80f2-2d64e082da9b,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,699 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,699 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,699 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,700 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,780 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,780 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:c8524e75-08b5-44d9-92d2-09caf7710c47,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,780 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,780 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,780 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,780 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,865 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,865 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:31ea8239-d848-4bbc-9997-cb69a0b1c2ae,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,865 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,865 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,865 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,866 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,964 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:06c5ced8-a435-4476-9d1c-b2ee1ca97814,timestamp:1626985209\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,965 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,965 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,965 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,965 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:09,965 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,058 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,058 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:e2f17635-71e9-4643-a689-e73d6b5ad23c,timestamp:1626985210\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,058 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,058 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,058 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,058 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,157 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,158 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,158 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,158 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,157 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:707accc3-9f32-4bc3-b168-32b2cff68842,timestamp:1626985210\u001b[0m\n",
      "\u001b[35m2021-07-22 20:20:10,158 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,450 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.66|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:db0d9c4f-1a97-48fe-abaf-f00ee749017e,timestamp:1626985210\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,451 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,451 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,451 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,452 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,452 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,534 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,534 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.4|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:9af1ffe1-30d3-4cd6-8298-c34f006aed65,timestamp:1626985210\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,535 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,535 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,536 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,536 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,685 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,685 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,686 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,686 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,686 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,686 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.83|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:39d740e5-e139-4ea7-8946-b07dd26d2bef,timestamp:1626985210\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,785 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,785 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.99|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:29f4fee3-25aa-4c2c-9e3c-6166a7908e1f,timestamp:1626985210\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,786 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,786 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,786 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,786 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,866 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:58d0597c-dc25-4c25-9abf-ed65ccb7ba01,timestamp:1626985210\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,866 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,867 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,867 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,867 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,867 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,980 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,980 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,980 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:b26e484b-d634-4c9c-9efc-1373332535e8,timestamp:1626985210\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,980 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,981 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:10,981 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,090 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:232143c7-21b7-4cb9-a45b-c1b70cdda445,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,091 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,091 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,091 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,091 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,091 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,203 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,204 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,204 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,204 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,204 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,203 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:d82667dc-e383-45c6-afae-1795c5325467,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,315 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:d7aa95e6-536a-40a5-b6eb-2ba3276f3685,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,315 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,316 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,316 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,316 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,408 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,408 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.94|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:cb1f1c35-67d7-4753-86ee-bd8dc9dc79e3,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,408 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,409 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,409 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,484 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:f5a39129-4dbe-4da3-8376-acd6a3b4058d,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,485 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,485 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,485 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,485 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,587 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,587 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:e4d8ab41-aab5-45c9-b40d-3713ae3f8910,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,587 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,588 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,588 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,588 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,687 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,687 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:bdd5b14b-4c45-4add-84ba-e25b1097c0a3,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,687 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,688 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,688 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,688 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,772 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,772 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:a2561c71-1da2-46b8-bda9-ce7bbec623dc,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,772 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,772 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,772 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,773 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,862 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,863 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,863 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,863 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,863 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,863 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.07|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:76f59255-5e76-4d47-a164-2813a4871203,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,960 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,960 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:379ed21b-d161-4d26-9d04-a3296f43da79,timestamp:1626985211\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,961 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,961 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,961 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:11,961 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,091 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.15|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:dc8e1c06-7a4f-483c-8981-884f76fb3751,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,091 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,091 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,091 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,092 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,092 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,250 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.98|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:fa361e8b-d878-48c9-b014-6234e33188dd,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,250 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,250 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,250 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,250 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,251 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,539 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,539 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:5317d3fb-d381-4625-a639-2fcdaebcea4d,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,539 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,539 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,539 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,539 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,628 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,629 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:67ca1734-e4e2-4718-a060-cd771632f8dc,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,629 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,629 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,629 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,629 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,729 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,729 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.87|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:07bfe745-d823-4792-b9be-3838ae9568be,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,729 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,729 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,730 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,730 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,817 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,818 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,818 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:a9c71c44-d70b-43ab-9102-86713aae6323,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,818 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,818 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,818 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,933 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,934 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,933 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:36ceb6e8-0484-4fa6-bd8d-24e0bbbdf803,timestamp:1626985212\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,934 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,934 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:12,935 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,017 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,017 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:03c118f9-e3d6-403c-986b-41c6c8acae1e,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,017 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,017 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,018 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,018 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,111 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,111 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.12|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:011e675b-c059-44a0-ba58-8aff4e54e657,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,111 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,112 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,112 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,112 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,196 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,196 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:bd683958-94ec-4ace-a430-5e882ffdae00,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,196 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,311 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,311 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.83|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:8da99c17-3536-4d7a-af8e-725bf90da080,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,311 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,311 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,311 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,311 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,643 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,643 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:5c8b57f3-d7f2-4051-91aa-789b807f799e,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,643 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,643 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,644 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,644 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,733 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,733 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,733 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.76|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:dcbeb517-530c-4d84-8ffc-be1a727e465e,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,733 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,734 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,734 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-07-22T20:20:09.764:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[36m2021-07-22T20:20:09.764:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2021-07-22T20:20:05.465:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,298 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,298 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,298 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:2e9148fb-d33f-40b6-a0c4-f1a58362dfdf,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,298 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,298 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,298 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,384 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,384 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:573a7083-a444-45f1-b15e-2ed673c4767c,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,385 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,385 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,385 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,385 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,481 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,481 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:a0a47a68-694d-4922-a7e9-1b57f08a9530,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,481 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,481 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,481 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,481 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,555 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:0ade84d2-0f83-4c62-86cb-e98d4d6684aa,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,555 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,556 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,556 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,556 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,556 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,653 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,654 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,654 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,654 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,654 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,654 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:e324a2ee-9dfd-43dd-af9b-2270c01c5ca5,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,739 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,739 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:357ef543-1439-4a6a-b15e-548e9c1b03b5,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,739 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,739 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,739 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,739 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,831 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.71|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:625ca57c-d740-4db5-92c0-28186fdf9c71,timestamp:1626985210\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,831 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,831 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:10,831 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,005 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,005 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:9c9b88d5-c884-48e8-b44b-24384fe2248e,timestamp:1626985211\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,005 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,006 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,090 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,090 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:d4e06b66-d35e-4dae-88ed-de01f37536d0,timestamp:1626985211\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,090 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,090 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,090 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,091 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,206 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,206 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:d87d3d47-06a3-4769-b989-8e3851ba7b3c,timestamp:1626985211\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,206 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,206 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,207 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,207 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,338 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,338 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:bd5c4981-73a0-4ca8-ac4f-b318bd445bc5,timestamp:1626985211\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,338 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,338 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,338 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,338 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,424 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:939f53ea59d9,requestID:d6d18059-ac21-4afb-837b-71baa8255d87,timestamp:1626985211\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,425 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,425 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:47840 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,425 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,425 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[33m2021-07-22 20:20:11,425 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:939f53ea59d9,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,829 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,829 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:471b761d-6f5a-4348-963a-7a7240ad11ce,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:2a5b3e41-110d-40b0-9395-5336e006d343,timestamp:1626985213\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,921 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,921 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,921 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,922 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:13,922 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,829 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,829 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.55|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:471b761d-6f5a-4348-963a-7a7240ad11ce,timestamp:1626985213\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,830 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:2a5b3e41-110d-40b0-9395-5336e006d343,timestamp:1626985213\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,921 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,921 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,921 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,922 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:13,922 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,004 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.25|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:2b90e6f7-a213-48a2-88f0-a8f0f0ae03fd,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:ea12abc4-8c24-4e48-99bd-5ac645b1c889,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,184 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,184 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:aff9072f-aa14-4648-851b-d6eadf298c7e,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,311 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:f56ca97e-6d56-4268-985e-81c871e22732,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,312 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,312 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,312 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,410 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,410 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:58bb94be-b7d5-4a2f-91a1-6fa679014e73,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,004 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,003 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.25|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:2b90e6f7-a213-48a2-88f0-a8f0f0ae03fd,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:ea12abc4-8c24-4e48-99bd-5ac645b1c889,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,099 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,184 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,184 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:aff9072f-aa14-4648-851b-d6eadf298c7e,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,185 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,311 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:f56ca97e-6d56-4268-985e-81c871e22732,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,312 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,312 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,312 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,410 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,410 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:58bb94be-b7d5-4a2f-91a1-6fa679014e73,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,411 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,494 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,494 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.05|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:0dd5eb74-c115-461b-860e-895399dc4f08,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,494 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,495 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,495 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,495 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,579 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:f125eeb3-1b8f-46f7-9b55-e3b6fc0766b8,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:e083a3bb-1150-4315-a545-cf31cb99652c,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.62|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:b3ceffa9-b211-4ad9-8793-516f5ec0b3ce,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,765 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,494 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,494 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.05|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:0dd5eb74-c115-461b-860e-895399dc4f08,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,494 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,495 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,495 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,495 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,579 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:f125eeb3-1b8f-46f7-9b55-e3b6fc0766b8,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:e083a3bb-1150-4315-a545-cf31cb99652c,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.62|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:b3ceffa9-b211-4ad9-8793-516f5ec0b3ce,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,764 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,765 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,842 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,842 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:9754b8c6-b1a9-4057-b76f-63e8800e01f4,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,842 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,844 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,844 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,844 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:8b5fc1cb-9a73-419d-8298-97d323955b59,timestamp:1626985214\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,955 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:14,955 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,038 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,038 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:396bc79a-7030-4c92-bfca-717867c15e43,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,038 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,039 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,039 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,039 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.0|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:5319c23f-0ab6-4b3f-8137-8079d187627b,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,119 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,119 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,216 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,216 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:7de7f053-49ba-4e8f-bfc4-25688c8b5140,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:3074a429-85c8-439d-be70-22f57db4c786,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,299 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,299 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,396 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,842 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,842 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:9754b8c6-b1a9-4057-b76f-63e8800e01f4,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,842 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,844 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,844 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,844 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:8b5fc1cb-9a73-419d-8298-97d323955b59,timestamp:1626985214\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,954 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,955 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:14,955 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,038 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,038 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:396bc79a-7030-4c92-bfca-717867c15e43,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,038 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,039 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,039 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,039 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.0|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:5319c23f-0ab6-4b3f-8137-8079d187627b,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,118 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,119 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,119 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,216 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,216 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:7de7f053-49ba-4e8f-bfc4-25688c8b5140,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,217 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:3074a429-85c8-439d-be70-22f57db4c786,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,298 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,299 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,299 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,396 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:01c0c4c7-cd99-457a-b62d-7b22dea7526e,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:1bc6893f-14bb-484c-a6f8-d2a7a449da35,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,619 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,619 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:22e849fa-45f3-42e4-9fd2-9ed71e03a9fb,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:e5b4aefd-837c-4c12-8a9d-53993e9fbaf6,timestamp:1626985215\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:01c0c4c7-cd99-457a-b62d-7b22dea7526e,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,397 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:1bc6893f-14bb-484c-a6f8-d2a7a449da35,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,524 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,619 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,619 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:22e849fa-45f3-42e4-9fd2-9ed71e03a9fb,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:59446 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:a07f985830f0,requestID:e5b4aefd-837c-4c12-8a9d-53993e9fbaf6,timestamp:1626985215\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-07-22 20:20:15,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:a07f985830f0,timestamp:null\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_transformer = estimator.transformer(instance_count=2, instance_type=\"ml.c4.xlarge\")\n",
    "\n",
    "dist_transformer.transform(\n",
    "    data=inference_inputs, data_type=\"S3Prefix\", content_type=\"application/x-image\", wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c90d38",
   "metadata": {},
   "source": [
    "## Look at all transform jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b30f99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 7, 22, 20, 14, 30, 460000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 22, 20, 20, 17, 701000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 7, 22, 20, 20, 17, 421000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-training-2021-07-22-20-14-30-227',\n",
      " 'TransformJobName': 'pytorch-training-2021-07-22-20-14-30-227',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 7, 22, 20, 14, 20, 820000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 22, 20, 19, 12, 535000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 7, 22, 20, 19, 12, 188000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-inference-2021-07-22-20-14-20-565',\n",
      " 'TransformJobName': 'pytorch-inference-2021-07-22-20-14-20-565',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 7, 22, 20, 7, 0, 78000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 22, 20, 11, 42, 883000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 7, 22, 20, 11, 42, 348000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-inference-2021-07-22-20-06-59-795',\n",
      " 'TransformJobName': 'pytorch-inference-2021-07-22-20-06-59-795',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 7, 20, 16, 26, 1, 183000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 20, 16, 31, 51, 935000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 7, 20, 16, 31, 51, 575000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-training-2021-07-20-16-26-00-977',\n",
      " 'TransformJobName': 'pytorch-training-2021-07-20-16-26-00-977',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 7, 20, 16, 24, 26, 470000, tzinfo=tzlocal()),\n",
      " 'FailureReason': 'ClientError: See job logs for more information',\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 20, 16, 29, 7, 431000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 7, 20, 16, 29, 6, 727000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-training-2021-07-20-16-24-26-210',\n",
      " 'TransformJobName': 'pytorch-training-2021-07-20-16-24-26-210',\n",
      " 'TransformJobStatus': 'Failed'}\n",
      "{'CreationTime': datetime.datetime(2021, 7, 20, 16, 15, 17, 580000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 7, 20, 16, 20, 20, 809000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 7, 20, 16, 20, 20, 540000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:474422712127:transform-job/pytorch-training-2021-07-20-16-15-17-315',\n",
      " 'TransformJobName': 'pytorch-training-2021-07-20-16-15-17-315',\n",
      " 'TransformJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "tjs = sm_cli.list_transform_jobs()[\"TransformJobSummaries\"]\n",
    "for tj in tjs:\n",
    "    pp.pprint(tj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "409b1b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 6, 4, 2, 27, 4, 117000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'Environment': {},\n",
      " 'ModelName': 'pytorch-training-2021-06-04-02-27-00-982',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '908',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Fri, 04 Jun 2021 02:36:18 GMT',\n",
      "                                      'x-amzn-requestid': 'dfa5913b-85aa-444d-9cad-1882e8eac6cc'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'dfa5913b-85aa-444d-9cad-1882e8eac6cc',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 4, 2, 32, 15, 196000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-688520471316/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-04-02-27-01-672',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-04-02-27-01-672',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-27-01-672'},\n",
      " 'TransformResources': {'InstanceCount': 2, 'InstanceType': 'ml.c4.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2021, 6, 4, 2, 30, 34, 445000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "res = sm_cli.describe_transform_job(TransformJobName=dist_transformer.latest_transform_job.name)\n",
    "\n",
    "pp.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad3abfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-474422712127 pytorch-inference-2021-07-22-20-14-20-565\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_bucket_and_prefix(s3_output_path):\n",
    "    trim = re.sub(\"s3://\", \"\", s3_output_path)\n",
    "    bucket, prefix = trim.split(\"/\")\n",
    "    return bucket, prefix\n",
    "\n",
    "\n",
    "local_path = \"output\"  # where to save the output locally\n",
    "\n",
    "bucket, output_prefix = get_bucket_and_prefix(res[\"TransformOutput\"][\"S3OutputPath\"])\n",
    "print(bucket, output_prefix)\n",
    "\n",
    "sagemaker_session.download_data(path=local_path, bucket=bucket, key_prefix=output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b341970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png.out   25.png.out\t40.png.out  56.png.out\t71.png.out  87.png.out\n",
      "10.png.out  26.png.out\t41.png.out  57.png.out\t72.png.out  88.png.out\n",
      "11.png.out  27.png.out\t42.png.out  58.png.out\t73.png.out  89.png.out\n",
      "12.png.out  28.png.out\t43.png.out  59.png.out\t74.png.out  8.png.out\n",
      "13.png.out  29.png.out\t44.png.out  5.png.out\t75.png.out  90.png.out\n",
      "14.png.out  2.png.out\t45.png.out  60.png.out\t76.png.out  91.png.out\n",
      "15.png.out  30.png.out\t46.png.out  61.png.out\t77.png.out  92.png.out\n",
      "16.png.out  31.png.out\t47.png.out  62.png.out\t78.png.out  93.png.out\n",
      "17.png.out  32.png.out\t48.png.out  63.png.out\t79.png.out  94.png.out\n",
      "18.png.out  33.png.out\t49.png.out  64.png.out\t7.png.out   95.png.out\n",
      "19.png.out  34.png.out\t4.png.out   65.png.out\t80.png.out  96.png.out\n",
      "1.png.out   35.png.out\t50.png.out  66.png.out\t81.png.out  97.png.out\n",
      "20.png.out  36.png.out\t51.png.out  67.png.out\t82.png.out  98.png.out\n",
      "21.png.out  37.png.out\t52.png.out  68.png.out\t83.png.out  99.png.out\n",
      "22.png.out  38.png.out\t53.png.out  69.png.out\t84.png.out  9.png.out\n",
      "23.png.out  39.png.out\t54.png.out  6.png.out\t85.png.out\n",
      "24.png.out  3.png.out\t55.png.out  70.png.out\t86.png.out\n"
     ]
    }
   ],
   "source": [
    "!ls {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c8e2f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 7}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 1}\n",
      "{'predictions': 7}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 4}\n",
      "{'predictions': 0}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 1}\n",
      "{'predictions': 9}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 7}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 9}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 4}\n",
      "{'predictions': 3}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 2}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 0}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 8}\n",
      "{'predictions': 3}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 8}\n",
      "{'predictions': 5}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 8}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 4}\n",
      "{'predictions': 9}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 8}\n",
      "{'predictions': 2}\n",
      "{'predictions': 6}\n",
      "{'predictions': 7}\n",
      "{'predictions': 7}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 9}\n",
      "{'predictions': 9}\n",
      "{'predictions': 3}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 5}\n",
      "{'predictions': 0}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, \"r\") as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 333.854918,
   "end_time": "2021-06-03T00:15:43.072184",
   "environment_variables": {},
   "exception": true,
   "input_path": "pytorch-mnist-batch-transform.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch-mnist-batch-transform-2021-06-03-00-06-06.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-03T00:10:09.217266",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01005530a5b1473b9f4a024b19c04c0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_968ed82ad8f0453e8f81a839df4428db",
       "placeholder": "",
       "style": "IPY_MODEL_e4f0965e53ee40adb1ae44da87428325",
       "value": "  0%"
      }
     },
     "0995f6633c0f4facabe6759837c606ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1410dcfcd117434889e9594cdde4e1b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "18caaab41d6146c1824859691f6cb435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d823500ff0dc4c2198b83cd231f8bffe",
       "placeholder": "",
       "style": "IPY_MODEL_7dab31892241494e8d27d38ca98e5aa6",
       "value": " 0/28881 [00:00&lt;?, ?it/s]"
      }
     },
     "19ef65b0ecae45bdbca066cea679878d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ceacd43f28744eb9b7a12f8276b6016",
        "IPY_MODEL_e44ddce6c5704f0b9495ee662806f5f6",
        "IPY_MODEL_7717cc87ebcc4c0581ae32848b40982c"
       ],
       "layout": "IPY_MODEL_59d0678977a343abb8a02dc5c9699b89"
      }
     },
     "2126024805384bff9b0409b4dc91e60c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "216ba33f9f1b486ebac2a6fce0510246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f94b5a0d68c541e894e325a0e2f899d2",
       "placeholder": "",
       "style": "IPY_MODEL_633cc1cdb94e43a6a07559483496c60d",
       "value": "  0%"
      }
     },
     "23445154eb524df985b5a755fcbddd32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_216ba33f9f1b486ebac2a6fce0510246",
        "IPY_MODEL_c4f4f4bfe979469c9bc59ab73bbf518f",
        "IPY_MODEL_fe83e178358040eaa07f6198ba693fc9"
       ],
       "layout": "IPY_MODEL_cf1f337300394948bce741af7bcd8b8c"
      }
     },
     "235ae38cf16e4aacb95c3d16d9749da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c2474d5a8144bf8930fa5cc02c73ccf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5495428879544d6da73e2ed7e70f0c96",
        "IPY_MODEL_6e2a4641cd944d9a8196f4a836e90590",
        "IPY_MODEL_9179e5f467c8450a988b988d7da06090"
       ],
       "layout": "IPY_MODEL_596f8cbad0884ec79cf6ee757cc9f38a"
      }
     },
     "2ceacd43f28744eb9b7a12f8276b6016": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a540362f86774590851c1d0892bea723",
       "placeholder": "",
       "style": "IPY_MODEL_bb9ebd025f05499da7b847b8ef7a9ff5",
       "value": ""
      }
     },
     "495839f4239743669d9ee61cfbc33967": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d62b9fde9104c8081b545c3933a077e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51a28ca59cf9407ea0e02da868d79ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5495428879544d6da73e2ed7e70f0c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_235ae38cf16e4aacb95c3d16d9749da3",
       "placeholder": "",
       "style": "IPY_MODEL_fe60ae53dd1646ca91018ba20934948b",
       "value": ""
      }
     },
     "596f8cbad0884ec79cf6ee757cc9f38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59d0678977a343abb8a02dc5c9699b89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "633cc1cdb94e43a6a07559483496c60d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63a57f663bfa4a1585c1ba36501b6b23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e2a4641cd944d9a8196f4a836e90590": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb8c653eeeb24799bcc9279389fdb523",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b513a456776d40b496f035c64360db90",
       "value": 1
      }
     },
     "7717cc87ebcc4c0581ae32848b40982c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b63360561b34257b171498e67902dda",
       "placeholder": "",
       "style": "IPY_MODEL_f86487d9a78940a394503b2bea77d756",
       "value": " 9920512/? [04:50&lt;00:00, 36552.15it/s]"
      }
     },
     "7bceed60fb344aa182dccc3dcf0ee886": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_01005530a5b1473b9f4a024b19c04c0e",
        "IPY_MODEL_e82a5227430443d98d29555fd77b2bd3",
        "IPY_MODEL_18caaab41d6146c1824859691f6cb435"
       ],
       "layout": "IPY_MODEL_63a57f663bfa4a1585c1ba36501b6b23"
      }
     },
     "7dab31892241494e8d27d38ca98e5aa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8b5b76e77cb14ecf95a310ba46ed86f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "9179e5f467c8450a988b988d7da06090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94ef992b73d44d829b863815da70111f",
       "placeholder": "",
       "style": "IPY_MODEL_1410dcfcd117434889e9594cdde4e1b0",
       "value": " 1654784/? [00:47&lt;00:00, 33514.08it/s]"
      }
     },
     "94ef992b73d44d829b863815da70111f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "968ed82ad8f0453e8f81a839df4428db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b63360561b34257b171498e67902dda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a540362f86774590851c1d0892bea723": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b513a456776d40b496f035c64360db90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb9ebd025f05499da7b847b8ef7a9ff5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c0b88a223b374693b6b0c74db9ffe346": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "c4f4f4bfe979469c9bc59ab73bbf518f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b5b76e77cb14ecf95a310ba46ed86f5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51a28ca59cf9407ea0e02da868d79ebd",
       "value": 0
      }
     },
     "cf1f337300394948bce741af7bcd8b8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d823500ff0dc4c2198b83cd231f8bffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e44ddce6c5704f0b9495ee662806f5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0995f6633c0f4facabe6759837c606ba",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d62b9fde9104c8081b545c3933a077e",
       "value": 1
      }
     },
     "e4f0965e53ee40adb1ae44da87428325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e82a5227430443d98d29555fd77b2bd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0b88a223b374693b6b0c74db9ffe346",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_495839f4239743669d9ee61cfbc33967",
       "value": 0
      }
     },
     "eb4c77cfe2c54976aef8efc0e3207140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f86487d9a78940a394503b2bea77d756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f94b5a0d68c541e894e325a0e2f899d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb8c653eeeb24799bcc9279389fdb523": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "fe60ae53dd1646ca91018ba20934948b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe83e178358040eaa07f6198ba693fc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2126024805384bff9b0409b4dc91e60c",
       "placeholder": "",
       "style": "IPY_MODEL_eb4c77cfe2c54976aef8efc0e3207140",
       "value": " 0/4542 [00:00&lt;?, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
