{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the end to end use case, we will deploy the mitigated model that is the end-product of this fraud detection use-case. We will show how to run inference and also how to use Clarify to interpret or \"explain\" the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.23.1 boto3==1.16.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything you may need to create them again or it may be your first time running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can change this to a region of your choice\n",
    "import sagemaker\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f'{model_2_name}-endpoint'\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "In the real-life MLOps lifecycle, a model package gets approved after evaluation by data scientists, subject matter experts and auditors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList'][0]\n",
    "model_package_update = {\n",
    "    'ModelPackageArn': second_model_package['ModelPackageArn'],\n",
    "    'ModelApprovalStatus': 'Approved'\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "Deploy the endpoint. This might take about 8minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)\n",
    "sample_policy_id  = int(test.sample(1)['policy_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "This will simulate getting data in real-time from a customer's insurance claim submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime  as datetime\n",
    "timer =[]\n",
    "MAXRECS = 100\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id  = int(test.sample(1)['policy_id'])\n",
    "    \n",
    "    temp_fg_name = 'fraud-detect-demo-claims'\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, \n",
    "        RecordIdentifierValueAsString= str(sample_policy_id)\n",
    "\n",
    "    )\n",
    "\n",
    "    if (claims_response.get('Record')):\n",
    "        claims_record = claims_response['Record']\n",
    "        claims_df = pd.DataFrame(claims_record).set_index('FeatureName')\n",
    "    else:\n",
    "        print (\"No Record returned / Record Key  \\n\")\n",
    "        \n",
    "    t0 = datetime.datetime.now()\n",
    "    \n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, \n",
    "        RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "    \n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response['Record']\n",
    "    customer_df = pd.DataFrame(customer_record).set_index('FeatureName')\n",
    "    \n",
    "    \n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop('fraud')\n",
    "    data_input = ','.join(blended_df['ValueAsString'])\n",
    "    \n",
    "    results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    #print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "    \n",
    "    arr = t1-t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "    \n",
    "    timer.append(seconds)\n",
    "    #print (prediction, \" done in {} \".format(seconds))\n",
    "    \n",
    "    return sample_policy_id, prediction\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction = barrage_of_inference()\n",
    "    print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above \"timer\" records the first call and then subsequent calls to the online Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "statistics.mean(timer)  \n",
    "\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(np.percentile(arr,95),np.percentile(arr,99),np.mean(arr), MAXRECS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "When a customer submits an insurance claim online for instant approval, the insurance company will need to pull customer-specific data from the online feature store to add to the claim data as input for a model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, \n",
    "    RecordIdentifierValueAsString=str(sample_policy_id))\n",
    "\n",
    "customer_record = customers_response['Record']\n",
    "customer_df = pd.DataFrame(customer_record).set_index('FeatureName')\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, \n",
    "    RecordIdentifierValueAsString=str(sample_policy_id))\n",
    "\n",
    "claims_record = claims_response['Record']\n",
    "claims_df = pd.DataFrame(claims_record).set_index('FeatureName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "The datapoint must match the exact input format as the model was trained--with all features in the correct order. In this example, the `col_order` variable was saved when you created the train and test datasets earlier in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop('fraud')\n",
    "data_input = ','.join(blended_df['ValueAsString'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictor.predict(data_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)\n",
    "Now that as a Data Scientist, you've manually experimented with each step in our machine learning workflow, you can take certain steps to allow for faster model creation and deployment without sacrificing transparency and tracking via model lineage. In the next section you will create a pipeline which trains a new model on SageMaker, persists the model in SageMaker and then adds the model to the registry and deploys it as a SageMaker hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
