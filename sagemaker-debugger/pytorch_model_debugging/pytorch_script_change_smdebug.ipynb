{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifty-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -Uq sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-yahoo",
   "metadata": {
    "papermill": {
     "duration": 0.019068,
     "end_time": "2021-06-01T00:12:50.157170",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.138102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using Amazon SageMaker Debugger for PyTorch Training Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-daughter",
   "metadata": {
    "papermill": {
     "duration": 0.019025,
     "end_time": "2021-06-01T00:12:50.195380",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.176355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Amazon SageMaker is a managed platform to build, train and host machine learning models. Amazon SageMaker Debugger is a new feature which offers capability to debug machine learning and deep learning models during training by identifying and detecting problems with the models in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-colony",
   "metadata": {
    "papermill": {
     "duration": 0.01907,
     "end_time": "2021-06-01T00:12:50.233588",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.214518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Amazon SageMaker also gives you the option of bringing your own algorithms packaged in a custom container, that can then be trained and deployed in the Amazon SageMaker environment. \n",
    "\n",
    "This notebook guides you through an example of using your own container with PyTorch for training, along with the recently added feature, Amazon SageMaker Debugger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-honolulu",
   "metadata": {
    "papermill": {
     "duration": 0.019013,
     "end_time": "2021-06-01T00:12:50.271674",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.252661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## How does Amazon SageMaker Debugger work?\n",
    "\n",
    "Amazon SageMaker Debugger lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Furthermore, it helps you monitor your training in real time using rules and CloudWatch events and react to issues like, for example, common training issues such as vanishing gradients or poor weight initialization.\n",
    "\n",
    "### Concepts\n",
    "\n",
    "* **Output Tensor**: These are the artifacts that define the state of the training job at any particular instant in its lifecycle.\n",
    "* **Debug Hook**: Captures the tensors flowing through the training computational graph every N steps.\n",
    "* **Debugging Rule**: Logic to analyze the tensors captured by the hook and report anomalies.\n",
    "\n",
    "With these concepts in mind, let's understand the overall flow of things which Amazon SageMaker Debugger uses to orchestrate debugging.\n",
    "\n",
    "It operates in two steps - saving tensors and analysis.\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "Tensors that debug hook captures are stored in S3 location specified by you. There are two ways you can configure Amazon SageMaker Debugger for storage:\n",
    "\n",
    "   1. **Zero code change (DEPRECATED for PyTorch versions >= 1.12)**: If you use any of SageMaker provided [Deep Learning containers](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html) then you don't need to make any changes to your training script for tensors to be stored. Amazon SageMaker Debugger will use the configuration you provide in the framework `Estimator` to save tensors in the fashion you specify.\n",
    "       \n",
    "       **Note**: In case of PyTorch training, Debugger collects output tensors in GLOBAL mode by default. In other words, this option does not distinguish output tensors from different phases within an epoch, such as training phase and validation phase.\n",
    "       \n",
    "   2. **Script change**: Use the SageMaker Debugger client library, SMDebug, and customize training scripts to save the specific tensors you want at different frequencies and configurations. Refer to the [DeveloperGuide](https://github.com/awslabs/sagemaker-debugger/tree/master/docs) for details on how to use SageMaker Debugger with your choice of framework in your training script.\n",
    "   \n",
    "In this notebook, we choose the second option to properly save the output tensors from different training phases since we're using PyTorch=1.12\n",
    "\n",
    "### Analysis of tensors\n",
    "\n",
    "Once tensors are saved, Amazon SageMaker Debugger can be configured to run debugging ***Rules*** on them. On a very broad level, a rule is a python script used to detect certain conditions during training. Some of the conditions that a data scientist training an algorithm might be interested in are monitoring for gradients getting too large or too small, detecting overfitting, and so on. Amazon SageMaker Debugger comes pre-packaged with certain built-in rules. You can also write your own rules using the Amazon SageMaker Debugger APIs. You can also analyze raw tensor data outside the Rules construct in a notebook, using Amazon SageMaker Debugger's full set of APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-booking",
   "metadata": {
    "papermill": {
     "duration": 0.018947,
     "end_time": "2021-06-01T00:12:50.309809",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.290862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## Import SageMaker Python SDK and install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "visible-search",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:50.351906Z",
     "iopub.status.busy": "2021-06-01T00:12:50.351414Z",
     "iopub.status.idle": "2021-06-01T00:12:50.898236Z",
     "shell.execute_reply": "2021-06-01T00:12:50.898614Z"
    },
    "papermill": {
     "duration": 0.569802,
     "end_time": "2021-06-01T00:12:50.898741",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.328939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-simpson",
   "metadata": {
    "papermill": {
     "duration": 0.019511,
     "end_time": "2021-06-01T00:12:50.938133",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.918622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook works with the SageMaker Python SDK version **2.39.1 or later**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elder-rover",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:50.983163Z",
     "iopub.status.busy": "2021-06-01T00:12:50.982377Z",
     "iopub.status.idle": "2021-06-01T00:12:53.182409Z",
     "shell.execute_reply": "2021-06-01T00:12:53.182792Z"
    },
    "papermill": {
     "duration": 2.225115,
     "end_time": "2021-06-01T00:12:53.182922",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.957807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "import sys\n",
    "\n",
    "def import_or_install(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        !{sys.executable} -m pip install {package}\n",
    "        \n",
    "required_packages=['smdebug', 'pytest']\n",
    "\n",
    "for package in required_packages:\n",
    "    import_or_install(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-bubble",
   "metadata": {
    "papermill": {
     "duration": 0.021428,
     "end_time": "2021-06-01T00:12:53.226536",
     "exception": false,
     "start_time": "2021-06-01T00:12:53.205108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## Modify a PyTorch training script\n",
    "\n",
    "We will focus on how to modify a training script to save tensors by registering debug hooks and specifying which tensors to save.\n",
    "\n",
    "The model used for this notebook is trained with the MNIST dataset. The example is based on https://github.com/pytorch/examples/blob/master/mnist/main.py (the version as of October 2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-control",
   "metadata": {
    "papermill": {
     "duration": 0.021317,
     "end_time": "2021-06-01T00:12:53.269125",
     "exception": false,
     "start_time": "2021-06-01T00:12:53.247808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Modifying the training script\n",
    "\n",
    "Before we define a PyTorch estimator and start training, we will explore parts of the training script in detail. (The entire training script can be found at [./scripts/pytorch_mnist.py](./scripts/pytorch_mnist.py))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-effort",
   "metadata": {
    "papermill": {
     "duration": 0.021206,
     "end_time": "2021-06-01T00:12:53.312017",
     "exception": false,
     "start_time": "2021-06-01T00:12:53.290811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **Step 1**: Import Amazon SageMaker Debugger client library, SMDebug.\n",
    "\n",
    "    ```python\n",
    "    import smdebug.pytorch as smd\n",
    "    \n",
    "    ```\n",
    "\n",
    "\n",
    "- **Step 2**: In the `train()` function, add the SMDebug hook for PyTorch with `TRAIN` mode.\n",
    "\n",
    "    ```python\n",
    "    hook.set_mode(smd.modes.TRAIN)\n",
    "    ```\n",
    "\n",
    "\n",
    "- **Step 3**: In the `test()` function, add the SMDebug hook for PyTorch with `EVAL` mode.\n",
    "\n",
    "    ```python\n",
    "    hook.set_mode(smd.modes.EVAL)\n",
    "    ```\n",
    "\n",
    "\n",
    "- **Step 4**: In the `main()` function, create the SMDebug hook and register to the model and loss function.\n",
    "\n",
    "    ```python\n",
    "    hook = smd.Hook.create_from_json_file()\n",
    "    hook.register_hook(model)\n",
    "    hook.register_loss(loss_fn)\n",
    "    ```\n",
    "\n",
    "\n",
    "- **Step 4**: In the `main()` function, pass the SMDebug hook to the `train()` and `test()` functions in the epoch loop.\n",
    "\n",
    "    ```python\n",
    "    train(args, model, loss_fn, device, train_loader, optimizer, epoch, hook)\n",
    "    test(model, device, loss_fn, test_loader, hook)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equal-macro",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:53.360847Z",
     "iopub.status.busy": "2021-06-01T00:12:53.358649Z",
     "iopub.status.idle": "2021-06-01T00:12:54.143210Z",
     "shell.execute_reply": "2021-06-01T00:12:54.142779Z"
    },
    "papermill": {
     "duration": 0.810123,
     "end_time": "2021-06-01T00:12:54.143318",
     "exception": false,
     "start_time": "2021-06-01T00:12:53.333195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize ./scripts/pytorch_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-terror",
   "metadata": {
    "papermill": {
     "duration": 0.022031,
     "end_time": "2021-06-01T00:12:54.187737",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.165706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## Set up a PyTorch estimator and run a training job\n",
    "\n",
    "Once these changes are made in the training script, Amazon SageMaker Debugger will start saving tensors during training into a specified output S3 bucket.\n",
    "\n",
    "Now, we will set up the estimator and start training using the modified training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efficient-reunion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:54.236549Z",
     "iopub.status.busy": "2021-06-01T00:12:54.236025Z",
     "iopub.status.idle": "2021-06-01T00:12:54.311575Z",
     "shell.execute_reply": "2021-06-01T00:12:54.311163Z"
    },
    "papermill": {
     "duration": 0.101981,
     "end_time": "2021-06-01T00:12:54.311710",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.209729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import boto3\n",
    "import pytest\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "    DebuggerHookConfig,\n",
    "    TensorBoardOutputConfig,\n",
    "    CollectionConfig,\n",
    "    rule_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-browser",
   "metadata": {
    "papermill": {
     "duration": 0.022544,
     "end_time": "2021-06-01T00:12:54.356775",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.334231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define the configuration of training to run. `ecr_image` is where you can provide link to your bring-your-own-container. `hyperparameters` are fed into the training script with data directory (directory where the training dataset is stored) and smdebug directory (directory where the tensors will be saved) are mandatory fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "south-sculpture",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:54.404516Z",
     "iopub.status.busy": "2021-06-01T00:12:54.404049Z",
     "iopub.status.idle": "2021-06-01T00:12:54.406120Z",
     "shell.execute_reply": "2021-06-01T00:12:54.405743Z"
    },
    "papermill": {
     "duration": 0.027379,
     "end_time": "2021-06-01T00:12:54.406215",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.378836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epochs\": \"5\", \"batch-size\": \"32\", \"test-batch-size\": \"100\", \"lr\": \"0.001\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-scroll",
   "metadata": {
    "papermill": {
     "duration": 0.022001,
     "end_time": "2021-06-01T00:12:54.450311",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.428310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configure a Debugger rule object\n",
    "\n",
    "The `rules` parameter is a new parameter that accepts a list of rules against output tensors that you want to evaluate.\n",
    "\n",
    "In this example, we use the following Debugger rules that will attempt to evaluate if there are overfit, overtraining, and vanishing gradients problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indoor-marshall",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:54.498223Z",
     "iopub.status.busy": "2021-06-01T00:12:54.497648Z",
     "iopub.status.idle": "2021-06-01T00:12:54.500307Z",
     "shell.execute_reply": "2021-06-01T00:12:54.500661Z"
    },
    "papermill": {
     "duration": 0.028483,
     "end_time": "2021-06-01T00:12:54.500772",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.472289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-phoenix",
   "metadata": {
    "papermill": {
     "duration": 0.022169,
     "end_time": "2021-06-01T00:12:54.546101",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.523932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For more information about the rules, see the following documentation.\n",
    "\n",
    "- [Vanishing gradient](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#vanishing-gradient)\n",
    "- [Overfit](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#overfit)\n",
    "- [Overtraining](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#overtraining)\n",
    "- [Poor weight initialization](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#poor-weight-initialization)\n",
    "\n",
    "In addition to the model debugging rules above, SageMaker Debugger runs the ProfilerReport rule by default. This runs rules for system bottleneck detections and autogenerates a profiling report. For more information, see the following documentation:\n",
    "\n",
    "- [SageMaker Debugger Profiling Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html)\n",
    "- [ProfilerReport rule](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#profiler-report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-knock",
   "metadata": {
    "papermill": {
     "duration": 0.022409,
     "end_time": "2021-06-01T00:12:54.590662",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.568253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configure Debugger hook parameters\n",
    "\n",
    "The following code shows how to adjust save intervals of the output tensors in the different training phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generic-fiber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:54.639138Z",
     "iopub.status.busy": "2021-06-01T00:12:54.638674Z",
     "iopub.status.idle": "2021-06-01T00:12:54.640955Z",
     "shell.execute_reply": "2021-06-01T00:12:54.640582Z"
    },
    "papermill": {
     "duration": 0.028125,
     "end_time": "2021-06-01T00:12:54.641048",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.612923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-comedy",
   "metadata": {
    "papermill": {
     "duration": 0.022149,
     "end_time": "2021-06-01T00:12:54.685498",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.663349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Construct a PyTorch estimator with the Debugger parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saved-scholarship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:54.742240Z",
     "iopub.status.busy": "2021-06-01T00:12:54.741779Z",
     "iopub.status.idle": "2021-06-01T00:12:55.230825Z",
     "shell.execute_reply": "2021-06-01T00:12:55.230404Z"
    },
    "papermill": {
     "duration": 0.523246,
     "end_time": "2021-06-01T00:12:55.230932",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.707686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"scripts/pytorch_mnist.py\",\n",
    "    base_job_name=\"smdebugger-demo-mnist-pytorch\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    volume_size=400,\n",
    "    max_run=3600,\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    ## Debugger parameters\n",
    "    rules=rules,\n",
    "    debugger_hook_config=hook_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-necklace",
   "metadata": {
    "papermill": {
     "duration": 0.022696,
     "end_time": "2021-06-01T00:12:55.276170",
     "exception": false,
     "start_time": "2021-06-01T00:12:55.253474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "convenient-textbook",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:55.325134Z",
     "iopub.status.busy": "2021-06-01T00:12:55.324659Z",
     "iopub.status.idle": "2021-06-01T00:12:55.949963Z",
     "shell.execute_reply": "2021-06-01T00:12:55.949524Z"
    },
    "papermill": {
     "duration": 0.651289,
     "end_time": "2021-06-01T00:12:55.950072",
     "exception": false,
     "start_time": "2021-06-01T00:12:55.298783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-draft",
   "metadata": {
    "papermill": {
     "duration": 0.022325,
     "end_time": "2021-06-01T00:12:55.995017",
     "exception": false,
     "start_time": "2021-06-01T00:12:55.972692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## Check SageMaker Debugger rule summaries\n",
    "\n",
    "As a result of calling the `fit()` method, Amazon SageMaker Debugger starts a rule evaluation job to monitor `vanishing_gradient()`, `overfit()`, and `overtraining()` issues in parallel with the training job. \n",
    "\n",
    "The `ProfilerReport` rule runs for all SageMaker training jobs by default. You will be able to receive a comprehensive training report regarding system bottlenecks and framework profiling.\n",
    "\n",
    "### Print the latest training job's rule summary in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eligible-assessment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:56.045375Z",
     "iopub.status.busy": "2021-06-01T00:12:56.044910Z",
     "iopub.status.idle": "2021-06-01T00:12:56.071304Z",
     "shell.execute_reply": "2021-06-01T00:12:56.071695Z"
    },
    "papermill": {
     "duration": 0.054471,
     "end_time": "2021-06-01T00:12:56.071818",
     "exception": false,
     "start_time": "2021-06-01T00:12:56.017347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-navigator",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:12:56.125828Z",
     "iopub.status.busy": "2021-06-01T00:12:56.125328Z",
     "iopub.status.idle": "2021-06-01T00:16:48.306033Z",
     "shell.execute_reply": "2021-06-01T00:16:48.305100Z"
    },
    "papermill": {
     "duration": 232.211672,
     "end_time": "2021-06-01T00:16:48.306240",
     "exception": true,
     "start_time": "2021-06-01T00:12:56.094568",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "while description[\"SecondaryStatus\"] not in {\"Stopped\", \"Completed\"}:\n",
    "    description = client.describe_training_job(TrainingJobName=job_name)\n",
    "    primary_status = description[\"TrainingJobStatus\"]\n",
    "    secondary_status = description[\"SecondaryStatus\"]\n",
    "    print(\"====================================================================\")\n",
    "    print(\"TrainingJobStatus: \", primary_status, \" | SecondaryStatus: \", secondary_status)\n",
    "    print(\"====================================================================\")\n",
    "    for r in range(len(estimator.latest_training_job.rule_job_summary())):\n",
    "        rule_summary = estimator.latest_training_job.rule_job_summary()\n",
    "        print(\n",
    "            rule_summary[r][\"RuleConfigurationName\"], \": \", rule_summary[r][\"RuleEvaluationStatus\"]\n",
    "        )\n",
    "        if rule_summary[r][\"RuleEvaluationStatus\"] == \"IssuesFound\":\n",
    "            print(rule_summary[r][\"StatusDetails\"])\n",
    "        print(\"====================================================================\")\n",
    "    print(\"Current time: \", time.asctime())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-galaxy",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Print URLs to the corresponding processing job logs in CloudWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-command",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_rule_job_name(training_job_name, rule_configuration_name, rule_job_arn):\n",
    "    \"\"\"Helper function to get the rule job name with correct casing\"\"\"\n",
    "    return \"{}-{}-{}\".format(\n",
    "        training_job_name[:26], rule_configuration_name[:26], rule_job_arn[-8:]\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_cw_url_for_rule_job(rule_job_name, region):\n",
    "    return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\".format(\n",
    "        region, region, rule_job_name\n",
    "    )\n",
    "\n",
    "\n",
    "def get_rule_jobs_cw_urls(estimator):\n",
    "    region = boto3.Session().region_name\n",
    "    training_job = estimator.latest_training_job\n",
    "    training_job_name = training_job.describe()[\"TrainingJobName\"]\n",
    "    rule_eval_statuses = training_job.describe()[\"DebugRuleEvaluationStatuses\"]\n",
    "\n",
    "    result = {}\n",
    "    for status in rule_eval_statuses:\n",
    "        if status.get(\"RuleEvaluationJobArn\", None) is not None:\n",
    "            rule_job_name = _get_rule_job_name(\n",
    "                training_job_name, status[\"RuleConfigurationName\"], status[\"RuleEvaluationJobArn\"]\n",
    "            )\n",
    "            result[status[\"RuleConfigurationName\"]] = _get_cw_url_for_rule_job(\n",
    "                rule_job_name, region\n",
    "            )\n",
    "    return result\n",
    "\n",
    "\n",
    "get_rule_jobs_cw_urls(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-premium",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## SageMaker Debugger reports and analysis\n",
    "\n",
    "Another aspect of the Amazon SageMaker Debugger is analysis. It allows us to perform interactive exploration of the tensors saved in real time or after the job. Here we focus on after-the-fact analysis of the above job. We import the smdebug library, which defines a concept of Trial that represents a single training run. Note how we fetch the path to debugger artifacts for the above job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-connectivity",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create an SMDebug trial object and retrieve saved output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-liquid",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-novel",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Print check what output tensors are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-soviet",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can list all the tensors that were recorded to know what we want to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-function",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-method",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can also retrieve tensors by some default collections that smdebug creates from your training job. Here we are interested in the losses collection, so we can retrieve the names of tensors in losses collection as follows. Amazon SageMaker Debugger creates default collections such as weights, gradients, biases, losses automatically. You can also create custom collections from your tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-russell",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Check the number of steps saved in the different training phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-spine",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(trial.tensor(\"NLLLoss_output_0\").steps(mode=ModeKeys.TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-think",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(trial.tensor(\"NLLLoss_output_0\").steps(mode=ModeKeys.EVAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-blast",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Set up functions to log and plot the output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-producer",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-commission",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "\n",
    "def plot_tensor(trial, tensor_name):\n",
    "\n",
    "    steps_train, vals_train = get_data(trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    host = host_subplot(111)\n",
    "\n",
    "    par = host.twiny()\n",
    "\n",
    "    host.set_xlabel(\"Steps (TRAIN)\")\n",
    "    par.set_xlabel(\"Steps (EVAL)\")\n",
    "    host.set_ylabel(tensor_name)\n",
    "\n",
    "    (p1,) = host.plot(steps_train, vals_train, label=tensor_name)\n",
    "    print(\"completed TRAIN plot\")\n",
    "    (p2,) = par.plot(steps_eval, vals_eval, label=\"val_\" + tensor_name)\n",
    "    print(\"completed EVAL plot\")\n",
    "    leg = plt.legend()\n",
    "\n",
    "    host.xaxis.get_label().set_color(p1.get_color())\n",
    "    leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "    par.xaxis.get_label().set_color(p2.get_color())\n",
    "    leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "    plt.ylabel(tensor_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-coordinate",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_tensor(trial, \"NLLLoss_output_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-scheduling",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Reflect the rule summary report\n",
    "\n",
    "Recall what the rule summary reported:\n",
    "\n",
    "```\n",
    "Overfit :  IssuesFound\n",
    "RuleEvaluationConditionMet: Evaluation of the rule Overfit at step 4000 resulted in the condition being met\n",
    "```\n",
    "\n",
    "Based on this rule evaluation and the plot above, we can conclude that the training job has an overfit issue. While the `NLLLoss_output_0` line is decreasing, the `val_NLLLoss_output_0` line is fluctuating and not decreasing. \n",
    "\n",
    "To resolve the overfit problem, you need to consider using or double-checking the following techniques:\n",
    "\n",
    "- Regularization\n",
    "- Weight initialization\n",
    "- Dropout regularization\n",
    "- Weight constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-thought",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Download, open, and display the ProfilerReport HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-aaron",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-philosophy",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! aws s3 ls {rule_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-organ",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! aws s3 cp {rule_output_path} ./ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-marshall",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get the autogenerated folder name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-mercury",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('3.8.11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 239.460793,
   "end_time": "2021-06-01T00:16:48.734820",
   "environment_variables": {},
   "exception": true,
   "input_path": "pytorch_script_change_smdebug.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch_script_change_smdebug-2021-06-01-00-08-41.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-01T00:12:49.274027",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
