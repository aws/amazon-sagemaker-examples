{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect stalled training and stop training job using debugger rule\n",
    " \n",
    "\n",
    "In this notebook, we'll show you how you can use StalledTrainingRule rule which can take action like stopping your training job when it finds that there has been no update in training job for certain threshold duration.\n",
    "\n",
    "## How does StalledTrainingRule works?\n",
    "\n",
    "Amazon Sagemaker debugger automatically captures tensors from training job which use AWS DLC(tensorflow, pytorch, mxnet, xgboost)[refer doc for supported versions](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/sagemaker.md#zero-script-change). StalledTrainingRule keeps watching on emission of tensors like loss. The execution happens outside of training containers. It is evident that if training job is running good and is not stalled it is expected to emit loss and metrics tensors at frequent intervals. If Rule doesn't find new tensors being emitted from training job for threshold period of time, it takes automatic action to issue StopTrainingJob.\n",
    "\n",
    "#### With no changes to your training script\n",
    "If you use one of the SageMaker provided [Deep Learning Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html). [Refer doc for supported framework versions](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/sagemaker.md#zero-script-change), then you don't need to make any changes to your training script for activating this rule. Loss tensors will automatically be captured and monitored by the rule.\n",
    "\n",
    "You can also emit tensors periodically by using [save scalar api of hook](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md#common-hook-api) . \n",
    "\n",
    "Also look at example how to use save_scalar api [here](https://github.com/awslabs/sagemaker-debugger/blob/master/examples/tensorflow2/scripts/tf_keras_fit_non_eager.py#L42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/Users/vikumar/anaconda3/envs/bokeh/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.66.0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig\n",
    "import smdebug_rulesconfig as rule_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the entrypoint script\n",
    "# Below script has 5 minutes sleep, we will create a stalledTrainingRule with 3 minutes of threshold.\n",
    "entrypoint_script='src/simple_stalled_training.py'\n",
    "\n",
    "# these hyperparameters ensure that vanishing gradient will trigger for our tensorflow mnist script\n",
    "hyperparameters = {\n",
    "    \"num_epochs\": \"10\",\n",
    "    \"lr\": \"10.00\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unique training job prefix\n",
    "We will create unique training job name prefix. this prefix would be passed to StalledTrainingRule to identify which training job, rule should take action on once the stalled training rule condition is met.\n",
    "Note that, this prefix needs to be unique. If rule doesn't find exactly one job with provided prefix, it will fallback to safe mode and not take action of stop training job. Rule will still emit a cloudwatch event if the rule condition is met. To see details about cloud watch event, check [here](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-debugger/tensorflow_action_on_rule/tf-mnist-stop-training-job.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593259362\n",
      "smdebug-stalled-demo-1593259362\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(int(time.time()))\n",
    "# Note that sagemaker appends date to your training job and truncates the provided name to 39 character. So, we will make \n",
    "# sure that we use less than 39 character in below prefix. Appending time is to provide a unique id\n",
    "base_job_name_prefix= 'smdebug-stalled-demo-' + str(int(time.time()))\n",
    "base_job_name_prefix = base_job_name_prefix[:34]\n",
    "print(base_job_name_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalled_training_job_rule = Rule.sagemaker(\n",
    "    base_config={\n",
    "                    'DebugRuleConfiguration': {\n",
    "                        'RuleConfigurationName': 'StalledTrainingRule', \n",
    "                        'RuleParameters': {'rule_to_invoke': 'StalledTrainingRule'}\n",
    "                    }\n",
    "                 },\n",
    "    rule_parameters={\n",
    "        'threshold': '120',\n",
    "        'training_job_name_prefix': base_job_name_prefix,\n",
    "        'stop_training_on_fire' : 'True'\n",
    "    },    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "    role='Admin',#sagemaker.get_execution_role(),\n",
    "    base_job_name=base_job_name_prefix,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.4xlarge',\n",
    "    entry_point=entrypoint_script,\n",
    "    #source_dir = 'src',\n",
    "    framework_version='1.15.0',\n",
    "    py_version='py3',\n",
    "    train_max_run=3600,\n",
    "    script_mode=True,\n",
    "    ## New parameter\n",
    "    rules = [stalled_training_job_rule]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27 12:02:46 Starting - Starting the training job...\n",
      "2020-06-27 12:02:48 Starting - Launching requested ML instances\n",
      "********* Debugger Rule Status *********\n",
      "*\n",
      "* StalledTrainingRule: InProgress        \n",
      "*\n",
      "****************************************\n",
      "......\n",
      "2020-06-27 12:04:03 Starting - Preparing the instances for training...\n",
      "2020-06-27 12:04:50 Downloading - Downloading input data...\n",
      "2020-06-27 12:05:17 Training - Training image download completed. Training in progress.\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-06-27 12:05:19,399 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-06-27 12:05:19,405 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-27 12:05:19,799 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-27 12:05:19,812 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-27 12:05:19,825 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-27 12:05:19,834 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"simple_stalled_training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"simple_stalled_training.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=simple_stalled_training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=simple_stalled_training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/source/sourcedir.tar.gz\",\"module_name\":\"simple_stalled_training\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"simple_stalled_training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 simple_stalled_training.py --model_dir s3://sagemaker-us-east-1-920076894685/smdebug-stalled-demo-1593259362-2020-06-27-12-02-42-898/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-06-27 12:05:22.408 ip-10-2-232-37.ec2.internal:48 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-27 12:05:22.408 ip-10-2-232-37.ec2.internal:48 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-27 12:05:22.408 ip-10-2-232-37.ec2.internal:48 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-06-27 12:05:22.486 ip-10-2-232-37.ec2.internal:48 INFO hook.py:326] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/smdebug/tensorflow/session.py:310: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.graph_util.extract_sub_graph`\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/smdebug/tensorflow/session.py:310: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.graph_util.extract_sub_graph`\u001b[0m\n",
      "\u001b[34mStep=0, Loss=61.636817932128906\u001b[0m\n",
      "\u001b[34mStep=1, Loss=76.62738037109375\u001b[0m\n",
      "\u001b[34mStep=2, Loss=137.65243530273438\u001b[0m\n",
      "\u001b[34mStep=3, Loss=124.34944152832031\u001b[0m\n",
      "\u001b[34mStep=4, Loss=139.6868133544922\u001b[0m\n",
      "\u001b[34mStep=5, Loss=90.82096099853516\u001b[0m\n",
      "\u001b[34mStep=6, Loss=93.99701690673828\u001b[0m\n",
      "\u001b[34mStep=7, Loss=78.5556869506836\u001b[0m\n",
      "\u001b[34mStep=8, Loss=121.077880859375\u001b[0m\n",
      "\u001b[34mStep=9, Loss=86.89076232910156\u001b[0m\n",
      "\u001b[34mStep=10, Loss=90.39352416992188\u001b[0m\n",
      "\u001b[34mStep=11, Loss=78.74629211425781\u001b[0m\n",
      "\u001b[34mStep=12, Loss=86.4300537109375\u001b[0m\n",
      "\u001b[34mStep=13, Loss=122.25215911865234\u001b[0m\n",
      "\u001b[34mStep=14, Loss=110.44364929199219\u001b[0m\n",
      "\u001b[34mStep=15, Loss=85.41569519042969\u001b[0m\n",
      "\u001b[34mStep=16, Loss=136.12832641601562\u001b[0m\n",
      "\u001b[34mStep=17, Loss=130.3118438720703\u001b[0m\n",
      "\u001b[34mStep=18, Loss=120.10881042480469\u001b[0m\n",
      "\u001b[34mStep=19, Loss=138.38021850585938\u001b[0m\n",
      "\u001b[34mStep=20, Loss=105.2777099609375\u001b[0m\n",
      "\u001b[34mStep=21, Loss=103.83732604980469\u001b[0m\n",
      "\u001b[34mStep=22, Loss=72.87864685058594\u001b[0m\n",
      "\u001b[34mStep=23, Loss=115.860107421875\u001b[0m\n",
      "\u001b[34mStep=24, Loss=75.30367279052734\u001b[0m\n",
      "\u001b[34mStep=25, Loss=86.53971099853516\u001b[0m\n",
      "\u001b[34mStep=26, Loss=132.53524780273438\u001b[0m\n",
      "\u001b[34mStep=27, Loss=72.7097396850586\u001b[0m\n",
      "\u001b[34mStep=28, Loss=99.77864074707031\u001b[0m\n",
      "\u001b[34mStep=29, Loss=82.06185913085938\u001b[0m\n",
      "\u001b[34mStep=30, Loss=150.12481689453125\u001b[0m\n",
      "\u001b[34mStep=31, Loss=64.39604949951172\u001b[0m\n",
      "\u001b[34mStep=32, Loss=84.48753356933594\u001b[0m\n",
      "\u001b[34mStep=33, Loss=78.08708953857422\u001b[0m\n",
      "\u001b[34mStep=34, Loss=92.37486267089844\u001b[0m\n",
      "\u001b[34mStep=35, Loss=92.40724182128906\u001b[0m\n",
      "\u001b[34mStep=36, Loss=79.97074127197266\u001b[0m\n",
      "\u001b[34mStep=37, Loss=118.78682708740234\u001b[0m\n",
      "\u001b[34mStep=38, Loss=75.77554321289062\u001b[0m\n",
      "\u001b[34mStep=39, Loss=83.64649963378906\u001b[0m\n",
      "\u001b[34mStep=40, Loss=119.5330581665039\u001b[0m\n",
      "\u001b[34mStep=41, Loss=102.8688735961914\u001b[0m\n",
      "\u001b[34mStep=42, Loss=88.9874496459961\u001b[0m\n",
      "\u001b[34mStep=43, Loss=103.56982421875\u001b[0m\n",
      "\u001b[34mStep=44, Loss=124.73907470703125\u001b[0m\n",
      "\u001b[34mStep=45, Loss=91.47120666503906\u001b[0m\n",
      "\u001b[34mStep=46, Loss=133.18099975585938\u001b[0m\n",
      "\u001b[34mStep=47, Loss=82.31591796875\u001b[0m\n",
      "\u001b[34mStep=48, Loss=80.1401138305664\u001b[0m\n",
      "\u001b[34mStep=49, Loss=97.57213592529297\u001b[0m\n",
      "\u001b[34mStep=50, Loss=85.309326171875\u001b[0m\n",
      "\u001b[34mStep=51, Loss=74.24087524414062\u001b[0m\n",
      "\u001b[34mStep=52, Loss=93.54154968261719\u001b[0m\n",
      "\u001b[34mStep=53, Loss=86.35009765625\u001b[0m\n",
      "\u001b[34mStep=54, Loss=90.83928680419922\u001b[0m\n",
      "\u001b[34mStep=55, Loss=121.9789047241211\u001b[0m\n",
      "\u001b[34mStep=56, Loss=77.1647720336914\u001b[0m\n",
      "\u001b[34mStep=57, Loss=97.45545959472656\u001b[0m\n",
      "\u001b[34mStep=58, Loss=87.28883361816406\u001b[0m\n",
      "\u001b[34mStep=59, Loss=76.23760986328125\u001b[0m\n",
      "\u001b[34mStep=60, Loss=71.92115783691406\u001b[0m\n",
      "\u001b[34mStep=61, Loss=76.26293182373047\u001b[0m\n",
      "\u001b[34mStep=62, Loss=109.66444396972656\u001b[0m\n",
      "\u001b[34mStep=63, Loss=123.03035736083984\u001b[0m\n",
      "\u001b[34mStep=64, Loss=65.3427963256836\u001b[0m\n",
      "\u001b[34mStep=65, Loss=48.84718704223633\u001b[0m\n",
      "\u001b[34mStep=66, Loss=77.2469482421875\u001b[0m\n",
      "\u001b[34mStep=67, Loss=140.335693359375\u001b[0m\n",
      "\u001b[34mStep=68, Loss=80.30182647705078\u001b[0m\n",
      "\u001b[34mStep=69, Loss=93.85020446777344\u001b[0m\n",
      "\u001b[34mStep=70, Loss=97.41108703613281\u001b[0m\n",
      "\u001b[34mStep=71, Loss=91.7099609375\u001b[0m\n",
      "\u001b[34mStep=72, Loss=94.1562271118164\u001b[0m\n",
      "\u001b[34mStep=73, Loss=97.63263702392578\u001b[0m\n",
      "\u001b[34mStep=74, Loss=149.68280029296875\u001b[0m\n",
      "\u001b[34mStep=75, Loss=111.36968994140625\u001b[0m\n",
      "\u001b[34mStep=76, Loss=68.02821350097656\u001b[0m\n",
      "\u001b[34mStep=77, Loss=113.71905517578125\u001b[0m\n",
      "\u001b[34mStep=78, Loss=87.5481185913086\u001b[0m\n",
      "\u001b[34mStep=79, Loss=74.9926986694336\u001b[0m\n",
      "\u001b[34mStep=80, Loss=100.95458984375\u001b[0m\n",
      "\u001b[34mStep=81, Loss=106.6003646850586\u001b[0m\n",
      "\u001b[34mStep=82, Loss=72.30493927001953\u001b[0m\n",
      "\u001b[34mStep=83, Loss=89.36466979980469\u001b[0m\n",
      "\u001b[34mStep=84, Loss=88.72581481933594\u001b[0m\n",
      "\u001b[34mStep=85, Loss=108.887451171875\u001b[0m\n",
      "\u001b[34mStep=86, Loss=89.35628509521484\u001b[0m\n",
      "\u001b[34mStep=87, Loss=124.39259338378906\u001b[0m\n",
      "\u001b[34mStep=88, Loss=133.83450317382812\u001b[0m\n",
      "\u001b[34mStep=89, Loss=103.58975982666016\u001b[0m\n",
      "\u001b[34mStep=90, Loss=96.07878875732422\u001b[0m\n",
      "\u001b[34mStep=91, Loss=123.74015808105469\u001b[0m\n",
      "\u001b[34mStep=92, Loss=120.95271301269531\u001b[0m\n",
      "\u001b[34mStep=93, Loss=89.57190704345703\u001b[0m\n",
      "\u001b[34mStep=94, Loss=103.43186950683594\u001b[0m\n",
      "\u001b[34mStep=95, Loss=99.25971984863281\u001b[0m\n",
      "\u001b[34mStep=96, Loss=111.5605697631836\u001b[0m\n",
      "\u001b[34mStep=97, Loss=79.01872253417969\u001b[0m\n",
      "\u001b[34mStep=98, Loss=88.46170043945312\u001b[0m\n",
      "\u001b[34mStep=99, Loss=129.40283203125\u001b[0m\n",
      "\u001b[34mSleeping for 10 minutes\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Debugger Rule Status *********\n",
      "*\n",
      "* StalledTrainingRule: IssuesFound       \n",
      "*\n",
      "****************************************\n",
      "\n",
      "2020-06-27 12:14:21 Stopping - Stopping the training job\u001b[34mWaking up and exiting\u001b[0m\n",
      "\u001b[34m[2020-06-27 12:15:23.056 ip-10-2-232-37.ec2.internal:48 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-06-27 12:15:23,427 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2020-06-27 12:15:23,427 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-27 12:15:48 Uploading - Uploading generated training model\n",
      "2020-06-27 12:15:48 Stopped - Training job stopped\n",
      "Training seconds: 658\n",
      "Billable seconds: 658\n"
     ]
    }
   ],
   "source": [
    "# After calling fit, SageMaker will spin off 1 training job and 1 rule job for you\n",
    "# The rule evaluation status(es) will be visible in the training logs\n",
    "# at regular intervals\n",
    "# wait=False makes this a fire and forget function. To stream the logs in the notebook leave this out\n",
    "\n",
    "estimator.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "\n",
    "SageMaker kicked off rule evaluation job `StalledTrainingRule` as specified in the estimator. \n",
    "Given that we've stalled our training script for 10 minutes such that `StalledTrainingRule` is bound to fire and take action StopTrainingJob, we should expect to see the `TrainingJobStatus` as\n",
    "`Stopped` once the `RuleEvaluationStatus` for `StalledTrainingRule` changes to `IssuesFound`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RuleConfigurationName': 'StalledTrainingRule',\n",
       "  'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:920076894685:processing-job/smdebug-stalled-demo-15932-stalledtrainingrule-730dc720',\n",
       "  'RuleEvaluationStatus': 'IssuesFound',\n",
       "  'StatusDetails': 'RuleEvaluationConditionMet: Evaluation of the rule StalledTrainingRule at step 101 resulted in the condition being met\\n',\n",
       "  'LastModifiedTime': datetime.datetime(2020, 6, 27, 5, 11, 39, 109000, tzinfo=tzlocal())}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rule job summary gives you the summary of the rule evaluations. You might have to run it over \n",
    "# a few times before you start to see all values populated/changing\n",
    "estimator.latest_training_job.rule_job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StalledTrainingRule': 'https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/ProcessingJobs;prefix=smdebug-stalled-demo-15932-StalledTrainingRule-730dc720;streamFilter=typeLogStreamPrefix'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This utility gives the link to monitor the CW event\n",
    "def _get_rule_job_name(training_job_name, rule_configuration_name, rule_job_arn):\n",
    "        \"\"\"Helper function to get the rule job name\"\"\"\n",
    "        return \"{}-{}-{}\".format(\n",
    "            training_job_name[:26], rule_configuration_name[:26], rule_job_arn[-8:]\n",
    "        )\n",
    "    \n",
    "def _get_cw_url_for_rule_job(rule_job_name, region):\n",
    "    return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\".format(region, region, rule_job_name)\n",
    "\n",
    "\n",
    "def get_rule_jobs_cw_urls(estimator):\n",
    "    region = boto3.Session().region_name\n",
    "    training_job = estimator.latest_training_job\n",
    "    training_job_name = training_job.describe()[\"TrainingJobName\"]\n",
    "    rule_eval_statuses = training_job.describe()[\"DebugRuleEvaluationStatuses\"]\n",
    "    \n",
    "    result={}\n",
    "    for status in rule_eval_statuses:\n",
    "        if status.get(\"RuleEvaluationJobArn\", None) is not None:\n",
    "            rule_job_name = _get_rule_job_name(training_job_name, status[\"RuleConfigurationName\"], status[\"RuleEvaluationJobArn\"])\n",
    "            result[status[\"RuleConfigurationName\"]] = _get_cw_url_for_rule_job(rule_job_name, region)\n",
    "    return result\n",
    "\n",
    "get_rule_jobs_cw_urls(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the last two cells over and until `VanishingGradient` reports `IssuesFound`, we'll attempt to describe the `TrainingJobStatus` for our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopped'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.describe()[\"TrainingJobStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "This notebook attempted to show a very simple setup of how you can use CloudWatch events for your training job to take action on rule evaluation status changes. Learn more about Amazon SageMaker Debugger in the [GitHub Documentation](https://github.com/awslabs/sagemaker-debugger)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
