{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3==1.16.40 in /root/.local/lib/python3.7/site-packages (1.16.40)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3==1.16.40) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.40 in /root/.local/lib/python3.7/site-packages (from boto3==1.16.40) (1.19.47)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3==1.16.40) (0.3.4)\n",
      "Collecting sagemaker==2.21.0\n",
      "  Using cached sagemaker-2.21.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.21.0) (0.1.5)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.21.0) (19.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.21.0) (20.1)\n",
      "Requirement already satisfied: google-pasta in /root/.local/lib/python3.7/site-packages (from sagemaker==2.21.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.21.0) (1.18.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.0 in /root/.local/lib/python3.7/site-packages (from sagemaker==2.21.0) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.21.0) (1.5.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.21.0) (3.14.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.40->boto3==1.16.40) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.40->boto3==1.16.40) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker==2.21.0) (2.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.21.0) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.21.0) (2.4.6)\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.20.0\n",
      "    Uninstalling sagemaker-2.20.0:\n",
      "      Successfully uninstalled sagemaker-2.20.0\n",
      "Successfully installed sagemaker-2.21.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install sagemaker==2.21.0 boto3==1.16.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "output_path             -> 's3://sagemaker-us-east-2-645431112437/export-flow\n",
      "timestamp               -> '2021-02-01-17-10'\n"
     ]
    }
   ],
   "source": [
    "# %store -z\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.lineage import context, artifact, association, action\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "\n",
    "from model_package_src.inference_specification import InferenceSpecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sagemaker.__version__ >= '2.21.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-east-2\"\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing timestamp: 2021-02-01-17-10\n"
     ]
    }
   ],
   "source": [
    "if 'timestamp' not in locals():\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "    %store timestamp\n",
    "else:\n",
    "    print(f'Using existing timestamp: {timestamp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "\n",
    "The data comes from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Online+Retail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274399, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Description_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3650,[1817],[1.0])</td>\n",
       "      <td>(4327,[109],[1.0])</td>\n",
       "      <td>(38,[5],[1.0])</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12</td>\n",
       "      <td>(2231,[1354,1495,1503],[1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3650,[1817],[1.0])</td>\n",
       "      <td>(4327,[2314],[1.0])</td>\n",
       "      <td>(38,[4],[1.0])</td>\n",
       "      <td>0.85</td>\n",
       "      <td>24</td>\n",
       "      <td>(2231,[1354,1495,1503],[1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3650,[1817],[1.0])</td>\n",
       "      <td>(4327,[584],[1.0])</td>\n",
       "      <td>(38,[2],[1.0])</td>\n",
       "      <td>0.85</td>\n",
       "      <td>48</td>\n",
       "      <td>(2231,[1354,1495,1503],[1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3650,[1817],[1.0])</td>\n",
       "      <td>(4327,[214],[1.0])</td>\n",
       "      <td>(38,[2],[1.0])</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12</td>\n",
       "      <td>(2231,[1354,1495,1503],[1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(3650,[1817],[1.0])</td>\n",
       "      <td>(4327,[1934],[1.0])</td>\n",
       "      <td>(38,[1],[1.0])</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>(2231,[1354,1495,1503],[1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             StockCode           CustomerID         Country  UnitPrice  \\\n",
       "0  (3650,[1817],[1.0])   (4327,[109],[1.0])  (38,[5],[1.0])       0.85   \n",
       "1  (3650,[1817],[1.0])  (4327,[2314],[1.0])  (38,[4],[1.0])       0.85   \n",
       "2  (3650,[1817],[1.0])   (4327,[584],[1.0])  (38,[2],[1.0])       0.85   \n",
       "3  (3650,[1817],[1.0])   (4327,[214],[1.0])  (38,[2],[1.0])       0.85   \n",
       "4  (3650,[1817],[1.0])  (4327,[1934],[1.0])  (38,[1],[1.0])       0.85   \n",
       "\n",
       "   Quantity                   Description_features  \n",
       "0        12  (2231,[1354,1495,1503],[1.0,1.0,1.0])  \n",
       "1        24  (2231,[1354,1495,1503],[1.0,1.0,1.0])  \n",
       "2        48  (2231,[1354,1495,1503],[1.0,1.0,1.0])  \n",
       "3        12  (2231,[1354,1495,1503],[1.0,1.0,1.0])  \n",
       "4         1  (2231,[1354,1495,1503],[1.0,1.0,1.0])  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wr.s3.read_csv(output_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(dataframe):      \n",
    "    n_rows = dataframe.shape[0]\n",
    "    n_customers = int(dataframe['CustomerID'][0].split(',')[0].strip('()'))\n",
    "    n_items = int(dataframe['StockCode'][0].split(',')[0].strip('()'))\n",
    "    n_countries = int(dataframe['Country'][0].split(',')[0].strip('()'))\n",
    "    n_tokens = int(dataframe['Description_features'][0].split(',')[0].strip('()'))\n",
    "    n_features = n_customers + n_items + n_countries + n_tokens + 1   # plus one is for the UnitPrice feature\n",
    "    \n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((n_rows, n_features)).astype('float32')\n",
    "    # Labels are stored in a vector\n",
    "    y = []\n",
    "    \n",
    "    for ix, row in dataframe.iterrows():\n",
    "        desc = row['Description_features']\n",
    "        \n",
    "        X[ix, 0] = row['UnitPrice']\n",
    "        X[ix, int(row['CustomerID'].split(',')[1].strip('[]')) + 1] = 1\n",
    "        X[ix, n_customers + int(row['StockCode'].split(',')[1].strip('[]')) + 1] = 1\n",
    "        X[ix, n_customers + n_items + int(row['Country'].split(',')[1].strip('[]')) + 1] = 1\n",
    "        \n",
    "        for col_idx in desc.split(',[')[1].strip(']').split(','):\n",
    "            X[ix, n_customers + n_items + n_countries + int(col_idx) + 1] = 1\n",
    "        \n",
    "        y.append(row['Quantity'])\n",
    "            \n",
    "    y=np.array(y).astype('float32')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((219519, 10247), (54880, 10247), (219519,), (54880,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'personalization'\n",
    "\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = f'{prefix}/train'\n",
    "\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = f'{prefix}/test'\n",
    "\n",
    "output_prefix  = f's3://{bucket}/{prefix}/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-645431112437/personalization/train/train.protobuf\n",
      "s3://sagemaker-us-east-2-645431112437/personalization/test/test.protobuf\n",
      "Output: s3://sagemaker-us-east-2-645431112437/personalization/output\n"
     ]
    }
   ],
   "source": [
    "def writeDatasetToProtobuf(X, y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, y_train, bucket, train_prefix, train_key)    \n",
    "test_data  = writeDatasetToProtobuf(X_test, y_test, bucket, test_prefix, test_key)    \n",
    "  \n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\", region=boto_session.region_name)\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   sagemaker_role, \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.c5.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sagemaker_session)\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=X_train.shape[1],\n",
    "                       predictor_type='regressor',\n",
    "                       mini_batch_size=1000,\n",
    "                       num_factors=64,\n",
    "                       epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 17:27:02 Starting - Starting the training job...\n",
      "2021-02-01 17:27:25 Starting - Launching requested ML instancesProfilerReport-1612200422: InProgress\n",
      "......\n",
      "2021-02-01 17:28:26 Starting - Preparing the instances for training...\n",
      "2021-02-01 17:28:46 Downloading - Downloading input data\n",
      "2021-02-01 17:28:46 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'20', u'feature_dim': u'10247', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'64'}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'20', u'feature_dim': u'10247', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 WARNING 140187809592704] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] Using default worker.\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:09.735] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:09.742] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 11, \"num_examples\": 1, \"num_bytes\": 101496}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] nvidia-smi took: 0.0251522064209 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 40.36378860473633, \"sum\": 40.36378860473633, \"min\": 40.36378860473633}}, \"EndTime\": 1612200549.781641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200549.731112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1612200549.781808, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200549.781771}\n",
      "\u001b[0m\n",
      "\u001b[34m[17:29:09] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204161.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[17:29:09] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204161.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=72.2251929731\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=5216.4785\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:09 INFO 140187809592704] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=17.6237460938\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:12.520] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 2707, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=91.1976463761\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #quality_metric: host=algo-1, epoch=0, train mse <loss>=8317.01070455\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=16.1903739213\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"update.time\": {\"count\": 1, \"max\": 2739.2499446868896, \"sum\": 2739.2499446868896, \"min\": 2739.2499446868896}}, \"EndTime\": 1612200552.521226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200549.781712}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 221, \"sum\": 221.0, \"min\": 221}, \"Total Records Seen\": {\"count\": 1, \"max\": 220519, \"sum\": 220519.0, \"min\": 220519}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1612200552.521388, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1612200549.781955}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=80130.4935458 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=70.0422265494\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=4905.9135\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:12 INFO 140187809592704] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=17.4677597656\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:14.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 2440, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=90.585931433\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #quality_metric: host=algo-1, epoch=1, train mse <loss>=8205.81097358\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=18.4109912953\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2441.856861114502, \"sum\": 2441.856861114502, \"min\": 2441.856861114502}}, \"EndTime\": 1612200554.964276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200552.521283}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 441, \"sum\": 441.0, \"min\": 441}, \"Total Records Seen\": {\"count\": 1, \"max\": 440038, \"sum\": 440038.0, \"min\": 440038}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1612200554.96442, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1612200552.522396}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=89887.8492611 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=69.8522261635\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=4879.3335\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:14 INFO 140187809592704] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=18.5177011719\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:17.356] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 2389, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=90.4347749731\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #quality_metric: host=algo-1, epoch=2, train mse <loss>=8178.44852443\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=18.5039464045\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2391.464948654175, \"sum\": 2391.464948654175, \"min\": 2391.464948654175}}, \"EndTime\": 1612200557.357098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200554.964337}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 661, \"sum\": 661.0, \"min\": 661}, \"Total Records Seen\": {\"count\": 1, \"max\": 659557, \"sum\": 659557.0, \"min\": 659557}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1612200557.357302, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1612200554.965604}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=91779.8704951 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=69.6672448142\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=4853.525\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:17 INFO 140187809592704] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=18.2606367187\u001b[0m\n",
      "\n",
      "2021-02-01 17:29:27 Training - Training image download completed. Training in progress.\u001b[34m[2021-02-01 17:29:19.848] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 2488, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=90.2783013844\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #quality_metric: host=algo-1, epoch=3, train mse <loss>=8150.17170085\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=18.1590187411\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2490.036964416504, \"sum\": 2490.036964416504, \"min\": 2490.036964416504}}, \"EndTime\": 1612200559.848416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200557.357167}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 881, \"sum\": 881.0, \"min\": 881}, \"Total Records Seen\": {\"count\": 1, \"max\": 879076, \"sum\": 879076.0, \"min\": 879076}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1612200559.848573, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1612200557.358352}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=88148.5593026 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=69.4958883676\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=4829.6785\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:19 INFO 140187809592704] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=18.005828125\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:22.151] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 2299, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=90.1369597915\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #quality_metric: host=algo-1, epoch=4, train mse <loss>=8124.67152045\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=17.9132543901\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2301.5379905700684, \"sum\": 2301.5379905700684, \"min\": 2301.5379905700684}}, \"EndTime\": 1612200562.151657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200559.848487}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1101, \"sum\": 1101.0, \"min\": 1101}, \"Total Records Seen\": {\"count\": 1, \"max\": 1098595, \"sum\": 1098595.0, \"min\": 1098595}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1612200562.151817, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1612200559.850092}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=95367.5375397 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=69.3436947386\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=4808.548\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:22 INFO 140187809592704] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=17.8287226563\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:24.542] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 2388, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=90.0108378867\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #quality_metric: host=algo-1, epoch=5, train mse <loss>=8101.95093707\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=17.7494947665\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2390.3250694274902, \"sum\": 2390.3250694274902, \"min\": 2390.3250694274902}}, \"EndTime\": 1612200564.543375, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200562.151721}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1321, \"sum\": 1321.0, \"min\": 1321}, \"Total Records Seen\": {\"count\": 1, \"max\": 1318114, \"sum\": 1318114.0, \"min\": 1318114}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1612200564.54356, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1612200562.153022}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=91824.6298137 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=69.2108589746\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=4790.143\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:24 INFO 140187809592704] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=17.7030917969\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:26.871] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 2326, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=89.8964044345\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #quality_metric: host=algo-1, epoch=6, train mse <loss>=8081.36353026\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=17.6211421298\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2327.620029449463, \"sum\": 2327.620029449463, \"min\": 2327.620029449463}}, \"EndTime\": 1612200566.872186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200564.543434}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1541, \"sum\": 1541.0, \"min\": 1541}, \"Total Records Seen\": {\"count\": 1, \"max\": 1537633, \"sum\": 1537633.0, \"min\": 1537633}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1612200566.872395, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1612200564.544537}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=94296.7227304 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=69.0962734162\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=4774.295\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:26 INFO 140187809592704] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=17.6248300781\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:29.250] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 2376, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=89.7916852256\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #quality_metric: host=algo-1, epoch=7, train mse <loss>=8062.54673565\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=17.5246430487\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2377.648115158081, \"sum\": 2377.648115158081, \"min\": 2377.648115158081}}, \"EndTime\": 1612200569.251109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200566.872257}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1761, \"sum\": 1761.0, \"min\": 1761}, \"Total Records Seen\": {\"count\": 1, \"max\": 1757152, \"sum\": 1757152.0, \"min\": 1757152}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1612200569.251289, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1612200566.873435}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=92314.1496191 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=68.9955071001\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=4760.38\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:29 INFO 140187809592704] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=17.5460097656\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:31.536] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 2282, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=89.6954630073\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #quality_metric: host=algo-1, epoch=8, train mse <loss>=8045.27608409\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=17.4535125266\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2284.442901611328, \"sum\": 2284.442901611328, \"min\": 2284.442901611328}}, \"EndTime\": 1612200571.536789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200569.251162}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1981, \"sum\": 1981.0, \"min\": 1981}, \"Total Records Seen\": {\"count\": 1, \"max\": 1976671, \"sum\": 1976671.0, \"min\": 1976671}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1612200571.536988, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1612200569.252322}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=96079.5454964 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=68.9033235773\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=4747.668\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:31 INFO 140187809592704] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=17.4690410156\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:33.954] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 2415, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=89.6075889081\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #quality_metric: host=algo-1, epoch=9, train mse <loss>=8029.51998991\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=17.3974170632\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2416.696071624756, \"sum\": 2416.696071624756, \"min\": 2416.696071624756}}, \"EndTime\": 1612200573.954717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200571.536842}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2201, \"sum\": 2201.0, \"min\": 2201}, \"Total Records Seen\": {\"count\": 1, \"max\": 2196190, \"sum\": 2196190.0, \"min\": 2196190}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1612200573.954874, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1612200571.537998}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=90824.2717251 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=68.8168366027\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=4735.757\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:33 INFO 140187809592704] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=17.4101503906\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:36.341] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 2384, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=89.5254025807\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #quality_metric: host=algo-1, epoch=10, train mse <loss>=8014.79770724\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=17.3460247425\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2386.2640857696533, \"sum\": 2386.2640857696533, \"min\": 2386.2640857696533}}, \"EndTime\": 1612200576.342271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200573.954786}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2421, \"sum\": 2421.0, \"min\": 2421}, \"Total Records Seen\": {\"count\": 1, \"max\": 2415709, \"sum\": 2415709.0, \"min\": 2415709}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1612200576.342417, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1612200573.955983}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=91982.964242 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=68.7353111581\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=4724.543\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:36 INFO 140187809592704] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=17.3666835938\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:38.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 2334, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=89.44866561\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #quality_metric: host=algo-1, epoch=11, train mse <loss>=8001.0637794\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=17.3014747115\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2335.8089923858643, \"sum\": 2335.8089923858643, \"min\": 2335.8089923858643}}, \"EndTime\": 1612200578.679393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200576.342332}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2641, \"sum\": 2641.0, \"min\": 2641}, \"Total Records Seen\": {\"count\": 1, \"max\": 2635228, \"sum\": 2635228.0, \"min\": 2635228}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1612200578.679539, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1612200576.34356}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=93969.6057052 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=68.6586192695\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=4714.006\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:38 INFO 140187809592704] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=17.3148261719\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:41.038] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 2356, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=89.3768527152\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #quality_metric: host=algo-1, epoch=12, train mse <loss>=7988.22180128\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=17.261515767\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2357.738971710205, \"sum\": 2357.738971710205, \"min\": 2357.738971710205}}, \"EndTime\": 1612200581.038458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200578.679451}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2861, \"sum\": 2861.0, \"min\": 2861}, \"Total Records Seen\": {\"count\": 1, \"max\": 2854747, \"sum\": 2854747.0, \"min\": 2854747}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1612200581.038608, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1612200578.680694}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=93095.4935694 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=68.5861866559\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=4704.065\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:41 INFO 140187809592704] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=17.2605605469\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:43.344] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 2303, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=89.3091719114\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #quality_metric: host=algo-1, epoch=13, train mse <loss>=7976.1281875\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=17.223388481\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2304.7409057617188, \"sum\": 2304.7409057617188, \"min\": 2304.7409057617188}}, \"EndTime\": 1612200583.344538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200581.03852}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3081, \"sum\": 3081.0, \"min\": 3081}, \"Total Records Seen\": {\"count\": 1, \"max\": 3074266, \"sum\": 3074266.0, \"min\": 3074266}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1612200583.344685, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1612200581.03977}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=95235.5527852 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=68.5168957265\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=4694.565\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:43 INFO 140187809592704] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=17.2162519531\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:45.749] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 2402, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=89.2452422226\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #quality_metric: host=algo-1, epoch=14, train mse <loss>=7964.71325938\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=17.1900720969\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2404.0188789367676, \"sum\": 2404.0188789367676, \"min\": 2404.0188789367676}}, \"EndTime\": 1612200585.749881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200583.344598}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3301, \"sum\": 3301.0, \"min\": 3301}, \"Total Records Seen\": {\"count\": 1, \"max\": 3293785, \"sum\": 3293785.0, \"min\": 3293785}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1612200585.750021, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1612200583.345835}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=91303.7263439 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=68.4515193403\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=4685.6105\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:45 INFO 140187809592704] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=17.1730625\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:48.079] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 2327, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=89.1845200767\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #quality_metric: host=algo-1, epoch=15, train mse <loss>=7953.87862131\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=17.1559468129\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2328.8521766662598, \"sum\": 2328.8521766662598, \"min\": 2328.8521766662598}}, \"EndTime\": 1612200588.080039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200585.749938}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3521, \"sum\": 3521.0, \"min\": 3521}, \"Total Records Seen\": {\"count\": 1, \"max\": 3513304, \"sum\": 3513304.0, \"min\": 3513304}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1612200588.080178, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1612200585.751162}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=94250.611788 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=68.3886905855\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=4677.013\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:48 INFO 140187809592704] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=17.1511132813\u001b[0m\n",
      "\n",
      "2021-02-01 17:29:59 Uploading - Uploading generated training model\u001b[34m[2021-02-01 17:29:50.522] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 2439, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=89.1266728502\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #quality_metric: host=algo-1, epoch=16, train mse <loss>=7943.56381335\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=17.127028449\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2441.3700103759766, \"sum\": 2441.3700103759766, \"min\": 2441.3700103759766}}, \"EndTime\": 1612200590.522753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200588.080094}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3741, \"sum\": 3741.0, \"min\": 3741}, \"Total Records Seen\": {\"count\": 1, \"max\": 3732823, \"sum\": 3732823.0, \"min\": 3732823}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1612200590.522942, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1612200588.081356}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=89904.8242084 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=68.32992024\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=4668.978\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:50 INFO 140187809592704] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=17.1077949219\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:52.849] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 2324, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=89.0712234675\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #quality_metric: host=algo-1, epoch=17, train mse <loss>=7933.68285\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=17.0970558771\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2325.601100921631, \"sum\": 2325.601100921631, \"min\": 2325.601100921631}}, \"EndTime\": 1612200592.849567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200590.522803}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3961, \"sum\": 3961.0, \"min\": 3961}, \"Total Records Seen\": {\"count\": 1, \"max\": 3952342, \"sum\": 3952342.0, \"min\": 3952342}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1612200592.849705, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1612200590.523941}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=94382.2297457 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=68.2733513166\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=4661.2505\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:52 INFO 140187809592704] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=17.0817890625\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:55.176] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 2324, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=89.0183242755\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #quality_metric: host=algo-1, epoch=18, train mse <loss>=7924.26205682\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=17.0706506481\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2325.671911239624, \"sum\": 2325.671911239624, \"min\": 2325.671911239624}}, \"EndTime\": 1612200595.176536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200592.849621}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4181, \"sum\": 4181.0, \"min\": 4181}, \"Total Records Seen\": {\"count\": 1, \"max\": 4171861, \"sum\": 4171861.0, \"min\": 4171861}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1612200595.176676, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1612200592.850841}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=94379.5014904 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=68.2199970683\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=4653.968\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:55 INFO 140187809592704] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=17.0528652344\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:57.470] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 2291, \"num_examples\": 220, \"num_bytes\": 22227276}\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=88.9675074242\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, epoch=19, train mse <loss>=7915.21737727\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=17.0465397505\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, train rmse <loss>=88.9675074242\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, train mse <loss>=7915.21737727\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, train absolute_loss <loss>=17.0465397505\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2293.55788230896, \"sum\": 2293.55788230896, \"min\": 2293.55788230896}}, \"EndTime\": 1612200597.471461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200595.176592}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 220, \"sum\": 220.0, \"min\": 220}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4401, \"sum\": 4401.0, \"min\": 4401}, \"Total Records Seen\": {\"count\": 1, \"max\": 4391380, \"sum\": 4391380.0, \"min\": 4391380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 219519, \"sum\": 219519.0, \"min\": 219519}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1612200597.471601, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1612200595.177877}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #throughput_metric: host=algo-1, train throughput=95700.5975381 records/second\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 WARNING 140187809592704] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2.5658607482910156, \"sum\": 2.5658607482910156, \"min\": 2.5658607482910156}}, \"EndTime\": 1612200597.474346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200597.471518}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] Saved checkpoint to \"/tmp/tmpxJO_gR/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:57.488] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 47753, \"num_examples\": 1, \"num_bytes\": 101420}\u001b[0m\n",
      "\u001b[34m[2021-02-01 17:29:57.696] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 208, \"num_examples\": 55, \"num_bytes\": 5555672}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 54880, \"sum\": 54880.0, \"min\": 54880}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}, \"Total Records Seen\": {\"count\": 1, \"max\": 54880, \"sum\": 54880.0, \"min\": 54880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 54880, \"sum\": 54880.0, \"min\": 54880}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1612200597.697216, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200597.488404}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #test_score (algo-1) : ('rmse', 67.83486679541969)\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #test_score (algo-1) : ('mse', 4601.569153152333)\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #test_score (algo-1) : ('absolute_loss', 16.85146811793914)\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, test rmse <loss>=67.8348667954\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, test mse <loss>=4601.56915315\u001b[0m\n",
      "\u001b[34m[02/01/2021 17:29:57 INFO 140187809592704] #quality_metric: host=algo-1, test absolute_loss <loss>=16.8514681179\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 48007.511138916016, \"sum\": 48007.511138916016, \"min\": 48007.511138916016}, \"setuptime\": {\"count\": 1, \"max\": 37.12606430053711, \"sum\": 37.12606430053711, \"min\": 37.12606430053711}}, \"EndTime\": 1612200597.698219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1612200597.474415}\n",
      "\u001b[0m\n",
      "\n",
      "2021-02-01 17:30:27 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 87\n",
      "Stored 'training_job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "if 'training_job_name' not in locals():\n",
    "    \n",
    "    fm.fit({'train': train_data, 'test': test_data})\n",
    "    training_job_name = fm.latest_training_job.job_name\n",
    "    %store training_job_name\n",
    "    \n",
    "else:\n",
    "    print(f'Using previous training job: {training_job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-2:645431112437:artifact/cdd7fbecb4eefa22c43b2ad48140acc2\n"
     ]
    }
   ],
   "source": [
    "training_data_s3_uri = training_job_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "matching_artifacts = list(artifact.Artifact.list(\n",
    "    source_uri=training_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    training_data_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {training_data_artifact.artifact_arn}')\n",
    "else:\n",
    "    training_data_artifact = artifact.Artifact.create(\n",
    "        artifact_name='TrainingData',\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type='Dataset',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-2:645431112437:artifact/34578c9e5251ea3f609cb909fff9b782\n"
     ]
    }
   ],
   "source": [
    "trained_model_s3_uri = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "matching_artifacts = list(artifact.Artifact.list(\n",
    "    source_uri=trained_model_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    model_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {model_artifact.artifact_arn}')\n",
    "else:\n",
    "    model_artifact = artifact.Artifact.create(\n",
    "        artifact_name='TrainedModel',\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type='Model',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {model_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set artifact associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(TrialComponentName=training_job_name+'-aws-training-job')\n",
    "trial_component_arn = trial_component['TrialComponentArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association already exists with DataSet\n",
      "Association with Model: SUCCEESFUL\n"
     ]
    }
   ],
   "source": [
    "artifact_list = (\n",
    "                 (training_data_artifact, 'ContributedTo'),\n",
    "                 (model_artifact, 'Produced')\n",
    ")\n",
    "\n",
    "for artifact, assoc in artifact_list:\n",
    "    try:\n",
    "        association.Association.create(\n",
    "            source_arn=artifact.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type=assoc,\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {artifact.artifact_type}: SUCCEESFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {artifact.artifact_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model retail-recommendations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: retail-recommendations\n"
     ]
    }
   ],
   "source": [
    "model_name = 'retail-recommendations'\n",
    "model_matches = sagemaker_boto_client.list_models(NameContains=model_name)['Models']\n",
    "\n",
    "if not model_matches:\n",
    "    print(f'Creating model {model_name}')\n",
    "    model = sagemaker_session.create_model_from_job(\n",
    "        name=model_name,\n",
    "        training_job_name=training_job_info['TrainingJobName'],\n",
    "        role=sagemaker_role,\n",
    "        image_uri=training_job_info['AlgorithmSpecification']['TrainingImage'])\n",
    "else:\n",
    "    \n",
    "    print(f\"Model {model_name} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model Registry\n",
    "\n",
    "Once a useful model has been trained and its artifacts properly associated, the next step is to register the model for future reference and possible deployment.\n",
    "\n",
    "### Create Model Package Group\n",
    "\n",
    "A Model Package Groups holds multiple versions or iterations of a model. Though it is not required to create them for every model in the registry, they help organize various models which all have the same purpose and provide autiomatic versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mpg_name' (str)\n",
      "Model Package Group name: retail-recommendation-2021-02-01-17-10\n"
     ]
    }
   ],
   "source": [
    "if 'mpg_name' not in locals():\n",
    "    mpg_name = f'retail-recommendation-{timestamp}'\n",
    "    %store mpg_name\n",
    "\n",
    "print(f'Model Package Group name: {mpg_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageGroupDescription': 'Recommendation for Online Retail Sales'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Model Package Group retail-recommendation-2021-02-01-17-10: SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "matching_mpg = sagemaker_boto_client.list_model_package_groups(NameContains=mpg_name)['ModelPackageGroupSummaryList']\n",
    "\n",
    "if matching_mpg:\n",
    "    print(f'Using existing Model Package Group: {mpg_name}')\n",
    "else:\n",
    "    mpg_response = sagemaker_boto_client.create_model_package_group(**mpg_input_dict)\n",
    "    print(f'Create Model Package Group {mpg_name}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {\n",
    "    'regression_metrics': {}\n",
    "}\n",
    "\n",
    "for metric in training_job_info['FinalMetricDataList']:\n",
    "    stat = {\n",
    "        metric['MetricName']: {\n",
    "            'value': metric['Value']\n",
    "        }\n",
    "    }\n",
    "    model_metrics_report['regression_metrics'].update(stat)\n",
    "    \n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "    \n",
    "metrics_s3_key = f\"training_jobs/{training_job_info['TrainingJobName']}/training_metrics.json\"\n",
    "s3_client.upload_file(Filename='training_metrics.json', Bucket=bucket, Key=metrics_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the inference spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_inference_spec = InferenceSpecification().get_inference_specification_dict(\n",
    "    ecr_image=training_job_info['AlgorithmSpecification']['TrainingImage'],\n",
    "    supports_gpu=False,\n",
    "    supported_content_types=['application/x-recordio-protobuf', 'application/json'],\n",
    "    supported_mime_types=['text/csv'])\n",
    "\n",
    "mp_inference_spec['InferenceSpecification']['Containers'][0]['ModelDataUrl'] = training_job_info['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model metrics\n",
    "Metrics other than model quality can be defined. See the Boto3 documentation for [creating a model package](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model_package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'ModelQuality': {\n",
    "        'Statistics': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f's3://{bucket}/{metrics_s3_key}'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageDescription': 'Factorization Machine Model to create personalized retail recommendations',\n",
    "    'ModelApprovalStatus': 'PendingManualApproval',\n",
    "    'ModelMetrics': model_metrics\n",
    "}\n",
    "\n",
    "mp_input_dict.update(mp_inference_spec)\n",
    "mp_response = sagemaker_boto_client.create_model_package(**mp_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait until model package is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model package status: Completed\n"
     ]
    }
   ],
   "source": [
    "mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp_response['ModelPackageArn'])\n",
    "mp_status = mp_info['ModelPackageStatus']\n",
    "\n",
    "while mp_status not in ['Completed', 'Failed']:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp_response['ModelPackageArn'])\n",
    "    mp_status = mp_info['ModelPackageStatus']\n",
    "    print(f'model package status: {mp_status}')\n",
    "print(f'model package status: {mp_status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList'][0]\n",
    "model_package_update = {\n",
    "    'ModelPackageArn': model_package['ModelPackageArn'],\n",
    "    'ModelApprovalStatus': 'Approved'\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create endpoint config and endpoint__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {'ModelPackageName': model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_name}-endpoint-config'\n",
    "existing_configs = sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name)['EndpointConfigs']\n",
    "\n",
    "if not existing_configs:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': 'ml.m4.xlarge',\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'ModelName': model_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name\n",
    "\n",
    "endpoint_name = f'{model_name}-endpoint'\n",
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name)['Endpoints']\n",
    "\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "Here we will take a single customer and try to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "class FMSerializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "        js = {'instances': []}\n",
    "        for row in data:\n",
    "              js['instances'].append({'features': row.tolist()})\n",
    "        return json.dumps(js)\n",
    "\n",
    "fm_predictor = fm.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=FMSerializer(),\n",
    "    deserializer= JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "popular_items = df.groupby(['StockCode', 'UnitPrice']).nunique()['CustomerID'].sort_values(ascending=False).reset_index()\n",
    "top_n_items = popular_items['StockCode'].iloc[:n].values\n",
    "top_n_prices = popular_items['UnitPrice'].iloc[:n].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock codes can have multiple descriptions, so we will choose whichever description is most common\n",
    "item_desc_map = df.groupby('StockCode').agg(lambda x: x.value_counts().index[0])['Description_features']\n",
    "customer_id = df.iloc[0]['CustomerID']\n",
    "country = df.iloc[0]['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'StockCode': top_n_items,\n",
    "        'Description_features': [item_desc_map[i] for i in top_n_items],\n",
    "        'CustomerID': customer_id,\n",
    "        'Country': country,\n",
    "        'UnitPrice': top_n_prices,\n",
    "       }\n",
    "\n",
    "df_inference = pd.DataFrame(data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Description_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3650,[0],[1.0])</td>\n",
       "      <td>(4327,[109],[1.0])</td>\n",
       "      <td>(38,[5],[1.0])</td>\n",
       "      <td>12.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2231,[15,58,148,214],[1.0,1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3650,[1],[1.0])</td>\n",
       "      <td>(4327,[109],[1.0])</td>\n",
       "      <td>(38,[5],[1.0])</td>\n",
       "      <td>2.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2231,[4,13,19,20,25],[1.0,1.0,1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3650,[4],[1.0])</td>\n",
       "      <td>(4327,[109],[1.0])</td>\n",
       "      <td>(38,[5],[1.0])</td>\n",
       "      <td>1.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2231,[60,77,89,337],[1.0,1.0,1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3650,[3],[1.0])</td>\n",
       "      <td>(4327,[109],[1.0])</td>\n",
       "      <td>(38,[5],[1.0])</td>\n",
       "      <td>4.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2231,[65,66],[1.0,1.0])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(3650,[6],[1.0])</td>\n",
       "      <td>(4327,[109],[1.0])</td>\n",
       "      <td>(38,[5],[1.0])</td>\n",
       "      <td>4.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2231,[0,1,8,12,15,46,68],[1.0,1.0,1.0,1.0,1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          StockCode          CustomerID         Country  UnitPrice Quantity  \\\n",
       "0  (3650,[0],[1.0])  (4327,[109],[1.0])  (38,[5],[1.0])      12.75      NaN   \n",
       "1  (3650,[1],[1.0])  (4327,[109],[1.0])  (38,[5],[1.0])       2.95      NaN   \n",
       "2  (3650,[4],[1.0])  (4327,[109],[1.0])  (38,[5],[1.0])       1.69      NaN   \n",
       "3  (3650,[3],[1.0])  (4327,[109],[1.0])  (38,[5],[1.0])       4.95      NaN   \n",
       "4  (3650,[6],[1.0])  (4327,[109],[1.0])  (38,[5],[1.0])       4.95      NaN   \n",
       "\n",
       "                                Description_features  \n",
       "0           (2231,[15,58,148,214],[1.0,1.0,1.0,1.0])  \n",
       "1       (2231,[4,13,19,20,25],[1.0,1.0,1.0,1.0,1.0])  \n",
       "2            (2231,[60,77,89,337],[1.0,1.0,1.0,1.0])  \n",
       "3                           (2231,[65,66],[1.0,1.0])  \n",
       "4  (2231,[0,1,8,12,15,46,68],[1.0,1.0,1.0,1.0,1.0...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inference, _ = loadDataset(df_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 15.505157470703125},\n",
       "  {'score': 45.32623291015625},\n",
       "  {'score': 47.73848342895508},\n",
       "  {'score': 19.60230255126953},\n",
       "  {'score': 16.89789581298828},\n",
       "  {'score': 51.341312408447266},\n",
       "  {'score': 18.874170303344727},\n",
       "  {'score': 17.15357208251953},\n",
       "  {'score': 12.38580322265625},\n",
       "  {'score': 26.633277893066406},\n",
       "  {'score': 32.23994445800781},\n",
       "  {'score': 30.322702407836914},\n",
       "  {'score': 47.75290298461914},\n",
       "  {'score': 37.8108024597168},\n",
       "  {'score': 26.108715057373047},\n",
       "  {'score': 8.026677131652832},\n",
       "  {'score': 18.226085662841797},\n",
       "  {'score': 13.117279052734375},\n",
       "  {'score': 29.297754287719727},\n",
       "  {'score': 31.275550842285156},\n",
       "  {'score': 30.882699966430664},\n",
       "  {'score': 25.639904022216797},\n",
       "  {'score': 20.291793823242188},\n",
       "  {'score': 34.24357604980469},\n",
       "  {'score': 18.868614196777344},\n",
       "  {'score': 28.178415298461914},\n",
       "  {'score': 34.03327560424805},\n",
       "  {'score': 16.524681091308594},\n",
       "  {'score': 31.802452087402344},\n",
       "  {'score': 26.684755325317383},\n",
       "  {'score': 29.63349723815918},\n",
       "  {'score': 31.846355438232422},\n",
       "  {'score': 32.29933547973633},\n",
       "  {'score': 13.866256713867188},\n",
       "  {'score': 50.921932220458984},\n",
       "  {'score': 40.04170227050781},\n",
       "  {'score': 22.970046997070312},\n",
       "  {'score': 33.30854415893555},\n",
       "  {'score': 40.72761535644531},\n",
       "  {'score': 32.72574996948242},\n",
       "  {'score': 23.55836296081543},\n",
       "  {'score': 35.30560302734375},\n",
       "  {'score': 23.40084457397461},\n",
       "  {'score': 21.242700576782227},\n",
       "  {'score': 21.774507522583008},\n",
       "  {'score': 17.197410583496094},\n",
       "  {'score': 31.960025787353516},\n",
       "  {'score': 32.18149185180664},\n",
       "  {'score': 19.432506561279297},\n",
       "  {'score': 38.7131462097168},\n",
       "  {'score': 9.188278198242188},\n",
       "  {'score': 25.14911651611328},\n",
       "  {'score': 29.830078125},\n",
       "  {'score': 25.823396682739258},\n",
       "  {'score': 15.287254333496094},\n",
       "  {'score': 38.36104965209961},\n",
       "  {'score': 41.13426971435547},\n",
       "  {'score': 18.46837615966797},\n",
       "  {'score': 26.540782928466797},\n",
       "  {'score': 15.052696228027344},\n",
       "  {'score': 35.867008209228516},\n",
       "  {'score': 29.193403244018555},\n",
       "  {'score': 14.894430160522461},\n",
       "  {'score': 35.610107421875},\n",
       "  {'score': 33.41218185424805},\n",
       "  {'score': 25.1015625},\n",
       "  {'score': 21.634138107299805},\n",
       "  {'score': 23.652503967285156},\n",
       "  {'score': 29.852153778076172},\n",
       "  {'score': 26.66362762451172},\n",
       "  {'score': 39.867889404296875},\n",
       "  {'score': 23.81863784790039},\n",
       "  {'score': 24.383670806884766},\n",
       "  {'score': 20.61553955078125},\n",
       "  {'score': 19.051420211791992},\n",
       "  {'score': 34.95948791503906},\n",
       "  {'score': 10.921318054199219},\n",
       "  {'score': 38.57939147949219},\n",
       "  {'score': 31.83325958251953},\n",
       "  {'score': 36.97489929199219},\n",
       "  {'score': 37.063636779785156},\n",
       "  {'score': 25.081520080566406},\n",
       "  {'score': 21.743349075317383},\n",
       "  {'score': 25.427915573120117},\n",
       "  {'score': 26.142824172973633},\n",
       "  {'score': 25.728530883789062},\n",
       "  {'score': 29.828725814819336},\n",
       "  {'score': 29.48556900024414},\n",
       "  {'score': 10.906341552734375},\n",
       "  {'score': 29.05748176574707},\n",
       "  {'score': 31.54995346069336},\n",
       "  {'score': 39.64269256591797},\n",
       "  {'score': 16.29904556274414},\n",
       "  {'score': 20.311866760253906},\n",
       "  {'score': 11.655982971191406},\n",
       "  {'score': 41.95033264160156},\n",
       "  {'score': 26.549665451049805},\n",
       "  {'score': 28.213478088378906},\n",
       "  {'score': 29.798030853271484},\n",
       "  {'score': 21.603498458862305}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fm_predictor.predict(X_inference.toarray())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 recommended products have Stock Numbers: ['(3650,[7],[1.0])' '(3650,[50],[1.0])' '(3650,[2],[1.0])'\n",
      " '(3650,[4],[1.0])' '(3650,[1],[1.0])']\n"
     ]
    }
   ],
   "source": [
    "preds = [i['score'] for i in result['predictions']]\n",
    "index_array = np.array(preds).argsort()\n",
    "top_5_recs = np.take_along_axis(np.array(top_n_items), index_array, axis=0)[:-6:-1]\n",
    "\n",
    "print(f'The top 5 recommended products have Stock Numbers: {top_5_recs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
