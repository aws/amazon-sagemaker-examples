{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use SageMaker Pipelines to Run Your Jobs Locally\n",
    "\n",
    "This notebook demonstrates how to orchestrate SageMaker jobs locally using SageMaker Pipelines. \n",
    "\n",
    "Using a `LocalPipelineSession` object, you can now run your pipelines on your local machine before running them in the cloud. \n",
    "\n",
    "The `LocalPipelineSession` object is used while defining each pipeline step and when defining the complete Pipeline object. To run this pipeline in the cloud, each step along with the Pipeline object must be redefined using `PipelineSession`.\n",
    "\n",
    "**Note**: This notebook will not run in SageMaker Studio. You can run this on SageMaker Classic Notebook instances OR your local IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines Local Mode\n",
    "\n",
    "SageMaker Pipelines Local Mode supports the following activities, which are demonstrated in this notebook:\n",
    "\n",
    "* ProcessingStep\n",
    "* TrainingStep\n",
    "* ConditionStep\n",
    "* ModelStep\n",
    "* TransformStep\n",
    "* FailStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset you use is the [UCI Machine Learning Abalone Dataset](https://archive.ics.uci.edu/ml/datasets/abalone) [1].  The aim for this task is to determine the age of an abalone snail from its physical measurements. At the core, this is a regression problem.\n",
    "\n",
    "The dataset contains several features: length (the longest shell measurement), diameter (the diameter perpendicular to length), height (the height with meat in the shell), whole_weight (the weight of whole abalone), shucked_weight (the weight of meat), viscera_weight (the gut weight after bleeding), shell_weight (the weight after being dried), sex ('M', 'F', 'I' where 'I' is Infant), and rings (integer).\n",
    "\n",
    "The number of rings turns out to be a good approximation for age (age is rings + 1.5). However, to obtain this number requires cutting the shell through the cone, staining the section, and counting the number of rings through a microscope, which is a time-consuming task. However, the other physical measurements are easier to determine. You use the dataset to build a predictive model of the variable rings through these other physical measurements.\n",
    "\n",
    "Before you upload the data to an S3 bucket, install the SageMaker Python SDK and gather some constants you can use later in this notebook.\n",
    "\n",
    "> [1] Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the latest version of the SageMaker Python SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'sagemaker' --upgrade\n",
    "!pip install -U ~/SageMaker/Blogs/LocalPipelines/SDK/sagemaker-2.96.1.dev0.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "\n",
    "# Create a `LocalPipelineSession` object so that each pipeline step will run locally\n",
    "# To run this pipeline in the cloud, you must change `LocalPipelineSession()` to `PipelineSession()`\n",
    "local_pipeline_session = LocalPipelineSession()\n",
    "\n",
    "region = local_pipeline_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = local_pipeline_session.default_bucket()\n",
    "prefix = \"sagemaker-pipelines-local-mode-example\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, upload the data into the default bucket. You can select our own data set for the `input_data_uri` as is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/abalone-data-set/abalone-dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Pull the dataset from SageMaker's public S3 bucket and upload it to your own S3 bucket\n",
    "\n",
    "local_path = \"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-sample-files\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/{prefix}/abalone-data-set\"\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat\n",
    "\n",
    "processing_instance_count = 1\n",
    "training_instance_count = 1\n",
    "transform_instance_count = 1\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Processing Step for Feature Engineering\n",
    "\n",
    "First, develop a preprocessing script that is specified in the Processing step.\n",
    "\n",
    "This notebook cell writes a file `preprocessing_abalone.py`, which contains the preprocessing script. You can update the script, and rerun this cell to overwrite. The preprocessing script uses `scikit-learn` to do the following:\n",
    "\n",
    "* Fill in missing sex category data and encode it so that it is suitable for training.\n",
    "* Scale and normalize all numerical fields, aside from sex and rings numerical data.\n",
    "* Split the data into training, validation, and test datasets.\n",
    "\n",
    "The Processing step executes the script on the input data. The Training step uses the preprocessed training features and labels to train a model. The Evaluation step uses the trained model and preprocessed test features and labels to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an instance of a `SKLearnProcessor` processor and use that in our `ProcessingStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we take the output of the processor's `run` method and pass that as arguments to the `ProcessingStep`. By passing the `local_pipeline_session` to the `sagemaker_session`, calling `.run()` does not launch the processing job, it returns the arguments needed to run the job as a step in the pipeline.\n",
    "\n",
    "Note the `\"train_data\"` and `\"test_data\"` named channels specified in the output configuration for the processing job. Step `Properties` can be used in subsequent steps and resolve to their runtime values at execution. Specifically, this usage is called out when you define the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sklearn-abalone-process-2022-08-22-16-26-51-482\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': ParameterString(name='InputData', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/abalone-data-set/abalone-dataset.csv'), 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/workflow/pipeline_context.py:212: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"AbaloneProcess\",\n",
    "    step_args = processor_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/abalone.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/abalone.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import tarfile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "TRAIN_VALIDATION_FRACTION = 0.2\n",
    "RANDOM_STATE_SAMPLING = 200\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def prepare_data(train_dir, validation_dir):\n",
    "    \"\"\"Read data from train and validation channel, and return predicting features and target variables.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): directory which saves the training data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of training features, training target, validation features, validation target.\n",
    "    \"\"\"\n",
    "    df_train = pd.read_csv(\n",
    "        os.path.join(train_dir, \"train.csv\"),\n",
    "        header=None,\n",
    "    )\n",
    "    df_train = df_train.iloc[np.random.permutation(len(df_train))]\n",
    "    df_train.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df_train.shape[1] - 1)]\n",
    "\n",
    "    try:\n",
    "        df_validation = pd.read_csv(\n",
    "            os.path.join(validation_dir, \"validation.csv\"),\n",
    "            header=None,\n",
    "        )\n",
    "        df_validation.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df_validation.shape[1] - 1)]\n",
    "\n",
    "    except FileNotFoundError:  # when validation data is not available in the directory\n",
    "        logging.info(\n",
    "            f\"Validation data is not found. {TRAIN_VALIDATION_FRACTION * 100}% of training data is \"\n",
    "            f\"randomly selected as validation data. The seed for random sampling is {RANDOM_STATE_SAMPLING}.\"\n",
    "        )\n",
    "        df_validation = df_train.sample(\n",
    "            frac=TRAIN_VALIDATION_FRACTION,\n",
    "            random_state=RANDOM_STATE_SAMPLING,\n",
    "        )\n",
    "        df_train.drop(df_validation.index, inplace=True)\n",
    "        df_validation.reset_index(drop=True, inplace=True)\n",
    "        df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train, y_train = df_train.iloc[:, 1:], df_train.iloc[:, :1]\n",
    "    X_val, y_val = df_validation.iloc[:, 1:], df_validation.iloc[:, :1]\n",
    "\n",
    "    return X_train.values, y_train.values, X_val.values, y_val.values\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run training.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--max_depth', type=int,)\n",
    "    parser.add_argument('--eta', type=float)\n",
    "    parser.add_argument('--gamma', type=int)\n",
    "    parser.add_argument('--min_child_weight', type=int)\n",
    "    parser.add_argument('--subsample', type=float)\n",
    "    parser.add_argument('--verbosity', type=int)\n",
    "    parser.add_argument('--objective', type=str)\n",
    "    parser.add_argument('--num_round', type=int)\n",
    "    parser.add_argument('--tree_method', type=str, default=\"auto\")\n",
    "    parser.add_argument('--predictor', type=str, default=\"auto\")\n",
    "    parser.add_argument('--learning_rate', type=str, default=\"auto\")\n",
    "    parser.add_argument('--output_data_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ.get('SM_HOSTS'))\n",
    "    parser.add_argument('--sm_current_host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    X_train, y_train, X_val, y_val = prepare_data(args.train, args.validation)\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": args.objective,\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"gamma\": args.gamma,\n",
    "        \"min_child_weight\": args.min_child_weight,\n",
    "        \"max_depth\": args.max_depth,\n",
    "        \"subsample\": args.subsample,\n",
    "        \"colsample_bytree\": 1,\n",
    "        \"reg_lambda\": 1,\n",
    "        \"reg_alpha\": 0,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=args.num_round,\n",
    "        evals=watchlist,\n",
    "        xgb_model=None,\n",
    "    )\n",
    "\n",
    "    model_location = args.model_dir + '/xgboost-model'\n",
    "    pkl.dump(bst, open(model_location, 'wb'))\n",
    "    logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/{prefix}/model\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    entry_point = 'code/abalone.py',\n",
    "    instance_type=instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.01,\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the output of the estimator's `.fit()` method as arguments to the `TrainingStep`. By passing the `local_pipeline_session` to the `sagemaker_session`, calling `.fit()` does not launch the training job, it returns the arguments needed to run the job as a step in the pipeline.\n",
    "\n",
    "Pass in the `S3Uri` of the `\"train_data\"` output channel to the `.fit()` method. Also, use the other `\"test_data\"` output channel for model evaluation in the pipeline. The `properties` attribute of a Pipeline step matches the object model of the corresponding response of a describe call. These properties can be referenced as placeholder values and are resolved at runtime. For example, the `ProcessingStep` `properties` attribute matches the object model of the [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "First, develop an evaluation script that is specified in a Processing step that performs the model evaluation.\n",
    "\n",
    "After pipeline execution, you can examine the resulting `evaluation.json` for analysis.\n",
    "\n",
    "The evaluation script uses `xgboost` to do the following:\n",
    "\n",
    "* Load the model.\n",
    "* Read the test data.\n",
    "* Issue predictions against the test data.\n",
    "* Build a classification report, including accuracy and ROC curve.\n",
    "* Save the evaluation report to the evaluation directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "    df.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df.shape[1] - 1)]\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": math.sqrt(mse), \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an instance of a `ScriptProcessor` processor and use it in the `ProcessingStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  script-abalone-eval-2022-08-22-16-26-55-887\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x7f0a144c8198>, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x7f0a145fc3c8>, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-26-55-887/input/code/evaluation.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-26-55-887/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the processor's arguments returned by `.run()` to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. \n",
    "\n",
    "Specifically, the `S3ModelArtifacts` from the `step_train` `properties` and the `S3Uri` of the `\"test_data\"` output channel of the `step_process` `properties` are passed as inputs. The `TrainingStep` and `ProcessingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) and [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response objects, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Create Model Step to Create a Model\n",
    "\n",
    "In order to perform batch transformation using the example model, create a SageMaker model. \n",
    "\n",
    "Specifically, pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object.\n",
    "\n",
    "We provide a custom inference script that defines the logic for the batch transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker_xgboost_container.encoder as xgb_encoders\n",
    "import xgboost as xgb\n",
    "import io\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialize and return fitted model.\n",
    "    \"\"\"\n",
    "    model_file = \"xgboost-model\"\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), \"rb\"))\n",
    "    return booster\n",
    "\n",
    "def transform_fn(model, request_body, request_content_type, accept):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if request_content_type == \"text/libsvm\":\n",
    "        input_data = xgb_encoders.libsvm_to_dmatrix(request_body)\n",
    "    if request_content_type == \"text/csv\":\n",
    "        df = pd.read_csv(io.StringIO(request_body.strip('\\n')), header = None)\n",
    "        df.drop(0, axis = 1, inplace=True)\n",
    "        input_data = xgb.DMatrix(data=df)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Content type {} is not supported.\".format(request_content_type))\n",
    "    \n",
    "    prediction = model.predict(input_data)\n",
    "    feature_contribs = model.predict(input_data, pred_contribs=True, validate_features=False)\n",
    "    output = np.hstack((prediction[:, np.newaxis], feature_contribs))\n",
    "    \n",
    "    logging.info(\"Successfully completed transform job!\")\n",
    "    \n",
    "    return \",\".join(str(x) for x in output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    source_dir='code',\n",
    "    entry_point='inference.py',\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `ModelStep` by providing the return values from `model.create()` as the step arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AbaloneCreateModel\",\n",
    "    step_args=model.create(instance_type=instance_type)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Transform Step to Perform Batch Transformation\n",
    "\n",
    "Now that a model instance is defined, create a `Transformer` instance with the appropriate model type, compute instance type, and desired output S3 URI.\n",
    "\n",
    "Specifically, pass in the `ModelName` from the `CreateModelStep`, `step_create_model` properties. The `CreateModelStep` `properties` attribute matches the object model of the [DescribeModel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeModel.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=transform_instance_count,\n",
    "    output_path=f\"s3://{default_bucket}/{prefix}/transform\",\n",
    "    sagemaker_session=local_pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass in the transformer instance and the `TransformInput` with the `batch_data` pipeline parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "transform_data = Join(on='/', values=[step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri, 'test.csv'])\n",
    "\n",
    "transform_args = transformer.transform(transform_data, content_type='text/csv')\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AbaloneTransform\", \n",
    "    step_args = transform_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "\n",
    "step_fail = FailStep(\n",
    "    name=\"AbaloneMSEFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation Or Terminate the Execution in Failed State\n",
    "\n",
    "In this step, the model is registered only if the accuracy of the model, as determined by the evaluation step `step_eval`, exceeded a specified value. Otherwise, the pipeline execution fails and terminates. A `ConditionStep` enables pipelines to support conditional execution in the pipeline DAG based on the conditions of the step properties.\n",
    "\n",
    "In the following section, you:\n",
    "\n",
    "* Define a `ConditionLessThanOrEqualTo` on the accuracy value found in the output of the evaluation step, `step_eval`.\n",
    "* Use the condition in the list of conditions in a `ConditionStep`.\n",
    "* Pass the `CreateModelStep` and `TransformStep` steps into the `if_steps` of the `ConditionStep`, which are only executed if the condition evaluates to `True`.\n",
    "* Pass the `FailStep` step into the `else_steps`of the `ConditionStep`, which is only executed if the condition evaluates to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=mse_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline using `LocalPipelineSession`\n",
    "\n",
    "In this section, combine the steps into a Pipeline so it can be executed. We provide a `LocalPipelineSession` object to the `Pipeline` so that when executed, all the steps in the pipeline will run locally on the  machine. By switching the `LocalPipelineSession` to a `sagemaker.session.Session` object, you can switch the execution to run in the cloud on SageMaker instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"LocalModelPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=local_pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Examining the pipeline definition\n",
    "\n",
    "The JSON of the pipeline definition can be examined to confirm the pipeline is well-defined and the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/abalone-data-set/abalone-dataset.csv'},\n",
       "  {'Name': 'MseThreshold', 'Type': 'Float', 'DefaultValue': 7.0}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'AbaloneProcess',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocessing.py']},\n",
       "    'RoleArn': 'arn:aws:iam::572539092864:role/service-role/AmazonSageMaker-ExecutionRole-20200407T174741',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/input/code/preprocessing.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'validation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/validation',\n",
       "        'LocalPath': '/opt/ml/processing/validation',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'AbaloneTrain',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1'},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.m5.xlarge',\n",
       "     'VolumeSizeInGB': 30},\n",
       "    'RoleArn': 'arn:aws:iam::572539092864:role/service-role/AmazonSageMaker-ExecutionRole-20200407T174741',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'validation'}],\n",
       "    'HyperParameters': {'objective': 'reg:squarederror',\n",
       "     'learning_rate': '0.01',\n",
       "     'num_round': '50',\n",
       "     'max_depth': '5',\n",
       "     'eta': '0.2',\n",
       "     'gamma': '4',\n",
       "     'min_child_weight': '6',\n",
       "     'subsample': '0.7',\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-572539092864/sagemaker-xgboost-2022-08-22-16-26-52-645/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"abalone.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"us-east-1\"'},\n",
       "    'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1661185612',\n",
       "      'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "      'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model'}}},\n",
       "  {'Name': 'AbaloneEval',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluation.py']},\n",
       "    'RoleArn': 'arn:aws:iam::572539092864:role/service-role/AmazonSageMaker-ExecutionRole-20200407T174741',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.AbaloneTrain.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-26-55-887/input/code/evaluation.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-26-55-887/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'AbaloneMSECond',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'LessThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.AbaloneEval.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'regression_metrics.mse.value'}},\n",
       "      'RightValue': {'Get': 'Parameters.MseThreshold'}}],\n",
       "    'IfSteps': [{'Name': 'AbaloneCreateModel-RepackModel-0',\n",
       "      'Type': 'Training',\n",
       "      'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "        'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},\n",
       "       'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-572539092864/'},\n",
       "       'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "       'ResourceConfig': {'InstanceCount': 1,\n",
       "        'InstanceType': 'ml.m5.large',\n",
       "        'VolumeSizeInGB': 30},\n",
       "       'RoleArn': 'arn:aws:iam::572539092864:role/service-role/AmazonSageMaker-ExecutionRole-20200407T174741',\n",
       "       'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "           'S3Uri': {'Get': 'Steps.AbaloneTrain.ModelArtifacts.S3ModelArtifacts'},\n",
       "           'S3DataDistributionType': 'FullyReplicated'}},\n",
       "         'ChannelName': 'training'}],\n",
       "       'HyperParameters': {'inference_script': '\"inference.py\"',\n",
       "        'model_archive': {'Std:Join': {'On': '',\n",
       "          'Values': [{'Get': 'Steps.AbaloneTrain.ModelArtifacts.S3ModelArtifacts'}]}},\n",
       "        'dependencies': 'null',\n",
       "        'source_dir': '\"code\"',\n",
       "        'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-572539092864/AbaloneCreateModel-RepackModel-0-480f37e5cf34fc2b51ec538b676e87f1/source/sourcedir.tar.gz\"',\n",
       "        'sagemaker_program': '\"_repack_model.py\"',\n",
       "        'sagemaker_container_log_level': '20',\n",
       "        'sagemaker_region': '\"us-east-1\"'},\n",
       "       'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-572539092864/',\n",
       "        'CollectionConfigurations': []}},\n",
       "      'Description': 'Used to repack a model with customer scripts for a register/create model step'},\n",
       "     {'Name': 'AbaloneCreateModel-CreateModel',\n",
       "      'Type': 'Model',\n",
       "      'Arguments': {'ExecutionRoleArn': 'arn:aws:iam::572539092864:role/service-role/AmazonSageMaker-ExecutionRole-20200407T174741',\n",
       "       'PrimaryContainer': {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1',\n",
       "        'Environment': {'SAGEMAKER_PROGRAM': 'inference.py',\n",
       "         'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code',\n",
       "         'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "         'SAGEMAKER_REGION': 'us-east-1'},\n",
       "        'ModelDataUrl': {'Get': 'Steps.AbaloneCreateModel-RepackModel-0.ModelArtifacts.S3ModelArtifacts'}}}},\n",
       "     {'Name': 'AbaloneTransform',\n",
       "      'Type': 'Transform',\n",
       "      'Arguments': {'ModelName': {'Get': 'Steps.AbaloneCreateModel-CreateModel.ModelName'},\n",
       "       'TransformInput': {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "          'S3Uri': {'Std:Join': {'On': '/',\n",
       "            'Values': [{'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "             'test.csv']}}}},\n",
       "        'ContentType': 'text/csv'},\n",
       "       'TransformOutput': {'S3OutputPath': 's3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/transform'},\n",
       "       'TransformResources': {'InstanceCount': 1,\n",
       "        'InstanceType': 'ml.m5.xlarge'}}}],\n",
       "    'ElseSteps': [{'Name': 'AbaloneMSEFail',\n",
       "      'Type': 'Fail',\n",
       "      'Arguments': {'ErrorMessage': {'Std:Join': {'On': ' ',\n",
       "         'Values': ['Execution failed due to MSE >',\n",
       "          {'Get': 'Parameters.MseThreshold'}]}}}}]}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Submit the pipeline definition to the Pipeline service. The Pipeline service uses the role that is passed in to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'LocalModelPipeline'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline and accept all the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execution for pipeline LocalModelPipeline. Execution ID is c5d44566-50db-486f-ab24-122d56bc9892\n",
      "Starting pipeline step: 'AbaloneProcess'\n",
      "Creating yribbofuao-algo-1-5ovjr ... \n",
      "Creating yribbofuao-algo-1-5ovjr ... done\n",
      "Attaching to yribbofuao-algo-1-5ovjr\n",
      "\u001b[36myribbofuao-algo-1-5ovjr exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "Pipeline step 'AbaloneProcess' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneTrain'\n",
      "Creating miek17ydt4-algo-1-02ag1 ... \n",
      "Creating miek17ydt4-algo-1-02ag1 ... done\n",
      "Attaching to miek17ydt4-algo-1-02ag1\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22 16:27:32.884 3d4bf0964a35:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:32:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:32:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Returning the value itself\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:32:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:32:INFO] Invoking user training script.\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:33:INFO] Module abalone does not provide a setup.py. \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Generating setup.py\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:33:INFO] Generating setup.cfg\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:33:INFO] Generating MANIFEST.in\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:33:INFO] Installing module with the following command:\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \u001b[?25hBuilding wheels for collected packages: abalone\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m   Building wheel for abalone (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \u001b[?25h  Created wheel for abalone: filename=abalone-1.0.0-py2.py3-none-any.whl size=5626 sha256=9ee09d50fde45f3256b673c4dbb0c5fcca533f85bf5528b4d19416286319465f\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-fzmfbhba/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Successfully built abalone\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Installing collected packages: abalone\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Successfully installed abalone-1.0.0\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \u001b[0m\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:36:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Returning the value itself\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2022-08-22:16:27:36:INFO] Invoking user script\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Training Env:\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     },\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"current_host\": \"algo-1-02ag1\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"algo-1-02ag1\"\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     ],\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"objective\": \"reg:squarederror\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"learning_rate\": 0.01,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"num_round\": 50,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"max_depth\": 5,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"eta\": 0.2,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"gamma\": 4,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"min_child_weight\": 6,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"subsample\": 0.7\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     },\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"train\": {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         },\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"validation\": {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         }\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     },\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"job_name\": \"AbaloneTrain-1661185649-8b2b\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"master_hostname\": \"algo-1-02ag1\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-572539092864/sagemaker-xgboost-2022-08-22-16-26-52-645/source/sourcedir.tar.gz\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"module_name\": \"abalone\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"current_host\": \"algo-1-02ag1\",\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m             \"algo-1-02ag1\"\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m         ]\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     },\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m     \"user_entry_point\": \"abalone.py\"\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m }\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Environment variables:\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HOSTS=[\"algo-1-02ag1\"]\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HPS={\"eta\":0.2,\"gamma\":4,\"learning_rate\":0.01,\"max_depth\":5,\"min_child_weight\":6,\"num_round\":50,\"objective\":\"reg:squarederror\",\"subsample\":0.7}\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_USER_ENTRY_POINT=abalone.py\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-02ag1\",\"hosts\":[\"algo-1-02ag1\"]}\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_CURRENT_HOST=algo-1-02ag1\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_MODULE_NAME=abalone\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-572539092864/sagemaker-xgboost-2022-08-22-16-26-52-645/source/sourcedir.tar.gz\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-02ag1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-02ag1\"],\"hyperparameters\":{\"eta\":0.2,\"gamma\":4,\"learning_rate\":0.01,\"max_depth\":5,\"min_child_weight\":6,\"num_round\":50,\"objective\":\"reg:squarederror\",\"subsample\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"AbaloneTrain-1661185649-8b2b\",\"log_level\":20,\"master_hostname\":\"algo-1-02ag1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-572539092864/sagemaker-xgboost-2022-08-22-16-26-52-645/source/sourcedir.tar.gz\",\"module_name\":\"abalone\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-02ag1\",\"hosts\":[\"algo-1-02ag1\"]},\"user_entry_point\":\"abalone.py\"}\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--learning_rate\",\"0.01\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\"]\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_OBJECTIVE=reg:squarederror\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_LEARNING_RATE=0.01\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_NUM_ROUND=50\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_MAX_DEPTH=5\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_ETA=0.2\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_GAMMA=4\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_MIN_CHILD_WEIGHT=6\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m SM_HP_SUBSAMPLE=0.7\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m /miniconda3/bin/python3 -m abalone --eta 0.2 --gamma 4 --learning_rate 0.01 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:squarederror --subsample 0.7\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m \n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [0]\ttrain-rmse:9.83627\tvalidation-rmse:9.90964\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [1]\ttrain-rmse:9.74358\tvalidation-rmse:9.81794\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [2]\ttrain-rmse:9.65199\tvalidation-rmse:9.72625\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [3]\ttrain-rmse:9.56188\tvalidation-rmse:9.63656\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [4]\ttrain-rmse:9.47152\tvalidation-rmse:9.54704\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [5]\ttrain-rmse:9.38278\tvalidation-rmse:9.45832\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [6]\ttrain-rmse:9.29520\tvalidation-rmse:9.37149\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [7]\ttrain-rmse:9.20795\tvalidation-rmse:9.28430\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [8]\ttrain-rmse:9.12176\tvalidation-rmse:9.19832\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [9]\ttrain-rmse:9.03671\tvalidation-rmse:9.11372\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [10]\ttrain-rmse:8.95223\tvalidation-rmse:9.02951\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [11]\ttrain-rmse:8.86911\tvalidation-rmse:8.94702\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [12]\ttrain-rmse:8.78666\tvalidation-rmse:8.86553\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [13]\ttrain-rmse:8.70497\tvalidation-rmse:8.78401\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [14]\ttrain-rmse:8.62424\tvalidation-rmse:8.70336\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [15]\ttrain-rmse:8.54419\tvalidation-rmse:8.62331\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [16]\ttrain-rmse:8.46434\tvalidation-rmse:8.54326\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [17]\ttrain-rmse:8.38606\tvalidation-rmse:8.46472\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [18]\ttrain-rmse:8.30846\tvalidation-rmse:8.38780\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [19]\ttrain-rmse:8.23142\tvalidation-rmse:8.31118\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [20]\ttrain-rmse:8.15579\tvalidation-rmse:8.23615\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [21]\ttrain-rmse:8.08071\tvalidation-rmse:8.16091\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [22]\ttrain-rmse:8.00626\tvalidation-rmse:8.08643\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [23]\ttrain-rmse:7.93269\tvalidation-rmse:8.01329\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [24]\ttrain-rmse:7.85981\tvalidation-rmse:7.94054\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [25]\ttrain-rmse:7.78838\tvalidation-rmse:7.86957\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [26]\ttrain-rmse:7.71723\tvalidation-rmse:7.79776\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [27]\ttrain-rmse:7.64703\tvalidation-rmse:7.72790\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [28]\ttrain-rmse:7.57699\tvalidation-rmse:7.65812\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [29]\ttrain-rmse:7.50739\tvalidation-rmse:7.58884\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [30]\ttrain-rmse:7.43891\tvalidation-rmse:7.51976\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [31]\ttrain-rmse:7.37156\tvalidation-rmse:7.45244\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [32]\ttrain-rmse:7.30425\tvalidation-rmse:7.38501\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [33]\ttrain-rmse:7.23792\tvalidation-rmse:7.31897\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [34]\ttrain-rmse:7.17263\tvalidation-rmse:7.25408\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [35]\ttrain-rmse:7.10873\tvalidation-rmse:7.19042\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [36]\ttrain-rmse:7.04489\tvalidation-rmse:7.12726\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [37]\ttrain-rmse:6.98105\tvalidation-rmse:7.06452\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [38]\ttrain-rmse:6.91805\tvalidation-rmse:7.00198\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [39]\ttrain-rmse:6.85571\tvalidation-rmse:6.93984\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [40]\ttrain-rmse:6.79428\tvalidation-rmse:6.87885\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [41]\ttrain-rmse:6.73333\tvalidation-rmse:6.81845\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [42]\ttrain-rmse:6.67334\tvalidation-rmse:6.75909\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [43]\ttrain-rmse:6.61378\tvalidation-rmse:6.69979\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [44]\ttrain-rmse:6.55548\tvalidation-rmse:6.64189\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [45]\ttrain-rmse:6.49766\tvalidation-rmse:6.58448\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [46]\ttrain-rmse:6.44007\tvalidation-rmse:6.52717\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [47]\ttrain-rmse:6.38313\tvalidation-rmse:6.47092\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [48]\ttrain-rmse:6.32683\tvalidation-rmse:6.41468\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m [49]\ttrain-rmse:6.27111\tvalidation-rmse:6.35915\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 |\u001b[0m INFO:root:Stored trained model at /opt/ml/model/xgboost-model\n",
      "\u001b[36mmiek17ydt4-algo-1-02ag1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "Pipeline step 'AbaloneTrain' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneEval'\n",
      "Creating fghyywf81f-algo-1-8e0rt ... \n",
      "Creating fghyywf81f-algo-1-8e0rt ... done\n",
      "Attaching to fghyywf81f-algo-1-8e0rt\n",
      "\u001b[36mfghyywf81f-algo-1-8e0rt exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "Pipeline step 'AbaloneEval' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneMSECond'\n",
      "Pipeline step 'AbaloneMSECond' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneCreateModel-RepackModel-0'\n",
      "Creating plitz7fm38-algo-1-hlquk ... \n",
      "Creating plitz7fm38-algo-1-hlquk ... done\n",
      "Attaching to plitz7fm38-algo-1-hlquk\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:43,999 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,002 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,002 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz to Json.\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Returning the value itself\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,009 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,233 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,233 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz to Json.\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Returning the value itself\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,244 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,245 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz to Json.\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Returning the value itself\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,255 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,256 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz to Json.\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Returning the value itself\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,263 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Training Env:\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m {\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     },\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"current_host\": \"algo-1-hlquk\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"algo-1-hlquk\"\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     ],\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"inference_script\": \"inference.py\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"model_archive\": \"s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"dependencies\": null,\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"source_dir\": \"code\"\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     },\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"training\": {\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         }\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     },\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"job_name\": \"AbaloneCreateModel-RepackModel-0-1661185661-12d2\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"master_hostname\": \"algo-1-hlquk\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-572539092864/AbaloneCreateModel-RepackModel-0-480f37e5cf34fc2b51ec538b676e87f1/source/sourcedir.tar.gz\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"module_name\": \"_repack_model\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"current_host\": \"algo-1-hlquk\",\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m             \"algo-1-hlquk\"\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m         ]\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     },\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m     \"user_entry_point\": \"_repack_model.py\"\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m }\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Environment variables:\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_HOSTS=[\"algo-1-hlquk\"]\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_HPS={\"dependencies\":null,\"inference_script\":\"inference.py\",\"model_archive\":\"s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz\",\"source_dir\":\"code\"}\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_USER_ENTRY_POINT=_repack_model.py\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-hlquk\",\"hosts\":[\"algo-1-hlquk\"]}\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_CURRENT_HOST=algo-1-hlquk\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_MODULE_NAME=_repack_model\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-572539092864/AbaloneCreateModel-RepackModel-0-480f37e5cf34fc2b51ec538b676e87f1/source/sourcedir.tar.gz\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-hlquk\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-hlquk\"],\"hyperparameters\":{\"dependencies\":null,\"inference_script\":\"inference.py\",\"model_archive\":\"s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz\",\"source_dir\":\"code\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"AbaloneCreateModel-RepackModel-0-1661185661-12d2\",\"log_level\":20,\"master_hostname\":\"algo-1-hlquk\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-572539092864/AbaloneCreateModel-RepackModel-0-480f37e5cf34fc2b51ec538b676e87f1/source/sourcedir.tar.gz\",\"module_name\":\"_repack_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-hlquk\",\"hosts\":[\"algo-1-hlquk\"]},\"user_entry_point\":\"_repack_model.py\"}\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_USER_ARGS=[\"--dependencies\",\"\",\"--inference_script\",\"inference.py\",\"--model_archive\",\"s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz\",\"--source_dir\",\"code\"]\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_HP_INFERENCE_SCRIPT=inference.py\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_HP_MODEL_ARCHIVE=s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_HP_DEPENDENCIES=\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m SM_HP_SOURCE_DIR=code\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m /miniconda3/bin/python _repack_model.py --dependencies  --inference_script inference.py --model_archive s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz --source_dir code\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m \n",
      "\u001b[36mplitz7fm38-algo-1-hlquk |\u001b[0m 2022-08-22 16:27:44,308 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mplitz7fm38-algo-1-hlquk exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "Pipeline step 'AbaloneCreateModel-RepackModel-0' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneCreateModel-CreateModel'\n",
      "Pipeline step 'AbaloneCreateModel-CreateModel' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneTransform'\n",
      "Attaching to tgxr1aio85-algo-1-3qbm0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] nginx config: \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m worker_processes auto;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m daemon off;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m events {\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m }\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m http {\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   }\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   server {\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     }\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     location / {\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     }\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   }\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m }\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] Module inference does not provide a setup.py. \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Generating setup.py\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] Generating setup.cfg\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] Generating MANIFEST.in\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:47:INFO] Installing module with the following command:\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25hBuilding wheels for collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Building wheel for inference (setup.py) ... \u001b[?25l/2022/08/22 16:27:50 [crit] 27#27: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m 172.18.0.1 - - [22/Aug/2022:16:27:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0mdone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25h  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=14675 sha256=e463bf023c111204cc18bf87efcc3b5ae7275fbd5436d98cce1406f62e1a3c40\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-rztlr7g6/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully built inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Installing collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully installed inference-1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [44] [INFO] Starting gunicorn 19.10.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [44] [INFO] Listening at: unix:/tmp/gunicorn.sock (44)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [44] [INFO] Using worker: gevent\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m /miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   return io.open(fd, *args, **kwargs)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [46] [INFO] Booting worker with pid: 46\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [47] [INFO] Booting worker with pid: 47\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [48] [INFO] Booting worker with pid: 48\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [49] [INFO] Booting worker with pid: 49\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [50] [INFO] Booting worker with pid: 50\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [51] [INFO] Booting worker with pid: 51\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:50 +0000] [52] [INFO] Booting worker with pid: 52\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22 16:27:51 +0000] [53] [INFO] Booting worker with pid: 53\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:52:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:55:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:55:INFO] Installing module with the following command:\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25hBuilding wheels for collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Building wheel for inference (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25h  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=22339 sha256=bd6985fa1373a7e904d2e1b302689b88241ab8d9f20ff8b7212a9d0a3e292681\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-hpx540p0/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully built inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Installing collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Attempting uninstall: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     Found existing installation: inference 1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     Can't uninstall 'inference'. No files were found to uninstall.\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully installed inference-1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m 172.18.0.1 - - [22/Aug/2022:16:27:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:58:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:27:58:INFO] Installing module with the following command:\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25hBuilding wheels for collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Building wheel for inference (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25h  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=30270 sha256=3975ffef400fc5a130050a78f87fc86d7a3f7077ea65cdcb35d68f381c7dd9ce\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-0h2wonqz/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully built inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Installing collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Attempting uninstall: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     Found existing installation: inference 1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     Can't uninstall 'inference'. No files were found to uninstall.\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully installed inference-1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m 172.18.0.1 - - [22/Aug/2022:16:28:01 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:28:01:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:28:01:INFO] Installing module with the following command:\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25hBuilding wheels for collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Building wheel for inference (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[?25h  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=38467 sha256=1ba9a84cae3688fce31f35356ca466f8a1483354923b3ff6d18416ddb1e26bb5\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-l2eljpui/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully built inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Installing collected packages: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m   Attempting uninstall: inference\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     Found existing installation: inference 1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m     Can't uninstall 'inference'. No files were found to uninstall.\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m Successfully installed inference-1.0.0\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m [2022-08-22:16:28:04:INFO] Successfully completed transform job!\n",
      "\u001b[36mtgxr1aio85-algo-1-3qbm0 |\u001b[0m 172.18.0.1 - - [22/Aug/2022:16:28:04 +0000] \"POST /invocations HTTP/1.1\" 200 140 \"-\" \"python-urllib3/1.26.8\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Pipeline step 'AbaloneTransform' SUCCEEDED.\n",
      "Pipeline execution c5d44566-50db-486f-ab24-122d56bc9892 SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineExecutionSteps': [{'EndTime': 1661185649.786114,\n",
       "   'Metadata': {'ProcessingJob': {'Arn': 'AbaloneProcess-1661185646-3973'}},\n",
       "   'StartTime': 1661185646.077175,\n",
       "   'StepName': 'AbaloneProcess',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1661185658.121373,\n",
       "   'Metadata': {'TrainingJob': {'Arn': 'AbaloneTrain-1661185649-8b2b'}},\n",
       "   'StartTime': 1661185649.786172,\n",
       "   'StepName': 'AbaloneTrain',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1661185661.55377,\n",
       "   'Metadata': {'ProcessingJob': {'Arn': 'AbaloneEval-1661185658-da6c'}},\n",
       "   'StartTime': 1661185658.121506,\n",
       "   'StepName': 'AbaloneEval',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1661185661.608325,\n",
       "   'Metadata': {'Condition': {'Outcome': True}},\n",
       "   'StartTime': 1661185661.553957,\n",
       "   'StepName': 'AbaloneMSECond',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1661185685.121105,\n",
       "   'Metadata': {'TransformJob': {'Arn': 'AbaloneTransform-1661185664-1868'}},\n",
       "   'StartTime': 1661185664.862347,\n",
       "   'StepName': 'AbaloneTransform',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1661185664.861809,\n",
       "   'Metadata': {'TrainingJob': {'Arn': 'AbaloneCreateModel-RepackModel-0-1661185661-12d2'}},\n",
       "   'StartTime': 1661185661.608629,\n",
       "   'StepDescription': 'Used to repack a model with customer scripts for a register/create model step',\n",
       "   'StepName': 'AbaloneCreateModel-RepackModel-0',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1661185664.862298,\n",
       "   'Metadata': {'Model': {'Arn': 'AbaloneCreateModel-CreateModel-1661185664-df03'}},\n",
       "   'StartTime': 1661185664.861876,\n",
       "   'StepName': 'AbaloneCreateModel-CreateModel',\n",
       "   'StepStatus': 'Succeeded'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the step outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/train\n",
      "s3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/validation\n",
      "s3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/test\n"
     ]
    }
   ],
   "source": [
    "# Get output files from processing job\n",
    "\n",
    "processing_job_name = steps['PipelineExecutionSteps'][0]['Metadata']['ProcessingJob']['Arn']\n",
    "outputs = local_pipeline_session.sagemaker_client.describe_processing_job(ProcessingJobName = processing_job_name)['ProcessingOutputConfig']['Outputs']\n",
    "for key in outputs:\n",
    "    print(outputs[key]['S3Output']['S3Uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model location :  s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model/AbaloneTrain-1661185649-8b2b/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Get output from training job\n",
    "\n",
    "training_job_name = steps['PipelineExecutionSteps'][1]['Metadata']['TrainingJob']['Arn']\n",
    "outputs = local_pipeline_session.sagemaker_client.describe_training_job(TrainingJobName = training_job_name)\n",
    "print(\"Model location : \", outputs['ModelArtifacts']['S3ModelArtifacts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-26-55-887/output/evaluation\n"
     ]
    }
   ],
   "source": [
    "# Get output from model evaluation step (processing job)\n",
    "\n",
    "processing_job_name = steps['PipelineExecutionSteps'][2]['Metadata']['ProcessingJob']['Arn']\n",
    "outputs = local_pipeline_session.sagemaker_client.describe_processing_job(ProcessingJobName = processing_job_name)['ProcessingOutputConfig']['Outputs']\n",
    "for key in outputs:\n",
    "    print(outputs[key]['S3Output']['S3Uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelName': 'AbaloneCreateModel-CreateModel-1661185664-df03', 'CreationTime': datetime.datetime(2022, 8, 22, 16, 27, 44, 862263), 'ExecutionRoleArn': 'local:arn-does-not-matter', 'ModelArn': 'local:arn-does-not-matter', 'PrimaryContainer': {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1', 'Environment': {'SAGEMAKER_PROGRAM': 'inference.py', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code', 'SAGEMAKER_CONTAINER_LOG_LEVEL': '20', 'SAGEMAKER_REGION': 'us-east-1'}, 'ModelDataUrl': 's3://sagemaker-us-east-1-572539092864/AbaloneCreateModel-RepackModel-0-1661185661-12d2/model.tar.gz'}}\n"
     ]
    }
   ],
   "source": [
    "# Get output of ModelStep\n",
    "import json\n",
    "model_name = steps['PipelineExecutionSteps'][-1]['Metadata']['Model']['Arn']\n",
    "outputs = local_pipeline_session.sagemaker_client.describe_model(ModelName = model_name)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformJobStatus': 'Completed', 'ModelName': 'AbaloneCreateModel-CreateModel-1661185664-df03', 'TransformJobName': 'AbaloneTransform-1661185664-1868', 'TransformJobArn': 'local:arn-does-not-matter', 'TransformEndTime': datetime.datetime(2022, 8, 22, 16, 28, 5, 120525), 'CreationTime': datetime.datetime(2022, 8, 22, 16, 28, 1, 158724), 'TransformStartTime': datetime.datetime(2022, 8, 22, 16, 28, 1, 158724), 'Environment': {}, 'BatchStrategy': 'MultiRecord', 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge'}, 'TransformOutput': {'S3OutputPath': 's3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/transform'}, 'TransformInput': {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-26-51-482/output/test/test.csv'}}, 'ContentType': 'text/csv'}}\n"
     ]
    }
   ],
   "source": [
    "# Get output from the TransformStep\n",
    "\n",
    "transform_job_name = steps['PipelineExecutionSteps'][4]['Metadata']['TransformJob']['Arn']\n",
    "outputs = local_pipeline_session.sagemaker_client.describe_transform_job(TransformJobName = transform_job_name)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition to running pipeline as SageMaker Managed Pipeline\n",
    "\n",
    "We will now use a non-local PipelineSession object to re-run the Pipeline steps via SageMaker as a managed service. This will also allow us to view and track the results directly in SageMaker Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/workflow/pipeline_context.py:212: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sklearn-abalone-process-2022-08-22-16-28-44-615\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': ParameterString(name='InputData', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/abalone-data-set/abalone-dataset.csv'), 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-28-44-615/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-28-44-615/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-28-44-615/output/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/sklearn-abalone-process-2022-08-22-16-28-44-615/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "# Recreate the SKLearnProcessor with non-local session\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session  # use non-local session\n",
    ")\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"AbaloneProcess\",\n",
    "    step_args = processor_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_uri: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1\n",
      "model_path: s3://sagemaker-us-east-1-572539092864/sagemaker-pipelines-local-mode-example/model\n"
     ]
    }
   ],
   "source": [
    "print(f'image_uri: {image_uri}')\n",
    "print(f'model_path: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Estimator instance with non-local session\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    entry_point = 'code/abalone.py',\n",
    "    instance_type=instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session  # use non-local session\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.01,\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  script-abalone-eval-2022-08-22-16-28-54-287\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x7f0a14b71438>, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x7f0a14650e80>, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-28-54-287/input/code/evaluation.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-572539092864/script-abalone-eval-2022-08-22-16-28-54-287/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "# Recreate the Script Processor instance with non-local session\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session  # use non-local session\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Model instance with non-local session\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    source_dir='code',\n",
    "    entry_point='inference.py',\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session  # use non-local session\n",
    ")\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AbaloneCreateModel\",\n",
    "    step_args=model.create(instance_type=instance_type)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Transformer instance with non-local session\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=transform_instance_count,\n",
    "    output_path=f\"s3://{default_bucket}/{prefix}/transform\",\n",
    "    sagemaker_session=pipeline_session,  # use non-local session\n",
    ")\n",
    "\n",
    "transform_data = Join(on='/', values=[step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri, 'test.csv'])\n",
    "\n",
    "transform_args = transformer.transform(transform_data, content_type='text/csv')\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AbaloneTransform\", \n",
    "    step_args = transform_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Step condition with new step instances\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that all the Steps are re-defined, we create a new Managed Pipeline\n",
    "\n",
    "We add each of the recreated steps to a new Pipeline instance that we will run as a managed (in-the-cloud) pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the Pipeline using non-local session\n",
    "\n",
    "pipeline_name = f\"SM-Managed-Pipeline\"\n",
    "\n",
    "sm_pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train,step_eval, step_cond],\n",
    "    sagemaker_session=pipeline_session,  # non-local session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:572539092864:pipeline/sm-managed-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '47f88c0f-8dc5-445e-ac14-bc5bbabe81f1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '47f88c0f-8dc5-445e-ac14-bc5bbabe81f1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '87',\n",
       "   'date': 'Mon, 22 Aug 2022 17:23:48 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start execution of SageMaker-managed pipeline\n",
    "sm_execution = sm_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_execution.wait(delay=60, max_attempts=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'AbaloneTransform',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 40, 48, 388000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 45, 35, 676000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TransformJob': {'Arn': 'arn:aws:sagemaker:us-east-1:572539092864:transform-job/pipelines-ratxlyko1u6t-abalonetransform-n2te88ysbc'}}},\n",
       " {'StepName': 'AbaloneCreateModel-CreateModel',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 40, 46, 313000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 40, 47, 498000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:572539092864:model/pipelines-ratxlyko1u6t-abalonecreatemodel-c-u4laudlcjk'}}},\n",
       " {'StepName': 'AbaloneCreateModel-RepackModel-0',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 36, 44, 725000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 40, 45, 884000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:572539092864:training-job/pipelines-ratxlyko1u6t-abalonecreatemodel-r-4pofown9hg'}}},\n",
       " {'StepName': 'AbaloneMSECond',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 36, 43, 776000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 36, 44, 109000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'Condition': {'Outcome': 'True'}}},\n",
       " {'StepName': 'AbaloneEval',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 32, 9, 925000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 36, 43, 313000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:572539092864:processing-job/pipelines-ratxlyko1u6t-abaloneeval-t8mq6q9psm'}}},\n",
       " {'StepName': 'AbaloneTrain',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 28, 40, 704000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 32, 8, 950000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:572539092864:training-job/pipelines-ratxlyko1u6t-abalonetrain-nqlu7m269v'}}},\n",
       " {'StepName': 'AbaloneProcess',\n",
       "  'StartTime': datetime.datetime(2022, 8, 22, 17, 23, 51, 953000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 8, 22, 17, 28, 40, 139000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:572539092864:processing-job/pipelines-ratxlyko1u6t-abaloneprocess-rjpozh1mn1'}}}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
