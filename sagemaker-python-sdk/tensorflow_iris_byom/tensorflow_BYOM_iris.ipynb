{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring your own Model - IRIS classifier example.\n",
    "\n",
    "This notebook can be compared to [tensorflow_iris_dnn_classifier_using_estimators.ipynb](https://github.com/awslabs/sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_iris_dnn_classifier_using_estimators/tensorflow_iris_dnn_classifier_using_estimators.ipynb). It seeks to solve the same problem, but instead of training by using Amazon SageMaker's distributed, managed training functionality, it relies on the user to train locally or bring a pre-trained model, and then setup a real-time hosted endpoint in SageMaker. To do that, we'll rely on the same set of functions for training. \n",
    "\n",
    "Consider the following mdoel definition for IRIS classification. This mdoe uses the ``tensorflow.estimator.DNNClassifier`` which is a pre-defined enstimator module for its model definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "role = <<Your_Sagemaker_Role>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "INPUT_TENSOR_NAME = 'x'\n",
    "\n",
    "\n",
    "def estimator_fn(run_config, params):\n",
    "    feature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\n",
    "    return tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                      hidden_units=[10, 20, 10],\n",
    "                                      n_classes=3,\n",
    "                                      config=run_config)\n",
    "\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_spec = {INPUT_TENSOR_NAME: tf.FixedLenFeature(dtype=tf.float32, shape=[4])}\n",
    "    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    \"\"\"Returns input function that would feed the model during training\"\"\"\n",
    "    return _generate_input_fn(training_dir, 'iris_training.csv')\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\n",
    "    return _generate_input_fn(training_dir, 'iris_test.csv')\n",
    "\n",
    "\n",
    "def _generate_input_fn(training_dir, training_filename):\n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=os.path.join(training_dir, training_filename),\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32)\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\n",
    "        y=np.array(training_set.target),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator object with this model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = estimator_fn(run_config = None, params = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and make the iris dataset from TensorFlow's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the input streamer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_func = train_input_fn('.', params = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train using TensorFlow's ``tensorflow.Estimator.train`` method. The model is trained locally in the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.train(input_fn = train_func, steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small difference between a SageMaker model and a TensorFlow model. The conversion is easy and fairly trivial. Simply move the tensorflow exported model into a directory ``export\\Servo\\`` and tar the entire directory. SageMaker will recognize this as a loadable TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exported_model = classifier.export_savedmodel(export_dir_base = 'export/Servo/', \n",
    "                               serving_input_receiver_fn = serving_input_fn)\n",
    "print (exported_model)\n",
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a new sagemaker session and upload the model into the default S3 bucket under the directory ``model``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ``sagemaker.tensorflow.model.TensorflowModel`` class directly to setup a trained model in a sagemaker session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
    "                                  role = role,\n",
    "                                  entry_point = 'iris_dnn_classifier.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the newly created SageMaker model to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                          instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a sample prediction on a sample to ensure that it works. Expect result ``1`` for this particular sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_samples = {}\n",
    "predict_samples ={INPUT_TENSOR_NAME: np.array([[6.4,3.2,4.5,1.5]])}\n",
    "predictor.predict(np.array([[6.4,3.2,4.5,1.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all temporary directories so that we are not affecting the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove('model.tar.gz')\n",
    "import shutil\n",
    "shutil.rmtree('export')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
