{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "filled-flash",
   "metadata": {
    "papermill": {
     "duration": 0.009489,
     "end_time": "2021-06-03T00:10:10.266437",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.256948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Batch Inference\n",
    "In this notebook, we'll examine how to do batch transform task with PyTorch in Amazon SageMaker. \n",
    "\n",
    "First, an image classification model is build on MNIST dataset. Then, we demonstrate batch transform by using SageMaker Python SDK PyTorch framework with different configurations\n",
    "- `data_type=S3Prefix`: uses all objects that match the specified S3 key name prefix for batch inference.\n",
    "- `data_type=ManifestFile`: a manifest file containing a list of object keys that you want to batch inference.\n",
    "- `instance_count>1`: distribute the batch inference dataset to multiple inference instance\n",
    "\n",
    "For batch transform in TensorFlow in Amazon SageMaker, you can follow other Jupyter notebooks [here](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-infrastructure",
   "metadata": {
    "papermill": {
     "duration": 0.009319,
     "end_time": "2021-06-03T00:10:10.285106",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.275787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "We'll begin with some necessary imports, and get an Amazon SageMaker session to help perform certain tasks, as well as an IAM role with the necessary permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "physical-stuff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:10.310480Z",
     "iopub.status.busy": "2021-06-03T00:10:10.309977Z",
     "iopub.status.idle": "2021-06-03T00:10:11.972019Z",
     "shell.execute_reply": "2021-06-03T00:10:11.971547Z"
    },
    "papermill": {
     "duration": 1.677667,
     "end_time": "2021-06-03T00:10:11.972131",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.294464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:\n",
      "sagemaker-us-west-2-688520471316\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-batch-inference-script\"\n",
    "print(\"Bucket:\\n{}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-idaho",
   "metadata": {
    "papermill": {
     "duration": 0.009748,
     "end_time": "2021-06-03T00:10:11.992188",
     "exception": false,
     "start_time": "2021-06-03T00:10:11.982440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-particle",
   "metadata": {
    "papermill": {
     "duration": 0.009924,
     "end_time": "2021-06-03T00:10:12.012090",
     "exception": false,
     "start_time": "2021-06-03T00:10:12.002166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since the main purpose of this notebook is to demonstrate SageMaker PyTorch batch transform, **we reuse this SageMaker Python SDK [PyTorch example](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_mnist) to train a PyTorch model**. It takes around 7 minutes to finish the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competent-encoding",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:12.038135Z",
     "iopub.status.busy": "2021-06-03T00:10:12.037362Z",
     "iopub.status.idle": "2021-06-03T00:15:42.451109Z",
     "shell.execute_reply": "2021-06-03T00:15:42.449969Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 330.429296,
     "end_time": "2021-06-03T00:15:42.451328",
     "exception": true,
     "start_time": "2021-06-03T00:10:12.022032",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script\n",
      "2021-06-03 20:07:42 Starting - Starting the training job...\n",
      "2021-06-03 20:07:47 Starting - Launching requested ML instancesProfilerReport-1622750862: InProgress\n",
      "......\n",
      "2021-06-03 20:08:59 Starting - Preparing the instances for training......\n",
      "2021-06-03 20:10:01 Downloading - Downloading input data......\n",
      "2021-06-03 20:11:09 Training - Training image download completed. Training in progress..\u001b[32mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[32mbash: no job control in this shell\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:08,330 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:08,332 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:08,341 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:09,637 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:09,639 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:09,647 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:08,158 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:08,160 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:08,168 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:12,754 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:13,152 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:13,163 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:13,174 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:13,182 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2021-06-03-20-07-42-031\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2021-06-03-20-07-42-031\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:14,574 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:14,399 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:14,751 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:14,762 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:14,772 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:14,781 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-06-03-20-07-42-031\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-06-03-20-07-42-031\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:14,971 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:14,982 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:14,993 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:15,002 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[32mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[32m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2021-06-03-20-07-42-031\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[32m}\n",
      "\u001b[0m\n",
      "\u001b[32mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[32mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[32mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[32mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[32mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[32mSM_RESOURCE_CONFIG={\"current_host\":\"algo-3\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[32mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[32mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[32mSM_CURRENT_HOST=algo-3\u001b[0m\n",
      "\u001b[32mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[32mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[32mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[32mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[32mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[32mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[32mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[32mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[32mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-3\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2021-06-03-20-07-42-031\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-03-20-07-42-031/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-3\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[32mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[32mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[32mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[32mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[32mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[32mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[32m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mDistributed training - True\u001b[0m\n",
      "\u001b[32mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:16.992 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mGet train data loader\u001b[0m\n",
      "\u001b[35mGet test data loader\u001b[0m\n",
      "\u001b[35mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:16.992 algo-2:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.325 algo-2:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.326 algo-2:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.326 algo-2:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.326 algo-2:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.327 algo-2:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[35m[2021-06-03 20:11:17.373 algo-2:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[32mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 2. Number of gpus: 0\u001b[0m\n",
      "\u001b[32mGet train data loader\u001b[0m\n",
      "\u001b[32mGet test data loader\u001b[0m\n",
      "\u001b[32mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[32mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.012 algo-3:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.363 algo-3:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.363 algo-3:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.364 algo-3:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.364 algo-3:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.364 algo-3:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[32m[2021-06-03 20:11:17.413 algo-3:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.341 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.341 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.342 algo-1:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.342 algo-1:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.342 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[34m[2021-06-03 20:11:17.391 algo-1:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [6400/20000 (32%)] Loss: 1.944218\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/20000 (32%)] Loss: 1.830737\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [6400/20000 (32%)] Loss: 2.076494\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [12800/20000 (64%)] Loss: 0.970919\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [12800/20000 (64%)] Loss: 1.229461\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/20000 (64%)] Loss: 1.132146\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.714048\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.667853\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.892621\u001b[0m\n",
      "\u001b[32mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 1.830737\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 1.132146\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.892621\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-03 20:11:24,819 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[35mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 1.944218\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 0.970919\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.714048\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[35mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-06-03 20:11:24,831 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[32mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 2. Number of gpus: 0\u001b[0m\n",
      "\u001b[32mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[32mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[32mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[32mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 2.076494\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 1.229461\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.667853\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[32mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-03 20:11:24,830 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-03 20:11:38 Uploading - Uploading generated training model\n",
      "2021-06-03 20:11:38 Completed - Training job completed\n",
      "Training seconds: 291\n",
      "Billable seconds: 291\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "local_dir = '/tmp/data'\n",
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "MNIST(\n",
    "    local_dir,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=local_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"mnist.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version='py3',\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"}, # set epochs to a more realistic number for real training\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-south",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Prepare batch inference data\n",
    "\n",
    "First, convert the test data into png image; second, upload to your default S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suffering-class",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST\tt10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "images\tt10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-revelation",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# untar gz => png\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "with gzip.open(os.path.join(local_dir, 't10k-images-idx3-ubyte.gz'),  'rb') as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "premium-appendix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consecutive-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 100 of test images and upload them to S3\n",
    "\n",
    "import random\n",
    "from PIL import Image as im\n",
    "\n",
    "ids = random.sample(range(len(images)), 100)\n",
    "ids = np.array(ids, dtype=np.int)\n",
    "selected_images = images[ids]\n",
    "\n",
    "image_dir = '/tmp/data/images'\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "for i, img in enumerate(selected_images):\n",
    "    pngimg = im.fromarray(img)\n",
    "    pngimg.save(os.path.join(image_dir, f'{i}.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gross-dubai",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['78.png',\n",
       " '2.png',\n",
       " '21.png',\n",
       " '59.png',\n",
       " '85.png',\n",
       " '97.png',\n",
       " '37.png',\n",
       " '27.png',\n",
       " '20.png',\n",
       " '47.png',\n",
       " '48.png',\n",
       " '18.png',\n",
       " '68.png',\n",
       " '94.png',\n",
       " '46.png',\n",
       " '62.png',\n",
       " '43.png',\n",
       " '82.png',\n",
       " '33.png',\n",
       " '80.png',\n",
       " '57.png',\n",
       " '83.png',\n",
       " '70.png',\n",
       " '35.png',\n",
       " '10.png',\n",
       " '17.png',\n",
       " '52.png',\n",
       " '26.png',\n",
       " '92.png',\n",
       " '75.png',\n",
       " '56.png',\n",
       " '32.png',\n",
       " '79.png',\n",
       " '15.png',\n",
       " '7.png',\n",
       " '51.png',\n",
       " '9.png',\n",
       " '34.png',\n",
       " '74.png',\n",
       " '5.png',\n",
       " '72.png',\n",
       " '8.png',\n",
       " '93.png',\n",
       " '69.png',\n",
       " '31.png',\n",
       " '96.png',\n",
       " '11.png',\n",
       " '28.png',\n",
       " '24.png',\n",
       " '84.png',\n",
       " '55.png',\n",
       " '81.png',\n",
       " '64.png',\n",
       " '65.png',\n",
       " '39.png',\n",
       " '76.png',\n",
       " '67.png',\n",
       " '66.png',\n",
       " '1.png',\n",
       " '98.png',\n",
       " '77.png',\n",
       " '30.png',\n",
       " '58.png',\n",
       " '71.png',\n",
       " '73.png',\n",
       " '86.png',\n",
       " '89.png',\n",
       " '44.png',\n",
       " '91.png',\n",
       " '99.png',\n",
       " '13.png',\n",
       " '19.png',\n",
       " '14.png',\n",
       " '0.png',\n",
       " '60.png',\n",
       " '49.png',\n",
       " '61.png',\n",
       " '36.png',\n",
       " '38.png',\n",
       " '42.png',\n",
       " '3.png',\n",
       " '88.png',\n",
       " '53.png',\n",
       " '22.png',\n",
       " '63.png',\n",
       " '40.png',\n",
       " '54.png',\n",
       " '87.png',\n",
       " '95.png',\n",
       " '4.png',\n",
       " '25.png',\n",
       " '6.png',\n",
       " '90.png',\n",
       " '50.png',\n",
       " '12.png',\n",
       " '16.png',\n",
       " '23.png',\n",
       " '29.png',\n",
       " '41.png',\n",
       " '45.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "angry-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-688520471316/batch_transform\n"
     ]
    }
   ],
   "source": [
    "inference_prefix = 'batch_transform'\n",
    "inference_inputs = sagemaker_session.upload_data(path=image_dir, bucket=bucket, key_prefix=inference_prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inference_inputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-drinking",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Create model transformer\n",
    "Now, we will create a transformer object for handling creating and interacting with Amazon SageMaker transform jobs. We can create the transformer in two ways as shown in the following notebook cells.\n",
    "- use fitted estimator directly\n",
    "- first create PyTorchModel from saved model artefect, then create transformer from PyTorchModel object\n",
    "\n",
    "\n",
    "Here, we implement the `model_fn`, `input_fn`, `predict_fn` and `output_fn` function to override the default [PyTorch inference handler](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_inference_handler.py). \n",
    "\n",
    "It is noted that in `input_fn` function, the inferenced images are encoded as a Python ByteArray. That's why we use `load_from_bytearray` function to load image from `io.BytesIO` then use `PIL.image` to read.\n",
    "\n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "    \n",
    "def load_from_bytearray(request_body):\n",
    "    image_as_bytes = io.BytesIO(request_body)\n",
    "    image = Image.open(image_as_bytes)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    # if set content_type as 'image/jpg' or 'applicaiton/x-npy', \n",
    "    # the input is also a python bytearray\n",
    "    if request_content_type == 'application/x-image': \n",
    "        image_tensor = load_from_bytearray(request_body)\n",
    "    else:\n",
    "        print(\"not support this type yet\")\n",
    "        raise ValueError(\"not support this type yet\")\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "def predict_fn(input_object, model):\n",
    "    output = model.forward(input_object)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    return {'predictions':pred.item()}\n",
    "\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "def output_fn(predictions, response_content_type):\n",
    "    return json.dumps(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numerous-birthday",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use fitted estimator directly\n",
    "transformer = estimator.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "actual-issue",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also create a Transformer object from saved model artefect\n",
    "\n",
    "# get model artefect location by estimator.model_data, or give a S3 key directly\n",
    "model_artefect_s3_location = estimator.model_data  #'s3://BUCKET/PREFIX/model.tar.gz'\n",
    "\n",
    "# create PyTorchModel from saved model artefect\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artefect_s3_location,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\".\",\n",
    "    entry_point=\"mnist.py\",\n",
    ")\n",
    "\n",
    "# then create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-dover",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Batch inference\n",
    "Next, we will inference the sampled 100 MNIST images in a batch manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-addition",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### input images directly from S3 location\n",
    "We set `S3DataType=S3Prefix` to uses all objects that match the specified S3 key name prefix for batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "polar-recorder",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34m2021-06-03 20:27:51,827 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 942 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:51,855 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:51,872 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 96a3766e8fbd45d0b58527f10680b25b\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:51,881 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:51,904 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,054 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,063 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,063 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,064 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,076 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,079 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,080 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,081 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]44\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,081 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,081 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,082 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,082 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,082 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,082 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,082 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,085 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,136 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,136 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,137 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,137 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,138 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,138 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,142 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,712 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,715 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.588714599609375|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,715 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.327198028564453|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,715 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.1|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,716 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6476.58203125|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,716 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:867.18359375|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:52,716 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:15.1|#Level:Host|#hostname:d9d539be4442,timestamp:1622752072\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,142 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 883\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,143 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1254|#Level:Host|#hostname:d9d539be4442,timestamp:1622752073\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,144 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:118|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,268 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1029\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,269 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1381|#Level:Host|#hostname:d9d539be4442,timestamp:1622752073\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,269 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:97|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,309 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1070\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,309 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1422|#Level:Host|#hostname:d9d539be4442,timestamp:1622752073\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,309 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:96|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,337 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,338 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1449|#Level:Host|#hostname:d9d539be4442,timestamp:1622752073\u001b[0m\n",
      "\u001b[34m2021-06-03 20:27:53,338 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:106|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,765 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:33768 \"GET /ping HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,765 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,796 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:33774 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,796 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,911 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,912 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,912 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,765 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:33768 \"GET /ping HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,765 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,796 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:33774 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,796 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,911 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,912 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,912 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,912 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.32|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f50ee6b6-538d-4d87-b70f-80bd7fdc1c78,timestamp:1622752081\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,913 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,913 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,994 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,912 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.32|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f50ee6b6-538d-4d87-b70f-80bd7fdc1c78,timestamp:1622752081\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,913 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,913 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,994 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,995 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:01,996 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.0|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:dbfda902-1c62-4cc7-9811-ffa5013349e6,timestamp:1622752081\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,175 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,177 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.16|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:4797888f-c2f1-4a05-9c4e-c10622e7e1f1,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:01,996 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.0|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:dbfda902-1c62-4cc7-9811-ffa5013349e6,timestamp:1622752081\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,175 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,177 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,176 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.16|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:4797888f-c2f1-4a05-9c4e-c10622e7e1f1,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,293 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,294 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,297 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.52|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:1b730d5b-e911-4da4-969e-8315a3593e21,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fe354cf5-eee4-48d4-8676-d24808ec6505,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,388 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,293 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,294 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,297 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.52|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:1b730d5b-e911-4da4-969e-8315a3593e21,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fe354cf5-eee4-48d4-8676-d24808ec6505,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,387 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,388 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:bfba17b4-037a-4354-82a8-e18bedaba2d1,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,563 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,563 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:b47e70db-54c1-4ab2-bed8-6ab06caaf081,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:520b9cda-ee44-49c1-8b9b-ec30a384a74b,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:1400b264-f8ca-4562-9eee-7bdd2ce7ffc7,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,739 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,739 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,828 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:aca73eb1-7b42-4403-84a3-529300894804,timestamp:1622752082\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,828 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,075 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:46745bb6-81c9-4bb5-8e63-6f527b6dc52c,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:bfba17b4-037a-4354-82a8-e18bedaba2d1,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,485 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,563 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,563 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:b47e70db-54c1-4ab2-bed8-6ab06caaf081,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,564 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:520b9cda-ee44-49c1-8b9b-ec30a384a74b,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,657 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:1400b264-f8ca-4562-9eee-7bdd2ce7ffc7,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,738 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,739 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,739 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,828 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:aca73eb1-7b42-4403-84a3-529300894804,timestamp:1622752082\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,828 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:02,829 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,075 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:46745bb6-81c9-4bb5-8e63-6f527b6dc52c,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,076 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,248 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,248 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:e31f2355-10e1-43a1-83dc-a695a73c5481,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,248 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,249 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,249 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,249 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,362 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,362 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:26a0fd9d-d70f-48c3-8c89-462514b97580,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,468 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,468 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:4fc423d4-88ad-477e-927f-c98ca2b18873,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,564 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,564 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:004ff8ba-9b7d-4075-8643-22eafd11d043,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,656 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c0596405-a308-4c4f-bb7e-9d4d20253d10,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:9cfd9aec-e6fe-4ac4-bd6b-3261d2946296,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,879 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:7612c366-37d4-40e5-b2e5-ff16e31c85b7,timestamp:1622752083\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,879 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,248 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,248 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:e31f2355-10e1-43a1-83dc-a695a73c5481,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,248 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,249 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,249 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,249 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,362 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,362 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:26a0fd9d-d70f-48c3-8c89-462514b97580,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,363 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,468 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,468 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:4fc423d4-88ad-477e-927f-c98ca2b18873,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,469 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,564 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,564 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:004ff8ba-9b7d-4075-8643-22eafd11d043,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,565 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,656 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c0596405-a308-4c4f-bb7e-9d4d20253d10,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,657 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:9cfd9aec-e6fe-4ac4-bd6b-3261d2946296,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,775 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,879 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:7612c366-37d4-40e5-b2e5-ff16e31c85b7,timestamp:1622752083\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,879 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:051be747-ffbc-4551-8ad1-9cbdf2f542c5,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,123 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:0444aa55-f15a-4293-bbd7-fe1f6e76b8b8,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,214 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:57510ba2-9fa5-4a72-8b3e-2d72b2fb6921,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,214 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:03,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:051be747-ffbc-4551-8ad1-9cbdf2f542c5,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,013 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,123 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:0444aa55-f15a-4293-bbd7-fe1f6e76b8b8,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,126 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,214 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:57510ba2-9fa5-4a72-8b3e-2d72b2fb6921,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,214 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,215 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:9275129e-2996-4de5-ad2d-6fdad476cc78,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,309 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,309 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:70f4f719-b294-440c-9402-784251f5eacf,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,394 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:0dac92e3-a8b0-45c6-84b4-be71d779f44d,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:9275129e-2996-4de5-ad2d-6fdad476cc78,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,308 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,309 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,309 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:70f4f719-b294-440c-9402-784251f5eacf,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,393 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,394 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:0dac92e3-a8b0-45c6-84b4-be71d779f44d,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,601 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,601 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:e454b698-c693-4923-94af-a3f14088d4fd,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d07ea0c3-060a-4b3b-bb87-2e7a0f5e261d,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8f8dfd9b-b623-49db-bbe8-78a90dfbe8cf,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fdb5b713-660f-4bd4-b065-5ceb0967c365,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,847 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,949 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,949 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:3706d4e2-13e7-4998-8497-59fc4a3a0e38,timestamp:1622752084\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,949 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,950 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,950 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:04,950 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,114 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:6429ae88-cb69-4602-8ea5-256d84f46089,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,185 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,185 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:75d270c2-1bf3-48d1-a9e9-bdf029a81d48,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,485 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,601 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,601 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:e454b698-c693-4923-94af-a3f14088d4fd,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,602 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d07ea0c3-060a-4b3b-bb87-2e7a0f5e261d,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,665 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8f8dfd9b-b623-49db-bbe8-78a90dfbe8cf,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,745 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fdb5b713-660f-4bd4-b065-5ceb0967c365,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,846 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,847 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,949 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,949 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:3706d4e2-13e7-4998-8497-59fc4a3a0e38,timestamp:1622752084\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,949 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,950 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,950 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:04,950 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,114 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:6429ae88-cb69-4602-8ea5-256d84f46089,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,115 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,185 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,185 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:75d270c2-1bf3-48d1-a9e9-bdf029a81d48,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,186 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[32m2021-06-03T20:28:01.806:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:a3975100-269d-4601-b1b3-6bdaec6c1bc9,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,297 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,297 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,378 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f8a61524-6365-4896-a634-a4f92638b184,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,516 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:5fcc4f92-11b9-4b5e-8b67-deffc4e726e8,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,594 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:851b4587-34b2-4225-9c9c-dcb66db14df9,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d6a2888c-230c-4944-9319-d67fa6301a6d,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,705 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,794 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,794 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:754c97b4-9c84-48d5-8472-4f4c757f8bbc,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:ecbe2ae9-eec9-46dc-8209-abdf8d3ecf77,timestamp:1622752085\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,034 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,034 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:98189729-bab8-4d66-b2e9-da8f8aca395c,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,169 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:e55c4065-6a34-4c3b-b310-f4d34ca6a4c8,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:a3975100-269d-4601-b1b3-6bdaec6c1bc9,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,296 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,297 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,297 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,378 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f8a61524-6365-4896-a634-a4f92638b184,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,379 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,516 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:5fcc4f92-11b9-4b5e-8b67-deffc4e726e8,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,517 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,594 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:851b4587-34b2-4225-9c9c-dcb66db14df9,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,595 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d6a2888c-230c-4944-9319-d67fa6301a6d,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,704 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,705 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,794 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,794 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:754c97b4-9c84-48d5-8472-4f4c757f8bbc,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,795 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:ecbe2ae9-eec9-46dc-8209-abdf8d3ecf77,timestamp:1622752085\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:05,923 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,034 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,034 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:98189729-bab8-4d66-b2e9-da8f8aca395c,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,035 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,169 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:e55c4065-6a34-4c3b-b310-f4d34ca6a4c8,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,170 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c47fc4b8-7acb-464b-bf08-67c80f10a552,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:36a9d310-d3bd-4ef4-b6e4-da642e6519d9,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,376 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,376 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,478 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,478 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:515945e9-c8f0-4c49-a7ee-135c0bd9a01c,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c26033ee-4db3-4cd9-b520-a2d0e3a04f5e,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,582 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,582 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,657 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,657 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f48551be-f46e-44d8-9565-06cd8adc1e31,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8b9baa00-91fd-4b79-974c-f98340bfaac0,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,753 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:eb1d19f9-02b6-47cf-a352-b8b6883122fe,timestamp:1622752086\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c47fc4b8-7acb-464b-bf08-67c80f10a552,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:36a9d310-d3bd-4ef4-b6e4-da642e6519d9,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,375 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,376 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,376 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,478 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,478 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:515945e9-c8f0-4c49-a7ee-135c0bd9a01c,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,479 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c26033ee-4db3-4cd9-b520-a2d0e3a04f5e,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,581 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,582 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,582 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,657 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,657 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f48551be-f46e-44d8-9565-06cd8adc1e31,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,658 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8b9baa00-91fd-4b79-974c-f98340bfaac0,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,752 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,753 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:eb1d19f9-02b6-47cf-a352-b8b6883122fe,timestamp:1622752086\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:dd9047fb-39ec-49de-9d56-0ab0a350b5ff,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,013 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,013 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:3fa57df9-81e5-44a2-8fd2-d802d5fe9928,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f5cd30de-bb2c-4ac3-a87c-2fb7d87f9484,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,221 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:06,911 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:dd9047fb-39ec-49de-9d56-0ab0a350b5ff,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,012 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,013 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,013 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:3fa57df9-81e5-44a2-8fd2-d802d5fe9928,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,128 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f5cd30de-bb2c-4ac3-a87c-2fb7d87f9484,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,220 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,221 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:742f0e46-1705-4bae-9c09-09f2d956a295,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,318 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,318 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,435 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,435 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d1f06190-cf06-48ce-9ae0-9304debd33e6,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,566 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,566 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:b3abf28e-3067-4c87-93d6-fcb1196305de,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:742f0e46-1705-4bae-9c09-09f2d956a295,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,318 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,318 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,435 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,435 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d1f06190-cf06-48ce-9ae0-9304debd33e6,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,436 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,566 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,566 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:b3abf28e-3067-4c87-93d6-fcb1196305de,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:057e0997-82f8-4353-9d8b-cf7c887d1f02,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,672 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,672 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fae5c316-c8d0-44ee-bdd6-db57262635d1,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8775b409-fb83-43a1-8274-f17fd5254e9d,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:36722bb7-e90c-4b18-a16c-60a2c28d842b,timestamp:1622752087\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,063 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,063 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:82033f41-5c1a-49dc-b9d8-1c01fc86ad29,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8e4c4346-29ad-4978-a2b8-3ce37da63c2e,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,135 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,135 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,237 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,237 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:7.45|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:7252a183-66dd-4533-9033-cc69b0e2a535,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 9\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:057e0997-82f8-4353-9d8b-cf7c887d1f02,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,671 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,672 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,672 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fae5c316-c8d0-44ee-bdd6-db57262635d1,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,768 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8775b409-fb83-43a1-8274-f17fd5254e9d,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:36722bb7-e90c-4b18-a16c-60a2c28d842b,timestamp:1622752087\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:07,980 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,063 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,063 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:82033f41-5c1a-49dc-b9d8-1c01fc86ad29,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,064 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8e4c4346-29ad-4978-a2b8-3ce37da63c2e,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,134 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,135 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,135 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,237 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,237 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:7.45|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:7252a183-66dd-4533-9033-cc69b0e2a535,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 9\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,238 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8486696e-cebe-495b-9989-05a6cadd467d,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:a81756a9-aa1d-4802-8ad3-f624165065b6,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8b844f91-c785-4ab7-8395-fab2072dad66,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:34cadb86-830b-4258-8235-dda06b790488,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:917dd40f-8a58-42df-bff0-a29542103cd5,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:b0d37b3a-97e4-4b32-8bf8-4b0cefb9f527,timestamp:1622752088\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,901 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:08,901 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,040 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d48aa376-99b4-4e4b-b843-be5fe0edbd9b,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.24|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f2cbe924-98a0-4739-823a-b1932ab9de43,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,233 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:5e057c73-c194-48c7-a6cc-f224b1cd19a6,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,237 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,237 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,237 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,238 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,238 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8486696e-cebe-495b-9989-05a6cadd467d,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:a81756a9-aa1d-4802-8ad3-f624165065b6,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,493 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8b844f91-c785-4ab7-8395-fab2072dad66,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,598 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:34cadb86-830b-4258-8235-dda06b790488,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,731 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:917dd40f-8a58-42df-bff0-a29542103cd5,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,801 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:b0d37b3a-97e4-4b32-8bf8-4b0cefb9f527,timestamp:1622752088\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,900 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,901 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:08,901 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,040 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:d48aa376-99b4-4e4b-b843-be5fe0edbd9b,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,041 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.24|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:f2cbe924-98a0-4739-823a-b1932ab9de43,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,121 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,233 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:5e057c73-c194-48c7-a6cc-f224b1cd19a6,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,237 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,237 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,237 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,238 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,238 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:84e78014-2109-4bf4-89f8-e65ef7a215c4,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:71a4ca86-1d0f-456d-b803-dfafdadbb6b2,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:caed11cd-dc4d-48af-9f02-7155cc6a3aa3,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,465 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,465 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fa665498-e214-4a2b-be62-0e88b9a0c9ef,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,659 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.24|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:34c0ed26-9aef-4c0b-9d29-ba736143edc4,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:84e78014-2109-4bf4-89f8-e65ef7a215c4,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,306 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:71a4ca86-1d0f-456d-b803-dfafdadbb6b2,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,387 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:caed11cd-dc4d-48af-9f02-7155cc6a3aa3,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,464 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,465 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,465 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fa665498-e214-4a2b-be62-0e88b9a0c9ef,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,562 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,659 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.24|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:34c0ed26-9aef-4c0b-9d29-ba736143edc4,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,748 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:86d31e29-ccdc-443f-9361-887ee3f79103,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,748 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fa795dcb-1d1b-48ab-998f-c80220d64e32,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:199950ba-3646-44e0-9c01-280098a431b8,timestamp:1622752089\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,055 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,055 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:dc64f96b-76e0-4dd3-888b-e3e7a2a9cce8,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:4e56d4f4-0dc6-471f-a2c1-d072acd95b36,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,660 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,748 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:86d31e29-ccdc-443f-9361-887ee3f79103,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,748 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,749 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fa795dcb-1d1b-48ab-998f-c80220d64e32,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,878 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:199950ba-3646-44e0-9c01-280098a431b8,timestamp:1622752089\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:09,968 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,055 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,055 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:dc64f96b-76e0-4dd3-888b-e3e7a2a9cce8,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,056 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:4e56d4f4-0dc6-471f-a2c1-d072acd95b36,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,168 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:19742c88-2722-481c-9726-8cedd0fc8cef,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:6ce0285c-577c-48cb-baa1-026a5017e81b,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.65|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:1618e00a-4966-4c5d-97dd-c3fc8b377a72,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:9c54c47d-0109-40b8-9d50-e26d3a4e8896,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,576 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:80393d38-6ef6-42ed-bcc5-b06168c6ecdf,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:865a66dd-2f6e-4b24-b20e-46d91bedcd19,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fd9c0c5d-eb9c-4790-8aa7-bb7d0ce938e1,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:19742c88-2722-481c-9726-8cedd0fc8cef,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,326 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:6ce0285c-577c-48cb-baa1-026a5017e81b,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.65|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:1618e00a-4966-4c5d-97dd-c3fc8b377a72,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,442 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:9c54c47d-0109-40b8-9d50-e26d3a4e8896,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,575 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,576 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:80393d38-6ef6-42ed-bcc5-b06168c6ecdf,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,647 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:865a66dd-2f6e-4b24-b20e-46d91bedcd19,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,735 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:fd9c0c5d-eb9c-4790-8aa7-bb7d0ce938e1,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:0a3c6602-5ff3-4459-a331-1b8f0f34bc78,timestamp:1622752090\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c980509a-cbd6-49ef-bcf7-f3c7ab574655,timestamp:1622752091\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,120 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,120 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:25fb2378-5c15-4679-bafc-e03d90af16b8,timestamp:1622752091\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.2|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:5ccb25c5-ecf0-49c1-9678-e3bfac9c07d3,timestamp:1622752091\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,843 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:0a3c6602-5ff3-4459-a331-1b8f0f34bc78,timestamp:1622752090\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:10,919 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:c980509a-cbd6-49ef-bcf7-f3c7ab574655,timestamp:1622752091\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,046 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,120 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,120 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:25fb2378-5c15-4679-bafc-e03d90af16b8,timestamp:1622752091\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,121 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.2|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:5ccb25c5-ecf0-49c1-9678-e3bfac9c07d3,timestamp:1622752091\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,189 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,680 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,680 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8c41f2fb-dc6c-4f5e-bfdb-57502ec6ea79,timestamp:1622752091\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:6b1c689e-870c-47dc-8228-bf550be31e61,timestamp:1622752091\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,926 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:100f674f-9c85-4186-b060-de39240f2df0,timestamp:1622752091\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,680 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,680 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:8c41f2fb-dc6c-4f5e-bfdb-57502ec6ea79,timestamp:1622752091\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:6b1c689e-870c-47dc-8228-bf550be31e61,timestamp:1622752091\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,854 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,926 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:100f674f-9c85-4186-b060-de39240f2df0,timestamp:1622752091\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:3d747ebe-7662-473f-8a73-1fa7995da89e,timestamp:1622752092\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,126 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,126 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:acbcfdbd-17aa-4b06-a1f1-fc2be5795c1a,timestamp:1622752092\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:11,927 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:3d747ebe-7662-473f-8a73-1fa7995da89e,timestamp:1622752092\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,036 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,126 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,126 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:d9d539be4442,requestID:acbcfdbd-17aa-4b06-a1f1-fc2be5795c1a,timestamp:1622752092\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33782 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-03 20:28:12,127 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:d9d539be4442,timestamp:null\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=inference_inputs, data_type=\"S3Prefix\", content_type=\"application/x-image\", wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-thumbnail",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### input images by manifest file\n",
    "First, we generate a manifest file. Then we use the manifest file containing a list of object keys that you want to batch inference. Some key points:\n",
    "- content_type = 'application/x-image' (!!! here the content_type is for the actual object to be inference, not for the manifest file)\n",
    "- data_type = 'ManifestFile'\n",
    "- Manifest file format must follow the format as [this document](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html#SageMaker-Type-S3DataSource-S3DataType) pointed out. We create the manifest file by using jsonlines package.\n",
    "``` json\n",
    "[ {\"prefix\": \"s3://customer_bucket/some/prefix/\"},\n",
    "\"relative/path/to/custdata-1\",\n",
    "\"relative/path/custdata-2\",\n",
    "...\n",
    "\"relative/path/custdata-N\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlikely-snapshot",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lonely-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_files\n",
      " ['78.png', '2.png', '21.png', '59.png', '85.png', '97.png', '37.png', '27.png', '20.png', '47.png', '48.png', '18.png', '68.png', '94.png', '46.png', '62.png', '43.png', '82.png', '33.png', '80.png', '57.png', '83.png', '70.png', '35.png', '10.png', '17.png', '52.png', '26.png', '92.png', '75.png', '56.png', '32.png', '79.png', '15.png', '7.png', '51.png', '9.png', '34.png', '74.png', '5.png', '72.png', '8.png', '93.png', '69.png', '31.png', '96.png', '11.png', '28.png', '24.png', '84.png', '55.png', '81.png', '64.png', '65.png', '39.png', '76.png', '67.png', '66.png', '1.png', '98.png', '77.png', '30.png', '58.png', '71.png', '73.png', '86.png', '89.png', '44.png', '91.png', '99.png', '13.png', '19.png', '14.png', '0.png', '60.png', '49.png', '61.png', '36.png', '38.png', '42.png', '3.png', '88.png', '53.png', '22.png', '63.png', '40.png', '54.png', '87.png', '95.png', '4.png', '25.png', '6.png', '90.png', '50.png', '12.png', '16.png', '23.png', '29.png', '41.png', '45.png']\n",
      "manifest_content\n",
      " [{'prefix': 's3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/images/'}, '78.png', '2.png', '21.png', '59.png', '85.png', '97.png', '37.png', '27.png', '20.png', '47.png', '48.png', '18.png', '68.png', '94.png', '46.png', '62.png', '43.png', '82.png', '33.png', '80.png', '57.png', '83.png', '70.png', '35.png', '10.png', '17.png', '52.png', '26.png', '92.png', '75.png', '56.png', '32.png', '79.png', '15.png', '7.png', '51.png', '9.png', '34.png', '74.png', '5.png', '72.png', '8.png', '93.png', '69.png', '31.png', '96.png', '11.png', '28.png', '24.png', '84.png', '55.png', '81.png', '64.png', '65.png', '39.png', '76.png', '67.png', '66.png', '1.png', '98.png', '77.png', '30.png', '58.png', '71.png', '73.png', '86.png', '89.png', '44.png', '91.png', '99.png', '13.png', '19.png', '14.png', '0.png', '60.png', '49.png', '61.png', '36.png', '38.png', '42.png', '3.png', '88.png', '53.png', '22.png', '63.png', '40.png', '54.png', '87.png', '95.png', '4.png', '25.png', '6.png', '90.png', '50.png', '12.png', '16.png', '23.png', '29.png', '41.png', '45.png']\n",
      "manifest_obj\n",
      " s3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "# build image list\n",
    "manifest_prefix = f\"s3://{bucket}/{prefix}/images/\"\n",
    "\n",
    "path = image_dir\n",
    "img_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "print('img_files\\n', img_files)\n",
    "\n",
    "manifest_content = [{\"prefix\": manifest_prefix}]\n",
    "manifest_content.extend(img_files)\n",
    "\n",
    "print('manifest_content\\n', manifest_content)\n",
    "\n",
    "# write jsonl file\n",
    "manifest_file = \"manifest.json\"\n",
    "with jsonlines.open(manifest_file, mode=\"w\") as writer:\n",
    "    writer.write(manifest_content)\n",
    "    \n",
    "# upload to S3\n",
    "manifest_obj = sagemaker_session.upload_data(path=manifest_file, key_prefix=prefix)\n",
    "\n",
    "print('manifest_obj\\n', manifest_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "changed-gregory",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch transform with manifest file\n",
    "transform_job = transformer.transform(\n",
    "    data=manifest_obj, data_type=\"ManifestFile\", content_type=\"application/x-image\", wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fatty-arrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest transform job \n",
      " pytorch-inference-2021-06-03-21-07-31-593\n"
     ]
    }
   ],
   "source": [
    "print('latest transform job \\n', transformer.latest_transform_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "downtown-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 7, 32, 528000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2021-06-03-20-12-03-872',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '943',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Thu, 03 Jun 2021 21:15:20 GMT',\n",
      "                                      'x-amzn-requestid': '5f59af42-1fc8-42c1-b59d-a5ca4411c211'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '5f59af42-1fc8-42c1-b59d-a5ca4411c211',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 12, 2, 959000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'ManifestFile',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-21-07-31-593',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-21-07-31-593',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-688520471316/pytorch-inference-2021-06-03-21-07-31-593'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.c5.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2021, 6, 3, 21, 10, 42, 238000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "# look at the status of the transform job\n",
    "import boto3\n",
    "import pprint as pp\n",
    "\n",
    "sm_cli = boto3.client('sagemaker')\n",
    "\n",
    "res = sm_cli.describe_transform_job(\n",
    "    TransformJobName=transformer.latest_transform_job.name\n",
    ")\n",
    "\n",
    "pp.pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-option",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "###  Multiple instance\n",
    "We use `instance_count > 1` to create multiple inference instances. When a batch transform job starts, Amazon SageMaker initializes compute instances and distributes the inference or preprocessing workload between them. Batch Transform partitions the Amazon S3 objects in the input by key and maps Amazon S3 objects to instances. When you have multiples files, one instance might process input1.csv, and another instance might process the file named input2.csv.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "civic-victorian",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_transformer = estimator.transformer(instance_count=2, instance_type=\"ml.c4.xlarge\")\n",
    "\n",
    "dist_transformer.transform(\n",
    "    data=inference_inputs, data_type=\"S3Prefix\", content_type=\"application/x-image\", wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-deployment",
   "metadata": {},
   "source": [
    "## Look at all transform jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "naughty-skill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 7, 32, 528000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 21, 12, 2, 962000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 12, 2, 959000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-21-07-31-593',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-21-07-31-593',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 5, 25, 664000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 21, 10, 38, 638000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 10, 38, 636000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-03-21-05-25-297',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-03-21-05-25-297',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 5, 19, 888000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 21, 9, 47, 923000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 9, 47, 920000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-21-05-19-449',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-21-05-19-449',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 23, 34, 835000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 28, 14, 566000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 28, 14, 563000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-20-23-34-620',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-20-23-34-620',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 23, 27, 979000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 28, 12, 860000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 28, 12, 857000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-20-23-27-273',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-20-23-27-273',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 22, 33, 696000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 28, 22, 94000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 28, 22, 92000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-03-20-22-33-397',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-03-20-22-33-397',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 12, 9, 12000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 17, 7, 970000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 17, 7, 967000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-03-20-12-08-657',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-03-20-12-08-657',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 12, 8, 119000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 16, 43, 35000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 16, 43, 9000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-20-12-07-923',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-20-12-07-923',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 12, 5, 734000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 16, 50, 996000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 16, 50, 994000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-20-12-05-578',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-20-12-05-578',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 5, 28, 20, 51, 36, 886000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 5, 28, 20, 56, 31, 746000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 5, 28, 20, 56, 31, 745000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/sagemaker-scikit-learn-2021-05-28-20-51-36-648',\n",
      " 'TransformJobName': 'sagemaker-scikit-learn-2021-05-28-20-51-36-648',\n",
      " 'TransformJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "tjs = sm_cli.list_transform_jobs()['TransformJobSummaries']\n",
    "for tj in tjs:\n",
    "    pp.pprint(tj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-closure",
   "metadata": {},
   "source": [
    "## Look at the output from the latest tranform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "lightweight-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "job_completed = False\n",
    "\n",
    "while not job_completed:\n",
    "    res = sm_cli.describe_transform_job(\n",
    "    TransformJobName=transformer.latest_transform_job.name\n",
    "        )\n",
    "    status = res['TransformJobStatus']\n",
    "    job_completed = (status == 'Completed' or status == 'Failed' or status == 'Stopped')\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the transformed output\n",
    "\n",
    "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 7, 32, 528000, tzinfo=tzlocal()),\n",
    " 'DataProcessing': {'InputFilter': '$',\n",
    "                    'JoinSource': 'None',\n",
    "                    'OutputFilter': '$'},\n",
    " 'ModelName': 'pytorch-inference-2021-06-03-20-12-03-872',\n",
    " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '943',\n",
    "                                      'content-type': 'application/x-amz-json-1.1',\n",
    "                                      'date': 'Thu, 03 Jun 2021 21:15:20 GMT',\n",
    "                                      'x-amzn-requestid': '5f59af42-1fc8-42c1-b59d-a5ca4411c211'},\n",
    "                      'HTTPStatusCode': 200,\n",
    "                      'RequestId': '5f59af42-1fc8-42c1-b59d-a5ca4411c211',\n",
    "                      'RetryAttempts': 0},\n",
    " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 12, 2, 959000, tzinfo=tzlocal()),\n",
    " 'TransformInput': {'CompressionType': 'None',\n",
    "                    'ContentType': 'application/x-image',\n",
    "                    'DataSource': {'S3DataSource': {'S3DataType': 'ManifestFile',\n",
    "                                                    'S3Uri': 's3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json'}},\n",
    "                    'SplitType': 'None'},\n",
    " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-21-07-31-593',\n",
    " 'TransformJobName': 'pytorch-inference-2021-06-03-21-07-31-593',\n",
    " 'TransformJobStatus': 'Completed',\n",
    " 'TransformOutput': {'AssembleWith': 'None',\n",
    "                     'KmsKeyId': '',\n",
    "                     'S3OutputPath': 's3://sagemaker-us-west-2-688520471316/pytorch-inference-2021-06-03-21-07-31-593'},\n",
    " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.c5.xlarge'},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "functioning-nightlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-688520471316 pytorch-inference-2021-06-03-21-07-31-593\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_bucket_and_prefix(s3_output_path):\n",
    "    trim = re.sub('s3://', '', s3_output_path)\n",
    "    bucket, prefix = trim.split('/')\n",
    "    return bucket, prefix\n",
    "\n",
    "local_path = '/tmp/output' # where to save the output locally\n",
    "\n",
    "bucket, output_prefix = get_bucket_and_prefix(res['TransformOutput']['S3OutputPath'])\n",
    "print(bucket, output_prefix)\n",
    "\n",
    "sagemaker_session.download_data(path=local_path, bucket=bucket, key_prefix=output_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "provincial-cycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png.out   24.png.out\t4.png.out   55.png.out\t70.png.out  86.png.out\n",
      "1.png.out   25.png.out\t40.png.out  56.png.out\t71.png.out  87.png.out\n",
      "10.png.out  26.png.out\t41.png.out  57.png.out\t72.png.out  88.png.out\n",
      "11.png.out  27.png.out\t42.png.out  58.png.out\t73.png.out  89.png.out\n",
      "12.png.out  28.png.out\t43.png.out  59.png.out\t74.png.out  9.png.out\n",
      "13.png.out  29.png.out\t44.png.out  6.png.out\t75.png.out  90.png.out\n",
      "14.png.out  3.png.out\t45.png.out  60.png.out\t76.png.out  91.png.out\n",
      "15.png.out  30.png.out\t46.png.out  61.png.out\t77.png.out  92.png.out\n",
      "16.png.out  31.png.out\t47.png.out  62.png.out\t78.png.out  93.png.out\n",
      "17.png.out  32.png.out\t48.png.out  63.png.out\t79.png.out  94.png.out\n",
      "18.png.out  33.png.out\t49.png.out  64.png.out\t8.png.out   95.png.out\n",
      "19.png.out  34.png.out\t5.png.out   65.png.out\t80.png.out  96.png.out\n",
      "2.png.out   35.png.out\t50.png.out  66.png.out\t81.png.out  97.png.out\n",
      "20.png.out  36.png.out\t51.png.out  67.png.out\t82.png.out  98.png.out\n",
      "21.png.out  37.png.out\t52.png.out  68.png.out\t83.png.out  99.png.out\n",
      "22.png.out  38.png.out\t53.png.out  69.png.out\t84.png.out\n",
      "23.png.out  39.png.out\t54.png.out  7.png.out\t85.png.out\n"
     ]
    }
   ],
   "source": [
    "!ls {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "neither-arrow",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 9}\n",
      "{'predictions': 0}\n",
      "{'predictions': 9}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 8}\n",
      "{'predictions': 7}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 9}\n",
      "{'predictions': 7}\n",
      "{'predictions': 1}\n",
      "{'predictions': 7}\n",
      "{'predictions': 2}\n",
      "{'predictions': 3}\n",
      "{'predictions': 8}\n",
      "{'predictions': 3}\n",
      "{'predictions': 0}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 9}\n",
      "{'predictions': 0}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 3}\n",
      "{'predictions': 7}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 6}\n",
      "{'predictions': 8}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 5}\n",
      "{'predictions': 0}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 9}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 6}\n",
      "{'predictions': 3}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 6}\n",
      "{'predictions': 2}\n",
      "{'predictions': 3}\n",
      "{'predictions': 9}\n",
      "{'predictions': 5}\n",
      "{'predictions': 9}\n",
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 8}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 9}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, 'r') as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 333.854918,
   "end_time": "2021-06-03T00:15:43.072184",
   "environment_variables": {},
   "exception": true,
   "input_path": "pytorch-mnist-batch-transform.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch-mnist-batch-transform-2021-06-03-00-06-06.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-03T00:10:09.217266",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01005530a5b1473b9f4a024b19c04c0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_968ed82ad8f0453e8f81a839df4428db",
       "placeholder": "",
       "style": "IPY_MODEL_e4f0965e53ee40adb1ae44da87428325",
       "value": "  0%"
      }
     },
     "0995f6633c0f4facabe6759837c606ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1410dcfcd117434889e9594cdde4e1b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "18caaab41d6146c1824859691f6cb435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d823500ff0dc4c2198b83cd231f8bffe",
       "placeholder": "",
       "style": "IPY_MODEL_7dab31892241494e8d27d38ca98e5aa6",
       "value": " 0/28881 [00:00&lt;?, ?it/s]"
      }
     },
     "19ef65b0ecae45bdbca066cea679878d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ceacd43f28744eb9b7a12f8276b6016",
        "IPY_MODEL_e44ddce6c5704f0b9495ee662806f5f6",
        "IPY_MODEL_7717cc87ebcc4c0581ae32848b40982c"
       ],
       "layout": "IPY_MODEL_59d0678977a343abb8a02dc5c9699b89"
      }
     },
     "2126024805384bff9b0409b4dc91e60c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "216ba33f9f1b486ebac2a6fce0510246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f94b5a0d68c541e894e325a0e2f899d2",
       "placeholder": "",
       "style": "IPY_MODEL_633cc1cdb94e43a6a07559483496c60d",
       "value": "  0%"
      }
     },
     "23445154eb524df985b5a755fcbddd32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_216ba33f9f1b486ebac2a6fce0510246",
        "IPY_MODEL_c4f4f4bfe979469c9bc59ab73bbf518f",
        "IPY_MODEL_fe83e178358040eaa07f6198ba693fc9"
       ],
       "layout": "IPY_MODEL_cf1f337300394948bce741af7bcd8b8c"
      }
     },
     "235ae38cf16e4aacb95c3d16d9749da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c2474d5a8144bf8930fa5cc02c73ccf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5495428879544d6da73e2ed7e70f0c96",
        "IPY_MODEL_6e2a4641cd944d9a8196f4a836e90590",
        "IPY_MODEL_9179e5f467c8450a988b988d7da06090"
       ],
       "layout": "IPY_MODEL_596f8cbad0884ec79cf6ee757cc9f38a"
      }
     },
     "2ceacd43f28744eb9b7a12f8276b6016": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a540362f86774590851c1d0892bea723",
       "placeholder": "",
       "style": "IPY_MODEL_bb9ebd025f05499da7b847b8ef7a9ff5",
       "value": ""
      }
     },
     "495839f4239743669d9ee61cfbc33967": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d62b9fde9104c8081b545c3933a077e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51a28ca59cf9407ea0e02da868d79ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5495428879544d6da73e2ed7e70f0c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_235ae38cf16e4aacb95c3d16d9749da3",
       "placeholder": "",
       "style": "IPY_MODEL_fe60ae53dd1646ca91018ba20934948b",
       "value": ""
      }
     },
     "596f8cbad0884ec79cf6ee757cc9f38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59d0678977a343abb8a02dc5c9699b89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "633cc1cdb94e43a6a07559483496c60d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63a57f663bfa4a1585c1ba36501b6b23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e2a4641cd944d9a8196f4a836e90590": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb8c653eeeb24799bcc9279389fdb523",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b513a456776d40b496f035c64360db90",
       "value": 1
      }
     },
     "7717cc87ebcc4c0581ae32848b40982c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b63360561b34257b171498e67902dda",
       "placeholder": "",
       "style": "IPY_MODEL_f86487d9a78940a394503b2bea77d756",
       "value": " 9920512/? [04:50&lt;00:00, 36552.15it/s]"
      }
     },
     "7bceed60fb344aa182dccc3dcf0ee886": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_01005530a5b1473b9f4a024b19c04c0e",
        "IPY_MODEL_e82a5227430443d98d29555fd77b2bd3",
        "IPY_MODEL_18caaab41d6146c1824859691f6cb435"
       ],
       "layout": "IPY_MODEL_63a57f663bfa4a1585c1ba36501b6b23"
      }
     },
     "7dab31892241494e8d27d38ca98e5aa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8b5b76e77cb14ecf95a310ba46ed86f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "9179e5f467c8450a988b988d7da06090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94ef992b73d44d829b863815da70111f",
       "placeholder": "",
       "style": "IPY_MODEL_1410dcfcd117434889e9594cdde4e1b0",
       "value": " 1654784/? [00:47&lt;00:00, 33514.08it/s]"
      }
     },
     "94ef992b73d44d829b863815da70111f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "968ed82ad8f0453e8f81a839df4428db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b63360561b34257b171498e67902dda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a540362f86774590851c1d0892bea723": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b513a456776d40b496f035c64360db90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb9ebd025f05499da7b847b8ef7a9ff5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c0b88a223b374693b6b0c74db9ffe346": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "c4f4f4bfe979469c9bc59ab73bbf518f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b5b76e77cb14ecf95a310ba46ed86f5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51a28ca59cf9407ea0e02da868d79ebd",
       "value": 0
      }
     },
     "cf1f337300394948bce741af7bcd8b8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d823500ff0dc4c2198b83cd231f8bffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e44ddce6c5704f0b9495ee662806f5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0995f6633c0f4facabe6759837c606ba",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d62b9fde9104c8081b545c3933a077e",
       "value": 1
      }
     },
     "e4f0965e53ee40adb1ae44da87428325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e82a5227430443d98d29555fd77b2bd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0b88a223b374693b6b0c74db9ffe346",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_495839f4239743669d9ee61cfbc33967",
       "value": 0
      }
     },
     "eb4c77cfe2c54976aef8efc0e3207140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f86487d9a78940a394503b2bea77d756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f94b5a0d68c541e894e325a0e2f899d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb8c653eeeb24799bcc9279389fdb523": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "fe60ae53dd1646ca91018ba20934948b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe83e178358040eaa07f6198ba693fc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2126024805384bff9b0409b4dc91e60c",
       "placeholder": "",
       "style": "IPY_MODEL_eb4c77cfe2c54976aef8efc0e3207140",
       "value": " 0/4542 [00:00&lt;?, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
