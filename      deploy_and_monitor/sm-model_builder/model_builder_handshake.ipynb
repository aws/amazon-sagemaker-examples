{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609dabdc97ce0a62",
   "metadata": {},
   "source": [
    "# Model Builder Redesign\n",
    "## This notebook highlights the new changes made to ModelBuilder and related utilities\n",
    "\n",
    "- Latest Container Image Utility function\n",
    "- Handshake with ModelTrainer \n",
    "- Unified Deployment from ModelBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0ea46e1886184",
   "metadata": {},
   "outputs": [],
   "source": [
    "alias = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421db5dfb9a7fa7",
   "metadata": {},
   "source": [
    "## Inital Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30656ece22011af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Session, get_execution_role\n",
    "\n",
    "sagemaker_session = Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    default_bucket_prefix_path = f\"{default_bucket_prefix}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea8169b21eaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare Data\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df[\"target\"] = iris.target\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "iris_df = iris_df[[\"target\"] + [col for col in iris_df.columns if col != \"target\"]]\n",
    "\n",
    "train_data, test_data = train_test_split(iris_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.to_csv(\"./data/train.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"./data/test.csv\", index=False, header=False)\n",
    "\n",
    "# Remove the target column from the testing data. We will use this to call invoke_endpoint later\n",
    "test_data_no_target = test_data.drop(\"target\", axis=1)\n",
    "\n",
    "prefix = \"DEMO-scikit-iris\"\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    prefix = f\"{default_bucket_prefix}/{prefix}\"\n",
    "\n",
    "TRAIN_DATA = \"train.csv\"\n",
    "TEST_DATA = \"test.csv\"\n",
    "DATA_DIRECTORY = \"data\"\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    DATA_DIRECTORY, bucket=bucket, key_prefix=\"{}/{}\".format(prefix, DATA_DIRECTORY)\n",
    ")\n",
    "\n",
    "\n",
    "s3_input_path = \"s3://{}/{}/data/{}\".format(bucket, prefix, TRAIN_DATA)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "s3_test_path = \"s3://{}/{}/data/{}\".format(bucket, prefix, TEST_DATA)\n",
    "\n",
    "print(s3_input_path)\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5055ba5ccb2bb",
   "metadata": {},
   "source": [
    "\n",
    "# Integration with ModelTrainer\n",
    "\n",
    "The handshake between ModelTrainer and ModelBuilder is made seamlessly as in this example. The created model trainer object is directly fed into the model attribute of ModelBuilder through resource chaining . Fetching of the model artifacts is done internally within the ModelBuilder. \n",
    "\n",
    "Note: \n",
    "- Other than the ModelTrainer, the ModelBuilder also supports chaining of attributes such as Estimator or sagemaker-core's TrainingJob into the model attribute. \n",
    "\n",
    "Other than this there is an upgrade designed for retrieving images for a particular framework. The enhanced `image_uris.retrieve()` method will fetch the latest version of an image automatically if the version is not provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a4f7d1713685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "from sagemaker_core.main.shapes import (\n",
    "    Channel,\n",
    "    DataSource,\n",
    "    S3DataSource,\n",
    "    OutputDataConfig,\n",
    "    StoppingCondition,\n",
    ")\n",
    "from sagemaker.modules.train.model_trainer import ModelTrainer\n",
    "\n",
    "# xgboost_image=\"433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest\"\n",
    "xgboost_image = image_uris.retrieve(framework=\"xgboost\", region=\"us-west-2\", image_scope=\"training\")\n",
    "print(xgboost_image)\n",
    "\n",
    "model_trainer = ModelTrainer(\n",
    "    base_job_name=f\"{alias}-mb-handshake\",\n",
    "    hyperparameters={\n",
    "        \"objective\": \"multi:softmax\",\n",
    "        \"num_class\": \"3\",\n",
    "        \"num_round\": \"10\",\n",
    "        \"eval_metric\": \"merror\",\n",
    "    },\n",
    "    training_image=xgboost_image,\n",
    "    training_input_mode=\"File\",\n",
    "    role=role,\n",
    "    output_data_config=OutputDataConfig(s3_output_path=s3_output_path),\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=600),\n",
    ")\n",
    "\n",
    "model_trainer.train(\n",
    "    input_data_config=[\n",
    "        Channel(\n",
    "            channel_name=\"train\",\n",
    "            content_type=\"csv\",\n",
    "            compression_type=\"None\",\n",
    "            record_wrapper_type=\"None\",\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type=\"S3Prefix\",\n",
    "                    s3_uri=s3_input_path,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\",\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a16ef277257a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sagemaker.serve.spec.inference_spec import InferenceSpec\n",
    "from sagemaker.serve import ModelBuilder\n",
    "\n",
    "data = {\"Name\": [\"Alice\", \"Bob\", \"Charlie\"]}\n",
    "df = pd.DataFrame(data)\n",
    "schema_builder = SchemaBuilder(sample_input=df, sample_output=df)\n",
    "\n",
    "\n",
    "class XGBoostSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        print(model_dir)\n",
    "        model = XGBClassifier()\n",
    "        model.load_model(model_dir + \"/xgboost-model\")\n",
    "        return model\n",
    "\n",
    "    def invoke(self, input_object: object, model: object):\n",
    "        prediction_probabilities = model.predict_proba(input_object)\n",
    "        predictions = np.argmax(prediction_probabilities, axis=1)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "model_builder = ModelBuilder(\n",
    "    model=model_trainer,  # ModelTrainer object passed onto ModelBuilder directly\n",
    "    role_arn=role,\n",
    "    image_uri=xgboost_image,\n",
    "    inference_spec=XGBoostSpec(),\n",
    "    schema_builder=schema_builder,\n",
    "    instance_type=\"ml.c6i.xlarge\",\n",
    ")\n",
    "model = model_builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b403edaf616ef0",
   "metadata": {},
   "source": [
    "Once the model has been built , it can be deployed directly through the model_builder.deploy() method. This abstracts out information that was previously used commonly in workflows for different deployment modes. The deploy() method takes in an optional parameter `inference_config`. This determines attributes for modes such as serverless, async, batch and multi-model/multi-container endpoints. If the `inference_config` is not provided, the default real-time deployment is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44416566576e26df",
   "metadata": {},
   "source": [
    "## ModelBuilder - Real-Time Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43000f6bd6018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model_builder.deploy(endpoint_name=f\"{alias}-xgboost-deploy-realtime\")\n",
    "sklearn_input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "result = predictor.predict(sklearn_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0e6f6e92d0aeb",
   "metadata": {},
   "source": [
    "## ModelBuilder - Serverless Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3c9973d2d8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "predictor = model_builder.deploy(\n",
    "    endpoint_name=f\"{alias}-xgboost-deploy-serverless\",\n",
    "    inference_config=ServerlessInferenceConfig(memory_size_in_mb=2048),\n",
    ")\n",
    "sklearn_input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "result = predictor.predict(sklearn_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93818038782f105d",
   "metadata": {},
   "source": [
    "## ModelBuilder - Async Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7104aaa9d6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "from sagemaker.s3_utils import s3_path_join\n",
    "\n",
    "predictor = model_builder.deploy(\n",
    "    endpoint_name=f\"{alias}-xgboost-deploy-async\",\n",
    "    inference_config=AsyncInferenceConfig(\n",
    "        output_path=s3_path_join(\n",
    "            \"s3://\", bucket, f\"{default_bucket_prefix_path}async_inference/output\"\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "sklearn_input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "result = predictor.predict(sklearn_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3e043b5f5f8d7",
   "metadata": {},
   "source": [
    "## ModelBuilder - Batch Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef3febc0f840133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.batch_inference.batch_transform_inference_config import BatchTransformInferenceConfig\n",
    "from sagemaker.s3_utils import s3_path_join\n",
    "\n",
    "transformer = model_builder.deploy(\n",
    "    endpoint_name=f\"{alias}-xgboost-deploy-batch\",\n",
    "    inference_config=BatchTransformInferenceConfig(\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        output_path=s3_path_join(\n",
    "            \"s3://\", bucket, f\"{default_bucket_prefix_path}batch_inference/output\"\n",
    "        ),\n",
    "        test_data_s3_path=s3_test_path,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e103b7292694eb",
   "metadata": {},
   "source": [
    "## ModelBuilder - Multi-Model Endpoint Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c622148377c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements\n",
    "\n",
    "predictor = model_builder.deploy(\n",
    "    endpoint_name=f\"{alias}-xgboost-deploy-multi-model\",\n",
    "    inference_config=ResourceRequirements(\n",
    "        requests={\n",
    "            \"num_cpus\": 0.5,\n",
    "            \"memory\": 512,\n",
    "            \"copies\": 2,\n",
    "        },\n",
    "        limits={},\n",
    "    ),\n",
    ")\n",
    "\n",
    "sklearn_input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "result = predictor.predict(sklearn_input)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
