{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Deploying ML Models using JAX on SageMaker\n",
    "Amazon SageMaker provides you the flexibility to train models using any framework that can work in a Docker container. In this example we'll show how to utilize the Bring-Your-Own-Container (BYOC) paradigm to train machine learning models using the increasingly popular [JAX library from Google](https://github.com/google/jax). We'll train a fashion mnist classification model using vanilla JAX, another using `jax.experimental.stax`, and a final model using the [higher level Trax library from Google](https://github.com/google/trax).\n",
    "\n",
    "For both of these demos, we'll show how both JAX and Trax can serialize models using the TensorFlow standard [SavedModel format](https://www.tensorflow.org/guide/saved_model). This enables us to train these models in a custom container, but then deploy them using the managed and optimized SageMaker TensorFlow inference containers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker_jax import JaxEstimator\n",
    "\n",
    "client = boto3.client(\"sts\")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "role = get_execution_role()\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "container_name = \"sagemaker-jax\"\n",
    "ecr_image = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account, region, container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Framework Estimator\n",
    "Since we'll be saving our JAX and Trax models as SavedModel format, we can create a subclass of the base [SageMaker Framework estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html?highlight=Framework#sagemaker.estimator.Framework). This will enable us to specify a custom `create_model` method which leverages the existing TensorFlowModel class to launch inference containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize sagemaker_jax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Docker Container\n",
    "Our custom training container is straight forward, though there are a few things worth mentioning that can be seen in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Publishing the Image\n",
    "The below shell script must be run if the docker image has not already been pushed to the Elastic Container Registry. \n",
    "\n",
    "**NOTE: Since SageMaker studio is already running inside a Docker container, this script cannot be run inside SageMaker Studio. Please push your container using awscli or use this toolkit: https://github.com/aws-samples/sagemaker-studio-image-build-cli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sh\n",
    "\n",
    "# container_name=sagemaker-jax\n",
    "# account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# # Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "# region=$(aws configure get region)\n",
    "# region=${region:-us-west-2}\n",
    "\n",
    "# fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${container_name}\"\n",
    "\n",
    "# # If the repository doesn't exist in ECR, create it.\n",
    "# aws ecr describe-repositories --repository-names \"${container_name}\" > /dev/null 2>&1\n",
    "# if [ $? -ne 0 ]\n",
    "# then\n",
    "#     aws ecr create-repository --repository-name \"${container_name}\" > /dev/null\n",
    "# fi\n",
    "\n",
    "# # Get the login command from ECR and execute it directly\n",
    "# $(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# # Build the docker image locally with the image name and then push it to ECR\n",
    "# # with the full name.\n",
    "# docker build  -t ${container_name} docker/\n",
    "# docker tag ${container_name} ${fullname}\n",
    "\n",
    "# docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing models as SavedModel format\n",
    "In the upcoming training jobs we'll be training a vanilla JAX model, a Stax model, and a Trax model on the [fashion mnist dataset](https://github.com/zalandoresearch/fashion-mnist).\n",
    "The full details of the model can be seen in the `training_scripts/` directory, but it is worth calling out the methods for serialization.\n",
    "\n",
    "The JAX model utilizes the new experimental jax2tf converter: https://github.com/google/jax/tree/master/jax/experimental/jax2tf\n",
    "\n",
    "The Trax model utilizes the new trax2keras functionality: https://github.com/google/trax/blob/master/trax/trax2keras.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using Vanilla JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_jax_estimator = JaxEstimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    base_job_name=container_name + \"-jax\",\n",
    "    source_dir=\"training_scripts\",\n",
    "    entry_point=\"train_jax.py\",\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    hyperparameters={\"num_epochs\": 3},\n",
    ")\n",
    "vanilla_jax_estimator.fit(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Using JAX Medium-level API Stax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stax_estimator = JaxEstimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    base_job_name=container_name + \"-jax\",\n",
    "    source_dir=\"training_scripts\",\n",
    "    entry_point=\"train_stax.py\",\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    hyperparameters={\"num_epochs\": 3},\n",
    ")\n",
    "\n",
    "stax_estimator.fit(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Using JAX High-level API Trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trax_estimator = JaxEstimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    base_job_name=container_name + \"-trax\",\n",
    "    source_dir=\"training_scripts\",\n",
    "    entry_point=\"train_trax.py\",\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    hyperparameters={\"train_steps\": 1000},\n",
    ")\n",
    "\n",
    "trax_estimator.fit(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Both Models to prebuilt TF Containers\n",
    "Since we've our customer Framework Estimator knows the models are to be served using TensorFlowModel, deploying these endpoints is just a trivial call to the `estimator.deploy()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_jax_predictor = vanilla_jax_estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trax_predictor = trax_estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stax_predictor = stax_estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference Endpoints\n",
    "This requires TF to be installed on your notebook's kernel as it is used to load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(predictor, test_images, test_labels, image_number):\n",
    "    np_img = np.expand_dims(np.expand_dims(test_images[image_number], axis=-1), axis=0)\n",
    "\n",
    "    result = predictor.predict(np_img)\n",
    "    pred_y = np.argmax(result[\"predictions\"])\n",
    "\n",
    "    print(\"True Label:\", test_labels[image_number])\n",
    "    print(\"Predicted Label:\", pred_y)\n",
    "    plt.imshow(test_images[image_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image(vanilla_jax_predictor, x_test, y_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image(stax_predictor, x_test, y_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image(trax_predictor, x_test, y_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Delete the running endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clean-Up\n",
    "vanilla_jax_predictor.delete_endpoint()\n",
    "stax_predictor.delete_endpoint()\n",
    "trax_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
