{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R API Serving Examples\n",
    "\n",
    "In this example, we compare the runtimes of three methods for serving a model from an R hosted API:\n",
    "\n",
    "* **Plumber**\n",
    " * Website: [https://www.rplumber.io/](https://www.rplumber.io/)\n",
    " * SageMaker Example: [r_byo_algo_with_plumber](../r_byo_algo_with_plumber)\n",
    "* **RestRServe**\n",
    " * Website: [https://restrserve.org](https://restrserve.org/)\n",
    " * SageMaker Example: [r_byo_algo_with_restrserve](../r_byo_algo_with_restrserve)\n",
    "* **FastAPI** (reticulated from Python)\n",
    " * Website: [https://fastapi.tiangolo.com](https://fastapi.tiangolo.com/)\n",
    " * SageMaker Example: [r_byo_algo_with_fastapi](../r_byo_algo_with_fastapi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Docker Images for Serving\n",
    "\n",
    "First, let's build each docker image from the provided SageMaker Examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plumber Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  269.8kB\n",
      "Step 1/9 : FROM r-base:3.6.3\n",
      " ---> cec2502269fb\n",
      "Step 2/9 : MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
      " ---> Using cache\n",
      " ---> d5c7ee17124e\n",
      "Step 3/9 : RUN apt-get -y update && apt-get install -y --no-install-recommends     wget     apt-transport-https     ca-certificates     libcurl4-openssl-dev     libsodium-dev\n",
      " ---> Using cache\n",
      " ---> 9045f663fee5\n",
      "Step 4/9 : RUN R -e \"install.packages(c('xgboost','plumber'), repos='https://cloud.r-project.org')\"\n",
      " ---> Using cache\n",
      " ---> f3e0508834a6\n",
      "Step 5/9 : COPY xgb.model /opt/ml/xgb.model\n",
      " ---> Using cache\n",
      " ---> 48db5ef0c627\n",
      "Step 6/9 : COPY endpoints.R /opt/ml/endpoints.R\n",
      " ---> 70251154d26a\n",
      "Step 7/9 : COPY deploy.R /opt/ml/deploy.R\n",
      " ---> 612f00e2f270\n",
      "Step 8/9 : WORKDIR /opt/ml\n",
      " ---> Running in 71498ac36221\n",
      "Removing intermediate container 71498ac36221\n",
      " ---> adad0fdfd9d6\n",
      "Step 9/9 : ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/deploy.R\", \"--no-save\"]\n",
      " ---> Running in 2c6b2b4d2634\n",
      "Removing intermediate container 2c6b2b4d2634\n",
      " ---> b55361c9106c\n",
      "Successfully built b55361c9106c\n",
      "Successfully tagged r-plumber:latest\n"
     ]
    }
   ],
   "source": [
    "!cd .. && docker build -t r-plumber -f r_byo_algo_with_plumber/Dockerfile r_byo_algo_with_plumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RestRServe Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  247.8kB\n",
      "Step 1/7 : FROM r-base:3.6.3\n",
      " ---> cec2502269fb\n",
      "Step 2/7 : MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
      " ---> Using cache\n",
      " ---> d5c7ee17124e\n",
      "Step 3/7 : RUN R -e \"install.packages(c('RestRserve','xgboost','dplyr'), repos='https://cloud.r-project.org')\"\n",
      " ---> Using cache\n",
      " ---> ebcf2f81ff2d\n",
      "Step 4/7 : COPY xgb.model /opt/ml/xgb.model\n",
      " ---> Using cache\n",
      " ---> d3c15c4582c7\n",
      "Step 5/7 : COPY restrserve.R /opt/ml/restrserve.R\n",
      " ---> Using cache\n",
      " ---> 1f157953f1d5\n",
      "Step 6/7 : WORKDIR /opt/ml\n",
      " ---> Using cache\n",
      " ---> 7f4145abcde0\n",
      "Step 7/7 : ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/restrserve.R\", \"--no-save\"]\n",
      " ---> Using cache\n",
      " ---> 5de8902faece\n",
      "Successfully built 5de8902faece\n",
      "Successfully tagged r-restrserve:latest\n"
     ]
    }
   ],
   "source": [
    "!cd .. && docker build -t r-restrserve -f r_byo_algo_with_restrserve/Dockerfile r_byo_algo_with_restrserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  266.2kB\n",
      "Step 1/10 : FROM r-base:3.6.3\n",
      " ---> cec2502269fb\n",
      "Step 2/10 : MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
      " ---> Using cache\n",
      " ---> d5c7ee17124e\n",
      "Step 3/10 : RUN apt-get -y update && apt-get install -y --no-install-recommends     wget     r-base     r-base-dev     apt-transport-https     ca-certificates     python3 python3-dev pip\n",
      " ---> Using cache\n",
      " ---> 627800afb90b\n",
      "Step 4/10 : RUN pip install fastapi uvicorn numpy\n",
      " ---> Using cache\n",
      " ---> 34ca8248acac\n",
      "Step 5/10 : RUN R -e \"install.packages(c('reticulate','xgboost'), repos='https://cloud.r-project.org')\"\n",
      " ---> Using cache\n",
      " ---> bca2bed23e72\n",
      "Step 6/10 : COPY endpoints.py /opt/ml/endpoints.py\n",
      " ---> Using cache\n",
      " ---> 5fa6298e7993\n",
      "Step 7/10 : COPY deploy.R /opt/ml/deploy.R\n",
      " ---> Using cache\n",
      " ---> 81170561a1ab\n",
      "Step 8/10 : COPY xgb.model /opt/ml/xgb.model\n",
      " ---> Using cache\n",
      " ---> 253c1f2ad5fc\n",
      "Step 9/10 : WORKDIR /opt/ml\n",
      " ---> Using cache\n",
      " ---> c8469fcd9c1d\n",
      "Step 10/10 : ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/deploy.R\", \"--no-save\"]\n",
      " ---> Using cache\n",
      " ---> 7e7562097ec2\n",
      "Successfully built 7e7562097ec2\n",
      "Successfully tagged r-fastapi:latest\n"
     ]
    }
   ],
   "source": [
    "!cd .. && docker build -t r-fastapi -f r_byo_algo_with_fastapi/Dockerfile r_byo_algo_with_fastapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Serving Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will launch each search container. The containers will be launch on the following ports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = {\n",
    "    \"plumber\": 5000,\n",
    "    \"restrserve\": 5001,\n",
    "    \"fastapi\": 5002,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Plumber\n",
      "d0c1d45551f3e3e21d10998ed90ffabb1a1283379e237da0db7fab49fbfbc29c\n",
      "Launching RestRServer\n",
      "d0912ec85abafc83c008da21df85bd64f263bf1baeb537a65ddc58845843dc9c\n",
      "Launching FastAPI\n",
      "fff726864968404a35db35f558db1ae8a76498a1bcc8263fc319eab3bd017fc8\n"
     ]
    }
   ],
   "source": [
    "!bash launch.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                  PORTS                    NAMES\n",
      "fff726864968        r-fastapi           \"/usr/bin/Rscript /o…\"   1 second ago        Up Less than a second   0.0.0.0:5002->8080/tcp   exciting_thompson\n",
      "d0912ec85aba        r-restrserve        \"/usr/bin/Rscript /o…\"   2 seconds ago       Up 1 second             0.0.0.0:5001->8080/tcp   vigilant_ellis\n",
      "d0c1d45551f3        r-plumber           \"/usr/bin/Rscript /o…\"   3 seconds ago       Up 1 second             0.0.0.0:5000->8080/tcp   nostalgic_shamir\n"
     ]
    }
   ],
   "source": [
    "!docker container list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simple Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(examples, instance=requests, port=5000):\n",
    "    payload = {\"features\": examples}\n",
    "    return instance.post(f\"http://127.0.0.1:{port}/invocations\", json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_health(instance=requests, port=5000):\n",
    "    instance.get(f\"http://127.0.0.1:{port}/ping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Example Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's a define an example from the [iris.csv](iris.csv) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_features = iris[[\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = iris_features.values[:1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_examples = iris_features.values[:100].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to test how each API server performs under stress.\n",
    "\n",
    "First, let's test how each one performs when each request generates a new connection. \n",
    "\n",
    "We will test the performance on following situations:\n",
    "* 1000 requests of a single example\n",
    "* 1000 requests of 100 examples\n",
    "* 1000 pings for health status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': [0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(example, port=ports[\"plumber\"]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 128.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(example, port=ports[\"plumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 104.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(many_examples, port=ports[\"plumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 342.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    get_health(port=ports[\"plumber\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RestRserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(example, port=ports[\"restrserve\"]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 49.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(example, port=ports[\"restrserve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:23<00:00, 43.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(many_examples, port=ports[\"restrserve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 133.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    get_health(port=ports[\"restrserve\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 0.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(example, port=ports[\"fastapi\"]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 240.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(example, port=ports[\"fastapi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 164.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(many_examples, port=ports[\"fastapi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 450.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    get_health(port=ports[\"fastapi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Alive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test how each one performs when each request reuses a session connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse the session for each post and get request\n",
    "instance = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:51<00:00, 19.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(example, instance=instance, port=ports[\"plumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:52<00:00, 19.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(many_examples, instance=instance, port=ports[\"plumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    get_health(instance=instance, port=ports[\"plumber\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RestRserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 225.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(example, instance=instance, port=ports[\"restrserve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 160.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(many_examples, instance=instance, port=ports[\"restrserve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 470.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    get_health(instance=instance, port=ports[\"restrserve\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 280.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(example, instance=instance, port=ports[\"fastapi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 186.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = get_predictions(many_examples, instance=instance, port=ports[\"fastapi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 600.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    get_health(instance=instance, port=ports[\"fastapi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop All Serving Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's shutdown the serving containers we launched for the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fff726864968\n",
      "d0912ec85aba\n",
      "d0c1d45551f3\n"
     ]
    }
   ],
   "source": [
    "!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
