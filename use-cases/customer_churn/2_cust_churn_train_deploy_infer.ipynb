{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [load the dw job output?]\n",
    "2. running the featurizations via sagemaker processing through a non dw generated script (.py)\n",
    "3. end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Customer Churn Model for Music Streaming App Users\n",
    "\n",
    "In this demo, you are going to learn how to use various SageMaker functionalities to build, train, and deploy the model from end to end, including data pre-processing steps like ingestion, cleaning and processing, feature engineering, training and hyperparameter tuning, model explainability, and eventually deploy the model. There are two parts of the demo: in part 1: Prepare Data, you will process the data with the help of Data Wrangler, then create features from the cleaned data. By the end of part 1, you will have a complete feature data set that contains all attributes built for each user, and it is ready for modeling. Then in part 2: Modeling and Reference, you will use the data set built from part 1 to find an optimal model for the use case, then test the model predictability with the test data. To start with Part 2, you can either read in data from the output of your Part 1 results, or use the provided 'data/full_feature_data.csv' as the input for the next steps.\n",
    "\n",
    "\n",
    "For how to set up the SageMaker Studio Notebook environment, please check the [onboarding video]( https://www.youtube.com/watch?v=wiDHCWVrjCU&feature=youtu.be). And for a list of services covered in the use case demo, please check the documentation linked in each section.\n",
    "\n",
    "\n",
    "## Content\n",
    "* [Overview](#Overview)\n",
    "* [Data Selection](#2)\n",
    "* [Ingest Data](#4)\n",
    "* [Data Cleaning and Data Exploration](#5)\n",
    "* [Pre-processing with SageMaker Data Wrangler](#7)\n",
    "* [Feature Engineering with SageMaker Processing](#6)\n",
    "* [Data Splitting](#8)\n",
    "* [Model Selection](#9)\n",
    "* [Training with SageMaker Estimator and Experiment](#10)\n",
    "* [Hyperparameter Tuning with SageMaker Hyperparameter Tuning Job](#11)\n",
    "* [Deploy the model with SageMaker Batch-transform](#12)\n",
    "* [Model Explainability with SageMaker Clarify](#15)\n",
    "* [Optional: Automate your training and model selection with SageMaker Autopilot (Console)](#13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### What is Customer Churn and why is it important for businesses?\n",
    "Customer churn, or customer retention/attrition, means a customer has the tendency to leave and stop paying for a business. It is one of the primary metrics companies want to track to get a sense of their customer satisfaction, especially for a subscription-based business model. The company can track churn rate (defined as the percentage of customers churned during a period) as a health indicator for the business, but we would love to identify the at-risk customers before they churn and offer appropriate treatment to keep them with the business, and this is where machine learning comes into play.\n",
    "### Use Cases for Customer Churn\n",
    "Any subscription-based business would track customer churn as one of the most critical Key Performance Indicators (KPIs). Such companies and industries include Telecom companies (cable, cell phone, internet, etc.), digital subscriptions of media (news, forums, blogposts platforms, etc.), music and video streaming services, and other Software as a Service (SaaS) providers (e-commerce, CRM, Mar-Tech, cloud computing, video conference provider, and visualization and data science tools, etc.)\n",
    "### Define Business problem\n",
    "To start with, here are some common business problems to consider depending on your specific use cases and your focus:\n",
    " * Will this customer churn (cancel the plan, cancel the subscription)?\n",
    " * Will this customer downgrade a pricing plan?\n",
    " * For a subscription business model, will a customer renew his/her subscription?\n",
    "\n",
    "### Machine learning problem formulation\n",
    "#### Classification: will this customer churn?\n",
    "To goal of classification is to identify the at-risk customers and sometimes their unusual behavior, such as: will this customer churn or downgrade their plan? Is there any unusual behavior for a customer? The latter question can be formulated as an anomaly detection problem.\n",
    "#### Time Series: will this customer churn in the next X months? When will this customer churn?\n",
    "You can further explore your users by formulating the problem as a time series one and detect when will the customer churn.\n",
    "\n",
    "### Data Requirements\n",
    "#### Data collection Sources\n",
    "Some most common data sources used to construct a data set for churn analysis are:\n",
    "* Customer Relationship Management platform (CRM), \n",
    "* engagement and usage data (analytics services), \n",
    "* passive feedback (ratings based on your request), and active feedback (customer support request, feedback on social media and review platforms).\n",
    "\n",
    "#### Construct a Data Set for Churn Analysis\n",
    "Most raw data collected from the sources mentioned above are huge and often needs a lot of cleaning and pre-processing. For example, usage data is usually event-based log data and can be more than a few gigabytes every day; you can aggregate the data to user-level daily for further analysis. Feedback and review data are mostly text data, so you would need to clean and pre-process the natural language data to be normalized, machine-readable data. If you are joining multiple data sources (especially from different platforms) together, you would want to make sure all data points are consistent, and the user identity can be matched across different platforms.\n",
    "           \n",
    "#### Challenges with Customer Churn\n",
    "* Business related\n",
    "    * Importance of domain knowledge: this is critical when you start building features for the machine learning model. It is important to understand the business enough to decide which features would trigger retention.\n",
    "* Data issues\n",
    "    * fewer churn data available (imbalanced classes): data for churn analysis is often very imbalanced as most of the customers of a business are happy customers (usually).\n",
    "    * User identity mapping problem: if you are joining data from different platforms (CRM, email, feedback, mobile app, and website usage data), you would want to make sure user A is recognized as the same user across multiple platforms. There are third-party solutions that help you tackle this problem.\n",
    "    * Not collecting the right data for the use case or Lacking enough data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "You can experiment with all your model choices and see which one gives better results. A few things to note when you choose algorithms:\n",
    "* **Start with simple ones**: Usually for tabular data classification that does not contain complex unstructured data (text, audio, image, etc.), you can start with logistic regression to see how your data performs, as sometimes the simplest model gives great results if your data have a strong linear pattern.\n",
    "\n",
    "* **Think about your data structure**: For imbalanced class data like churn analysis, you can experiment with tree-based models like the random forest, gradient boosting, or XGboost since they are less sensitive to class imbalance.\n",
    "\n",
    "* **Interpretability**: logistic regression model generally has better interpretability because of its linearity. You can also use feature importance from tree-based models or Support Vector Machines as an overall observation, but not to your predicting instance level. Instead, you can utilize tools like SHAP or the SageMaker new feature SageMaker Clarify to better visualize which feature contributing more to your prediction results.\n",
    "\n",
    "In this use case, a tree-based model XGBoost is chosen due to consideration of imbalanced class, and in the family of tree based models, XGBoost usually gives best results as its built for model performance and computational speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='10'></a>\n",
    "\n",
    "## Training with SageMaker Estimator and Experiment\n",
    "Once you decide on a range of models you want to experiment with, you can start training and comparing model results to choose the best one. A few things left for you to make a decision:\n",
    "* SageMaker estimator configuration\n",
    "  * to initialize your training job, you would need to config your SageMaker estimator and SageMaker training image by specifying the model choice, instance size, and type.\n",
    "* Choose evaluation methods\n",
    "    * You can check the [model parameter documentation page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst#learning-task-parameters) for all the evaluation metrics you can choose for a model. For a imbalanced classification problem, you can choose F1 as your evaluation especially for comparing different models;  area under curve (auc) is also a good choice when your output is probability.\n",
    "* Hyper-parameters\n",
    "    * You can look at the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) for a complete list of hyper-parameters tunable for the model (The XGBoost model here was given as an example). For best performances, you can experiment with a range of combinations for the hyper-parameters and compare the validation results.\n",
    "   \n",
    "### How to create a training job as a trial in SageMaker Experiment    \n",
    "#### Get ECR image URIs for pre-built SageMaker Docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                                 -> 'sagemaker-us-east-2-738335684114'\n",
      "prefix                                 -> 'music-streaming'\n",
      "processing_job_output_name             -> 'processing_job_output.csv'\n",
      "processing_output_filename             -> 's3://sagemaker-us-east-2-738335684114/music-strea\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob \n",
    "import s3fs\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3 = sagemaker_session.boto_session.resource('s3')\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', region, version='1.0-1', instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\":\"12\",\n",
    "    \"eta\":\"0.08\",\n",
    "    \"gamma\":\"4\",\n",
    "    \"min_child_weight\":\"7\",\n",
    "    \"subsample\":\"0.7\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"800\",\n",
    "    \"early_stopping_rounds\": \"50\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SageMaker estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66 µs, sys: 0 ns, total: 66 µs\n",
      "Wall time: 68.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'train'), content_type=content_type)\n",
    "validation_input = TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'validation'), content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-08 08:32:24 Starting - Starting the training job...\n",
      "2021-03-08 08:32:47 Starting - Launching requested ML instancesProfilerReport-1615192344: InProgress\n",
      "......\n",
      "2021-03-08 08:33:48 Starting - Preparing the instances for training......\n",
      "2021-03-08 08:34:49 Downloading - Downloading input data\n",
      "2021-03-08 08:34:49 Training - Downloading the training image...\n",
      "2021-03-08 08:35:23 Uploading - Uploading generated training model.\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:35:20] 708x25 matrix with 17700 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:35:20] 204x25 matrix with 5100 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 708 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 204 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.91781#011validation-auc:0.94342\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.92840#011validation-auc:0.96039\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.94363#011validation-auc:0.97048\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.94334#011validation-auc:0.96876\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.94254#011validation-auc:0.96828\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.94555#011validation-auc:0.96441\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.95124#011validation-auc:0.97182\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.95292#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.95358#011validation-auc:0.97558\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.95427#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.95353#011validation-auc:0.98105\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.95531#011validation-auc:0.98363\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.96100#011validation-auc:0.98309\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.96146#011validation-auc:0.98309\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.96149#011validation-auc:0.98288\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.96179#011validation-auc:0.98363\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.96177#011validation-auc:0.98298\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.96526#011validation-auc:0.98127\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.96487#011validation-auc:0.98159\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.96492#011validation-auc:0.98041\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.96468#011validation-auc:0.98030\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.96635#011validation-auc:0.97960\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.96607#011validation-auc:0.97864\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.96583#011validation-auc:0.97928\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.96567#011validation-auc:0.97955\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.96615#011validation-auc:0.97751\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.96651#011validation-auc:0.97730\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.96876#011validation-auc:0.97901\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.96879#011validation-auc:0.97987\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.97054#011validation-auc:0.97880\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.97054#011validation-auc:0.97676\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.97037#011validation-auc:0.97697\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.97033#011validation-auc:0.97837\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.97130#011validation-auc:0.97955\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.97153#011validation-auc:0.97933\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.97187#011validation-auc:0.97901\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.97248#011validation-auc:0.97901\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.97246#011validation-auc:0.97907\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.97306#011validation-auc:0.98003\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.97328#011validation-auc:0.98143\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.97318#011validation-auc:0.98132\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.97302#011validation-auc:0.98068\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.97304#011validation-auc:0.98046\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.97304#011validation-auc:0.98046\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.97357#011validation-auc:0.98057\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.97329#011validation-auc:0.98025\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.97338#011validation-auc:0.97880\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.97341#011validation-auc:0.97848\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.97334#011validation-auc:0.97858\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.97346#011validation-auc:0.97815\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.97346#011validation-auc:0.97815\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.97395#011validation-auc:0.97837\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.97469#011validation-auc:0.97826\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.97442#011validation-auc:0.97783\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.97439#011validation-auc:0.97740\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.97479#011validation-auc:0.97772\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.97479#011validation-auc:0.97772\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.97493#011validation-auc:0.97762\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.97493#011validation-auc:0.97762\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.97491#011validation-auc:0.97719\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.97491#011validation-auc:0.97719\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.97519#011validation-auc:0.97719\u001b[0m\n",
      "\n",
      "2021-03-08 08:35:49 Completed - Training job completed\n",
      "Training seconds: 66\n",
      "Billable seconds: 66\n",
      "CPU times: user 423 ms, sys: 32.2 ms, total: 455 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit(inputs={'train': train_input, 'validation': validation_input}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SageMaker Experiment and Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom trial name \n",
    "experiment_name = 'music-streaming-churn-exp'\n",
    "trial_name_xgb = 'xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment creation music-streaming-churn-exp: SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2021-03-08-08-36-07-158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create trial xgboost: SUCCESSFUL\n",
      "2021-03-08 08:36:07 Starting - Starting the training job...\n",
      "2021-03-08 08:36:31 Starting - Launching requested ML instancesProfilerReport-1615192567: InProgress\n",
      "......\n",
      "2021-03-08 08:37:31 Starting - Preparing the instances for training......\n",
      "2021-03-08 08:38:32 Downloading - Downloading input data...\n",
      "2021-03-08 08:38:52 Training - Downloading the training image...\n",
      "2021-03-08 08:39:33 Uploading - Uploading generated training model\n",
      "2021-03-08 08:39:33 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:39:18] 708x25 matrix with 17700 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:39:18] 204x25 matrix with 5100 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 708 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 204 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.91781#011validation-auc:0.94342\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.92840#011validation-auc:0.96039\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.94363#011validation-auc:0.97048\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.94334#011validation-auc:0.96876\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.94254#011validation-auc:0.96828\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.94555#011validation-auc:0.96441\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.95124#011validation-auc:0.97182\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.95292#011validation-auc:0.97354\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.95358#011validation-auc:0.97558\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.95427#011validation-auc:0.97461\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.95353#011validation-auc:0.98105\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.95531#011validation-auc:0.98363\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.96100#011validation-auc:0.98309\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.96146#011validation-auc:0.98309\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.96149#011validation-auc:0.98288\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.96179#011validation-auc:0.98363\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.96177#011validation-auc:0.98298\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.96526#011validation-auc:0.98127\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.96487#011validation-auc:0.98159\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.96492#011validation-auc:0.98041\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.96468#011validation-auc:0.98030\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.96635#011validation-auc:0.97960\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.96607#011validation-auc:0.97864\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.96583#011validation-auc:0.97928\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.96567#011validation-auc:0.97955\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.96615#011validation-auc:0.97751\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.96651#011validation-auc:0.97730\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.96876#011validation-auc:0.97901\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.96879#011validation-auc:0.97987\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.97054#011validation-auc:0.97880\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.97054#011validation-auc:0.97676\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.97037#011validation-auc:0.97697\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.97033#011validation-auc:0.97837\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.97130#011validation-auc:0.97955\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.97153#011validation-auc:0.97933\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.97187#011validation-auc:0.97901\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.97248#011validation-auc:0.97901\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.97246#011validation-auc:0.97907\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.97306#011validation-auc:0.98003\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.97328#011validation-auc:0.98143\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.97318#011validation-auc:0.98132\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.97302#011validation-auc:0.98068\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.97304#011validation-auc:0.98046\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.97304#011validation-auc:0.98046\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.97357#011validation-auc:0.98057\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.97329#011validation-auc:0.98025\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.97338#011validation-auc:0.97880\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.97341#011validation-auc:0.97848\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.97334#011validation-auc:0.97858\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.97346#011validation-auc:0.97815\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.97346#011validation-auc:0.97815\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.97395#011validation-auc:0.97837\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.97469#011validation-auc:0.97826\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.97442#011validation-auc:0.97783\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.97439#011validation-auc:0.97740\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.97479#011validation-auc:0.97772\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.97479#011validation-auc:0.97772\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.97493#011validation-auc:0.97762\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.97493#011validation-auc:0.97762\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.97491#011validation-auc:0.97719\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.97491#011validation-auc:0.97719\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.97519#011validation-auc:0.97719\u001b[0m\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>early_stopping_rounds</th>\n",
       "      <th>eta</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>...</th>\n",
       "      <th>validation:auc - Last</th>\n",
       "      <th>validation:auc - Count</th>\n",
       "      <th>train - MediaType</th>\n",
       "      <th>train - Value</th>\n",
       "      <th>validation - MediaType</th>\n",
       "      <th>validation - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sagemaker-xgboost-2021-03-08-08-36-07-158-aws-...</td>\n",
       "      <td>churn-xgboost</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:738335684114:train...</td>\n",
       "      <td>257758044811.dkr.ecr.us-east-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m4.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>auc</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97719</td>\n",
       "      <td>60</td>\n",
       "      <td>csv</td>\n",
       "      <td>s3://sagemaker-us-east-2-738335684114/music-st...</td>\n",
       "      <td>csv</td>\n",
       "      <td>s3://sagemaker-us-east-2-738335684114/music-st...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-2-738335684114/music-st...</td>\n",
       "      <td>[xgboost]</td>\n",
       "      <td>[music-streaming-churn-exp]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName    DisplayName  \\\n",
       "0  sagemaker-xgboost-2021-03-08-08-36-07-158-aws-...  churn-xgboost   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0  arn:aws:sagemaker:us-east-2:738335684114:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0  257758044811.dkr.ecr.us-east-2.amazonaws.com/s...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB  early_stopping_rounds  \\\n",
       "0           ml.m4.xlarge                      30.0                   50.0   \n",
       "\n",
       "    eta eval_metric  ...  validation:auc - Last  validation:auc - Count  \\\n",
       "0  0.08         auc  ...                0.97719                      60   \n",
       "\n",
       "   train - MediaType                                      train - Value  \\\n",
       "0                csv  s3://sagemaker-us-east-2-738335684114/music-st...   \n",
       "\n",
       "  validation - MediaType                                 validation - Value  \\\n",
       "0                    csv  s3://sagemaker-us-east-2-738335684114/music-st...   \n",
       "\n",
       "   SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                 None   \n",
       "\n",
       "                     SageMaker.ModelArtifact - Value     Trials  \\\n",
       "0  s3://sagemaker-us-east-2-738335684114/music-st...  [xgboost]   \n",
       "\n",
       "                   Experiments  \n",
       "0  [music-streaming-churn-exp]  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from smexperiments import experiment, trial\n",
    "from sagemaker import analytics\n",
    "#create experiment if it doesn't exist\n",
    "try:\n",
    "    my_experiment = experiment.Experiment.load(experiment_name=experiment_name)\n",
    "    print(f'Experiment loaded {experiment_name}: SUCCESS')\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_experiment = experiment.Experiment.create(experiment_name=experiment_name)\n",
    "        print(f'Experiment creation {experiment_name}: SUCCESS')\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    my_trial = trial.Trial.load(trial_name=trial_name_xgb)\n",
    "    print(f'Trial loaded {trial_name_xgb}: SUCCESS')\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_trial = trial.Trial.create(experiment_name=experiment_name, trial_name=trial_name_xgb)\n",
    "        print(f'Create trial {my_trial.trial_name}: SUCCESSFUL')\n",
    "\n",
    "\n",
    "xgb.fit(\n",
    "    inputs={\n",
    "    'train': train_input, \n",
    "    'validation': validation_input\n",
    "    }, \n",
    "    wait=True,\n",
    "    experiment_config={\n",
    "        \"ExperimentName\": my_experiment.experiment_name,\n",
    "        \"TrialName\": my_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"churn-xgboost\",\n",
    "    },\n",
    "    logs = True\n",
    ")\n",
    "\n",
    "trial_component_analytics = analytics.ExperimentAnalytics(experiment_name=my_experiment.experiment_name)\n",
    "\n",
    "analytic_table = trial_component_analytics.dataframe()\n",
    "analytic_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11'></a>\n",
    "\n",
    "## Hyperparameter Tuning with SageMaker Hyperparameter Tuning Job\n",
    "Now that you understand how training one model works and how to create a SageMaker experiment, and selected the XGBoost model as the final model, you will need to fine-tune the hyperparameters for the best model performances. For a xgboost model, you can start with defining ranges for the eta, alpha, min_child_weight, and max_depth. You can check the [documentation when considering what haperparameter to tune](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-considerations.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the Hyperparameter Tuning Job Settings\n",
    "To specify settings for the hyperparameter tuning job, you define a JSON object. You pass the object as the value of the HyperParameterTuningJobConfig parameter to CreateHyperParameterTuningJob when you create the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"1\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"eta\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"2\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"alpha\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"min_child_weight\"\n",
    "        }\n",
    "      ],\n",
    "      \"IntegerParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"max_depth\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "      \"MaxNumberOfTrainingJobs\": 20,\n",
    "      \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"TrainingJobEarlyStoppingType\": \"Auto\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "      \"MetricName\": \"validation:auc\",\n",
    "      \"Type\": \"Maximize\"\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Training Jobs\n",
    "To configure the training jobs that the tuning job launches, define a JSON object that you pass as the value of the TrainingJobDefinition parameter of the CreateHyperParameterTuningJob call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = 's3://{}/{}/train'.format(bucket, prefix)\n",
    "s3_input_validation ='s3://{}/{}/validation'.format(bucket, prefix)\n",
    "\n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "      \"TrainingImage\": container,\n",
    "      \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "      {\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": s3_input_train\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"ChannelName\": \"validation\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": s3_input_validation\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "      \"InstanceCount\": 2,\n",
    "      \"InstanceType\": \"ml.c4.2xlarge\",\n",
    "      \"VolumeSizeInGB\": 10\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "      \"eval_metric\": \"auc\",\n",
    "      \"num_round\": \"100\",\n",
    "      \"objective\": \"binary:logistic\",\n",
    "      \"rate_drop\": \"0.3\",\n",
    "      \"tweedie_variance_power\": \"1.4\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "      \"MaxRuntimeInSeconds\": 43200\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name and Launch the Hyperparameter Tuning Job\n",
    "Now you can provide a name for the hyperparameter tuning job and then launch it by calling the CreateHyperParameterTuningJob API. Pass tuning_job_config, and training_job_definition that you created in previous steps as the values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tuning_job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "#custom a tuner job name\n",
    "tuning_job_name = \"ChurnPrediction-Tuning-Job\"\n",
    "%store tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if tuner job has been created\n",
    "list_tuning_job = smclient.list_hyper_parameter_tuning_jobs(NameContains=tuning_job_name)\n",
    "job_results = [[i for i in list_tuning_job[x]] for x in list_tuning_job.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobSummaries': [],\n",
       " 'NextToken': 'cIws2QhTXUIa8bi8WqnvV4N1YqMOHlD7jElQ14IwjIiM23XR+iTNwl0QRUs3sqoGPq0wb7EV0PwrapO02tAa3p7M45vnGbbMzIudgmhwM9BEW2rDR/mkAMmvP8Z1+VgcHTi3DpOUkFByBxya+k903BMe7iXR0CI30QbLCqdXHPeRO+Scb7IfHtPtNT6eN1gCctGtgIGYyD7Ux0w/h1NImVHyMbL/RwIWo6KY6/2NH3OHSGvfvACsI/AbzyI/0WyY7NaP5WxDD2daO3uKbojjvkv+SgNk28r0NIFFTUgnqeocPDMxWhy2DXeWQG1GsNGbFCxIPIzR0qtlKpcTQVMbZpgaGHUeCKVD4P5vJETI2gwwJPs2vbh2xevh/PsmimxgfUeBtVaFiYpSuAYwj5J9QlcGSi2wRwyCZp9+x+idcw5y9WhYihOQmLEFtToXQTeRR2u7ueNhTpcjhMVLjkYQfIcBOGPKzEi2lyVdK+JCka8T/PwEvFxrWaztLs6wDNB3yjr1boyPzljUuKPNf5jSqEqN1XnVyb01DHDLf/ejgpqLcu1H9HSEkm/Zk1t7kVRvAhwHQkqReTEoyS0WItcCh+5TUVewRViCBm/5Jn7DPtBkeee5ZoGDYgUrW5RqQtDmnoWTYPGVzQofpwAK',\n",
       " 'ResponseMetadata': {'RequestId': '4e9a1155-588a-4b64-88d2-6416912c926c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4e9a1155-588a-4b64-88d2-6416912c926c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '710',\n",
       "   'date': 'Mon, 08 Mar 2021 08:39:49 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.list_hyper_parameter_tuning_jobs(NameContains=tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create tuning job ChurnPrediction-Tuning-Job: SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "# create the tuning job if it doesn't exist\n",
    "try:\n",
    "    if tuning_job_name == job_results[0][0]['HyperParameterTuningJobName']:\n",
    "        print(f'Tuning job exists')\n",
    "except Exception as ex:   \n",
    "    # create hyperparameter tuning job\n",
    "    smclient.create_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName = tuning_job_name,\n",
    "        HyperParameterTuningJobConfig = tuning_job_config,\n",
    "        TrainingJobDefinition = training_job_definition\n",
    "    )\n",
    "    print(f'Create tuning job {tuning_job_name}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Progress of a Hyperparameter Tuning Job\n",
    "\n",
    "To monitor the progress of a hyperparameter tuning job and the training jobs that it launches, you can use the Amazon SageMaker console.\n",
    "\n",
    "<div>\n",
    "<img src=\"image/hp1.PNG\" width=\"600\"/>\n",
    "   </div>\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='12'></a>\n",
    "## Deploy the model with SageMaker Batch-transform\n",
    "You can directly deploy the best model from your hyperparameter tuning job by getting the best training job from your tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# check status\n",
    "import time\n",
    "status = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name )['HyperParameterTuningJobStatus']\n",
    "\n",
    "while status == 'InProgress':\n",
    "    print(status)\n",
    "    time.sleep(60)\n",
    "    status = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name )['HyperParameterTuningJobStatus']\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChurnPrediction-Tuning-Job-011-2ea4198a\n",
      "\n",
      "2021-03-08 08:54:04 Starting - Preparing the instances for training\n",
      "2021-03-08 08:54:04 Downloading - Downloading input data\n",
      "2021-03-08 08:54:04 Training - Training image download completed. Training in progress.\n",
      "2021-03-08 08:54:04 Uploading - Uploading generated training model\n",
      "2021-03-08 08:54:04 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2021-03-08-09-04-53-811\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2021-03-08-09-04-54-145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Attach to an existing hyperparameter tuning job.\n",
    "tuning_job_details = smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name)\n",
    "xgb_tuner = HyperparameterTuner.attach(\n",
    "    tuning_job_name, job_details = tuning_job_details,\n",
    "    sagemaker_session = sagemaker_session, \n",
    "    estimator_cls = None\n",
    ")\n",
    "\n",
    "# Get the best XGBoost training job name from the HPO job\n",
    "xgb_best_training_job = xgb_tuner.best_training_job()\n",
    "print(xgb_best_training_job)\n",
    "# Attach estimator to the best training job name\n",
    "best_estimator = sagemaker.estimator.Estimator.attach(xgb_best_training_job)\n",
    "\n",
    "# Create model to be passed to the inference pipeline\n",
    "best_model = sagemaker.model.Model(\n",
    "    model_data=best_estimator.model_data,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri =best_estimator.image_uri\n",
    ")\n",
    "\n",
    "predictor = best_model.deploy(initial_instance_count = 1, instance_type = 'ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following code to find and deploy the best model. Replace with your best model output path. Go to SageMaker Console $\\rightarrow$ Hyperparameter Tuning Job $\\rightarrow$ [Your hyperparameter Tuning Job] $\\rightarrow$ Best model $\\rightarrow$ Output. You can also choose to **create a model** from the console under **best training job**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your best model output path\n",
    "#model_artifacts = 's3://{}/{}/output/ChurnPrediction-TuningJob-020-20eee831/output/model.tar.gz'.format(bucket, prefix)\n",
    "#best_model = sagemaker.model.Model(\n",
    "#    model_data= model_artifacts,\n",
    "#    image_uri =container,\n",
    "#    role=role)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The location of the test dataset\n",
    "test_data = pd.read_csv('data/test_w_header.csv')\n",
    "test_set = test_data.drop(columns = ['user_churned'])\n",
    "test_set.to_csv('data/test.csv', index = False, header = False)\n",
    "s3_input_validation = boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/testdata/test.csv')).upload_file('data/test.csv')\n",
    "\n",
    "batch_input = 's3://{}/{}/test/testdata'.format(bucket, prefix)\n",
    "\n",
    "batch_output = 's3://{}/{}/batch-inference'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2021-03-08-09-12-26-031\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2021-03-08-09-12-26-441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m[2021-03-08:09:17:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:07:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/03/08 09:17:07 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:07 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/08 09:17:07 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:07 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"POST /invocations HTTP/1.1\" 200 1989 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m2021-03-08T09:17:09.811:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:07:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[35m[2021-03-08:09:17:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-08:09:17:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-08:09:17:07:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/03/08 09:17:07 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:07 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/08 09:17:07 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:07 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021/03/08 09:17:07 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Mar/2021:09:17:07 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/03/08 09:17:07 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Mar/2021:09:17:07 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-03-08 09:17:07 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2021-03-08 09:17:07 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-08:09:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"POST /invocations HTTP/1.1\" 200 1989 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-08:09:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-08:09:17:09:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-08:09:17:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [08/Mar/2021:09:17:09 +0000] \"POST /invocations HTTP/1.1\" 200 1989 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-03-08T09:17:09.811:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer = best_model.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n",
    "transformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the previous step to be completed. Once done, you can download the prediction results to your instance for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket).download_file(prefix + '/batch-inference/test.csv.out',  'batch_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('batch_results') as f:\n",
    "    results = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model results to actual\n",
    "\n",
    "You can evaluate your model results with the test data you left out earlier and check the precision and recall. In customer churn problem, precision and recall means:\n",
    "\n",
    "* Precision – Of all the users that the algorithm predicts will churn, how many of them do actually churn?\n",
    "* Recall – What percentage of users that end up churning does the algorithm successfully find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_churned</th>\n",
       "      <th>predicted_results</th>\n",
       "      <th>predicted_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.879375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_churned  predicted_results  predicted_binary\n",
       "0             0.0           0.124609                 0\n",
       "1             0.0           0.124609                 0\n",
       "2             0.0           0.199627                 0\n",
       "3             0.0           0.261825                 0\n",
       "4             0.0           0.251063                 0\n",
       "..            ...                ...               ...\n",
       "97            1.0           0.880904                 1\n",
       "98            1.0           0.879375                 1\n",
       "99            1.0           0.135027                 0\n",
       "100           1.0           0.898226                 1\n",
       "101           1.0           0.886231                 1\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['predicted_results'] = pd.to_numeric(results)\n",
    "#define a threshold to convert probability to class, you can set as 0.5 by default\n",
    "test_data['predicted_binary'] = [1 if x >= 0.5 else 0 for x in test_data['predicted_results']]\n",
    "test_data[['user_churned', 'predicted_results', 'predicted_binary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You did a good job and your model can detect 85% of the users who are going to churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Evaluation: \n",
      "Average F1 Score:  0.8736913204998312\n",
      "Precision Score:  0.9285714285714286\n",
      "Recall Score:  0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "test_labels = test_data['user_churned']\n",
    "test_pred = test_data['predicted_binary']\n",
    "\n",
    "test_f1 = metrics.f1_score(test_labels, test_pred, average=None)\n",
    "# fbeta_test= metrics.f1_score(mtest_labels, mpreds_test_xgb, average=None)\n",
    "prec, rec, fbeta_test, support = metrics.precision_recall_fscore_support(test_labels, test_pred, average = None)\n",
    "metrics.precision_recall_fscore_support(test_labels, test_pred, average = None)\n",
    "print (\"Test Evaluation: \")\n",
    "print (\"Average F1 Score: \",(test_f1[0]+test_f1[1])/2 )\n",
    "print (\"Precision Score: \", (prec[1]) )\n",
    "print (\"Recall Score: \", (rec[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='15'></a>\n",
    "## Model Explainability with SageMaker Clarify\n",
    "You can visualize which feature contributes most to your prediction results by using the new SageMaker feature SageMaker Clarify. It  will provide SHAP values which measures the importance of a feature by replacing it with a dummy and seeing how it affects the prediciton. (In reality, SHAP is smart about the choice of dummy and also takes into account feature interactions.)  For a more general overview of model interpretability, see [this post](https://towardsdatascience.com/guide-to-interpretable-machine-learning-d40e8a64b6cf). For other capabilities of SageMaker Clarify, please see the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-fairness-and-explainability.html) and the [example notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.0.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import clarify\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.c4.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_uri =  's3://{}/{}/train/train.csv'.format(bucket, prefix).format(bucket, prefix)\n",
    "train_input = TrainingInput(train_uri, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "xgb_endpoint_name = smclient.list_endpoints()['Endpoints'][0]['EndpointName']\n",
    "xgb_model_name = smclient.list_models()['Models'][0]['ModelName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_binary', 'predicted_results', 'user_churned'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_data.columns) - set(test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(baseline=[test_set.iloc[0].values.tolist()],\n",
    "                                 num_samples=100,\n",
    "                                 agg_method='mean_abs')\n",
    "\n",
    "explainability_output_path = 's3://{}/{}/clarify-explainability'.format(bucket, prefix)\n",
    "\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_uri,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label='user_churned',\n",
    "    headers=test_data.drop(['predicted_results', 'predicted_binary'], axis=1).columns.to_list(),\n",
    "    dataset_type='text/csv'\n",
    ")\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=xgb_model_name,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    instance_count=1,\n",
    "    accept_type='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name Clarify-Explainability-2021-03-08-09-17-40-516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Explainability-2021-03-08-09-17-40-516\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-738335684114/music-streaming/train/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-738335684114/music-streaming/clarify-explainability/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-2-738335684114/music-streaming/clarify-explainability', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".................................\u001b[34mINFO:sagemaker-clarify-processing:Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis config path: /opt/ml/processing/input/config\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is algo-1.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is the leader.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Dataset uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Dataset type: text/csv\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Creating endpoint-config with name sagemaker-clarify-endpoint-config-1615195377-c119\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Creating endpoint sagemaker-clarify-endpoint-1615195377-96b7\u001b[0m\n",
      "\u001b[34mINFO:explainers.kernel_shap:n_samples 100\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Checking endpoint status\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Endpoint is in service after 421 seconds\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:=====================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:Shap analyzer: explaining 708 rows, 25 columns...\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:=====================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Prediction batch size is initialized with 27354\u001b[0m\n",
      "\u001b[34mN/A% (0 of 708) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--\u001b[0m\n",
      "\u001b[34m100% (708 of 708) |######################| Elapsed Time: 0:00:16 Time:  0:00:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:getting explanations took 17.21 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:converting explanations to tabular took 0.07 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:Wrote 708 local explanations to: /opt/ml/processing/output/explanations_shap/out.csv\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:writing local explanations took 0.03 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:aggregating local explanations took 0.00 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap_analyzer:Shap analysis finished.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Stop using endpoint: sagemaker-clarify-endpoint-1615195377-96b7\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint configuration with name: sagemaker-clarify-endpoint-config-1615195377-c119\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint with name: sagemaker-clarify-endpoint-1615195377-96b7\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Model endpoint delivered 40.56592 requests per second and a total of 709 requests over 17 seconds\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Delivered 709 predict calls with a total of 71509 examples.\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 322322 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34mINFO:analyzer.report:HTML report '/opt/ml/processing/output/report.html' generated successfully.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.report:PDF report '/opt/ml/processing/output/report.pdf' generated successfully.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"explanations\": {\n",
      "        \"kernel_shap\": {\n",
      "            \"label0\": {\n",
      "                \"global_shap_values\": {\n",
      "                    \"average_events_weekend\": 0.0024658913146869592,\n",
      "                    \"average_events_weekday\": 0.002742561279134083,\n",
      "                    \"num_songs_played_7d\": 0.0024382007195435096,\n",
      "                    \"num_ads_7d\": 0.004631176661331634,\n",
      "                    \"num_error_7d\": 0.003972475319055126,\n",
      "                    \"num_songs_played_30d\": 0.0022691988573569446,\n",
      "                    \"num_songs_played_90d\": 0.001491335195691336,\n",
      "                    \"num_sessions\": 0.0021328185466089286,\n",
      "                    \"avg_time_per_session\": 0.002697253155270966,\n",
      "                    \"avg_events_per_session\": 0.0023554986675084137,\n",
      "                    \"avg_gap_between_session\": 0.01742342811335529,\n",
      "                    \"num_events\": 0.0023322993847796794,\n",
      "                    \"num_songs\": 0.002256752583304841,\n",
      "                    \"num_artists\": 0.0022115586265173664,\n",
      "                    \"num_thumbs_down\": 0.0023810045076971408,\n",
      "                    \"num_thumbs_up\": 0.0023794550733254156,\n",
      "                    \"num_add_to_playlist\": 0.002382917255465297,\n",
      "                    \"num_ads\": 0.002367353333742104,\n",
      "                    \"num_add_friend\": 0.0024720282987710186,\n",
      "                    \"num_downgrade\": 0.002177965229707748,\n",
      "                    \"num_upgrade\": 0.002243450653034547,\n",
      "                    \"num_error\": 0.0024892174536462613,\n",
      "                    \"percentage_ad\": 0.0024966171787593272,\n",
      "                    \"days_since_active\": 0.2325886702895201,\n",
      "                    \"repeats_ratio\": 0.009735877090359344\n",
      "                },\n",
      "                \"expected_value\": 0.12460903078317642\n",
      "            }\n",
      "        }\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:analyzer.system_util:exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\u001b[34m-------!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='13'></a>\n",
    "## Optional: Automate your training and model selection with SageMaker Autopilot (Console)\n",
    "With [SageMaker Autopilot](https://aws.amazon.com/blogs/aws/amazon-sagemaker-autopilot-fully-managed-automatic-machine-learning/), you can skip all the steps above and let it automatically tracks the inputs, parameters, configurations, and results of your iterations as trials. Go to SageMaker Experiments List on the left navigation pane, then choose **Create Experiment**. You will be directed to the experiment creating page. All you need to do is do give the Experiment job a name, specify your input and output data location, specify your target variable, and choose your ML problem type (classification or regression), or leave it as auto.\n",
    "\n",
    "<div>\n",
    "<img src=\"image/sm1.PNG\" width=\"400\"/>\n",
    "   </div>\n",
    "<div>\n",
    "<img src=\"image/sm2.PNG\" width=\"400\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_w_header.csv')\n",
    "validation_data = pd.read_csv('data/validation_w_header.csv')\n",
    "\n",
    "data_for_experiment = pd.concat([train_data, validation_data])\n",
    "data_for_experiment.to_csv('full_feature_data.csv', index = False)\n",
    "s3_input_full_set = boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'full/fullset.csv')).upload_file('full_feature_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment job will take some time to run (for the default 250 trials). It will go through data exploration, feature engineering, model selection and hyperparameter tuning. It will create a **data exploration notebook** that describes the data (missing values, numerical feature distributions, etc.), and a **candidate generation notebook** that describes the AutoML job. At the end of the Experiment job, the best model chosen is highlighted, and you can directly deploy the model for real-time prediction from the SageMaker Experiment Console. \n",
    "<div>\n",
    "<img src=\"image/sm3.PNG\" width=\"800\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: deploy model created from SageMaker Autopilot\n",
    "#### From Console\n",
    "You can navigate to the SageMaker Hyperparameter Tuning Job from the console to find the best model by go to **SageMaker  $\\rightarrow$ Hyperparameter tuning jobs  $\\rightarrow$ \\<your most recent job name marked as complete\\> $\\rightarrow$ Best training job** then choose **Create model**.\n",
    "<div>\n",
    "<img src=\"image/sm4.PNG\" width=\"800\"/>\n",
    "\n",
    "</div>\n",
    "\n",
    "#### With Code\n",
    "Alternatively, you can take look at the candidate generation notebook that describes the AutoML job. As part of the job, the input dataset has been randomly split into two pieces, one for training and one for validation. The notebook helps you inspect and modify the data transformation approaches proposed by Amazon SageMaker Autopilot. You can interactively train the data transformation models and use them to transform the data. Finally, you can execute a multiple algorithm hyperparameter optimization (multi-algo HPO) job that helps you find the best model for your dataset by jointly optimizing the data transformations and machine learning algorithms. Note that with the data transformation pipeline created by the AutoML job, the final model may contain more features than what you already created in this notebook, hence it would be better to test the models created by the AutoML job in the **Candidate generation notebook** to make sure your test data is also processed by the data transformation pipeline and has all the feature needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "\n",
    "The data used in this notebook is synthetic and does not contain real user data. The results (all the names, emails, IP addresses, and browser information) of this simulation are fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation\n",
    "The data used in this notebook is simulated using the [EventSim](https://github.com/Interana/eventsim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
