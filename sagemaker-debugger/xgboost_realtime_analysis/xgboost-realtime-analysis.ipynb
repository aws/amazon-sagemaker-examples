{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging XGBoost training jobs in real time with Amazon SageMaker Debugger \n",
    "\n",
    "This notebook uses the MNIST dataset to demonstrate real-time analysis of XGBoost training jobs while the training jobs are running. \n",
    "\n",
    "This notebook was created and tested on an ml.m5.4xlarge notebook instance using 100GB instance volume. \n",
    "\n",
    "## Overview \n",
    "\n",
    "Amazon SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning training.  \n",
    "SageMaker Debugger helps you to monitor your training in near real time using rules and provides alerts if it detects an inconsistency in training.  \n",
    "\n",
    "Using SageMaker Debugger is a two step process: Saving tensors and analysis. \n",
    "Let's look at each one of them closely. \n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "In deep learning algorithms, tensors define the state of the training job at any particular instant in its lifecycle.\n",
    "Amazon SageMaker Debugger exposes a library which allows you to capture these tensors and save them for analysis.\n",
    "Although XGBoost is not a deep learning algorithm, Amazon SageMaker Debugger is highly customizable and can help you interpret results by saving insightful metrics. For example, performance metrics or the importance of features at different frequencies. \n",
    "Refer to [documentation](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/xgboost.md) for details on how to save the metrics you want. \n",
    "\n",
    "\n",
    "### Analysis\n",
    "\n",
    "There are two ways to get to tensors and run analysis on them.\n",
    "\n",
    "One way is to use concept called ***Rules***. On a very broad level, a rule is Python code used to detect certain conditions during training.\n",
    "Some of the conditions that a data scientist training an algorithm may care about are monitoring for gradients getting too large or too small, detecting overfitting, and so on.\n",
    "Amazon SageMaker Debugger comes pre-packaged with certain built-in rules that can be invoked on Amazon SageMaker. You can also write your own rules using the Amazon SageMaker Debugger APIs. \n",
    "For more details about automatic analysis using rules, see [rules documentation](https://github.com/awslabs/sagemaker-debugger/tree/master/docs/rules).\n",
    "\n",
    "This notebook focuses on another approach: **Manual analysis**, which can be performed in realtime while training jobs are running.\n",
    "\n",
    "Manual analysis is helpful to detect which type of issue you're running into. You save raw tensors in order to understand your data and model better and figure out the root cause of your training job problem.\n",
    "\n",
    "Manual analysis is powered by the Amazon SageMaker Debugger API. This API framework enables retrieving tensors and scalars (e.g., debugging data) saved during training job via few lines of code. One of the most powerful features provided by it is realtime access to data. You can get tensors and scalars ***while your training job is running***.\n",
    "\n",
    "![Animated confusion matrix](cm.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Debugger is available in Amazon SageMaker XGBoost container version `0.90-2` or later. If you want to use XGBoost with Amazon SageMaker Debugger, you have to specify `repo_version='0.90-2'` in the `get_image_uri` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# Below changes the region to be one where this notebook is running\n",
    "region = boto3.Session().region_name\n",
    "container = get_image_uri(region, \"xgboost\", repo_version=\"0.90-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost models in Amazon SageMaker with Amazon SageMaker Debugger\n",
    "\n",
    "In this section you learn to train an XGBoost model with Amazon SageMaker Debugger enabled and monitor the training jobs.\n",
    "This is done using the SageMaker [Estimator API](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator).\n",
    "While training job is running use the SageMaker Debugger API to access saved tensors in real time and visualize them.\n",
    "You can rely on SageMaker Debugger to take care of downloading fresh set of tensors every time we query for them.\n",
    "\n",
    "This example is adapted from [XGBoost for Classification](https://github.com/awslabs/amazon-sagemaker/examples/tree/master/introduction_to_amazon_algorithms/xgboost_mnist).\n",
    "Refer to [XGBoost for Classification](https://github.com/awslabs/amazon-sagemaker/examples/tree/master/introduction_to_amazon_algorithms/xgboost_mnist) for an example of using classification from Amazon SageMaker's implementation of [XGBoost](https://github.com/dmlc/xgboost).\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "Use the [MNIST data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html) stored in [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_mnist, upload_to_s3\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"DEMO-smdebug-xgboost-mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_file, validation_file = load_mnist()\n",
    "upload_to_s3(train_file, bucket, f\"{prefix}/train/mnist.train.libsvm\")\n",
    "upload_to_s3(validation_file, bucket, f\"{prefix}/validation/mnist.validation.libsvm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enabling Amazon SageMaker Debugger in the estimator object\n",
    "\n",
    "Enabling Amazon SageMaker Debugger in a training job can be accomplished by adding its configuration into an Estimator object constructor:\n",
    "\n",
    "```\n",
    "from sagemaker.debugger import DebuggerHookConfig\n",
    "\n",
    "estimator = Estimator(\n",
    "    ...,\n",
    "    debugger_hook_config = DebuggerHookConfig(\n",
    "        s3_output_path=\"s3://{bucket_name}/{location_in_bucket}\",  # Required\n",
    "        collection_configs=[\n",
    "            CollectionConfig(\n",
    "                name=\"metrics\",\n",
    "                parameters={\n",
    "                    \"save_interval\": \"10\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "```\n",
    "Here, the `DebuggerHookConfig` object configures which data `Estimator` should save for the real-time visualization. Provide two parameters:\n",
    "\n",
    "- `s3_output_path`: Points to an S3 bucket where you intend to store the debugging tensors. Amount of data saved depends on multiple factors, major ones are training job, data set, model, frequency of saving tensors. This bucket should be in your AWS account and you should have full access control over it. **Important**: This S3 bucket should be originally created in the same Region where your training job is running, otherwise you might run into problems with cross-Region access.\n",
    "\n",
    "- `collection_configs`: It enumerates named collections of tensors to save. Collections are a convenient way to organize relevant tensors under same umbrella to make it easy to navigate them during analysis. In this particular example, you are interested in a single collection named `metrics`. You also configured Amazon SageMaker Debugger to save metrics every 10 iterations. For all parameters that are supported by Collections and DebuggerConfig, see [Collection documentation](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Amazon SageMaker Debugger with XGBoost Classification\n",
    "\n",
    "Import the libraries for the demo of Amazon SageMaker Debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "base_job_name = \"demo-smdebug-xgboost-classification\"\n",
    "bucket_path = 's3://{}'.format(bucket)\n",
    "\n",
    "num_round = 25\n",
    "save_interval = 3\n",
    "hyperparameters={\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.1\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"0\",\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"num_class\": \"10\",  # num_class is required for 'multi:*' objectives\n",
    "    \"num_round\": num_round,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "xgboost_algorithm_mode_estimator = Estimator(\n",
    "    role=role,\n",
    "    base_job_name=base_job_name,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.xlarge',\n",
    "    image_name=container,\n",
    "    hyperparameters=hyperparameters,\n",
    "    train_max_run=1800,\n",
    "\n",
    "    debugger_hook_config = DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Required\n",
    "        collection_configs=[\n",
    "            CollectionConfig(\n",
    "                name=\"metrics\",\n",
    "                parameters={\n",
    "                    \"save_interval\": str(save_interval)\n",
    "                }\n",
    "            ),\n",
    "            CollectionConfig(\n",
    "                name=\"predictions\",\n",
    "                parameters={\n",
    "                    \"save_interval\": str(save_interval)\n",
    "                }\n",
    "            ),\n",
    "            CollectionConfig(\n",
    "                name=\"labels\",\n",
    "                parameters={\n",
    "                    \"save_interval\": str(save_interval)\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With the next step you are going to actually start a training job using the Estimator object you created above. This job is started in asynchronous, non-blocking way. This means that control is passed back to the notebook and further commands can be run while training job is progressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "train_s3_input = s3_input(\"s3://{}/{}/{}\".format(bucket, prefix, \"train\"), content_type=\"libsvm\")\n",
    "validation_s3_input = s3_input(\"s3://{}/{}/{}\".format(bucket, prefix, \"validation\"), content_type=\"libsvm\")\n",
    "\n",
    "# This is a fire and forget event. By setting wait=False, you just submit the job to run in the background.\n",
    "# Amazon SageMaker will start one training job and release control to next cells in the notebook.\n",
    "# Follow this notebook to see status of the training job.\n",
    "xgboost_algorithm_mode_estimator.fit(\n",
    "    {\n",
    "        \"train\": train_s3_input,\n",
    "        \"validation\": validation_s3_input\n",
    "    },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "As a result of the above command, Amazon SageMaker starts one training job for you and it produces the tensors to be analyzed.\n",
    "This job will run in a background without you having to wait for it to complete in order to continue with the rest of the notebook.\n",
    "Because of this asynchronous nature of a training job, you need to monitor its status so that you don't start to request debugging too early.\n",
    "\n",
    "\n",
    "## Analysis and Visualization\n",
    "\n",
    "### Checking on the training job status\n",
    "\n",
    "Check the status of the training job by running the following code.\n",
    "It checks on the status of an Amazon SageMaker training job every 15 seconds.\n",
    "Once job has started its training cycle control is released to next cells in the notebook.\n",
    "That means training job started to tune the model and, in parallel, emit debugging tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "# Below command will give the status of training job\n",
    "job_name = xgboost_algorithm_mode_estimator.latest_training_job.name\n",
    "client = xgboost_algorithm_mode_estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "print('Training job name: ' + job_name)\n",
    "\n",
    "if description['TrainingJobStatus'] != 'Completed':\n",
    "    while description['SecondaryStatus'] not in ['Training', 'Completed']:\n",
    "        description = client.describe_training_job(TrainingJobName=job_name)\n",
    "        primary_status = description['TrainingJobStatus']\n",
    "        secondary_status = description['SecondaryStatus']\n",
    "        print(\"{}: {}, {}\".format(strftime('%X', gmtime()), primary_status, secondary_status))\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving and Analyzing tensors\n",
    "\n",
    "Before getting to analysis, here are some notes on concepts being used in Amazon SageMaker Debugger that help with analysis.\n",
    "- ***Trial*** - Object that is a centerpiece of the SageMaker Debugger API when it comes to getting access to tensors. It is a top level abstract that represents a single run of a training job. All tensors emitted by a training job are associated with its *trial*.\n",
    "- ***Step*** - Object that represents next level of abstraction. In SageMaker Debugger, *step* is a representation of a single batch of a training job. Each trial has multiple steps. Each tensor is associated with multiple steps and has a particular value at each of the steps.\n",
    "- ***Tensor*** - object that represent actual *tensor* saved during training job. *Note* - it could be a scalar as well (for example, metrics are saved as scalars).\n",
    "\n",
    "For more details on aforementioned concepts as well as on SageMaker Debugger API in general (including examples) see [SageMaker Debugger Analysis API](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/analysis.md) documentation.\n",
    "\n",
    "In the following code cell, use a ***Trial*** to access tensors. You can do that by inspecting currently running training job and extract necessary parameters from its debug configuration to instruct SageMaker Debugger where the data you are looking for is located. Keep in mind the following:\n",
    "- Tensors are being stored in your own S3 bucket to which you can navigate and manually inspect its content if desired.\n",
    "- You might notice a slight delay before trial object is created. This is normal as SageMaker Debugger monitors the corresponding bucket with tensors and waits until tensors appear in it. The delay is introduced by less than instantaneous upload of tensors from a training container to your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "s3_output_path = xgboost_algorithm_mode_estimator.latest_job_debugger_artifacts_path()\n",
    "\n",
    "# This is where we create a Trial object that allows access to saved tensors.\n",
    "trial = create_trial(s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "def plot_confusion_for_one_step(trial, step, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    cm = confusion_matrix(\n",
    "        trial.tensor(\"labels\").value(step),\n",
    "        trial.tensor(\"predictions\").value(step)\n",
    "    )\n",
    "    normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(normalized_cm, cmap=\"bone\", ax=ax, cbar=False, annot=cm, fmt='')\n",
    "    print(f\"iteration: {step}\")\n",
    "\n",
    "\n",
    "def plot_and_update_confusion_for_all_steps(trial):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rendered_steps = []\n",
    "    # trial.loaded_all_steps is a way to keep monitoring for a state of a training job\n",
    "    # as seen by Amazon SageMaker Debugger.\n",
    "    # When training job is completed Trial becomes aware of it.\n",
    "    while not rendered_steps or not trial.loaded_all_steps:\n",
    "        steps = trial.steps()\n",
    "        # quick way to get diff between two lists\n",
    "        steps_to_render = list(set(steps).symmetric_difference(set(rendered_steps)))\n",
    "        # plot only from newer chunk\n",
    "        for step in steps_to_render:\n",
    "            clear_output(wait=True)\n",
    "            plot_confusion_for_one_step(trial, step, ax=ax)\n",
    "            display(fig)\n",
    "            plt.pause(5)\n",
    "            ax.clear()\n",
    "            rendered_steps.extend(steps_to_render)\n",
    "    fig.clear()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing confusion matrix of a running training job\n",
    "\n",
    "Finally, wait until Amazon SageMaker Debugger has downloaded initial collection of tensors to look at. Once that collection is ready you keep getting new tensors every five seconds and plot their tensors correspondingly one under another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_update_confusion_for_all_steps(trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
