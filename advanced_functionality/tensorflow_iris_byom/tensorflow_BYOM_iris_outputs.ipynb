{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b630b3",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [12]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d285c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:49.827043Z",
     "iopub.status.busy": "2022-03-23T00:15:49.826302Z",
     "iopub.status.idle": "2022-03-23T00:15:49.829122Z",
     "shell.execute_reply": "2022-03-23T00:15:49.829557Z"
    },
    "papermill": {
     "duration": 0.02588,
     "end_time": "2022-03-23T00:15:49.829781",
     "exception": false,
     "start_time": "2022-03-23T00:15:49.803901",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "kms_key = \"arn:aws:kms:us-west-2:000000000000:1234abcd-12ab-34cd-56ef-1234567890ab\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be520160",
   "metadata": {
    "papermill": {
     "duration": 0.014624,
     "end_time": "2022-03-23T00:15:49.859548",
     "exception": false,
     "start_time": "2022-03-23T00:15:49.844924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TensorFlow BYOM: Train locally and deploy on SageMaker.\n",
    "\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)\n",
    "    1. [Permissions and environment variables](#Permissions-and-environment-variables)\n",
    "    2. [Model definitions](#Model-definitions)\n",
    "    3. [Data Setup](#Data-setup)\n",
    "3. [Training the network locally](#Training)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "    1. [Export from TensorFlow](#Export-the-model-from-tensorflow)\n",
    "    2. [Import model into SageMaker](#Import-model-into-SageMaker)\n",
    "    3. [Create endpoint](#Create-endpoint) \n",
    "5. [Validate the endpoint for use](#Validate-the-endpoint-for-use)\n",
    "\n",
    "__Note__: Compare this with the [tensorflow bring your own model example](../tensorflow_iris_byom/tensorflow_BYOM_iris.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca58f7",
   "metadata": {
    "papermill": {
     "duration": 0.014501,
     "end_time": "2022-03-23T00:15:49.888979",
     "exception": false,
     "start_time": "2022-03-23T00:15:49.874478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction \n",
    "\n",
    "This notebook can be compared to [Iris classification example notebook](../tensorflow_iris_dnn_classifier_using_estimators/tensorflow_iris_dnn_classifier_using_estimators.ipynb) in terms of its functionality. We will do the same classification task, but we will train the same network locally in the box from where this notebook is being run. We then setup a real-time hosted endpoint in SageMaker.\n",
    "\n",
    "Consider the following model definition for IRIS classification. This mode uses the ``tensorflow.estimator.DNNClassifier`` which is a pre-defined estimator module for its model definition. The model definition is the same as the one used in the [Iris classification example notebook](../tensorflow_iris_dnn_classifier_using_estimators/tensorflow_iris_dnn_classifier_using_estimators.ipynb)\n",
    "\n",
    "## Prequisites and Preprocessing\n",
    "### Permissions and environment variables\n",
    "\n",
    "Here we set up the linkage and authentication to AWS services. In this notebook we only need the roles used to give learning and hosting access to your data. The Sagemaker SDK will use S3 defualt buckets when needed. If the ``get_execution_role``  does not return a role with the appropriate permissions, you'll need to specify an IAM role arn that does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86f72b1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:49.922740Z",
     "iopub.status.busy": "2022-03-23T00:15:49.921897Z",
     "iopub.status.idle": "2022-03-23T00:15:50.896748Z",
     "shell.execute_reply": "2022-03-23T00:15:50.896279Z"
    },
    "isConfigCell": true,
    "papermill": {
     "duration": 0.993359,
     "end_time": "2022-03-23T00:15:50.896868",
     "exception": false,
     "start_time": "2022-03-23T00:15:49.903509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852dbf02",
   "metadata": {
    "papermill": {
     "duration": 0.014773,
     "end_time": "2022-03-23T00:15:50.926480",
     "exception": false,
     "start_time": "2022-03-23T00:15:50.911707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Definitions\n",
    "\n",
    "We use the [``tensorflow.estimator.DNNClassifier``](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) estimator to set up our network. We also need to write some methods for serving inputs during hosting and training. These methods are all found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6081e831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:50.960838Z",
     "iopub.status.busy": "2022-03-23T00:15:50.960260Z",
     "iopub.status.idle": "2022-03-23T00:15:51.111280Z",
     "shell.execute_reply": "2022-03-23T00:15:51.111715Z"
    },
    "papermill": {
     "duration": 0.170585,
     "end_time": "2022-03-23T00:15:51.111868",
     "exception": false,
     "start_time": "2022-03-23T00:15:50.941283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = \"inputs\"\r\n",
      "\r\n",
      "\r\n",
      "def estimator_fn(run_config, params):\r\n",
      "    feature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\r\n",
      "    return tf.estimator.DNNClassifier(\r\n",
      "        feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3, config=run_config\r\n",
      "    )\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_spec = {INPUT_TENSOR_NAME: tf.FixedLenFeature(dtype=tf.float32, shape=[4])}\r\n",
      "    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    \"\"\"Returns input function that would feed the model during training\"\"\"\r\n",
      "    return _generate_input_fn(training_dir, \"iris_training.csv\")\r\n",
      "\r\n",
      "\r\n",
      "def _generate_input_fn(training_dir, training_filename):\r\n",
      "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n",
      "        filename=os.path.join(training_dir, training_filename),\r\n",
      "        target_dtype=np.int,\r\n",
      "        features_dtype=np.float32,\r\n",
      "    )\r\n",
      "\r\n",
      "    return tf.estimator.inputs.numpy_input_fn(\r\n",
      "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\r\n",
      "        y=np.array(training_set.target),\r\n",
      "        num_epochs=None,\r\n",
      "        shuffle=True,\r\n",
      "    )\r\n"
     ]
    }
   ],
   "source": [
    "!cat iris_dnn_classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac7f0e",
   "metadata": {
    "papermill": {
     "duration": 0.015917,
     "end_time": "2022-03-23T00:15:51.143410",
     "exception": false,
     "start_time": "2022-03-23T00:15:51.127493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create an estimator object with this model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c1b5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:51.178787Z",
     "iopub.status.busy": "2022-03-23T00:15:51.178164Z",
     "iopub.status.idle": "2022-03-23T00:15:52.318554Z",
     "shell.execute_reply": "2022-03-23T00:15:52.318958Z"
    },
    "papermill": {
     "duration": 1.16061,
     "end_time": "2022-03-23T00:15:52.319100",
     "exception": false,
     "start_time": "2022-03-23T00:15:51.158490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp30xlr8oh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp30xlr8oh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f051f2da450>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "from iris_dnn_classifier import estimator_fn\n",
    "\n",
    "classifier = estimator_fn(run_config=None, params=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0eccf",
   "metadata": {
    "papermill": {
     "duration": 0.01633,
     "end_time": "2022-03-23T00:15:52.351952",
     "exception": false,
     "start_time": "2022-03-23T00:15:52.335622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data setup\n",
    "\n",
    "Next, we need to pull the data from tensorflow repository and make them ready for training. The following will code block should do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e387ca8",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:52.392733Z",
     "iopub.status.busy": "2022-03-23T00:15:52.392106Z",
     "iopub.status.idle": "2022-03-23T00:15:52.532893Z",
     "shell.execute_reply": "2022-03-23T00:15:52.532419Z"
    },
    "papermill": {
     "duration": 0.164561,
     "end_time": "2022-03-23T00:15:52.533014",
     "exception": false,
     "start_time": "2022-03-23T00:15:52.368453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "        f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "        f.write(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8ff43",
   "metadata": {
    "papermill": {
     "duration": 0.0167,
     "end_time": "2022-03-23T00:15:52.566601",
     "exception": false,
     "start_time": "2022-03-23T00:15:52.549901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create the data input streamer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54369b29",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:52.604736Z",
     "iopub.status.busy": "2022-03-23T00:15:52.604123Z",
     "iopub.status.idle": "2022-03-23T00:15:53.181408Z",
     "shell.execute_reply": "2022-03-23T00:15:53.180914Z"
    },
    "papermill": {
     "duration": 0.598077,
     "end_time": "2022-03-23T00:15:53.181531",
     "exception": false,
     "start_time": "2022-03-23T00:15:52.583454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/ml/processing/input/iris_dnn_classifier.py:30: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/ml/processing/input/iris_dnn_classifier.py:33: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from iris_dnn_classifier import train_input_fn\n",
    "\n",
    "train_func = train_input_fn(\".\", params=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab768c02",
   "metadata": {
    "papermill": {
     "duration": 0.017503,
     "end_time": "2022-03-23T00:15:53.216873",
     "exception": false,
     "start_time": "2022-03-23T00:15:53.199370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training\n",
    "\n",
    "It is time to train the network. Since we are training the network locally, we can make use of TensorFlow's ``tensorflow.Estimator.train`` method. The model is trained locally in the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8d744e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:53.256666Z",
     "iopub.status.busy": "2022-03-23T00:15:53.256152Z",
     "iopub.status.idle": "2022-03-23T00:15:58.011736Z",
     "shell.execute_reply": "2022-03-23T00:15:58.011273Z"
    },
    "papermill": {
     "duration": 4.777402,
     "end_time": "2022-03-23T00:15:58.011867",
     "exception": false,
     "start_time": "2022-03-23T00:15:53.234465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 00:15:54.174613: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-23 00:15:54.197173: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\n",
      "2022-03-23 00:15:54.197479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56175755cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-23 00:15:54.197516: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-23 00:15:54.197908: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp30xlr8oh/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp30xlr8oh/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 125.37703, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 125.37703, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 221.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 221.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 47.72212, step = 101 (0.454 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 47.72212, step = 101 (0.454 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 351.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 351.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 26.168016, step = 201 (0.285 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 26.168016, step = 201 (0.285 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 359.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 359.887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 34.883865, step = 301 (0.276 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 34.883865, step = 301 (0.276 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 360.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 360.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 16.502636, step = 401 (0.279 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 16.502636, step = 401 (0.279 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 347.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 347.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 13.170721, step = 501 (0.286 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 13.170721, step = 501 (0.286 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 357.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 357.314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 18.432014, step = 601 (0.280 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 18.432014, step = 601 (0.280 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 360.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 360.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 10.949158, step = 701 (0.279 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 10.949158, step = 701 (0.279 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 357.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 357.425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.3594036, step = 801 (0.280 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.3594036, step = 801 (0.280 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 354.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 354.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.612733, step = 901 (0.282 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.612733, step = 901 (0.282 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp30xlr8oh/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp30xlr8oh/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 15.934229.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 15.934229.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f0548ba7a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_func, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f82af8",
   "metadata": {
    "papermill": {
     "duration": 0.038063,
     "end_time": "2022-03-23T00:15:58.088339",
     "exception": false,
     "start_time": "2022-03-23T00:15:58.050276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "### Export the model from tensorflow\n",
    "\n",
    "In order to set up hosting, we have to import the model from training to hosting. We will begin by exporting the model from TensorFlow and saving it down. Analogous to the [MXNet example](../mxnet_mnist_byom/mxnet_mnist.ipynb), some structure needs to be followed. The exported model has to be converted into a form that is readable by ``sagemaker.tensorflow.model.TensorFlowModel``. The following code describes exporting the model in a form that does the same:\n",
    "\n",
    "There is a small difference between a SageMaker model and a TensorFlow model. The conversion is easy and fairly trivial. Simply move the tensorflow exported model into a directory ``export\\Servo\\`` and tar the entire directory. SageMaker will recognize this as a loadable TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4a7595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:58.171864Z",
     "iopub.status.busy": "2022-03-23T00:15:58.171206Z",
     "iopub.status.idle": "2022-03-23T00:15:58.482878Z",
     "shell.execute_reply": "2022-03-23T00:15:58.483288Z"
    },
    "papermill": {
     "duration": 0.356634,
     "end_time": "2022-03-23T00:15:58.483434",
     "exception": false,
     "start_time": "2022-03-23T00:15:58.126800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_207/1464523179.py:4: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function has been renamed, use `export_saved_model` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_207/1464523179.py:4: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function has been renamed, use `export_saved_model` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/ml/processing/input/iris_dnn_classifier.py:17: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/ml/processing/input/iris_dnn_classifier.py:17: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:145: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:145: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp30xlr8oh/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp30xlr8oh/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: export/Servo/temp-1647994558/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: export/Servo/temp-1647994558/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'export/Servo/1647994558'\n"
     ]
    }
   ],
   "source": [
    "from iris_dnn_classifier import serving_input_fn\n",
    "\n",
    "exported_model = classifier.export_savedmodel(\n",
    "    export_dir_base=\"export/Servo/\", serving_input_receiver_fn=serving_input_fn\n",
    ")\n",
    "\n",
    "print(exported_model)\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"model.tar.gz\", mode=\"w:gz\") as archive:\n",
    "    archive.add(\"export\", recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc4c3e",
   "metadata": {
    "papermill": {
     "duration": 0.04574,
     "end_time": "2022-03-23T00:15:58.575316",
     "exception": false,
     "start_time": "2022-03-23T00:15:58.529576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import model into SageMaker\n",
    "\n",
    "Open a new sagemaker session and upload the model on to the default S3 bucket. We can use the ``sagemaker.Session.upload_data`` method to do this. We need the location of where we exported the model from TensorFlow and where in our default bucket we want to store the model(``/model``). The default S3 bucket can be found using the ``sagemaker.Session.default_bucket`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a4a3e2",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:58.680942Z",
     "iopub.status.busy": "2022-03-23T00:15:58.680416Z",
     "iopub.status.idle": "2022-03-23T00:15:58.967029Z",
     "shell.execute_reply": "2022-03-23T00:15:58.966511Z"
    },
    "papermill": {
     "duration": 0.34571,
     "end_time": "2022-03-23T00:15:58.967157",
     "exception": false,
     "start_time": "2022-03-23T00:15:58.621447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path=\"model.tar.gz\", key_prefix=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414f6e1",
   "metadata": {
    "papermill": {
     "duration": 0.045939,
     "end_time": "2022-03-23T00:15:59.060136",
     "exception": false,
     "start_time": "2022-03-23T00:15:59.014197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use the ``sagemaker.tensorflow.model.TensorFlowModel`` to import the model into SageMaker that can be deployed. We need the location of the S3 bucket where we have the model, the role for authentication and the entry_point where the model defintion is stored (``iris_dnn_classifier.py``). The import call is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984d50ad",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:59.157920Z",
     "iopub.status.busy": "2022-03-23T00:15:59.157191Z",
     "iopub.status.idle": "2022-03-23T00:15:59.161875Z",
     "shell.execute_reply": "2022-03-23T00:15:59.162282Z"
    },
    "papermill": {
     "duration": 0.056424,
     "end_time": "2022-03-23T00:15:59.162420",
     "exception": false,
     "start_time": "2022-03-23T00:15:59.105996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "sagemaker_model = TensorFlowModel(\n",
    "    model_data=\"s3://\" + sagemaker_session.default_bucket() + \"/model/model.tar.gz\",\n",
    "    role=role,\n",
    "    framework_version=\"1.12\",\n",
    "    entry_point=\"iris_dnn_classifier.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7f0ca",
   "metadata": {
    "papermill": {
     "duration": 0.045708,
     "end_time": "2022-03-23T00:15:59.254241",
     "exception": false,
     "start_time": "2022-03-23T00:15:59.208533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create endpoint\n",
    "\n",
    "Now the model is ready to be deployed at a SageMaker endpoint. We can use the ``sagemaker.tensorflow.model.TensorFlowModel.deploy`` method to do this. Unless you have created or prefer other instances, we recommend using 1 ``'ml.m5.xlarge'`` instance for this example. These are supplied as arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd450920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:15:59.350024Z",
     "iopub.status.busy": "2022-03-23T00:15:59.349476Z",
     "iopub.status.idle": "2022-03-23T00:17:30.906534Z",
     "shell.execute_reply": "2022-03-23T00:17:30.906101Z"
    },
    "papermill": {
     "duration": 91.607012,
     "end_time": "2022-03-23T00:17:30.906646",
     "exception": false,
     "start_time": "2022-03-23T00:15:59.299634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-tensorflow-serving-2022-03-23-00-15-59-935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint with name sagemaker-tensorflow-serving-2022-03-23-00-16-00-193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 366 ms, sys: 33.1 ms, total: 400 ms\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620e64e",
   "metadata": {
    "papermill": {
     "duration": 0.048243,
     "end_time": "2022-03-23T00:17:31.002955",
     "exception": false,
     "start_time": "2022-03-23T00:17:30.954712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Validate the endpoint for use\n",
    "\n",
    "We can now use this endpoint to classify. Run an example prediction on a sample to ensure that it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca670135",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a173386b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T00:17:31.106135Z",
     "iopub.status.busy": "2022-03-23T00:17:31.105613Z",
     "iopub.status.idle": "2022-03-23T00:17:31.508346Z",
     "shell.execute_reply": "2022-03-23T00:17:31.507574Z"
    },
    "papermill": {
     "duration": 0.457148,
     "end_time": "2022-03-23T00:17:31.508596",
     "exception": true,
     "start_time": "2022-03-23T00:17:31.051448",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{ \"error\": \"Failed to process element: 0 of 'instances' list. Error: Invalid argument: JSON Value: 6.4 Type: Number is not of expected type: string\" }\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-tensorflow-serving-2022-03-23-00-16-00-193 in account 521695447989 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_207/3614219113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sagemaker/tensorflow/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CustomAttributes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlowPredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{ \"error\": \"Failed to process element: 0 of 'instances' list. Error: Invalid argument: JSON Value: 6.4 Type: Number is not of expected type: string\" }\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-tensorflow-serving-2022-03-23-00-16-00-193 in account 521695447989 for more information."
     ]
    }
   ],
   "source": [
    "sample = [6.4, 3.2, 4.5, 1.5]\n",
    "predictor.predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f47cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Delete all temporary directories so that we are not affecting the next run. Also, optionally delete the end points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571849db",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(\"model.tar.gz\")\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a02d43",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "If you do not want to continue using the endpoint, you can remove it. Remember, open endpoints are charged. If this is a simple test or practice, it is recommended to delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f63193",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "papermill": {
   "default_parameters": {},
   "duration": 106.12067,
   "end_time": "2022-03-23T00:17:35.052667",
   "environment_variables": {},
   "exception": true,
   "input_path": "tensorflow_BYOM_iris.ipynb",
   "output_path": "/opt/ml/processing/output/tensorflow_BYOM_iris-2022-03-23-00-10-57.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:000000000000:1234abcd-12ab-34cd-56ef-1234567890ab"
   },
   "start_time": "2022-03-23T00:15:48.931997",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}