{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6bcf871-9f26-4238-9954-09d13dc8ed4d",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify Model Explainability Monitor for Batch Transform - JSON Lines Format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fae672-0f0d-4416-90c9-d5af21e9fec2",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 60 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e2db0-3572-445f-9503-5456d3e5f87b",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [General Setup](#General-Setup)\n",
    "    * [Imports](#Imports)\n",
    "    * [Handful of configuration](#Handful-of-configuration)\n",
    "    * [Data files](#Data-files)\n",
    "    * [SageMaker model](#SageMaker-model)\n",
    "* [Batch Transform Job](#Batch-Transform-Job)\n",
    "    * [Captured data](#Captured-data)\n",
    "    * [Transform input](#Transform-input)\n",
    "* [Model Explainability Monitor](#Model-Explainability-Monitor)\n",
    "    * [Baselining job](#Baselining-job)\n",
    "        * [Configurations](#Configurations)\n",
    "        * [Kick off baselining job](#Kick-off-baselining-job)\n",
    "    * [Monitoring Schedule](#Monitoring-Schedule)\n",
    "        * [Wait for the first execution](#Wait-for-the-first-execution)\n",
    "        * [Wait for the execution to finish](#Wait-for-the-execution-to-finish)\n",
    "        * [Inspect execution results](#Inspect-execution-results)\n",
    "* [Cleanup](#Cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6fc14-9b15-447d-bdd1-408214b7e6a9",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) continuously monitors the quality of Amazon SageMaker machine learning models in production. It enables developers to set alerts for when there are deviations in the model quality. Early and pro-active detection of these deviations enables corrective actions, such as retraining models, auditing upstream systems, or fixing data quality issues without having to monitor models manually or build additional tooling. \n",
    "\n",
    "[Amazon SageMaker Clarify Model Explainability Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html) is a model monitor that helps data scientists and ML engineers monitor predictions for feature attribution drift on a regular basis. A drift in the distribution of live data for models in production can result in a corresponding drift in the feature attribution values. As the model is monitored, customers can view exportable reports and graphs detailing feature attributions in SageMaker Studio and configure alerts in Amazon CloudWatch to receive notifications if it is detected that the attribution values drift beyond a certain threshold. \n",
    "\n",
    "This notebook demonstrates the process for setting up a [SageMaker Clarify Feature Attribution Drift Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html) for continuous monitoring of feature attribution drift of the data and model used by a regularly running [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) job. The model input and output are in [SageMaker JSON Lines dense format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#common-in-formats).\n",
    "\n",
    "In general, you can use the model explainability monitor for batch transform in this way,\n",
    "\n",
    "1. Schedule a model explainability monitor to monitor a data capture S3 location\n",
    "1. Regularly run transform jobs with data capture enabled, the jobs save captured data to the data capture S3 URI\n",
    "\n",
    "The monitor executes processing jobs regularly to do feature attribution analysis, and then generate analysis reports and publish metrics to CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6b92b-92f4-46c9-ad91-61dd25c03fe4",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6e4c6-ab3f-4c0b-86f0-19003bae248b",
   "metadata": {},
   "source": [
    "The notebook uses the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk). The following cell upgrades the SDK and its dependencies. Then you may need to restart the kernel and rerun the notebook to pick up the up-to-date APIs, if the notebook is executed in the SageMaker Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5996819-b139-4487-8555-a8db5115edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker\n",
    "!pip install -U boto3\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee3e5c-2c32-4b72-8834-feb7ca57f07b",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following cell imports the APIs to be used by the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8a3dca-5e39-4d7e-aaf7-f025fb57df0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71dd08-c4eb-4a1a-b383-df735686d842",
   "metadata": {},
   "source": [
    "### Handful of configuration\n",
    "\n",
    "To begin, ensure that these prerequisites have been completed.\n",
    "\n",
    "* Specify an AWS Region to host the model.\n",
    "* Specify an IAM role to execute jobs.\n",
    "* Define the S3 URIs that stores the model file, input data and output data. For demonstration purposes, this notebook uses the same bucket for them. In reality, they could be separated with different security policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9057d5-162f-4fa7-8d2e-3274d7f9baee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS region: us-west-2\n",
      "RoleArn: arn:aws:iam::000000000000:role/service-role/AmazonSageMaker-ExecutionRole-20200714T163791\n",
      "Demo Bucket: sagemaker-us-west-2-000000000000\n",
      "Demo Prefix: sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c\n",
      "Demo S3 key: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c\n",
      "The transform job will save the results to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/transform-output\n",
      "The transform job will save the captured data to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/data-capture\n",
      "The baselining job will save the analysis results to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/baselining-output\n",
      "The monitor will save the analysis results to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/monitor-output\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f\"AWS region: {region}\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"RoleArn: {role}\")\n",
    "\n",
    "# A different bucket can be used, but make sure the role for this notebook has\n",
    "# the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Demo Bucket: {bucket}\")\n",
    "prefix = sagemaker.utils.unique_name_from_base(\"sagemaker/DEMO-ClarifyModelMonitor\")\n",
    "print(f\"Demo Prefix: {prefix}\")\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "print(f\"Demo S3 key: {s3_key}\")\n",
    "\n",
    "data_capture_s3_uri = f\"{s3_key}/data-capture\"\n",
    "transform_output_s3_uri = f\"{s3_key}/transform-output\"\n",
    "baselining_output_s3_uri = f\"{s3_key}/baselining-output\"\n",
    "monitor_output_s3_uri = f\"{s3_key}/monitor-output\"\n",
    "\n",
    "print(f\"The transform job will save the results to: {transform_output_s3_uri}\")\n",
    "print(f\"The transform job will save the captured data to: {data_capture_s3_uri}\")\n",
    "print(f\"The baselining job will save the analysis results to: {baselining_output_s3_uri}\")\n",
    "print(f\"The monitor will save the analysis results to: {monitor_output_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1bf1c-e60e-4a07-9cb0-dba16d3d0576",
   "metadata": {},
   "source": [
    "### Data files\n",
    "\n",
    "This example includes two dataset files, both in the JSON Lines format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1311db6e-25e2-4d30-8ea9-12f81f759feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_path = \"test_data/validation-dataset.jsonl\"\n",
    "test_dataset_path = \"test_data/test-dataset.jsonl\"\n",
    "dataset_type = \"application/jsonlines\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6ce22-bde4-4fb8-be05-74605f2248a5",
   "metadata": {},
   "source": [
    "The train dataset has the features and the ground truth label (pointed to by the key \"label\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea97710e-a4cc-4c5f-bd5d-8657eb17dd80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"features\":[41,2,220531,14,15,2,9,0,4,1,0,0,60,38],\"label\":1}\n",
      "{\"features\":[33,2,35378,9,13,2,11,5,4,0,0,0,45,38],\"label\":1}\n",
      "{\"features\":[36,2,223433,12,14,2,11,0,4,1,7688,0,50,38],\"label\":1}\n",
      "{\"features\":[40,2,220589,7,12,4,0,1,4,0,0,0,40,38],\"label\":0}\n",
      "{\"features\":[30,2,231413,15,10,2,2,0,4,1,0,0,40,38],\"label\":1}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 $train_dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81923f6-224a-4bbf-aee3-00702864a865",
   "metadata": {},
   "source": [
    "The test dataset only has features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb9caa5-589c-4559-82fd-03ac259e0a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"features\":[28,2,133937,9,13,2,0,0,4,1,15024,0,55,37]}\n",
      "{\"features\":[43,2,72338,12,14,2,12,0,1,1,0,0,40,37]}\n",
      "{\"features\":[34,2,162604,11,9,4,2,2,2,1,0,0,40,37]}\n",
      "{\"features\":[20,2,258509,11,9,4,6,3,2,1,0,0,40,37]}\n",
      "{\"features\":[27,2,446947,9,13,4,0,4,2,0,0,0,55,37]}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 $test_dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db74735-e307-46cd-b1ab-4469508033bf",
   "metadata": {},
   "source": [
    "Here are the headers of the train dataset. \"Target\" is the header of the ground truth label, and the others are the feature headers. They will be used to beautify the analysis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf229d7-c727-4cca-9674-a036d955f868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_headers = [\n",
    "    \"Age\",\n",
    "    \"Workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"Education\",\n",
    "    \"Education-Num\",\n",
    "    \"Marital Status\",\n",
    "    \"Occupation\",\n",
    "    \"Relationship\",\n",
    "    \"Ethnic group\",\n",
    "    \"Sex\",\n",
    "    \"Capital Gain\",\n",
    "    \"Capital Loss\",\n",
    "    \"Hours per week\",\n",
    "    \"Country\",\n",
    "    \"Target\",\n",
    "]\n",
    "label_header = all_headers[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258450e-47fd-4613-a89d-c78bfb1a26ab",
   "metadata": {},
   "source": [
    "To verify that the execution role for this notebook has the necessary permissions to proceed, put a simple test object into the S3 bucket specified above. If this command fails, update the role to have `s3:PutObject` permission on the bucket and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aedff42-c561-402f-ba79-b5eb7fbd2e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We are all set to proceed with uploading to S3.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.s3.S3Uploader.upload_string_as_file_body(\n",
    "    body=\"hello\",\n",
    "    desired_s3_uri=f\"{s3_key}/upload-test-file.txt\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(\"Success! We are all set to proceed with uploading to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2985e-829c-44df-acfe-83f02c6eae51",
   "metadata": {},
   "source": [
    "Then upload the data files to S3 so that they can be used by SageMaker jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997fdb72-a9ba-42e2-a205-58e9c8aaa1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is uploaded to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/validation-dataset.jsonl\n",
      "Test data is uploaded to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/test-dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_data_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=train_dataset_path,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Train data is uploaded to: {train_data_s3_uri}\")\n",
    "test_data_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=test_dataset_path,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Test data is uploaded to: {test_data_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0537ba9-363d-4649-940a-27091a474b8a",
   "metadata": {},
   "source": [
    "### SageMaker model\n",
    "\n",
    "This example includes a prebuilt [SageMaker Linear Learner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) model trained by [a SageMaker Clarify offline processing example notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability_jsonlines_format.ipynb). The model supports [SageMaker JSON Lines dense format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#common-in-formats) (MIME type `\"application/jsonlines\"`).\n",
    "\n",
    "* The model input can one or more lines, each line is a JSON object that has a \"features\" key pointing to a list of feature values concerning demographic characteristics of individuals. For example,\n",
    "\n",
    "```\n",
    "{\"features\":[28,2,133937,9,13,2,0,0,4,1,15024,0,55,37]}\n",
    "{\"features\":[43,2,72338,12,14,2,12,0,1,1,0,0,40,37]}\n",
    "```\n",
    "\n",
    "* The model output has the predictions of whether a person has a yearly income that is more than $50,000. Each prediction is a JSON object that has a \"predicted_label\" key pointing to the predicted label, and the \"score\" key pointing to the confidence score. For example,\n",
    "\n",
    "```\n",
    "{\"predicted_label\":1,\"score\":0.989977359771728}\n",
    "{\"predicted_label\":1,\"score\":0.504138827323913}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b1691d1-35cb-4459-979f-f1b3890a0796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file has been uploaded to s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/ll-adult-prediction-model.tar.gz\n",
      "SageMaker model name: DEMO-xgb-churn-pred-model-monitor-1674109279-6af2\n",
      "SageMaker Linear Learner image: 174872318107.dkr.ecr.us-west-2.amazonaws.com/linear-learner:1\n",
      "SageMaker model created\n"
     ]
    }
   ],
   "source": [
    "model_file = \"model/ll-adult-prediction-model.tar.gz\"\n",
    "model_url = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=model_file,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Model file has been uploaded to {model_url}\")\n",
    "\n",
    "model_name = sagemaker.utils.unique_name_from_base(\"DEMO-xgb-churn-pred-model-monitor\")\n",
    "print(f\"SageMaker model name: {model_name}\")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"linear-learner\", region, \"1\")\n",
    "print(f\"SageMaker Linear Learner image: {image_uri}\")\n",
    "\n",
    "model = sagemaker.model.Model(image_uri=image_uri, model_data=model_url, role=role)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)\n",
    "print(\"SageMaker model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2dec3-ce5d-493c-92be-4d3cccc49a65",
   "metadata": {},
   "source": [
    "## Batch Transform Job\n",
    "\n",
    "For continuous monitoring, batch transform jobs should be executed regularly with the latest data. But for demonstration purpose, the following cell only executes the job once before the monitor is scheduled, so that the first monitoring execution has captured data to process. \n",
    "\n",
    "See [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html#sagemaker.transformer.Transformer.transform) for the API reference. The `destination_s3_uri` is used to specify the data capture S3 URI which is a key connection between the job and the monitor.\n",
    "\n",
    "**NOTE**: The following cell takes about 5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da953e25-883c-4afe-bf64-8895e665002d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................!\n"
     ]
    }
   ],
   "source": [
    "transfomer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    accept=dataset_type,  # The transform output data format\n",
    "    assemble_with=\"Line\",  # JSON Lines records are terminated by new lines\n",
    "    output_path=transform_output_s3_uri,\n",
    ")\n",
    "\n",
    "transfomer.transform(\n",
    "    data=test_data_s3_uri,\n",
    "    content_type=dataset_type,  # The transform input format\n",
    "    split_type=\"Line\",  # JSON Lines records are terminated by new lines\n",
    "    batch_data_capture_config=sagemaker.inputs.BatchDataCaptureConfig(\n",
    "        destination_s3_uri=data_capture_s3_uri,\n",
    "    ),\n",
    "    wait=True,  # In real world you don't have to wait, but for demo purpose we wait for the output\n",
    "    logs=False,  # You can change it to True to view job logs inline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c512806-c51c-43b4-b043-9f81b70f2f42",
   "metadata": {},
   "source": [
    "### Captured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b5231-2111-45cf-8e36-ecc1a3630f3f",
   "metadata": {},
   "source": [
    "Once the transform job completed, an \"input\" folders is created under `data_capture_s3_uri`, to includes the captured data files of transform input. Note that, batch transform data capture is unlike endpoint data capture, it does not capture the data for real as it will create tremendous amount of duplications. Instead, it generates [manifest](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html#sagemaker-Type-S3DataSource-S3Uri) files which refer to the transform output S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e1039-3922-4b36-889c-7c73523e5a48",
   "metadata": {},
   "source": [
    "Now list the captured data files stored in Amazon S3. There should be different files from different time periods organized based on the hour in which the batch transformation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{data_capture_s3_uri}/input/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3daf52-e42a-496a-bf87-463da78122f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found capture data files:\n",
      "s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/data-capture/input/2023/01/19/06/fb6e1338-3d5c-4268-9f33-3fde11467816.json\n"
     ]
    }
   ],
   "source": [
    "data_capture_output = f\"{data_capture_s3_uri}/input\"\n",
    "captured_data_files = sorted(\n",
    "    sagemaker.s3.S3Downloader.list(\n",
    "        s3_uri=data_capture_output,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")\n",
    "print(\"Found capture data files:\")\n",
    "print(\"\\n \".join(captured_data_files[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88051d9-12d0-4ef1-bb82-e174d33d7082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"prefix\": \"s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/test-dataset.jsonl\"\n",
      "    },\n",
      "    \"\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "captured_data_file = captured_data_files[-1]\n",
    "captured_data_file_content = sagemaker.s3.S3Downloader.read_file(\n",
    "    s3_uri=captured_data_files[-1],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "data_capture_input_dict = json.loads(captured_data_file_content)\n",
    "print(json.dumps(data_capture_input_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc97568-4384-45a1-b278-44f220a5c586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_captured_data(offset):\n",
    "    yyyy_mm_dd_hh = \"%Y/%m/%d/%H\"\n",
    "    file_path, file_name = os.path.split(captured_data_file)\n",
    "    this_hour_str = file_path[len(data_capture_output) + 1 :]  # like \"2023/01/18/22\"\n",
    "    this_hour = datetime.datetime.strptime(this_hour_str, yyyy_mm_dd_hh)\n",
    "    next_hour = this_hour + datetime.timedelta(hours=offset)\n",
    "    next_hour_str = next_hour.strftime(yyyy_mm_dd_hh)  # like \"2023/01/18/23\"\n",
    "    sagemaker.s3.S3Uploader.upload_string_as_file_body(\n",
    "        body=captured_data_file_content,\n",
    "        desired_s3_uri=f\"{data_capture_output}/{next_hour_str}/{file_name}\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "\n",
    "\n",
    "# For demostration purpose, only needed for this example\n",
    "# copy the captured file to the last hour's folder, just in case the first monitoring execution is started in this hour.\n",
    "upload_captured_data(-1)\n",
    "# copy the captured file to the next hour's folder, just in case the first monitoring execution is started after next hour.\n",
    "upload_captured_data(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea870333-e59d-4d80-9d44-8dffd54044d0",
   "metadata": {},
   "source": [
    "### Transform input\n",
    "\n",
    "The captured data file refers to the transform input file. The cell below shows the first few records of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c970061-3bf3-4fab-9201-43eead9c4ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"features\":[29,2,178610,15,10,0,7,4,4,0,0,0,21,37]}\n",
      "{\"features\":[49,2,96854,11,9,0,7,4,4,1,0,0,40,37]}\n",
      "{\"features\":[45,2,293628,15,10,2,9,0,4,1,0,0,50,28]}\n",
      "{\"features\":[67,2,192995,11,9,6,0,4,4,0,6723,0,40,37]}\n",
      "{\"features\":[30,2,235847,9,13,4,7,3,4,0,0,0,24,37]}\n"
     ]
    }
   ],
   "source": [
    "transform_input = data_capture_input_dict[0][\"prefix\"]\n",
    "transform_output_content = sagemaker.s3.S3Downloader.read_file(\n",
    "    s3_uri=transform_input,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ").splitlines()\n",
    "print(*transform_output_content[-5:], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b55f85-56fe-4b95-a691-46eebb3ae140",
   "metadata": {},
   "source": [
    "## Model Explainability Monitor\n",
    "\n",
    "Similar to the other monitoring types, the standard procedure of creating a [feature attribution drift monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html) is first run a baselining job, and then schedule the monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e97232ac-c328-454e-b999-3a489e1af479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffea0b8-3dc7-426d-a91c-7ddd09f6143d",
   "metadata": {},
   "source": [
    "### Baselining job\n",
    "\n",
    "A baselining job runs predictions on training dataset and suggests constraints. The `suggest_baseline()` method of `ModelExplainabilityMonitor` starts a SageMaker Clarify processing job to generate the constraints.\n",
    "\n",
    "The step is not mandatory, but providing constraints file to the monitor can enable violations file generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3bc55-beb4-4060-ab8d-43b9d8fd9365",
   "metadata": {},
   "source": [
    "#### Configurations\n",
    "\n",
    "Information about the input data need to be provided to the processor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097e9de-cd90-4029-933d-1e8f427038f4",
   "metadata": {},
   "source": [
    "`DataConfig` stores information about the dataset to be analyzed. For example, the dataset file and its format (like JSON Lines), where to store the analysis results. Some special things to note about this configuration for the JSON Lines dataset,\n",
    "\n",
    "* The parameter value `\"features\"` or `\"label\"` is **NOT** a header string. Instead, it is a `JMESPath` expression ([refer to its specification](https://jmespath.org/specification.html)) that is used to locate the features list or the ground truth label in the dataset (the ground truth label is not needed for the explainability analysis, the parameter is specified so that the job knows it should be excluded from the dataset). In this example notebook they happen to be the same as the keys in the dataset. But for example, if the dataset has records like below, then the `features` parameter should use value `\"data.features.values\"`, and the `label` parameter should use value `\"data.label\"`.\n",
    "\n",
    "  ```\n",
    "  {\"data\": {\"features\": {\"values\": [25, 2, 226802, 1, 7, 4, 6, 3, 2, 1, 0, 0, 40, 37]}, \"label\": 0}}\n",
    "  ```\n",
    "\n",
    "* SageMaker Clarify processing job will load the JSON Lines dataset into tabular representation for further analysis, and the parameter `headers` is the list of column names. **The label header shall be the last one in the headers list**, and the order of feature headers shall be the same as the order of features in a record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e935fbb4-44ba-478f-b286-b108c6bbb933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_jmespath = \"features\"\n",
    "ground_truth_label_jmespath = \"label\"\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_s3_uri,\n",
    "    s3_output_path=baselining_output_s3_uri,\n",
    "    features=features_jmespath,\n",
    "    label=ground_truth_label_jmespath,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502e2d3-d532-4c2b-9d62-ea95a39b7736",
   "metadata": {},
   "source": [
    "`ModelConfig` is configuration related to model to be used for inferencing. In order to compute SHAP values, the SageMaker Clarify explainer generates synthetic dataset and then get its predictions for the SageMaker model. To accomplish this, the processing job will use the model to create an ephemeral endpoint (also known as \"shadow endpoint\"). The processing job will delete the shadow endpoint after the computations are completed. One special thing to note about this configuration for the JSON Lines model input and output,\n",
    "\n",
    "* `content_template` is used by SageMaker Clarify processing job to convert the tabular data to the request payload acceptable to the shadow endpoint. To be more specific, the placeholder `$features` will be replaced by **the features list** from records. The request payload of a record from the testing dataset happens to be similar to the record itself, like `{\"features\":[28,2,133937,9,13,2,0,0,4,1,15024,0,55,37]}`, because both the dataset and the model input conform to the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29488add-859f-4582-b592-a2d6dbad417e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_template = '{\"features\":$features}'\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_name,  # The name of the SageMaker model\n",
    "    instance_type=\"ml.m5.xlarge\",  # The instance type of the shadow endpoint\n",
    "    instance_count=1,  # The instance count of the shadow endpoint\n",
    "    content_type=dataset_type,  # The data format of the model input\n",
    "    accept_type=dataset_type,  # The data format of the model output\n",
    "    content_template=content_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8833d4-b2f2-4d83-a471-4ef296620354",
   "metadata": {},
   "source": [
    "Currently, the SageMaker Clarify explainer offers a scalable and efficient implementation of SHAP, so the explainability config is `SHAPConfig`, including\n",
    "\n",
    "* `baseline`: A list of records (at least one) to be used as the baseline dataset in the Kernel SHAP algorithm, each record is JSON object that includes a list of features. It can also be a S3 object URI, the S3 file should be in the same format as dataset.\n",
    "* `num_samples`: Number of samples to be used in the Kernel SHAP algorithm. This number determines the size of the generated synthetic dataset to compute the SHAP values.\n",
    "* `agg_method`: Aggregation method for global SHAP values. Valid values are\n",
    "  * \"mean_abs\" (mean of absolute SHAP values for all instances),\n",
    "  * \"median\" (median of SHAP values for all instances) and\n",
    "  * \"mean_sq\" (mean of squared SHAP values for all instances).\n",
    "* `use_logit`: Indicator of whether the logit function is to be applied to the model predictions. Default is False. If \"use_logit\" is true then the SHAP values will have log-odds units.\n",
    "* `save_local_shap_values`: Indicator of whether to save the local SHAP values in the output location. Default is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "679d8b02-d15c-4a1d-adc2-e1ae107f0b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP baseline: [{'features': [39, 2, 184870, 10, 10, 3, 6, 1, 4, 1, 1597, 61, 41, 37]}]\n"
     ]
    }
   ],
   "source": [
    "# Here use the mean value of train dataset as SHAP baseline\n",
    "dataset = []\n",
    "with open(train_dataset_path) as f:\n",
    "    dataset = [json.loads(row)[\"features\"] for row in f]\n",
    "mean_values = pd.DataFrame(dataset).mean().round().astype(int).to_list()\n",
    "mean_record = {\"features\": mean_values}\n",
    "shap_baseline = [mean_record]\n",
    "print(f\"SHAP baseline: {shap_baseline}\")\n",
    "\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=100,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c977b-d1fe-41b0-a9b3-05884fedea67",
   "metadata": {},
   "source": [
    "#### Kick off baselining job\n",
    "\n",
    "Call the `suggest_baseline()` method to start the baselining job. The model output has a key \"score\" pointing to a confidence score value between `0` and `1`. So, the `model_scores` parameter is set to the `JMESPath` expression\"score\" which can locate the score in the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5454eeea-1013-4722-8065-7dcc5e9b1b07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2023-01-19-06-26-41-177\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/validation-dataset.jsonl', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/baselining-output/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/baselining-output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7fe3a8083110>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_score_jmespath = \"score\"\n",
    "model_explainability_monitor.suggest_baseline(\n",
    "    explainability_config=shap_config,\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    model_scores=confidence_score_jmespath,  # The JMESPath to locate the confidence score in model output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac063d72-2955-40c9-a82c-4b1d177ccfef",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell waits until the baselining job is completed (in about 10 minutes). It then inspects the suggested constraints. This step can be skipped, because the monitor to be scheduled will automatically pick up baselining job name and wait for it before monitoring execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5a2c40f-fea1-4477-a155-c46acceb88d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................!\n",
      "Suggested constraints: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/baselining-output/analysis.json\n",
      "{\n",
      "    \"version\": \"1.0\",\n",
      "    \"explanations\": {\n",
      "        \"kernel_shap\": {\n",
      "            \"label0\": {\n",
      "                \"global_shap_values\": {\n",
      "                    \"Age\": 0.05966147427879835,\n",
      "                    \"Workclass\": 0.00912397024204763,\n",
      "                    \"fnlwgt\": 0.0010359326386406794,\n",
      "                    \"Education\": 0.014584218772494863,\n",
      "                    \"Education-Num\": 0.09914514927164537,\n",
      "                    \"Marital Status\": 0.05460401411146745,\n",
      "                    \"Occupation\": 0.002615299661494767,\n",
      "                    \"Relationship\": 0.018177001453756298,\n",
      "                    \"Ethnic group\": 0.005266052293379711,\n",
      "                    \"Sex\": 0.03201881160113639,\n",
      "                    \"Capital Gain\": 0.09911907893044279,\n",
      "                    \"Capital Loss\": 0.013593711604795078,\n",
      "                    \"Hours per week\": 0.036417023377112064,\n",
      "                    \"Country\": 0.004667358596049477\n",
      "                },\n",
      "                \"expected_value\": 0.250623226165771\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_explainability_monitor.latest_baselining_job.wait(logs=False)\n",
    "print()\n",
    "model_explainability_constraints = model_explainability_monitor.suggested_constraints()\n",
    "print(f\"Suggested constraints: {model_explainability_constraints.file_s3_uri}\")\n",
    "print(\n",
    "    sagemaker.s3.S3Downloader.read_file(\n",
    "        s3_uri=model_explainability_constraints.file_s3_uri,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f3cb9-acb9-4d39-9730-a1226146a3fa",
   "metadata": {},
   "source": [
    "### Monitoring Schedule\n",
    "\n",
    "With above constraints collected, now call `create_monitoring_schedule()` method to schedule an hourly model explainability monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94470149-a340-47ab-8c65-20f25c9d76c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "If a baselining job has been submitted, then the monitor object will automatically pick up the analysis configuration from the baselining job. But if the baselining step is skipped, or if the capture dataset has different nature than the training dataset, then analysis configuration has to be provided.\n",
    "\n",
    "`ModelConfig` is required by `ExplainabilityAnalysisConfig` for the same reason as it is required by the baselining job. Note that only features are required for computing feature attribution, so ground truth label should be excluded.\n",
    "\n",
    "Highlights,\n",
    "\n",
    "* `data_capture_s3_uri` is the location of data captured by the batch transform job\n",
    "* `features_attribute` is the `JMESPath` expression to locate the features in model input, similar to the `features` parameter of `DataConfig`.\n",
    "* `inference_attribute` stores the `JMESPath` expression to locate the confidence score in model output, similar to the `model_scores` parameter of the `suggest_baseline()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55a5fbb0-71a6-4cd5-83b9-a6ceb6b67d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule_expression = sagemaker.model_monitor.CronExpressionGenerator.hourly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17317354-7991-4d57-87bd-a7c7ce051de6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model explainability monitoring schedule: monitoring-schedule-2023-01-19-06-34-54-167\n"
     ]
    }
   ],
   "source": [
    "# Remove label because only features are required for the analysis\n",
    "headers_without_label_header = copy.deepcopy(all_headers)\n",
    "headers_without_label_header.remove(label_header)\n",
    "model_explainability_analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "    explainability_config=shap_config,\n",
    "    model_config=model_config,\n",
    "    headers=headers_without_label_header,\n",
    ")\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    analysis_config=model_explainability_analysis_config,\n",
    "    batch_transform_input=sagemaker.model_monitor.BatchTransformInput(\n",
    "        data_captured_destination_s3_uri=data_capture_s3_uri,\n",
    "        destination=\"/opt/ml/processing/transform\",\n",
    "        dataset_format=sagemaker.model_monitor.MonitoringDatasetFormat.json(lines=True),\n",
    "        features_attribute=features_jmespath,\n",
    "        inference_attribute=confidence_score_jmespath,\n",
    "    ),\n",
    "    output_s3_uri=monitor_output_s3_uri,\n",
    "    schedule_cron_expression=schedule_expression,\n",
    ")\n",
    "print(\n",
    "    f\"Model explainability monitoring schedule: {model_explainability_monitor.monitoring_schedule_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ab8ff-9f40-4c77-93bf-8fa3dec8980b",
   "metadata": {},
   "source": [
    "#### Wait for the first execution\n",
    "\n",
    "The schedule starts jobs at the previously specified intervals. Code below waits until time crosses the hour boundary (in UTC) to see executions kick off.\n",
    "\n",
    "Note: Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule executions. The execution might start in anywhere from zero to ~20 minutes from the hour boundary. This is expected and done for load balancing in the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12eccd87-e503-4f2a-ae7c-ff5c5c6b84c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_execution_to_start(model_monitor):\n",
    "    print(\n",
    "        \"An hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\"\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for the first execution to happen\", end=\"\")\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    while \"LastMonitoringExecutionSummary\" not in schedule_desc:\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(60)\n",
    "    print()\n",
    "    print(\"Done! Execution has been created\")\n",
    "\n",
    "    print(\"Now waiting for execution to start\", end=\"\")\n",
    "    while schedule_desc[\"LastMonitoringExecutionSummary\"][\"MonitoringExecutionStatus\"] in \"Pending\":\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(10)\n",
    "\n",
    "    print()\n",
    "    print(\"Done! Execution has started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c29159-4c63-4e84-8b08-5ab3ae95214e",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell waits until the first monitoring execution is started. As explained above, the wait could take more than 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4c96d12-deb7-4724-a84d-0c5b5023faff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\n",
      "Waiting for the first execution to happen...............................\n",
      "Done! Execution has been created\n",
      "Now waiting for execution to start.\n",
      "Done! Execution has started\n"
     ]
    }
   ],
   "source": [
    "wait_for_execution_to_start(model_explainability_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672426d-d2fd-49d9-a851-4f94db156c62",
   "metadata": {},
   "source": [
    "In real world, a monitoring schedule is supposed to be active all the time. But in this example, it can be stopped to avoid incurring extra charges. A stopped schedule will not trigger further executions, but the ongoing execution will continue. And if needed, the schedule can be restarted by `start_monitoring_schedule()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "434799f5-cbc0-4c45-b63a-697be96ba05b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping Monitoring Schedule with name: monitoring-schedule-2023-01-19-06-34-54-167\n"
     ]
    }
   ],
   "source": [
    "model_explainability_monitor.stop_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42324b88-111b-485f-82f6-c00a12f17205",
   "metadata": {},
   "source": [
    "#### Wait for the execution to finish\n",
    "\n",
    "In the previous cell, the first execution has started. This section waits for the execution to finish so that its analysis results are available. Here are the possible terminal states and what each of them mean:\n",
    "\n",
    "* `Completed` - This means the monitoring execution completed, and no issues were found in the violations report.\n",
    "* `CompletedWithViolations` - This means the execution completed, but constraint violations were detected.\n",
    "* `Failed` - The monitoring execution failed, maybe due to client error (perhaps incorrect role permissions) or infrastructure issues. Further examination of `FailureReason` and `ExitMessage` is necessary to identify what exactly happened.\n",
    "* `Stopped` - job exceeded max runtime or was manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cb1249a-d49a-423a-83ea-cf142affc785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Waits for the schedule to have last execution in a terminal status.\n",
    "def wait_for_execution_to_finish(model_monitor):\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "    if execution_summary is not None:\n",
    "        print(\"Waiting for execution to finish\", end=\"\")\n",
    "        while execution_summary[\"MonitoringExecutionStatus\"] not in [\n",
    "            \"Completed\",\n",
    "            \"CompletedWithViolations\",\n",
    "            \"Failed\",\n",
    "            \"Stopped\",\n",
    "        ]:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(60)\n",
    "            schedule_desc = model_monitor.describe_schedule()\n",
    "            execution_summary = schedule_desc[\"LastMonitoringExecutionSummary\"]\n",
    "        print()\n",
    "        print(f\"Done! Execution Status: {execution_summary['MonitoringExecutionStatus']}\")\n",
    "    else:\n",
    "        print(\"Last execution not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d93e4e-e0b0-48b8-b51b-cd13e43ec727",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell takes about 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4128240b-a510-4321-b34f-7e81b70f2d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution to finish........\n",
      "Done! Execution Status: Completed\n"
     ]
    }
   ],
   "source": [
    "wait_for_execution_to_finish(model_explainability_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27232906-188f-4d6d-8425-419b33b345b4",
   "metadata": {},
   "source": [
    "#### Inspect execution results\n",
    "\n",
    "List the generated reports,\n",
    "\n",
    "* analysis.json includes the global SHAP values.\n",
    "* report.* files are static report files to visualize the SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36089938-1460-4a11-b40a-79ad320e9657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report URI: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/monitor-output/monitoring-schedule-2023-01-19-06-34-54-167/2023/01/19/07\n",
      "Found Report Files:\n",
      "s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/monitor-output/monitoring-schedule-2023-01-19-06-34-54-167/2023/01/19/07/analysis.json\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/monitor-output/monitoring-schedule-2023-01-19-06-34-54-167/2023/01/19/07/report.html\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/monitor-output/monitoring-schedule-2023-01-19-06-34-54-167/2023/01/19/07/report.ipynb\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674109279-6b1c/monitor-output/monitoring-schedule-2023-01-19-06-34-54-167/2023/01/19/07/report.pdf\n"
     ]
    }
   ],
   "source": [
    "schedule_desc = model_explainability_monitor.describe_schedule()\n",
    "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
    "    \"Completed\",\n",
    "    \"CompletedWithViolations\",\n",
    "]:\n",
    "    last_model_explainability_monitor_execution = model_explainability_monitor.list_executions()[-1]\n",
    "    last_model_explainability_monitor_execution_report_uri = (\n",
    "        last_model_explainability_monitor_execution.output.destination\n",
    "    )\n",
    "    print(f\"Report URI: {last_model_explainability_monitor_execution_report_uri}\")\n",
    "    last_model_explainability_monitor_execution_report_files = sorted(\n",
    "        sagemaker.s3.S3Downloader.list(\n",
    "            s3_uri=last_model_explainability_monitor_execution_report_uri,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "        )\n",
    "    )\n",
    "    print(\"Found Report Files:\")\n",
    "    print(\"\\n \".join(last_model_explainability_monitor_execution_report_files))\n",
    "else:\n",
    "    last_model_explainability_monitor_execution = None\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716a5f4-66b2-42be-abe3-97999cc4946f",
   "metadata": {},
   "source": [
    "If there are any violations compared to the baseline, they are listed here. See [Feature Attribution Drift Violations](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-model-attribution-drift-violations.html) for the schema of the file, and how violations are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adbdbf7f-14a8-4c6d-b864-64473fc85e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "violations = model_explainability_monitor.latest_monitoring_constraint_violations()\n",
    "if violations is not None:\n",
    "    pprint.PrettyPrinter(indent=4).pprint(violations.body_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cabfe-1c81-41c5-a1ec-cdad45113819",
   "metadata": {},
   "source": [
    "By default, the analysis results are also published to CloudWatch, see [CloudWatch Metrics for Feature Attribution Drift Analysis](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-feature-attribute-drift-cw.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af941ee2-cb23-4389-8896-dda7488dad58",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "If there is no plan to collect more data for feature attribution drift monitoring, then the monitor should be stopped (and deleted) to avoid incurring additional charges. Note that deleting the monitor does not delete the data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a06d224-40a5-4688-8bc4-613eb4cacd8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping Monitoring Schedule with name: monitoring-schedule-2023-01-19-06-34-54-167\n",
      "Waiting for execution to finish\n",
      "Done! Execution Status: Completed\n",
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2023-01-19-06-34-54-167\n"
     ]
    }
   ],
   "source": [
    "model_explainability_monitor.stop_monitoring_schedule()\n",
    "wait_for_execution_to_finish(model_explainability_monitor)\n",
    "model_explainability_monitor.delete_monitoring_schedule()\n",
    "sagemaker_session.delete_model(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/deploy_and_monitor|sm-clarify_model_bias_monitor_batch_transform|sm-clarify_model_bias_monitor_batch_transform.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
