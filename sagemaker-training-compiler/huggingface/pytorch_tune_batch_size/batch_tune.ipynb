{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54639867",
   "metadata": {},
   "source": [
    "## Batch tune  script to find max batch_size fit into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d0d015",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "This example notebook requires the **SageMaker Python SDK v2.70.0** and **transformers v4.11.0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall sagemaker==2.70.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72baccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "import boto3\n",
    "import sagemaker\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"sagemaker: {sagemaker.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe300d2",
   "metadata": {},
   "source": [
    "### SageMaker environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# SageMaker session bucket -> used for uploading data, models and logs\n",
    "# SageMaker will automatically create this bucket if it does not exist\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d694a6f",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638355e6",
   "metadata": {},
   "source": [
    "This notebook uses HF training script to demonstrate how to find max batch size can fit in memory, if you're using a customized training script, please update `find_max_batch_size.py` script and `hyperparameters` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE_MODELING_LOSS = \"clm\"  \n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "TOKENIZER_NAME = \"gpt2\"\n",
    "MODEL_CONFIG = \"model_name_or_path\"\n",
    "\n",
    "INSTANCE_TYPE = \"ml.p3.8xlarge\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f82c6",
   "metadata": {},
   "source": [
    "### Tune Native PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af774d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters are passed to the training entrypoint as arguments\n",
    "hyperparameters = {\n",
    "    \"training_script\": f\"run_{LANGUAGE_MODELING_LOSS}.py\",\n",
    "    MODEL_CONFIG: MODEL_NAME,\n",
    "    \"tokenizer_name\": TOKENIZER_NAME,\n",
    "    \"fp16\": True,\n",
    "    \"sequence_len\": 512,\n",
    "    \"per_device_train_batch_size_min\" : 1,\n",
    "    \"per_device_train_batch_size_max\" : 128,\n",
    "}\n",
    "\n",
    "# configure the training job\n",
    "native_estimator = HuggingFace(\n",
    "    entry_point=\"find_max_batch_size.py\",\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    transformers_version=\"4.11.0\",\n",
    "    pytorch_version=\"1.9.0\",\n",
    "    volume_size=100,\n",
    "    hyperparameters=hyperparameters,\n",
    "    disable_profiler=True,  # Disabling SageMaker Profiler to avoid overheads during benchmarking\n",
    "    debugger_hook_config=False,  # Disabling SageMaker Debugger to avoid overheads during benchmarking\n",
    ")\n",
    "\n",
    "# start the training job\n",
    "native_estimator.fit(wait=False)\n",
    "native_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c78890",
   "metadata": {},
   "source": [
    "### Training with Optimized PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./scripts/launch_sm_training_compiler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace, TrainingCompilerConfig\n",
    "\n",
    "# configure the training job\n",
    "optimized_estimator = HuggingFace(\n",
    "    entry_point=\"find_max_batch_size.py\",  # Wrapper around training script that enables multi GPU training\n",
    "    compiler_config=TrainingCompilerConfig(),  # We are enabling SageMaker Training Compiler here !\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    volume_size=100,\n",
    "    py_version=\"py38\",\n",
    "    transformers_version=\"4.11.0\",\n",
    "    pytorch_version=\"1.9.0\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    disable_profiler=True,  # Disabling SageMaker Profiler to avoid overheads during benchmarking\n",
    "    debugger_hook_config=False,  # Disabling SageMaker Debugger to avoid overheads during benchmarking\n",
    ")\n",
    "\n",
    "# start the training job\n",
    "optimized_estimator.fit(wait=False)\n",
    "optimized_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d654b",
   "metadata": {},
   "source": [
    "### Wait for training jobs to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = native_estimator.sagemaker_session.sagemaker_client.get_waiter(\n",
    "    \"training_job_completed_or_stopped\"\n",
    ")\n",
    "waiter.wait(TrainingJobName=native_estimator.latest_training_job.name)\n",
    "waiter = optimized_estimator.sagemaker_session.sagemaker_client.get_waiter(\n",
    "    \"training_job_completed_or_stopped\"\n",
    ")\n",
    "waiter.wait(TrainingJobName=optimized_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c840d",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d11e2",
   "metadata": {},
   "source": [
    "### Load logs for compiler optimized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture optimized\n",
    "\n",
    "# access the logs of the optimized training job\n",
    "optimized_estimator.sagemaker_session.logs_for_job(optimized_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762682a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in optimized.stdout.split(\"\\n\"):\n",
    "    if 'result' in line and 'max_batch_size' in line or 'Total max batch' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57676d",
   "metadata": {},
   "source": [
    "### Load logs for native case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture native\n",
    "\n",
    "# access the logs of the native training job\n",
    "native_estimator.sagemaker_session.logs_for_job(native_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in native.stdout.split(\"\\n\"):\n",
    "    if 'result' in line and 'max_batch_size' in line or 'Total max batch' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043fcc1",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Stop all training jobs launched if the jobs are still running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf378f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def stop_training_job(name):\n",
    "    status = sm.describe_training_job(TrainingJobName=name)[\"TrainingJobStatus\"]\n",
    "    if status == \"InProgress\":\n",
    "        sm.stop_training_job(TrainingJobName=name)\n",
    "\n",
    "\n",
    "stop_training_job(native_estimator.latest_training_job.name)\n",
    "stop_training_job(optimized_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fafb67",
   "metadata": {},
   "source": [
    "Also, to find instructions on cleaning up resources, see [Clean Up](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html) in the *Amazon SageMaker Developer Guide*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
