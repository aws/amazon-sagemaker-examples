{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e48755a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker JumpStart Foundation Models - Inference Latency and Throughput Benchmarking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59b5a329",
   "metadata": {},
   "source": [
    "***\n",
    "Welcome to Amazon [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)! You can use SageMaker JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#use-prebuilt-models-with-sagemaker-jumpstart).\n",
    "\n",
    "\n",
    "In this demo notebook, we demonstrate how to run latency and throughput benchmarking analyses on a set of SageMaker JumpStart models. The structure of the notebook allows you to both benchmark a single model against multiple payloads and multiple models against a single payload. \n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46c6f117",
   "metadata": {},
   "source": [
    "1. [Set up](#1.-Set-up)\n",
    "2. [Run latency and throughput benchmarking](#2.-Run-latency-and-throughput-benchmarking)\n",
    "3. [Visualize benchmarking results](#3.-Visualize-benchmarking-results)\n",
    "4. [Clean up](#4.-Clean-up)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c59ee575",
   "metadata": {},
   "source": [
    "### 1. Set up\n",
    "\n",
    "***\n",
    "Before executing the notebook, there are some initial steps required for set up. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade sagemaker ipywidgets --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2bd729",
   "metadata": {},
   "source": [
    "***\n",
    "Here, you will query the SageMaker SDK to return a list of all HuggingFace text generation (and text2text) models hosted by SageMaker Model Hub. You can manually select any combination of these models to run benchmarking on with the Jupyter Widget produced in the output of this cell. By default, only a few models are selected.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6eceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import SelectMultiple, Layout\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "from sagemaker.jumpstart.filters import And, Or\n",
    "\n",
    "# Retrieves all Text Generation models available by SageMaker Built-In Algorithms.\n",
    "tasks = [\"textgeneration\", \"textgeneration1\", \"textgeneration2\", \"text2text\"]\n",
    "filter_value = And(Or(*[f\"task == {task}\" for task in tasks]), \"framework == huggingface\")\n",
    "text_models = list_jumpstart_models(filter=filter_value)\n",
    "selected_text_models = [\n",
    "    \"huggingface-text2text-flan-t5-xxl\",\n",
    "    \"huggingface-textgeneration1-gpt-j-6b\",\n",
    "    \"huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16\",\n",
    "    \"huggingface-textgeneration-bloom-1b7\",\n",
    "]\n",
    "# if you would like to run on all JumpStart LLMs instead, uncomment the following line.\n",
    "# selected_text_models = text_models.copy()\n",
    "# selected_text_models.remove(\"huggingface-textgeneration1-bloom-176b-int8\")\n",
    "# selected_text_models.remove(\"huggingface-textgeneration1-bloomz-176b-fp16\")\n",
    "\n",
    "models_selection = SelectMultiple(\n",
    "    options=text_models,\n",
    "    value=selected_text_models,\n",
    "    description=\"Models:\",\n",
    "    rows=25,\n",
    "    layout=Layout(width=\"100%\"),\n",
    ")\n",
    "display(models_selection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60d8e537",
   "metadata": {},
   "source": [
    "***\n",
    "In the following cell, you will select the models and payloads to benchmark. Every payload will be benchmarked against every model.\n",
    "- **MODELS**: A list of SageMaker JumpStart model IDs to run benchmarking against.\n",
    "- **PAYLOADS**: A dictionary with keys identifying a unique name for a query payload and values containing a valid payload dictionary.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = models_selection.value\n",
    "\n",
    "PAYLOADS = {\n",
    "    \"simple_short_input\": {\n",
    "        \"text_inputs\": \"Hello!\",\n",
    "        \"do_sample\": True,\n",
    "    },\n",
    "    \"generate_summary\": {\n",
    "        \"text_inputs\": (\n",
    "            \"Write a short summary for this text: Amazon Comprehend uses natural language \"\n",
    "            \"processing (NLP) to extract insights about the content of documents. It develops \"\n",
    "            \"insights by recognizing the entities, key phrases, language, sentiments, and other \"\n",
    "            \"common elements in a document. Use Amazon Comprehend to create new products based on \"\n",
    "            \"understanding the structure of documents. For example, using Amazon Comprehend you \"\n",
    "            \"can search social networking feeds for mentions of products or scan an entire \"\n",
    "            \"document repository for key phrases. \\nYou can access Amazon Comprehend document \"\n",
    "            \"analysis capabilities using the Amazon Comprehend console or using the Amazon \"\n",
    "            \"Comprehend APIs. You can run real-time analysis for small workloads or you can start \"\n",
    "            \"asynchronous analysis jobs for large document sets. You can use the pre-trained \"\n",
    "            \"models that Amazon Comprehend provides, or you can train your own custom models for \"\n",
    "            \"classification and entity recognition. \\nAll of the Amazon Comprehend features \"\n",
    "            \"accept UTF-8 text documents as the input. In addition, custom classification and \"\n",
    "            \"custom entity recognition accept image files, PDF files, and Word files as input. \\n\"\n",
    "            \"Amazon Comprehend can examine and analyze documents in a variety of languages, \"\n",
    "            \"depending on the specific feature. For more information, see Languages supported in \"\n",
    "            \"Amazon Comprehend. Amazon Comprehend's Dominant language capability can examine \"\n",
    "            \"documents and determine the dominant language for a far wider selection of languages.\"\n",
    "        ),\n",
    "        \"do_sample\": True,\n",
    "        \"max_length\": 500,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22f60ab8",
   "metadata": {},
   "source": [
    "***\n",
    "The following set of constants drive the behavior of this notebook:\n",
    "- **MAX_CONCURRENT_INVOCATIONS_PER_MODEL**: The maximum number of endpoint predictions to request concurrently.\n",
    "- **MAX_CONCURRENT_BENCHMARKS**: The maximum number of models to concurrently benchmark.\n",
    "- **RETRY_WAIT_TIME_SECONDS**: The amount of time in seconds to wait between Amazon CloudWatch queries. This is necessary because the endpoint emits CloudWatch metrics on a periodic interval, so we need to wait until all samples are emitted to CloudWatch before publishing benchmarking statistics.\n",
    "- **MAX_TOTAL_RETRY_TIME_SECONDS**: The maximum amount of time in seconds to wait on Amazon CloudWatch emissions before proceeding without collecting the requested benchmarking metrics.\n",
    "- **NUM_INVOCATIONS**: The number of endpoint predictions to request per benchmark.\n",
    "- **SAVE_METRICS_FILE_PATH**: The JSON file used to save the resulting metrics.\n",
    "- **SM_SESSION**: SageMaker Session object with custom configuration to resolve [SDK rate exceeded and throttling exceptions](https://aws.amazon.com/premiumsupport/knowledge-center/sagemaker-python-throttlingexception/).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb86ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "MAX_CONCURRENT_INVOCATIONS_PER_MODEL = 30\n",
    "MAX_CONCURRENT_BENCHMARKS = 50\n",
    "RETRY_WAIT_TIME_SECONDS = 30.0\n",
    "MAX_TOTAL_RETRY_TIME_SECONDS = 120.0\n",
    "NUM_INVOCATIONS = 10\n",
    "SAVE_METRICS_FILE_PATH = Path.cwd() / \"latency_benchmarking.json\"\n",
    "SM_SESSION = Session(\n",
    "    sagemaker_client=boto3.client(\n",
    "        \"sagemaker\",\n",
    "        config=Config(connect_timeout=5, read_timeout=60, retries={\"max_attempts\": 20}),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6047aa",
   "metadata": {},
   "source": [
    "### 2. Run latency and throughput benchmarking\n",
    "\n",
    "***\n",
    "\n",
    "The following block defines a function to run benchmarking on a single SageMaker JumpStart model ID. This function performs the following actions:\n",
    "- Create a SageMaker JumpStart `Model` object.\n",
    "- Deploy the Model and obtain a `Predictor`.\n",
    "- Run all benchmarking load tests for each payload defined in the `PAYLOADS` dictionary. The benchmarking process includes:\n",
    "  - Obtain latency statistics - serially invoke an endpoint to obtain a batch of predictions and utilize the Amazon CloudWatch [GetMetricStatistics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html) API to obtain latency statistics regarding the batch of predictions. The endpoint is invoked `NUM_INVOCATIONS` times.\n",
    "  - Obtain throughput statistics - concurrently invoke an endpoint to obtain client-side throughput statistics. The endpoint is invoked `NUM_INVOCATIONS` times.\n",
    "- Clean up predictor model and endpoint. If any errors occur during the benchmarking process for a given model, this clean up process still occurs prior to raising the error.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "from benchmarking.load_test import run_benchmarking_load_tests\n",
    "from benchmarking.load_test import logging_prefix\n",
    "\n",
    "\n",
    "def run_benchmarking(model_id: str) -> List[Dict[str, Any]]:\n",
    "    model = JumpStartModel(model_id=model_id, sagemaker_session=SM_SESSION)\n",
    "\n",
    "    endpoint_name = name_from_base(f\"jumpstart-bm-{model_id.replace('huggingface', 'hf')}\")\n",
    "\n",
    "    print(f\"{logging_prefix(model_id)} Deploying endpoint {endpoint_name} ...\")\n",
    "    predictor = model.deploy(endpoint_name=endpoint_name)\n",
    "    predictor.serializer = JSONSerializer()\n",
    "    predictor.content_type = \"application/json\"\n",
    "\n",
    "    metrics = []\n",
    "    try:\n",
    "        for payload_name, payload in PAYLOADS.items():\n",
    "            metrics_payload = run_benchmarking_load_tests(\n",
    "                predictor=predictor,\n",
    "                payload=payload,\n",
    "                model_id=model_id,\n",
    "                payload_name=payload_name,\n",
    "                num_invocations=NUM_INVOCATIONS,\n",
    "                max_workers=MAX_CONCURRENT_INVOCATIONS_PER_MODEL,\n",
    "                retry_wait_time=RETRY_WAIT_TIME_SECONDS,\n",
    "                max_total_retry_time=MAX_TOTAL_RETRY_TIME_SECONDS,\n",
    "            )\n",
    "            metrics.append(metrics_payload)\n",
    "    finally:\n",
    "        print(f\"{logging_prefix(model_id)} Cleaning up resources ...\")\n",
    "        predictor.delete_model()\n",
    "        predictor.delete_endpoint()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17f3350",
   "metadata": {},
   "source": [
    "***\n",
    "In the following block, the `run_benchmarking` function is called for all model IDs specified within the previously defined `MODELS` list. To avoid a serial deployment process, the Python standard library [concurrent futures](https://docs.python.org/3/library/concurrent.futures.html) module is used to concurrently execute a `MAX_CONCURRENT_BENCHMARKS` number of executor threads. When a thread completes execution, the computed metrics are extended into a single list. If any thread raises an error instead of returning metrics, the errors are recorded in a dictionary without re-raising the error. This allows benchmarking to continue for all other models.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7460a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "\n",
    "metrics = []\n",
    "benchmarking_error_dict = {}\n",
    "with futures.ThreadPoolExecutor(max_workers=MAX_CONCURRENT_BENCHMARKS) as executor:\n",
    "    future_to_model_id = {\n",
    "        executor.submit(run_benchmarking, model_id): model_id for model_id in MODELS\n",
    "    }\n",
    "    for future in futures.as_completed(future_to_model_id):\n",
    "        model_id = future_to_model_id[future]\n",
    "        try:\n",
    "            metrics.extend(future.result())\n",
    "        except Exception as e:\n",
    "            benchmarking_error_dict[model_id] = e\n",
    "            print(f\"(Model {model_id}) Benchmarking failed: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c3470dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "Finally, we save these benchmarked metrics to a JSON file for use in downstream analyses.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d743be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "output = {\"models\": MODELS, \"payloads\": PAYLOADS, \"metrics\": metrics}\n",
    "with open(SAVE_METRICS_FILE_PATH, \"w\") as file:\n",
    "    json.dump(output, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a484d018",
   "metadata": {},
   "source": [
    "### 3. Visualize benchmarking results\n",
    "\n",
    "***\n",
    "The saved JSON results are now re-loaded into a normalized pandas DataFrame for visualization. This cell shows the following:\n",
    "1. The column names of the DataFrame. These are the available statistics you are able to explore.\n",
    "2. A table that shows a sample output from each model ID in `MODELS` for each payload in `PAYLOAD`.\n",
    "3. A table that shows key latency and throughput statistics for each model ID in `MODELS` and each payload in `PAYLOAD`.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50763cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the available statistics:  ['Throughput', 'WordThroughput', 'ModelID', 'PayloadName', 'SampleOutput', 'ModelLatency.SampleCount', 'ModelLatency.Average', 'ModelLatency.Minimum', 'ModelLatency.Maximum', 'ModelLatency.p50', 'ModelLatency.p90', 'ModelLatency.p95', 'OverheadLatency.SampleCount', 'OverheadLatency.Average', 'OverheadLatency.Minimum', 'OverheadLatency.Maximum', 'OverheadLatency.p50', 'OverheadLatency.p90', 'OverheadLatency.p95', 'Client.InputSequenceWords.Average', 'Client.InputSequenceWords.Minimum', 'Client.InputSequenceWords.Maximum', 'Client.InputSequenceWords.p50', 'Client.InputSequenceWords.p90', 'Client.InputSequenceWords.p95', 'Client.OutputSequenceWords.Average', 'Client.OutputSequenceWords.Minimum', 'Client.OutputSequenceWords.Maximum', 'Client.OutputSequenceWords.p50', 'Client.OutputSequenceWords.p90', 'Client.OutputSequenceWords.p95', 'Client.Latency.Average', 'Client.Latency.Minimum', 'Client.Latency.Maximum', 'Client.Latency.p50', 'Client.Latency.p90', 'Client.Latency.p95', 'Client.LatencyPerOutputWord.Average', 'Client.LatencyPerOutputWord.Minimum', 'Client.LatencyPerOutputWord.Maximum', 'Client.LatencyPerOutputWord.p50', 'Client.LatencyPerOutputWord.p90', 'Client.LatencyPerOutputWord.p95']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SampleOutput</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PayloadName</th>\n",
       "      <th>ModelID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"42\" valign=\"top\">generate_summary</th>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-fp16</th>\n",
       "      <td>Use Amazon Comprehend to analyze text documents in a variety of languages.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-bnb-int8</th>\n",
       "      <td>Documents in UTF-8, PDF files, Word files, and image files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b7</th>\n",
       "      <td>When you choose Amazon Comprehend to analyze your documents, you can change Amazon Comprehend to other languages if you don't want your document analyzed using a dominant language.\\n\\nQuestions related to the above: \\n\\nIf a user has created Amazon Comprehend's document repository, the document repository can be used to run analysis jobs with Amazon Comprehend. If not, how can the documents in the document repository used to run Amazon Comprehend analysis?\\nCan I run a dataset on my document repository using Amazon Comprehend? How and where I should start? I know I can import any document in the repository to run analysis, but I didn't get the training dataset, or any samples of the document in the repository that could be used to implement the algorithm.\\nCan I start a new analysis job with a document repository already having input documents from a search? What should I do to include the documents (or subsets of them) I already have in the analysis job?\\n\\nPlease let me know if I'm missing some important details. Thanks!\\n\\nA:\\n\\nAmazon Comprehend documents are stored as base64 encoded byte arrays.  If you convert input stream to bytes, then you can use that as the input stream for the analysis.  However, if you have to convert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp</th>\n",
       "      <td>Use Amazon Comprehend to scan social networking feeds for mentions of specific products using Amazon Comprehend Spotlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl</th>\n",
       "      <td>Finds common elements from a document by performing Natural Language Processing (NLP) of textual content.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-fp16</th>\n",
       "      <td>Documents and other media (images, PDFs, Word files) Sentiment analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-bnb-int8</th>\n",
       "      <td>Understand the structure of documents using Amazon Comprehend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-ul2-bf16</th>\n",
       "      <td>Describes the architecture of Amazon Comprephend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m</th>\n",
       "      <td>\\n\\nProperties\\n\\nAmazon Comprehends the Language in the Document in the Document:\\n[https://aws.amazon.com/comprehend/](https://aws.amazon.com/comprehend/)\\nAmazon Comprehend's Language\\n[https://developer.amazon.com/comprehends/latest/feature/compularnglbl/?hl=en-US,pct=en-GB&amp;ioc='amazon-comprehend']\\n\\nA:\\n\\nI use the Amazon Comprehend API in a couple of situations in my work as a project manager for Amazon Ecosystem team.\\nThey have a collection called Resources for your project, which you can interact with as you work. Also you can create a Resource, which contains your user-defined resources. Here is a link for a related project.\\nNow, these are the APIs that you can use to make your project's resources work. In case you are using a library that provides a library that requires some data, they can use it to provide the access that you need to your library.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-3b-fp16</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m-fp16</th>\n",
       "      <td>\\n\\nGoogle Translate Language\\nIn Google Translate Language, you are able to view documents that are translated into other languages (e.g. English, French, Spanish, German, Swedish, Spanish, Czech, Portuguese, German, German, Dutch, Bulgarian, Hungarian). However, it is a language based on a translation platform, which means you need a transliterate translation service like TransLang.\\nExample translated into French, Spanish, German, Italian, Hungarian, Croatian, Czech, Portuguese, Slovak, Serbian, and Ukrainian (but no English). Translate-language documents are often created in English. \\nYour Translates file may look different according to the translation service's terms of service (e.g. translations are translated to Spanish, English, or French). When your Translates file is translated, as in a translated text file, the translated text file includes a small bit of Latin text of an external language (in this case, French), and so it becomes your Translates file. This translates the text into another English language, which you are able to translate into other languages (e.g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xl</th>\n",
       "      <td>Use Amazon Comprehend to discover and analyze the content in any document.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b-fp16</th>\n",
       "      <td>For an example of the Language selection, see Language selector in Amazon Comprehend console. \\nAmazon Comprehend is a product that is currently available for customers in the United States. At the time of writing, it does not yet support users outside the United States. \\n\\n Version 3.0 of Amazon Comprehend was released on 19 November 2018. \\n\\n Amazon Comprehend v3.0 provides faster search and analysis times and reduced storage requirements over Amazon Comprehend v2.0. This version includes a number of new features including support for new input methods, full-text search across diverse data sources and Amazon's machine learning models, automatic classification and entity recognition and other features. \\n Amazon Comprehend v3.0 also includes support for document classification and identification in a number of languages and an improved set of training scenarios, and a new set of training models. In addition, Amazon Comprehend v3.0 provides a range of features that are not currently included in Amazon Comprehend v2.0. Amazon Comprehend v3.0 is available for customers in the United States. Amazon Comprehend v3.0 is now available for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b</th>\n",
       "      <td>\\n\\nAmazon Comprehend requires your computer to run a Java runtime environment on Windows or Mac OS X. Amazon Comprehend does not support Windows XP or Windows Vista.\\n\\nAdditional information\\n\\nReferences\\n\\nExternal links \\n \\n\\nCategory:Cloud computing\\nCategory:Machine learning\\nCategory:Text analytics\\nCategory:Natural language processing\\nCategory:Natural language processing tools\\nCategory:Web services\\nCategory:Web analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b-fp16</th>\n",
       "      <td>Amazon Comprehend includes a number of features that can be used to identify languages and determine the dominant language for a document based on text or a set of words. These features are:\\nLanguage detection: Amazon Comprehend can detect the language of an English document. For example, you can find out what languages are in Google search queries.\\nLanguage types: Amazon Comprehend can classify each word as a noun, verb, or adjective, and each type of word as a noun, verb, adjective, or adverb. Each of the following examples shows how to identify the language of a document using the Language Type feature.\\nThe majority of Amazon Comprehend training uses the WordNet dictionary to determine word types, rather than a machine learning method. This approach is faster than training models on all words in the document and often results in better accuracy. More information on WordNet's methods for identifying word types can be found here. Amazon Comprehend also uses this WordNet dictionary during the course of natural language processing, providing a way for the training system to detect language types. \\nYou can train models using the following languages:\\nAll the examples given above assume that the system is given domain (or topic)-specific input. For example,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl</th>\n",
       "      <td>For more information, see Language feature in Amazon Comprehend. Using Amazon Comprehend with other languages is supported, but not supported at this time. \\nThis post is part of a series that discusses Amazon's machine learning offerings. The series includes: Amazon Machine Learning: Best practices and frameworks, Amazon Machine Learning: Using a wide variety of data types, Amazon Machine Learning: More examples, Amazon Machine Learning: Best-practice APIs, and Amazon Machine Learning: Machine Learning for Machine Learning Professionals. For more details, see the other posts in this series on Amazon's machine learning offerings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1-fp16</th>\n",
       "      <td>This capability runs in parallel with other features and does not require any language-specific knowledge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-7b1-fp16</th>\n",
       "      <td>For more information, see Identify a Language in a Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b</th>\n",
       "      <td>The NLP: It provides, a human you have more. NLP\\nin, you have the book of analysis functionality to be more.It is better.\\nWe, for more than you inception of these thoughts. The book. It is a more a to the new feed book in social P, NLP preprocessing functionality.\\nNLP, and make a farrecognition models, you use for the user-based and preprocessing of new knowledge ( for the web training your products on your content recognition more to be training than have some that was previously preclassifications. The web processing in your paper, previously with an human\\n or add the. ToDo check. While an.\\nIt on your web scans, you to make larger personPleaved people as you get all text, it and.\\nproduct the\\nwork, it was also be was for the large can check, you moreLPC-words model\\n and\\n of the original. use is do, web with more. The was running on PDF. The firstPurchas you the structure using the data\\nnws to be.\\n This Book to learn as PDF.\\n, your web: When you, you are in an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b-fp16</th>\n",
       "      <td>See Dominant language for more information. For more information about languages supported in Amazon Comprehend, see Language support. \\nWhen you use Amazon Comprehend document analysis features, Amazon Comprehend analyzes the documents. Amazon Comprehend can then determine the result, and provide feedback to help you with the result. You also can get information about the job as the job progresses. You can check the status of the job and stop it at any time. \\nFor more information about Amazon Comprehend, see Amazon Comprehend. For more information about data formats, see Using Amazon Comprehend with content in different data formats. \\nAmazon Comprehend uses the Amazon Elastic Compute Cloud (Amazon EC2). All Amazon Comprehend capabilities require that you are using an Amazon EC2 instance, which also requires an Internet connection. \\nFor general information about Amazon EC2, see Amazon Elastic Compute Cloud (EC2). For information about the Amazon EC2 instance types, see Amazon EC2 instance types. For information about your instance types, see Access information about your EC2 instances. \\nYou can use the Amazon Comprehend API to work with Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b</th>\n",
       "      <td>\\nTo learn more about Amazon Comprehend, visit www.amazon.com/comprehend. \\n \\nAWS Documentation\\nAmazon Comprehend Docs: https://docs.aws.amazon.com/comprehend/latest/dg/amazon-comprehend-overview.html\\nAmazon Comprehend Amazon Web Services Documentation: https://docs.aws.amazon.com/comprehend/latest/dg/amazon-comprehend-services-overview.html\\n \\nAmazon Comprehend Key Features \\nAmazon Comprehend Key Features include:\\n\\nEntity recognition: Recognize and annotate words, documents, and other concepts in the input text.\\nEntity classification: Determine the type of a word or other concept of the input text.\\nHighlighting entities: Highlight or remove key words or phrases from the text.\\nHighlighting phrases: Highlight phrases that contain content that is relevant to the input text. \\n \\nAmazon Comprehend Key Features with Amazon Rekognition API \\nAmazon Comprehend Key Features include:\\n\\nEntity recognition: Recognize and annot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b-fp16</th>\n",
       "      <td>For more information, see Supported languages. \\nAll of the Amazon Comprehend features accept UTF-8 text documents as the input. In addition, custom classification and custom entity recognition accept image files, PDF files, and Word files as input. \\n\\nAWS AutoML uses machine learning techniques to help you design, build, and deploy software products that can learn from their own experiences to improve in the future. It trains multiple computer systems to work together to autonomously optimize the behavior of existing data. The result is software that can continuously learn through its use and generate accurate predictions from unlabeled data, or automatically detect missing data.\\n\\nAmazon AutoML uses machine learning to improve products and processes by working with your existing data to build a software model to improve them. AutoML is a service provided by AWS, which uses the AWS AutoML API to train and deploy AutoML models that perform tasks such as sentiment analysis, natural language processing, text classification, sentiment classification, and domain adaptation.\\n\\nAWS AutoML offers machine learning tools and capabilities, including the cloud-based Amazon AutoML service, to help you build and deploy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b</th>\n",
       "      <td>You can use language detection to perform text analyses, sentiment detection, and out-of-band information. \\nLanguage detection — A language is detected in your documents, whether or not they're written in English. \\nKeyphrasonicallanguage detection — Automatically recognize the languages in the documents you send for interpretation. You can choose the language detection from the Amazon Comprehend console, the Amazon Comprehend, and can identify all the languages used in any of our products. It's also possible to train the model for other languages. All you language-detection capabilities support UTF-8 text documents as the input or text that includes Unicode characters.\\n\\n\\nThe Amazon Comprehend service uses a machine learning algorithm to analyze documents with the Amazon Comprehend is one of the most popular language detection. For more information, see Detecting documents, the results. If your documents are in a list of the document, which is a language detection service and language translation. The service provides. You can make any custom classification, and custom text analytics services. It's not possible.\\nAmazon Comprehend can be specified using Elasticsearch. Amazon Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neox-20b-fp16</th>\n",
       "      <td>The features within Language Identification are provided by Amazon Comprehend. \\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl-fp16</th>\n",
       "      <td>This capability is also available via the pre-trained models. You can use Amazon Comprehend with Microsoft Word, Google Docs, and other online document editors. For more details, see Languages supported in Amazon Comprehend. To learn more about Amazon Kinesis Cloud, see the Amazon Kinesis product page. In this post, we focus on the Amazon Comprehend model class analysis features that use NLP features to classify documents. We'll discuss the model class analysis capability that can be used to identify the entity of documents, for example, whether a document is about a product or an event. Finally, we'll discuss the models that use entity recognizers to identify other entities, such as the author or publisher in the case of a magazine. The following table lists a few examples of the features Amazon Comprehend models include in its models. Model Classifications  Document classification feature Feature Label English documents  • • • nouns • • • nouns • • • punctuation • • • nouns • • • sentences • English-to-Japanese sentences • • • sentences • Japanese-to- English sentences • • • sentences Japanese-to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b1</th>\n",
       "      <td>Amazon Comprehend automatically translates human readable content into the various formats supported by the AWS Command Line Interface. \\nAmazon Comprehend supports multiple file formats, including text, image, video, text-only documents and files with embedded audio. For example, a text-based document can be analyzed with Amazon Comprehend using the.txt or.txtc formats supported by Amazon Comprehend. In cases that native Amazon Comprehend or standard Text to Speech applications cannot handle the text, Amazon Comprehend can utilize an external source to deliver the text to a text-to-text converter or machine translation tool. \\nAs of November 2012, Amazon Comprehend has a full range of text detection tools based on Open Media Object Description Protocol (OMOP) specifications, including Google's OMT and the ISO/IEC 10517. OMT allows for text to speech conversions in OOV, OOI, and OOVI. \\nYou can also use Amazon Comprehend to create short summaries from documents such as:\\n - Extracting key phrases from a list of tags\\n - Filtering the output to the appropriate documents\\n - Creating a summary from a list of sentences\\n - Understanding text and sentence level phrases\\n - Understanding the general nature of documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16</th>\n",
       "      <td>In addition to English, for example, the languages supported include Arabic, Chinese, Czech, Dutch, French, German, Italian, Japanese, Korean, Polish, Portuguese (Brazilian and European), Russian, Spanish\\n&lt;human&gt;: \\n\\n\\n\\nOn March 30, 2015, Apple announced Watch OS 1.0, watchOS is the kernel of watchOS, built on top of watchOS is the user interface of the watch. On September 9, 2015, Apple announced Watch OS 2, and that the company had released the watchOS 2 developer beta for testing. On March 21, 2016, Apple announced the Apple Watch Series 2, which runs watchOS 3. The launch of watchOS 3 was held on September 7, 2016. \\n\\n Question: What is the release date of watchOS 3?\\n\\n Prediction: September 7, 2016\\n\\n Correct Answer: September 7, 2016\\n&lt;bot&gt;: September 7, 2016\\n&lt;human&gt;: Write an article that answers the following question: what is the largest island in the archipelago?\\n&lt;bot&gt;: Mount Teide National Park (Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bart4csc-base-chinese</th>\n",
       "      <td>write a short summary for this text : amazon comprehend uses natural language processing ( nlp ) to extract insights about the content of documents. it develops insightce by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. use amazon complehend to create new products based on understanding the structure of docains. for example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-t5-one-line-summary</th>\n",
       "      <td>Analyzing Document Structure and Structure Using Amazon Comprehend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-models</th>\n",
       "      <td>The information is used to guide automatic translation. \\nTo check whether the document is of relevance to Amazon Comprehend, just visit Amazon Comprehend's documentation page. Alternatively, you can view the relevant document using several search terms in the Amazon Comprehend documentation. \\nYour knowledge of Amazon Comprehend can be used to develop the following tasks:\\n\\nCreate content-based recommendations. \\nRank a document. \\nSearch for more relevant documents. \\nMark documents that are relevant to Amazon Comprehend for more detailed analysis. \\nMark documents that exceed Amazon Comprehend's thresholds. \\nAnalyze the trends and patterns in documents. \\nUse Amazon Comprehend's best practices to create relevant insights.\\n\\nYou can use Amazon Comprehend for several purposes using the Amazon Comprehend console. Visit the Amazon Comprehend documentation page for instructions and help in using the console. \\nMany open source technologies allow you to develop open source tools and integrate them with your own applications or other open source projects. \\nIn addition, you can use Amazon Comprehend to build and integrate new programs to improve productivity and productivity. \\nFor more information about the open source world and open source productivity, see http://www.amazon.com/support/amazon-desktop-concepts/. \\nIf you get stuck, you can always contact Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-560m</th>\n",
       "      <td>You can enable Amazon Comprehend to automatically support foreign languages and add Amazon Comprehend support in languages you wish. \\nFor additional info, visit Amazon Comprehend Helpdesk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-small</th>\n",
       "      <td>It works by recognizing the entities, key phrases, language, and other common elements in a document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-large</th>\n",
       "      <td>Use Amazon Comprehend's document analysis features. Analyze documents with Amazon Comprehend. Use Amazon Comprehend to search for document information, including keywords and phrases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-distilgpt2</th>\n",
       "      <td>The authors write languages supported in the traditional text format that would be much easier to parse using the Microsoft Language Specification. \\nThe most commonly used search engine for English and Spanish (SEO) search words. The SEO engine offers the \"Gesperized Search Engine\" feature that enables the Microsoft software to analyze and read certain types of documents and phrases. These features enable the Microsoft software to identify words, phrases, and phrases within the context of a document that should be used in the context of a document. \\nFor more information, see Language support in.\\nThe search engine for Spanish and Spanish (SEO) search words. The.\\nThe Search Engine for Spanish and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search words. The.\\nThe search engine for English and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-qcpg-sentences</th>\n",
       "      <td>For example, Amazon Comprehend can analyse and analyze the data of the various languages as well as the languages of the languages that it supports, to do so, to provide an overview of the customer's strengths with the Product Profiles.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b7</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base</th>\n",
       "      <td>Use Amazon Comprehend to make products based on understanding the contents of a paper.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-gpt2</th>\n",
       "      <td>Amazon Comprehend's Native Language Language feature allows users to specify their preferred language for the search term or other criteria used by Amazon Comprehend. For example, consider the following examples: Amazon Comprehend searches on the following keywords in terms of keywords the user will most likely have at hand. English Wikipedia: I can get a picture with 1,000 photos of the person's face. This is my \"name:\" picture on English Wikipedia, when I'm in a relationship with an adult and I'm getting \"your picture.\"\\nEtsy: My husband and I want to use the word \"tummy\"...\\nRenta: I make $1,000 a month, I will make $1,000 if you make it.\\n\\nAmazon Cloud: My job is to create a cloud service for Amazon cloud service providers.\\n\\nLearn more about Amazon Comprehend using our Amazon Developer Guide.\\n\\nAmazon Comprehend's New Features\\n\\nAmazon Comprehend does many things, all within a single console. Most examples I found useful were the first:\\n\\nThe Amazon Comprehend web page and its accompanying documents (e.g., Amazon Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-pegasus-paraphrase</th>\n",
       "      <td>write a short summary for this text : amazon comprehend uses natural language processing ( nlp ) to extract insights about the content of documents. it develops insightce by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. use amazon complehend to create new products based on understanding the structure of doclates. for example, using amazon com 伸ehend you can search social networking feeds for mentions of products or scan an entity recoti line line line list com com comtiti com com s comcom com com line line con contititi connect conti com line com com 认 认 认 com com app com com story com comcom con com com family com com net com com connect connect com com ma com com store store com com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base-samsum</th>\n",
       "      <td>Amazon Comprehend uses natural language processing (NLP) to create and analyze documents. Amazon Comprehend uses natural language processing to recognize objects, key phrases, and language, and allows customers to operate applications such as automation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"42\" valign=\"top\">simple_short_input</th>\n",
       "      <th>huggingface-textgeneration-bloom-1b1</th>\n",
       "      <td>Can I ask you something? I have a question about your product ‘Jewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-t5-one-line-summary</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b-fp16</th>\n",
       "      <td>I'm your regular commenter. How did you find my blog? I am also from the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl</th>\n",
       "      <td>Look! I'm not dead! I haven't been dead for a long, long time! You're kidding! You're the worst!\" --\\n\\nPapa's got no time for nobody! Papa's got no time for everybody!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1-fp16</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b</th>\n",
       "      <td>I'm trying to make a video of the same video on one of them here in the new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-7b1-fp16</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-small</th>\n",
       "      <td>hey, i know you've got a new puppy. ooh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b-fp16</th>\n",
       "      <td>My name is Dariu. I am an Italian artist. I'm here to\\nspeak about the most interesting art and graphic projects,\\nas those that have inspired me to draw.\\nMy main subjects are : Digital art, comics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b</th>\n",
       "      <td>I am so sorry to hear about your loss. My heart breaks for you and your family during this difficult time. I am sending warm wishes to your family and friends. Have you seen any other messages with a similar theme?\\n\\nM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-pegasus-paraphrase</th>\n",
       "      <td>hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b-fp16</th>\n",
       "      <td>So, there's a new kid on the block with a new product or service - an amazing one. The new kid on the block is called Facebook. It was initially created by Mark Zuckerberg and graduated from Harvard as the first university in the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b</th>\n",
       "      <td>There was a question to which I don’t answer which I feel like I ought to: Are you the type of person who sees their personal health goals as ‘quests’ or have you found them to be ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-large</th>\n",
       "      <td>Hello, how may I assist you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neox-20b-fp16</th>\n",
       "      <td>My name is Zainab and I have been teaching a primary school, preparing students to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base-samsum</th>\n",
       "      <td>hello, hello to you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b</th>\n",
       "      <td>We are all well today here and we are pleased to see you here. We are having the most awesome time. We have been looking forward to getting your questions about our home and how we work. We have been getting so many people who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-qcpg-sentences</th>\n",
       "      <td>- Hello! -Oh, dear!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl-fp16</th>\n",
       "      <td>I hope you are having a good day so far. I am not sure of the actual name of the blog, but I do see a lot of posts of people talking about this blog. I have come to realize that as a child,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-560m</th>\n",
       "      <td>We’re all here to help you on this project today:\\nI love getting things organized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xl</th>\n",
       "      <td>The lovely Jill from the Hello &amp; Hi! site is back. (Yes, another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-bnb-int8</th>\n",
       "      <td>Check out this awesome video of my favorite place in all the USA. It's The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-models</th>\n",
       "      <td>The first phase was almost finished in four days. I’ve already finished the last few of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b7</th>\n",
       "      <td>This is actually a quite good short article. I will be happy if you visit this website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp</th>\n",
       "      <td>I hope you all have had a delightful Monday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-distilgpt2</th>\n",
       "      <td>For example, in the following example, it was a very complex, complex web page. I've tried to use your basic setup to make sure that the entire page is not as complex as the original (or so I wrote as my own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl</th>\n",
       "      <td>! is our new store!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-fp16</th>\n",
       "      <td>Welcome to the web site of St Luc Catholic School in Thief River Falls, Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16</th>\n",
       "      <td>\\n&lt;human&gt;: Explain like I am five: How to use growth ring to build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-fp16</th>\n",
       "      <td>My name is Ximena and I am a student from Venezuela. I recently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-gpt2</th>\n",
       "      <td>I have an issue, this is bad. Why is she doing so badly?! So I will try to answer. First off the first problem is that the first option of the article isn't going to be \"I do want to learn what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-bnb-int8</th>\n",
       "      <td>I'd like to thank you for your interest in employment with the St. Louis County Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-ul2-bf16</th>\n",
       "      <td>I  you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b7</th>\n",
       "      <td>Today I will be using the Word 2003 Standard Edition with MS Word. If you have never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m</th>\n",
       "      <td>\\n\\nAlfa Romeo and the latest of all Romeo Racing's new motorcycles, the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1</th>\n",
       "      <td>How can I get to this code? how are you folks? It's been? I've been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b1</th>\n",
       "      <td>I would like to order Cialis 50 mg online no prescription. Cialis in the United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-3b-fp16</th>\n",
       "      <td>My name is Yvan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m-fp16</th>\n",
       "      <td>I'm the one who posted this idea to the world. This is real.\\nI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b-fp16</th>\n",
       "      <td>This is a place for me to record and play with my friends playing the guitar. If I've missed you, please leave a comment.\\n\\nThis video was made using a laptop running Windows Vista.\\n\\nI have a few guitars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base</th>\n",
       "      <td>YELP ISP for Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bart4csc-base-chinese</th>\n",
       "      <td>hello!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          SampleOutput\n",
       "PayloadName        ModelID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "generate_summary   huggingface-text2text-flan-t5-xxl-fp16                    Use Amazon Comprehend to analyze text documents in a variety of languages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            Documents in UTF-8, PDF files, Word files, and image files                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "                   huggingface-textgeneration-bloom-1b7                       When you choose Amazon Comprehend to analyze your documents, you can change Amazon Comprehend to other languages if you don't want your document analyzed using a dominant language.\\n\\nQuestions related to the above: \\n\\nIf a user has created Amazon Comprehend's document repository, the document repository can be used to run analysis jobs with Amazon Comprehend. If not, how can the documents in the document repository used to run Amazon Comprehend analysis?\\nCan I run a dataset on my document repository using Amazon Comprehend? How and where I should start? I know I can import any document in the repository to run analysis, but I didn't get the training dataset, or any samples of the document in the repository that could be used to implement the algorithm.\\nCan I start a new analysis job with a document repository already having input documents from a search? What should I do to include the documents (or subsets of them) I already have in the analysis job?\\n\\nPlease let me know if I'm missing some important details. Thanks!\\n\\nA:\\n\\nAmazon Comprehend documents are stored as base64 encoded byte arrays.  If you convert input stream to bytes, then you can use that as the input stream for the analysis.  However, if you have to convert                                                                                                                                       \n",
       "                   huggingface-text2text-bigscience-t0pp                     Use Amazon Comprehend to scan social networking feeds for mentions of specific products using Amazon Comprehend Spotlight.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "                   huggingface-text2text-flan-t5-xxl                         Finds common elements from a document by performing Natural Language Processing (NLP) of textual content.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                Documents and other media (images, PDFs, Word files) Sentiment analysis                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                Understand the structure of documents using Amazon Comprehend.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-text2text-flan-ul2-bf16                       Describes the architecture of Amazon Comprephend.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "                   huggingface-textgeneration1-gpt-neo-125m                  \\n\\nProperties\\n\\nAmazon Comprehends the Language in the Document in the Document:\\n[https://aws.amazon.com/comprehend/](https://aws.amazon.com/comprehend/)\\nAmazon Comprehend's Language\\n[https://developer.amazon.com/comprehends/latest/feature/compularnglbl/?hl=en-US,pct=en-GB&ioc='amazon-comprehend']\\n\\nA:\\n\\nI use the Amazon Comprehend API in a couple of situations in my work as a project manager for Amazon Ecosystem team.\\nThey have a collection called Resources for your project, which you can interact with as you work. Also you can create a Resource, which contains your user-defined resources. Here is a link for a related project.\\nNow, these are the APIs that you can use to make your project's resources work. In case you are using a library that provides a library that requires some data, they can use it to provide the access that you need to your library.\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-textgeneration1-bloom-7b1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             \\n\\nGoogle Translate Language\\nIn Google Translate Language, you are able to view documents that are translated into other languages (e.g. English, French, Spanish, German, Swedish, Spanish, Czech, Portuguese, German, German, Dutch, Bulgarian, Hungarian). However, it is a language based on a translation platform, which means you need a transliterate translation service like TransLang.\\nExample translated into French, Spanish, German, Italian, Hungarian, Croatian, Czech, Portuguese, Slovak, Serbian, and Ukrainian (but no English). Translate-language documents are often created in English. \\nYour Translates file may look different according to the translation service's terms of service (e.g. translations are translated to Spanish, English, or French). When your Translates file is translated, as in a translated text file, the translated text file includes a small bit of Latin text of an external language (in this case, French), and so it becomes your Translates file. This translates the text into another English language, which you are able to translate into other languages (e.g                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-text2text-flan-t5-xl                          Use Amazon Comprehend to discover and analyze the content in any document.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16              For an example of the Language selection, see Language selector in Amazon Comprehend console. \\nAmazon Comprehend is a product that is currently available for customers in the United States. At the time of writing, it does not yet support users outside the United States. \\n\\n Version 3.0 of Amazon Comprehend was released on 19 November 2018. \\n\\n Amazon Comprehend v3.0 provides faster search and analysis times and reduced storage requirements over Amazon Comprehend v2.0. This version includes a number of new features including support for new input methods, full-text search across diverse data sources and Amazon's machine learning models, automatic classification and entity recognition and other features. \\n Amazon Comprehend v3.0 also includes support for document classification and identification in a number of languages and an improved set of training scenarios, and a new set of training models. In addition, Amazon Comprehend v3.0 provides a range of features that are not currently included in Amazon Comprehend v2.0. Amazon Comprehend v3.0 is available for customers in the United States. Amazon Comprehend v3.0 is now available for                                                                                                                                                                                                                                         \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  \\n\\nAmazon Comprehend requires your computer to run a Java runtime environment on Windows or Mac OS X. Amazon Comprehend does not support Windows XP or Windows Vista.\\n\\nAdditional information\\n\\nReferences\\n\\nExternal links \\n \\n\\nCategory:Cloud computing\\nCategory:Machine learning\\nCategory:Text analytics\\nCategory:Natural language processing\\nCategory:Natural language processing tools\\nCategory:Web services\\nCategory:Web analytics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                  Amazon Comprehend includes a number of features that can be used to identify languages and determine the dominant language for a document based on text or a set of words. These features are:\\nLanguage detection: Amazon Comprehend can detect the language of an English document. For example, you can find out what languages are in Google search queries.\\nLanguage types: Amazon Comprehend can classify each word as a noun, verb, or adjective, and each type of word as a noun, verb, adjective, or adverb. Each of the following examples shows how to identify the language of a document using the Language Type feature.\\nThe majority of Amazon Comprehend training uses the WordNet dictionary to determine word types, rather than a machine learning method. This approach is faster than training models on all words in the document and often results in better accuracy. More information on WordNet's methods for identifying word types can be found here. Amazon Comprehend also uses this WordNet dictionary during the course of natural language processing, providing a way for the training system to detect language types. \\nYou can train models using the following languages:\\nAll the examples given above assume that the system is given domain (or topic)-specific input. For example,                                                                                                          \n",
       "                   huggingface-textgeneration1-gpt-2-xl                       For more information, see Language feature in Amazon Comprehend. Using Amazon Comprehend with other languages is supported, but not supported at this time. \\nThis post is part of a series that discusses Amazon's machine learning offerings. The series includes: Amazon Machine Learning: Best practices and frameworks, Amazon Machine Learning: Using a wide variety of data types, Amazon Machine Learning: More examples, Amazon Machine Learning: Best-practice APIs, and Amazon Machine Learning: Machine Learning for Machine Learning Professionals. For more details, see the other posts in this series on Amazon's machine learning offerings.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                 This capability runs in parallel with other features and does not require any language-specific knowledge.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16                For more information, see Identify a Language in a Document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration1-bloom-3b                       The NLP: It provides, a human you have more. NLP\\nin, you have the book of analysis functionality to be more.It is better.\\nWe, for more than you inception of these thoughts. The book. It is a more a to the new feed book in social P, NLP preprocessing functionality.\\nNLP, and make a farrecognition models, you use for the user-based and preprocessing of new knowledge ( for the web training your products on your content recognition more to be training than have some that was previously preclassifications. The web processing in your paper, previously with an human\\n or add the. ToDo check. While an.\\nIt on your web scans, you to make larger personPleaved people as you get all text, it and.\\nproduct the\\nwork, it was also be was for the large can check, you moreLPC-words model\\n and\\n of the original. use is do, web with more. The was running on PDF. The firstPurchas you the structure using the data\\nnws to be.\\n This Book to learn as PDF.\\n, your web: When you, you are in an                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                  See Dominant language for more information. For more information about languages supported in Amazon Comprehend, see Language support. \\nWhen you use Amazon Comprehend document analysis features, Amazon Comprehend analyzes the documents. Amazon Comprehend can then determine the result, and provide feedback to help you with the result. You also can get information about the job as the job progresses. You can check the status of the job and stop it at any time. \\nFor more information about Amazon Comprehend, see Amazon Comprehend. For more information about data formats, see Using Amazon Comprehend with content in different data formats. \\nAmazon Comprehend uses the Amazon Elastic Compute Cloud (Amazon EC2). All Amazon Comprehend capabilities require that you are using an Amazon EC2 instance, which also requires an Internet connection. \\nFor general information about Amazon EC2, see Amazon Elastic Compute Cloud (EC2). For information about the Amazon EC2 instance types, see Amazon EC2 instance types. For information about your instance types, see Access information about your EC2 instances. \\nYou can use the Amazon Comprehend API to work with Amazon                                                                                                                                                                                                                           \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                   \\nTo learn more about Amazon Comprehend, visit www.amazon.com/comprehend. \\n \\nAWS Documentation\\nAmazon Comprehend Docs: https://docs.aws.amazon.com/comprehend/latest/dg/amazon-comprehend-overview.html\\nAmazon Comprehend Amazon Web Services Documentation: https://docs.aws.amazon.com/comprehend/latest/dg/amazon-comprehend-services-overview.html\\n \\nAmazon Comprehend Key Features \\nAmazon Comprehend Key Features include:\\n\\nEntity recognition: Recognize and annotate words, documents, and other concepts in the input text.\\nEntity classification: Determine the type of a word or other concept of the input text.\\nHighlighting entities: Highlight or remove key words or phrases from the text.\\nHighlighting phrases: Highlight phrases that contain content that is relevant to the input text. \\n \\nAmazon Comprehend Key Features with Amazon Rekognition API \\nAmazon Comprehend Key Features include:\\n\\nEntity recognition: Recognize and annot                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16              For more information, see Supported languages. \\nAll of the Amazon Comprehend features accept UTF-8 text documents as the input. In addition, custom classification and custom entity recognition accept image files, PDF files, and Word files as input. \\n\\nAWS AutoML uses machine learning techniques to help you design, build, and deploy software products that can learn from their own experiences to improve in the future. It trains multiple computer systems to work together to autonomously optimize the behavior of existing data. The result is software that can continuously learn through its use and generate accurate predictions from unlabeled data, or automatically detect missing data.\\n\\nAmazon AutoML uses machine learning to improve products and processes by working with your existing data to build a software model to improve them. AutoML is a service provided by AWS, which uses the AWS AutoML API to train and deploy AutoML models that perform tasks such as sentiment analysis, natural language processing, text classification, sentiment classification, and domain adaptation.\\n\\nAWS AutoML offers machine learning tools and capabilities, including the cloud-based Amazon AutoML service, to help you build and deploy                                                                                                                                                            \n",
       "                   huggingface-textgeneration1-gpt-j-6b                       You can use language detection to perform text analyses, sentiment detection, and out-of-band information. \\nLanguage detection — A language is detected in your documents, whether or not they're written in English. \\nKeyphrasonicallanguage detection — Automatically recognize the languages in the documents you send for interpretation. You can choose the language detection from the Amazon Comprehend console, the Amazon Comprehend, and can identify all the languages used in any of our products. It's also possible to train the model for other languages. All you language-detection capabilities support UTF-8 text documents as the input or text that includes Unicode characters.\\n\\n\\nThe Amazon Comprehend service uses a machine learning algorithm to analyze documents with the Amazon Comprehend is one of the most popular language detection. For more information, see Detecting documents, the results. If your documents are in a list of the document, which is a language detection service and language translation. The service provides. You can make any custom classification, and custom text analytics services. It's not possible.\\nAmazon Comprehend can be specified using Elasticsearch. Amazon Comp                                                                                                                                                                                      \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16              The features within Language Identification are provided by Amazon Comprehend. \\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                  This capability is also available via the pre-trained models. You can use Amazon Comprehend with Microsoft Word, Google Docs, and other online document editors. For more details, see Languages supported in Amazon Comprehend. To learn more about Amazon Kinesis Cloud, see the Amazon Kinesis product page. In this post, we focus on the Amazon Comprehend model class analysis features that use NLP features to classify documents. We'll discuss the model class analysis capability that can be used to identify the entity of documents, for example, whether a document is about a product or an event. Finally, we'll discuss the models that use entity recognizers to identify other entities, such as the author or publisher in the case of a magazine. The following table lists a few examples of the features Amazon Comprehend models include in its models. Model Classifications  Document classification feature Feature Label English documents  • • • nouns • • • nouns • • • punctuation • • • nouns • • • sentences • English-to-Japanese sentences • • • sentences • Japanese-to- English sentences • • • sentences Japanese-to                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration-bloom-1b1                       Amazon Comprehend automatically translates human readable content into the various formats supported by the AWS Command Line Interface. \\nAmazon Comprehend supports multiple file formats, including text, image, video, text-only documents and files with embedded audio. For example, a text-based document can be analyzed with Amazon Comprehend using the.txt or.txtc formats supported by Amazon Comprehend. In cases that native Amazon Comprehend or standard Text to Speech applications cannot handle the text, Amazon Comprehend can utilize an external source to deliver the text to a text-to-text converter or machine translation tool. \\nAs of November 2012, Amazon Comprehend has a full range of text detection tools based on Open Media Object Description Protocol (OMOP) specifications, including Google's OMT and the ISO/IEC 10517. OMT allows for text to speech conversions in OOV, OOI, and OOVI. \\nYou can also use Amazon Comprehend to create short summaries from documents such as:\\n - Extracting key phrases from a list of tags\\n - Filtering the output to the appropriate documents\\n - Creating a summary from a list of sentences\\n - Understanding text and sentence level phrases\\n - Understanding the general nature of documents                                                                                                                                                       \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16   In addition to English, for example, the languages supported include Arabic, Chinese, Czech, Dutch, French, German, Italian, Japanese, Korean, Polish, Portuguese (Brazilian and European), Russian, Spanish\\n<human>: \\n\\n\\n\\nOn March 30, 2015, Apple announced Watch OS 1.0, watchOS is the kernel of watchOS, built on top of watchOS is the user interface of the watch. On September 9, 2015, Apple announced Watch OS 2, and that the company had released the watchOS 2 developer beta for testing. On March 21, 2016, Apple announced the Apple Watch Series 2, which runs watchOS 3. The launch of watchOS 3 was held on September 7, 2016. \\n\\n Question: What is the release date of watchOS 3?\\n\\n Prediction: September 7, 2016\\n\\n Correct Answer: September 7, 2016\\n<bot>: September 7, 2016\\n<human>: Write an article that answers the following question: what is the largest island in the archipelago?\\n<bot>: Mount Teide National Park (Spanish                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "                   huggingface-text2text-bart4csc-base-chinese               write a short summary for this text : amazon comprehend uses natural language processing ( nlp ) to extract insights about the content of documents. it develops insightce by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. use amazon complehend to create new products based on understanding the structure of docains. for example                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "                   huggingface-text2text-t5-one-line-summary                 Analyzing Document Structure and Structure Using Amazon Comprehend                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "                   huggingface-textgeneration-models                          The information is used to guide automatic translation. \\nTo check whether the document is of relevance to Amazon Comprehend, just visit Amazon Comprehend's documentation page. Alternatively, you can view the relevant document using several search terms in the Amazon Comprehend documentation. \\nYour knowledge of Amazon Comprehend can be used to develop the following tasks:\\n\\nCreate content-based recommendations. \\nRank a document. \\nSearch for more relevant documents. \\nMark documents that are relevant to Amazon Comprehend for more detailed analysis. \\nMark documents that exceed Amazon Comprehend's thresholds. \\nAnalyze the trends and patterns in documents. \\nUse Amazon Comprehend's best practices to create relevant insights.\\n\\nYou can use Amazon Comprehend for several purposes using the Amazon Comprehend console. Visit the Amazon Comprehend documentation page for instructions and help in using the console. \\nMany open source technologies allow you to develop open source tools and integrate them with your own applications or other open source projects. \\nIn addition, you can use Amazon Comprehend to build and integrate new programs to improve productivity and productivity. \\nFor more information about the open source world and open source productivity, see http://www.amazon.com/support/amazon-desktop-concepts/. \\nIf you get stuck, you can always contact Amazon\n",
       "                   huggingface-textgeneration-bloom-560m                      You can enable Amazon Comprehend to automatically support foreign languages and add Amazon Comprehend support in languages you wish. \\nFor additional info, visit Amazon Comprehend Helpdesk.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-text2text-flan-t5-small                       It works by recognizing the entities, key phrases, language, and other common elements in a document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-text2text-flan-t5-large                       Use Amazon Comprehend's document analysis features. Analyze documents with Amazon Comprehend. Use Amazon Comprehend to search for document information, including keywords and phrases.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-textgeneration-distilgpt2                      The authors write languages supported in the traditional text format that would be much easier to parse using the Microsoft Language Specification. \\nThe most commonly used search engine for English and Spanish (SEO) search words. The SEO engine offers the \"Gesperized Search Engine\" feature that enables the Microsoft software to analyze and read certain types of documents and phrases. These features enable the Microsoft software to identify words, phrases, and phrases within the context of a document that should be used in the context of a document. \\nFor more information, see Language support in.\\nThe search engine for Spanish and Spanish (SEO) search words. The.\\nThe Search Engine for Spanish and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search words. The.\\nThe search engine for English and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search words. The.\\nThe Search Engine for English and Spanish (SEO) search                                                                                                                                                                                                                                                                                                                            \n",
       "                   huggingface-text2text-qcpg-sentences                      For example, Amazon Comprehend can analyse and analyze the data of the various languages as well as the languages of the languages that it supports, to do so, to provide an overview of the customer's strengths with the Product Profiles.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration-bloomz-1b7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "                   huggingface-text2text-flan-t5-base                        Use Amazon Comprehend to make products based on understanding the contents of a paper.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "                   huggingface-textgeneration-gpt2                            Amazon Comprehend's Native Language Language feature allows users to specify their preferred language for the search term or other criteria used by Amazon Comprehend. For example, consider the following examples: Amazon Comprehend searches on the following keywords in terms of keywords the user will most likely have at hand. English Wikipedia: I can get a picture with 1,000 photos of the person's face. This is my \"name:\" picture on English Wikipedia, when I'm in a relationship with an adult and I'm getting \"your picture.\"\\nEtsy: My husband and I want to use the word \"tummy\"...\\nRenta: I make $1,000 a month, I will make $1,000 if you make it.\\n\\nAmazon Cloud: My job is to create a cloud service for Amazon cloud service providers.\\n\\nLearn more about Amazon Comprehend using our Amazon Developer Guide.\\n\\nAmazon Comprehend's New Features\\n\\nAmazon Comprehend does many things, all within a single console. Most examples I found useful were the first:\\n\\nThe Amazon Comprehend web page and its accompanying documents (e.g., Amazon Comp                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-text2text-pegasus-paraphrase                  write a short summary for this text : amazon comprehend uses natural language processing ( nlp ) to extract insights about the content of documents. it develops insightce by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. use amazon complehend to create new products based on understanding the structure of doclates. for example, using amazon com 伸ehend you can search social networking feeds for mentions of products or scan an entity recoti line line line list com com comtiti com com s comcom com com line line con contititi connect conti com line com com 认 认 认 com com app com com story com comcom con com com family com com net com com connect connect com com ma com com store store com com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 Amazon Comprehend uses natural language processing (NLP) to create and analyze documents. Amazon Comprehend uses natural language processing to recognize objects, key phrases, and language, and allows customers to operate applications such as automation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-textgeneration-bloomz-1b1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "simple_short_input huggingface-textgeneration-bloom-1b1                       Can I ask you something? I have a question about your product ‘Jewelry                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-text2text-t5-one-line-summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                  I'm your regular commenter. How did you find my blog? I am also from the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl                       Look! I'm not dead! I haven't been dead for a long, long time! You're kidding! You're the worst!\" --\\n\\nPapa's got no time for nobody! Papa's got no time for everybody!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-textgeneration1-bloom-3b                       I'm trying to make a video of the same video on one of them here in the new                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "                   huggingface-text2text-flan-t5-small                       hey, i know you've got a new puppy. ooh                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                  My name is Dariu. I am an Italian artist. I'm here to\\nspeak about the most interesting art and graphic projects,\\nas those that have inspired me to draw.\\nMy main subjects are : Digital art, comics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                   I am so sorry to hear about your loss. My heart breaks for you and your family during this difficult time. I am sending warm wishes to your family and friends. Have you seen any other messages with a similar theme?\\n\\nM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-text2text-pegasus-paraphrase                  hello!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16              So, there's a new kid on the block with a new product or service - an amazing one. The new kid on the block is called Facebook. It was initially created by Mark Zuckerberg and graduated from Harvard as the first university in the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "                   huggingface-textgeneration1-gpt-j-6b                       There was a question to which I don’t answer which I feel like I ought to: Are you the type of person who sees their personal health goals as ‘quests’ or have you found them to be ‘                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "                   huggingface-text2text-flan-t5-large                       Hello, how may I assist you?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16              My name is Zainab and I have been teaching a primary school, preparing students to                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 hello, hello to you.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                   We are all well today here and we are pleased to see you here. We are having the most awesome time. We have been looking forward to getting your questions about our home and how we work. We have been getting so many people who                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                   huggingface-text2text-qcpg-sentences                       - Hello! -Oh, dear!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                  I hope you are having a good day so far. I am not sure of the actual name of the blog, but I do see a lot of posts of people talking about this blog. I have come to realize that as a child,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "                   huggingface-textgeneration-bloom-560m                      We’re all here to help you on this project today:\\nI love getting things organized                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                   huggingface-text2text-flan-t5-xl                          The lovely Jill from the Hello & Hi! site is back. (Yes, another                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            Check out this awesome video of my favorite place in all the USA. It's The                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "                   huggingface-textgeneration-models                          The first phase was almost finished in four days. I’ve already finished the last few of the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration-bloom-1b7                       This is actually a quite good short article. I will be happy if you visit this website                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-text2text-bigscience-t0pp                     I hope you all have had a delightful Monday!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "                   huggingface-textgeneration-distilgpt2                      For example, in the following example, it was a very complex, complex web page. I've tried to use your basic setup to make sure that the entire page is not as complex as the original (or so I wrote as my own                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-text2text-flan-t5-xxl                         ! is our new store!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    Welcome to the web site of St Luc Catholic School in Thief River Falls, Minnesota                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  \\n<human>: Explain like I am five: How to use growth ring to build                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                My name is Ximena and I am a student from Venezuela. I recently                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "                   huggingface-textgeneration-gpt2                            I have an issue, this is bad. Why is she doing so badly?! So I will try to answer. First off the first problem is that the first option of the article isn't going to be \"I do want to learn what                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                I'd like to thank you for your interest in employment with the St. Louis County Economic                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "                   huggingface-text2text-flan-ul2-bf16                        I  you                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "                   huggingface-textgeneration-bloomz-1b7                      Today I will be using the Word 2003 Standard Edition with MS Word. If you have never                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "                   huggingface-textgeneration1-gpt-neo-125m                  \\n\\nAlfa Romeo and the latest of all Romeo Racing's new motorcycles, the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "                   huggingface-textgeneration1-bloom-7b1                      How can I get to this code? how are you folks? It's been? I've been                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-textgeneration-bloomz-1b1                      I would like to order Cialis 50 mg online no prescription. Cialis in the United                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                 My name is Yvan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16              I'm the one who posted this idea to the world. This is real.\\nI                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16              This is a place for me to record and play with my friends playing the guitar. If I've missed you, please leave a comment.\\n\\nThis video was made using a laptop running Windows Vista.\\n\\nI have a few guitars                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "                   huggingface-text2text-flan-t5-base                        YELP ISP for Ukraine                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                   huggingface-text2text-bart4csc-base-chinese               hello!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Throughput</th>\n",
       "      <th>ModelLatency.Average</th>\n",
       "      <th>Client.Latency.Average</th>\n",
       "      <th>Client.OutputSequenceWords.Average</th>\n",
       "      <th>WordThroughput</th>\n",
       "      <th>Client.LatencyPerOutputWord.Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PayloadName</th>\n",
       "      <th>ModelID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"42\" valign=\"top\">generate_summary</th>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m</th>\n",
       "      <td>1.823</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.535</td>\n",
       "      <td>109.7</td>\n",
       "      <td>199.965</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m-fp16</th>\n",
       "      <td>2.062</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.474</td>\n",
       "      <td>102.1</td>\n",
       "      <td>210.496</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b-fp16</th>\n",
       "      <td>0.554</td>\n",
       "      <td>1.669</td>\n",
       "      <td>1.726</td>\n",
       "      <td>147.2</td>\n",
       "      <td>81.576</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-qcpg-sentences</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.948</td>\n",
       "      <td>62.2</td>\n",
       "      <td>49.813</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b-fp16</th>\n",
       "      <td>0.459</td>\n",
       "      <td>2.667</td>\n",
       "      <td>2.730</td>\n",
       "      <td>173.2</td>\n",
       "      <td>79.540</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl-fp16</th>\n",
       "      <td>0.414</td>\n",
       "      <td>1.729</td>\n",
       "      <td>1.787</td>\n",
       "      <td>128.8</td>\n",
       "      <td>53.285</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b</th>\n",
       "      <td>0.468</td>\n",
       "      <td>2.754</td>\n",
       "      <td>2.811</td>\n",
       "      <td>155.6</td>\n",
       "      <td>72.866</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-small</th>\n",
       "      <td>5.224</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.197</td>\n",
       "      <td>10.1</td>\n",
       "      <td>52.759</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bart4csc-base-chinese</th>\n",
       "      <td>0.822</td>\n",
       "      <td>1.324</td>\n",
       "      <td>1.383</td>\n",
       "      <td>74.7</td>\n",
       "      <td>61.433</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-gpt2</th>\n",
       "      <td>0.373</td>\n",
       "      <td>3.488</td>\n",
       "      <td>3.548</td>\n",
       "      <td>174.2</td>\n",
       "      <td>64.945</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl</th>\n",
       "      <td>0.554</td>\n",
       "      <td>3.155</td>\n",
       "      <td>3.215</td>\n",
       "      <td>152.1</td>\n",
       "      <td>84.323</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base-samsum</th>\n",
       "      <td>3.047</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.469</td>\n",
       "      <td>21.7</td>\n",
       "      <td>66.124</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b</th>\n",
       "      <td>0.464</td>\n",
       "      <td>3.322</td>\n",
       "      <td>3.386</td>\n",
       "      <td>149.3</td>\n",
       "      <td>69.273</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b-fp16</th>\n",
       "      <td>0.285</td>\n",
       "      <td>3.600</td>\n",
       "      <td>3.658</td>\n",
       "      <td>150.4</td>\n",
       "      <td>42.919</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-pegasus-paraphrase</th>\n",
       "      <td>0.722</td>\n",
       "      <td>1.366</td>\n",
       "      <td>1.425</td>\n",
       "      <td>67.5</td>\n",
       "      <td>48.766</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base</th>\n",
       "      <td>2.462</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.342</td>\n",
       "      <td>14.1</td>\n",
       "      <td>34.713</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b-fp16</th>\n",
       "      <td>0.539</td>\n",
       "      <td>3.607</td>\n",
       "      <td>3.669</td>\n",
       "      <td>152.0</td>\n",
       "      <td>81.951</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b</th>\n",
       "      <td>0.342</td>\n",
       "      <td>5.235</td>\n",
       "      <td>5.298</td>\n",
       "      <td>194.1</td>\n",
       "      <td>66.456</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-t5-one-line-summary</th>\n",
       "      <td>4.892</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.244</td>\n",
       "      <td>8.8</td>\n",
       "      <td>43.051</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-models</th>\n",
       "      <td>0.204</td>\n",
       "      <td>3.211</td>\n",
       "      <td>3.273</td>\n",
       "      <td>110.4</td>\n",
       "      <td>22.570</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b7</th>\n",
       "      <td>0.240</td>\n",
       "      <td>2.787</td>\n",
       "      <td>2.848</td>\n",
       "      <td>94.5</td>\n",
       "      <td>22.683</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-560m</th>\n",
       "      <td>0.450</td>\n",
       "      <td>3.393</td>\n",
       "      <td>3.455</td>\n",
       "      <td>119.0</td>\n",
       "      <td>53.555</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b1</th>\n",
       "      <td>0.218</td>\n",
       "      <td>4.805</td>\n",
       "      <td>4.868</td>\n",
       "      <td>155.6</td>\n",
       "      <td>33.881</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b7</th>\n",
       "      <td>3.920</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.416</td>\n",
       "      <td>9.5</td>\n",
       "      <td>37.237</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16</th>\n",
       "      <td>0.176</td>\n",
       "      <td>5.689</td>\n",
       "      <td>5.751</td>\n",
       "      <td>165.4</td>\n",
       "      <td>29.034</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-3b-fp16</th>\n",
       "      <td>6.922</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.183</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.613</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-7b1-fp16</th>\n",
       "      <td>3.488</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.259</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.907</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-large</th>\n",
       "      <td>1.303</td>\n",
       "      <td>0.951</td>\n",
       "      <td>1.010</td>\n",
       "      <td>25.6</td>\n",
       "      <td>33.356</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1</th>\n",
       "      <td>6.144</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.347</td>\n",
       "      <td>3.9</td>\n",
       "      <td>23.960</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xl</th>\n",
       "      <td>1.782</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.798</td>\n",
       "      <td>18.3</td>\n",
       "      <td>32.611</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1-fp16</th>\n",
       "      <td>3.002</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.309</td>\n",
       "      <td>4.2</td>\n",
       "      <td>12.606</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neox-20b-fp16</th>\n",
       "      <td>0.242</td>\n",
       "      <td>4.404</td>\n",
       "      <td>4.470</td>\n",
       "      <td>108.0</td>\n",
       "      <td>26.172</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b</th>\n",
       "      <td>0.343</td>\n",
       "      <td>5.299</td>\n",
       "      <td>5.362</td>\n",
       "      <td>123.8</td>\n",
       "      <td>42.516</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-distilgpt2</th>\n",
       "      <td>0.689</td>\n",
       "      <td>1.282</td>\n",
       "      <td>1.343</td>\n",
       "      <td>100.6</td>\n",
       "      <td>69.315</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b1</th>\n",
       "      <td>9.184</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.244</td>\n",
       "      <td>3.7</td>\n",
       "      <td>33.983</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-fp16</th>\n",
       "      <td>0.754</td>\n",
       "      <td>1.404</td>\n",
       "      <td>1.468</td>\n",
       "      <td>10.9</td>\n",
       "      <td>8.214</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-fp16</th>\n",
       "      <td>0.397</td>\n",
       "      <td>2.083</td>\n",
       "      <td>2.142</td>\n",
       "      <td>19.2</td>\n",
       "      <td>7.619</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-ul2-bf16</th>\n",
       "      <td>0.359</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.488</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4.919</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-bnb-int8</th>\n",
       "      <td>0.341</td>\n",
       "      <td>2.318</td>\n",
       "      <td>2.380</td>\n",
       "      <td>12.5</td>\n",
       "      <td>4.263</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl</th>\n",
       "      <td>0.345</td>\n",
       "      <td>3.115</td>\n",
       "      <td>3.173</td>\n",
       "      <td>17.6</td>\n",
       "      <td>6.072</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-bnb-int8</th>\n",
       "      <td>0.186</td>\n",
       "      <td>3.522</td>\n",
       "      <td>3.582</td>\n",
       "      <td>20.1</td>\n",
       "      <td>3.747</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp</th>\n",
       "      <td>0.171</td>\n",
       "      <td>3.198</td>\n",
       "      <td>3.261</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.913</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"42\" valign=\"top\">simple_short_input</th>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m</th>\n",
       "      <td>15.013</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.183</td>\n",
       "      <td>13.3</td>\n",
       "      <td>199.678</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-125m-fp16</th>\n",
       "      <td>15.784</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.181</td>\n",
       "      <td>14.8</td>\n",
       "      <td>233.604</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b-fp16</th>\n",
       "      <td>2.689</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.503</td>\n",
       "      <td>34.9</td>\n",
       "      <td>93.851</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-distilgpt2</th>\n",
       "      <td>2.421</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.472</td>\n",
       "      <td>30.7</td>\n",
       "      <td>74.331</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl-fp16</th>\n",
       "      <td>1.938</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.658</td>\n",
       "      <td>36.1</td>\n",
       "      <td>69.967</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-1-3b</th>\n",
       "      <td>1.643</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.723</td>\n",
       "      <td>37.2</td>\n",
       "      <td>61.108</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b-fp16</th>\n",
       "      <td>2.106</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.762</td>\n",
       "      <td>38.3</td>\n",
       "      <td>80.667</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-gpt2</th>\n",
       "      <td>1.405</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.840</td>\n",
       "      <td>39.2</td>\n",
       "      <td>55.072</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-neo-2-7b</th>\n",
       "      <td>2.215</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.922</td>\n",
       "      <td>36.6</td>\n",
       "      <td>81.064</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b-fp16</th>\n",
       "      <td>2.591</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.976</td>\n",
       "      <td>37.3</td>\n",
       "      <td>96.640</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-2-xl</th>\n",
       "      <td>2.374</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.082</td>\n",
       "      <td>35.1</td>\n",
       "      <td>83.326</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-models</th>\n",
       "      <td>2.350</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.566</td>\n",
       "      <td>15.9</td>\n",
       "      <td>37.361</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b1</th>\n",
       "      <td>2.171</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.590</td>\n",
       "      <td>16.6</td>\n",
       "      <td>36.045</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-1b7</th>\n",
       "      <td>2.225</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.576</td>\n",
       "      <td>16.2</td>\n",
       "      <td>36.041</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b-fp16</th>\n",
       "      <td>3.882</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.566</td>\n",
       "      <td>15.6</td>\n",
       "      <td>60.558</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b1</th>\n",
       "      <td>2.468</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.521</td>\n",
       "      <td>14.1</td>\n",
       "      <td>34.799</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-gpt-j-6b</th>\n",
       "      <td>1.496</td>\n",
       "      <td>1.480</td>\n",
       "      <td>1.544</td>\n",
       "      <td>37.0</td>\n",
       "      <td>55.358</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloom-560m</th>\n",
       "      <td>2.268</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.530</td>\n",
       "      <td>14.2</td>\n",
       "      <td>32.208</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-3b-fp16</th>\n",
       "      <td>6.162</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.498</td>\n",
       "      <td>11.7</td>\n",
       "      <td>72.095</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base</th>\n",
       "      <td>5.893</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.322</td>\n",
       "      <td>8.7</td>\n",
       "      <td>51.266</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration-bloomz-1b7</th>\n",
       "      <td>2.667</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.520</td>\n",
       "      <td>12.6</td>\n",
       "      <td>33.601</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-base-samsum</th>\n",
       "      <td>6.033</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.278</td>\n",
       "      <td>7.2</td>\n",
       "      <td>43.439</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neox-20b-fp16</th>\n",
       "      <td>2.119</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.593</td>\n",
       "      <td>13.8</td>\n",
       "      <td>29.238</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1</th>\n",
       "      <td>3.643</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.364</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.037</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16</th>\n",
       "      <td>2.117</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.611</td>\n",
       "      <td>12.6</td>\n",
       "      <td>26.673</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xl</th>\n",
       "      <td>2.193</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.729</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.701</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-7b1-fp16</th>\n",
       "      <td>4.498</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.511</td>\n",
       "      <td>10.5</td>\n",
       "      <td>47.225</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloom-3b</th>\n",
       "      <td>3.592</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.547</td>\n",
       "      <td>12.7</td>\n",
       "      <td>45.618</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-textgeneration1-bloomz-7b1-fp16</th>\n",
       "      <td>6.788</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.1</td>\n",
       "      <td>61.771</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-large</th>\n",
       "      <td>2.999</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.457</td>\n",
       "      <td>7.2</td>\n",
       "      <td>21.595</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-qcpg-sentences</th>\n",
       "      <td>10.074</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.240</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.177</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-t5-one-line-summary</th>\n",
       "      <td>13.682</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.248</td>\n",
       "      <td>2.5</td>\n",
       "      <td>34.204</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-fp16</th>\n",
       "      <td>1.141</td>\n",
       "      <td>1.042</td>\n",
       "      <td>1.106</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.662</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-fp16</th>\n",
       "      <td>1.150</td>\n",
       "      <td>1.158</td>\n",
       "      <td>1.221</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.335</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp</th>\n",
       "      <td>0.892</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.285</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.296</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl</th>\n",
       "      <td>1.035</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.299</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.387</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-small</th>\n",
       "      <td>11.801</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.256</td>\n",
       "      <td>6.2</td>\n",
       "      <td>73.165</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bart4csc-base-chinese</th>\n",
       "      <td>25.981</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.981</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-pegasus-paraphrase</th>\n",
       "      <td>27.132</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.132</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-ul2-bf16</th>\n",
       "      <td>1.138</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.298</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.382</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-flan-t5-xxl-bnb-int8</th>\n",
       "      <td>0.472</td>\n",
       "      <td>2.064</td>\n",
       "      <td>2.127</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.673</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huggingface-text2text-bigscience-t0pp-bnb-int8</th>\n",
       "      <td>0.629</td>\n",
       "      <td>2.286</td>\n",
       "      <td>2.349</td>\n",
       "      <td>11.9</td>\n",
       "      <td>7.489</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             Throughput   \n",
       "PayloadName        ModelID                                                                \n",
       "generate_summary   huggingface-textgeneration1-gpt-neo-125m                  1.823       \\\n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             2.062        \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             0.554        \n",
       "                   huggingface-text2text-qcpg-sentences                      0.801        \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             0.459        \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 0.414        \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  0.468        \n",
       "                   huggingface-text2text-flan-t5-small                       5.224        \n",
       "                   huggingface-text2text-bart4csc-base-chinese               0.822        \n",
       "                   huggingface-textgeneration-gpt2                           0.373        \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      0.554        \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 3.047        \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  0.464        \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 0.285        \n",
       "                   huggingface-text2text-pegasus-paraphrase                  0.722        \n",
       "                   huggingface-text2text-flan-t5-base                        2.462        \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 0.539        \n",
       "                   huggingface-textgeneration1-bloom-3b                      0.342        \n",
       "                   huggingface-text2text-t5-one-line-summary                 4.892        \n",
       "                   huggingface-textgeneration-models                         0.204        \n",
       "                   huggingface-textgeneration-bloom-1b7                      0.240        \n",
       "                   huggingface-textgeneration-bloom-560m                     0.450        \n",
       "                   huggingface-textgeneration-bloom-1b1                      0.218        \n",
       "                   huggingface-textgeneration-bloomz-1b7                     3.920        \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  0.176        \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                6.922        \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               3.488        \n",
       "                   huggingface-text2text-flan-t5-large                       1.303        \n",
       "                   huggingface-textgeneration1-bloom-7b1                     6.144        \n",
       "                   huggingface-text2text-flan-t5-xl                          1.782        \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                3.002        \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             0.242        \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      0.343        \n",
       "                   huggingface-textgeneration-distilgpt2                     0.689        \n",
       "                   huggingface-textgeneration-bloomz-1b1                     9.184        \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    0.754        \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                0.397        \n",
       "                   huggingface-text2text-flan-ul2-bf16                       0.359        \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                0.341        \n",
       "                   huggingface-text2text-flan-t5-xxl                         0.345        \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            0.186        \n",
       "                   huggingface-text2text-bigscience-t0pp                     0.171        \n",
       "simple_short_input huggingface-textgeneration1-gpt-neo-125m                  15.013       \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             15.784       \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             2.689        \n",
       "                   huggingface-textgeneration-distilgpt2                     2.421        \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 1.938        \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  1.643        \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             2.106        \n",
       "                   huggingface-textgeneration-gpt2                           1.405        \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  2.215        \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 2.591        \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      2.374        \n",
       "                   huggingface-textgeneration-models                         2.350        \n",
       "                   huggingface-textgeneration-bloom-1b1                      2.171        \n",
       "                   huggingface-textgeneration-bloom-1b7                      2.225        \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 3.882        \n",
       "                   huggingface-textgeneration-bloomz-1b1                     2.468        \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      1.496        \n",
       "                   huggingface-textgeneration-bloom-560m                     2.268        \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                6.162        \n",
       "                   huggingface-text2text-flan-t5-base                        5.893        \n",
       "                   huggingface-textgeneration-bloomz-1b7                     2.667        \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 6.033        \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             2.119        \n",
       "                   huggingface-textgeneration1-bloom-7b1                     3.643        \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  2.117        \n",
       "                   huggingface-text2text-flan-t5-xl                          2.193        \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                4.498        \n",
       "                   huggingface-textgeneration1-bloom-3b                      3.592        \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               6.788        \n",
       "                   huggingface-text2text-flan-t5-large                       2.999        \n",
       "                   huggingface-text2text-qcpg-sentences                      10.074       \n",
       "                   huggingface-text2text-t5-one-line-summary                 13.682       \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    1.141        \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                1.150        \n",
       "                   huggingface-text2text-bigscience-t0pp                     0.892        \n",
       "                   huggingface-text2text-flan-t5-xxl                         1.035        \n",
       "                   huggingface-text2text-flan-t5-small                       11.801       \n",
       "                   huggingface-text2text-bart4csc-base-chinese               25.981       \n",
       "                   huggingface-text2text-pegasus-paraphrase                  27.132       \n",
       "                   huggingface-text2text-flan-ul2-bf16                       1.138        \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                0.472        \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            0.629        \n",
       "\n",
       "                                                                             ModelLatency.Average   \n",
       "PayloadName        ModelID                                                                          \n",
       "generate_summary   huggingface-textgeneration1-gpt-neo-125m                  0.473                 \\\n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             0.416                  \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             1.669                  \n",
       "                   huggingface-text2text-qcpg-sentences                      0.886                  \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             2.667                  \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 1.729                  \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  2.754                  \n",
       "                   huggingface-text2text-flan-t5-small                       0.139                  \n",
       "                   huggingface-text2text-bart4csc-base-chinese               1.324                  \n",
       "                   huggingface-textgeneration-gpt2                           3.488                  \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      3.155                  \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 0.409                  \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  3.322                  \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 3.600                  \n",
       "                   huggingface-text2text-pegasus-paraphrase                  1.366                  \n",
       "                   huggingface-text2text-flan-t5-base                        0.284                  \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 3.607                  \n",
       "                   huggingface-textgeneration1-bloom-3b                      5.235                  \n",
       "                   huggingface-text2text-t5-one-line-summary                 0.183                  \n",
       "                   huggingface-textgeneration-models                         3.211                  \n",
       "                   huggingface-textgeneration-bloom-1b7                      2.787                  \n",
       "                   huggingface-textgeneration-bloom-560m                     3.393                  \n",
       "                   huggingface-textgeneration-bloom-1b1                      4.805                  \n",
       "                   huggingface-textgeneration-bloomz-1b7                     0.356                  \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  5.689                  \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                0.125                  \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               0.199                  \n",
       "                   huggingface-text2text-flan-t5-large                       0.951                  \n",
       "                   huggingface-textgeneration1-bloom-7b1                     0.289                  \n",
       "                   huggingface-text2text-flan-t5-xl                          0.733                  \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                0.250                  \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             4.404                  \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      5.299                  \n",
       "                   huggingface-textgeneration-distilgpt2                     1.282                  \n",
       "                   huggingface-textgeneration-bloomz-1b1                     0.166                  \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    1.404                  \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                2.083                  \n",
       "                   huggingface-text2text-flan-ul2-bf16                       2.428                  \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                2.318                  \n",
       "                   huggingface-text2text-flan-t5-xxl                         3.115                  \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            3.522                  \n",
       "                   huggingface-text2text-bigscience-t0pp                     3.198                  \n",
       "simple_short_input huggingface-textgeneration1-gpt-neo-125m                  0.119                  \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             0.120                  \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             0.422                  \n",
       "                   huggingface-textgeneration-distilgpt2                     0.406                  \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 0.574                  \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  0.659                  \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             0.695                  \n",
       "                   huggingface-textgeneration-gpt2                           0.773                  \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  0.858                  \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 0.912                  \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      1.000                  \n",
       "                   huggingface-textgeneration-models                         0.501                  \n",
       "                   huggingface-textgeneration-bloom-1b1                      0.523                  \n",
       "                   huggingface-textgeneration-bloom-1b7                      0.511                  \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 0.499                  \n",
       "                   huggingface-textgeneration-bloomz-1b1                     0.455                  \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      1.480                  \n",
       "                   huggingface-textgeneration-bloom-560m                     0.465                  \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                0.433                  \n",
       "                   huggingface-text2text-flan-t5-base                        0.259                  \n",
       "                   huggingface-textgeneration-bloomz-1b7                     0.455                  \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 0.216                  \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             0.527                  \n",
       "                   huggingface-textgeneration1-bloom-7b1                     0.301                  \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  0.548                  \n",
       "                   huggingface-text2text-flan-t5-xl                          0.655                  \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                0.444                  \n",
       "                   huggingface-textgeneration1-bloom-3b                      0.484                  \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               0.408                  \n",
       "                   huggingface-text2text-flan-t5-large                       0.372                  \n",
       "                   huggingface-text2text-qcpg-sentences                      0.154                  \n",
       "                   huggingface-text2text-t5-one-line-summary                 0.184                  \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    1.042                  \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                1.158                  \n",
       "                   huggingface-text2text-bigscience-t0pp                     1.221                  \n",
       "                   huggingface-text2text-flan-t5-xxl                         1.234                  \n",
       "                   huggingface-text2text-flan-t5-small                       0.171                  \n",
       "                   huggingface-text2text-bart4csc-base-chinese               0.104                  \n",
       "                   huggingface-text2text-pegasus-paraphrase                  0.110                  \n",
       "                   huggingface-text2text-flan-ul2-bf16                       1.200                  \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                2.064                  \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            2.286                  \n",
       "\n",
       "                                                                             Client.Latency.Average   \n",
       "PayloadName        ModelID                                                                            \n",
       "generate_summary   huggingface-textgeneration1-gpt-neo-125m                  0.535                   \\\n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             0.474                    \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             1.726                    \n",
       "                   huggingface-text2text-qcpg-sentences                      0.948                    \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             2.730                    \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 1.787                    \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  2.811                    \n",
       "                   huggingface-text2text-flan-t5-small                       0.197                    \n",
       "                   huggingface-text2text-bart4csc-base-chinese               1.383                    \n",
       "                   huggingface-textgeneration-gpt2                           3.548                    \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      3.215                    \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 0.469                    \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  3.386                    \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 3.658                    \n",
       "                   huggingface-text2text-pegasus-paraphrase                  1.425                    \n",
       "                   huggingface-text2text-flan-t5-base                        0.342                    \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 3.669                    \n",
       "                   huggingface-textgeneration1-bloom-3b                      5.298                    \n",
       "                   huggingface-text2text-t5-one-line-summary                 0.244                    \n",
       "                   huggingface-textgeneration-models                         3.273                    \n",
       "                   huggingface-textgeneration-bloom-1b7                      2.848                    \n",
       "                   huggingface-textgeneration-bloom-560m                     3.455                    \n",
       "                   huggingface-textgeneration-bloom-1b1                      4.868                    \n",
       "                   huggingface-textgeneration-bloomz-1b7                     0.416                    \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  5.751                    \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                0.183                    \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               0.259                    \n",
       "                   huggingface-text2text-flan-t5-large                       1.010                    \n",
       "                   huggingface-textgeneration1-bloom-7b1                     0.347                    \n",
       "                   huggingface-text2text-flan-t5-xl                          0.798                    \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                0.309                    \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             4.470                    \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      5.362                    \n",
       "                   huggingface-textgeneration-distilgpt2                     1.343                    \n",
       "                   huggingface-textgeneration-bloomz-1b1                     0.244                    \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    1.468                    \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                2.142                    \n",
       "                   huggingface-text2text-flan-ul2-bf16                       2.488                    \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                2.380                    \n",
       "                   huggingface-text2text-flan-t5-xxl                         3.173                    \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            3.582                    \n",
       "                   huggingface-text2text-bigscience-t0pp                     3.261                    \n",
       "simple_short_input huggingface-textgeneration1-gpt-neo-125m                  0.183                    \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             0.181                    \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             0.503                    \n",
       "                   huggingface-textgeneration-distilgpt2                     0.472                    \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 0.658                    \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  0.723                    \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             0.762                    \n",
       "                   huggingface-textgeneration-gpt2                           0.840                    \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  0.922                    \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 0.976                    \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      1.082                    \n",
       "                   huggingface-textgeneration-models                         0.566                    \n",
       "                   huggingface-textgeneration-bloom-1b1                      0.590                    \n",
       "                   huggingface-textgeneration-bloom-1b7                      0.576                    \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 0.566                    \n",
       "                   huggingface-textgeneration-bloomz-1b1                     0.521                    \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      1.544                    \n",
       "                   huggingface-textgeneration-bloom-560m                     0.530                    \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                0.498                    \n",
       "                   huggingface-text2text-flan-t5-base                        0.322                    \n",
       "                   huggingface-textgeneration-bloomz-1b7                     0.520                    \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 0.278                    \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             0.593                    \n",
       "                   huggingface-textgeneration1-bloom-7b1                     0.364                    \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  0.611                    \n",
       "                   huggingface-text2text-flan-t5-xl                          0.729                    \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                0.511                    \n",
       "                   huggingface-textgeneration1-bloom-3b                      0.547                    \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               0.470                    \n",
       "                   huggingface-text2text-flan-t5-large                       0.457                    \n",
       "                   huggingface-text2text-qcpg-sentences                      0.240                    \n",
       "                   huggingface-text2text-t5-one-line-summary                 0.248                    \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    1.106                    \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                1.221                    \n",
       "                   huggingface-text2text-bigscience-t0pp                     1.285                    \n",
       "                   huggingface-text2text-flan-t5-xxl                         1.299                    \n",
       "                   huggingface-text2text-flan-t5-small                       0.256                    \n",
       "                   huggingface-text2text-bart4csc-base-chinese               0.167                    \n",
       "                   huggingface-text2text-pegasus-paraphrase                  0.172                    \n",
       "                   huggingface-text2text-flan-ul2-bf16                       1.298                    \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                2.127                    \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            2.349                    \n",
       "\n",
       "                                                                             Client.OutputSequenceWords.Average   \n",
       "PayloadName        ModelID                                                                                        \n",
       "generate_summary   huggingface-textgeneration1-gpt-neo-125m                  109.7                               \\\n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             102.1                                \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             147.2                                \n",
       "                   huggingface-text2text-qcpg-sentences                      62.2                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             173.2                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 128.8                                \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  155.6                                \n",
       "                   huggingface-text2text-flan-t5-small                       10.1                                 \n",
       "                   huggingface-text2text-bart4csc-base-chinese               74.7                                 \n",
       "                   huggingface-textgeneration-gpt2                           174.2                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      152.1                                \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 21.7                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  149.3                                \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 150.4                                \n",
       "                   huggingface-text2text-pegasus-paraphrase                  67.5                                 \n",
       "                   huggingface-text2text-flan-t5-base                        14.1                                 \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 152.0                                \n",
       "                   huggingface-textgeneration1-bloom-3b                      194.1                                \n",
       "                   huggingface-text2text-t5-one-line-summary                 8.8                                  \n",
       "                   huggingface-textgeneration-models                         110.4                                \n",
       "                   huggingface-textgeneration-bloom-1b7                      94.5                                 \n",
       "                   huggingface-textgeneration-bloom-560m                     119.0                                \n",
       "                   huggingface-textgeneration-bloom-1b1                      155.6                                \n",
       "                   huggingface-textgeneration-bloomz-1b7                     9.5                                  \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  165.4                                \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                2.4                                  \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               3.7                                  \n",
       "                   huggingface-text2text-flan-t5-large                       25.6                                 \n",
       "                   huggingface-textgeneration1-bloom-7b1                     3.9                                  \n",
       "                   huggingface-text2text-flan-t5-xl                          18.3                                 \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                4.2                                  \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             108.0                                \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      123.8                                \n",
       "                   huggingface-textgeneration-distilgpt2                     100.6                                \n",
       "                   huggingface-textgeneration-bloomz-1b1                     3.7                                  \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    10.9                                 \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                19.2                                 \n",
       "                   huggingface-text2text-flan-ul2-bf16                       13.7                                 \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                12.5                                 \n",
       "                   huggingface-text2text-flan-t5-xxl                         17.6                                 \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            20.1                                 \n",
       "                   huggingface-text2text-bigscience-t0pp                     17.0                                 \n",
       "simple_short_input huggingface-textgeneration1-gpt-neo-125m                  13.3                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             14.8                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             34.9                                 \n",
       "                   huggingface-textgeneration-distilgpt2                     30.7                                 \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 36.1                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  37.2                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             38.3                                 \n",
       "                   huggingface-textgeneration-gpt2                           39.2                                 \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  36.6                                 \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 37.3                                 \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      35.1                                 \n",
       "                   huggingface-textgeneration-models                         15.9                                 \n",
       "                   huggingface-textgeneration-bloom-1b1                      16.6                                 \n",
       "                   huggingface-textgeneration-bloom-1b7                      16.2                                 \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 15.6                                 \n",
       "                   huggingface-textgeneration-bloomz-1b1                     14.1                                 \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      37.0                                 \n",
       "                   huggingface-textgeneration-bloom-560m                     14.2                                 \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                11.7                                 \n",
       "                   huggingface-text2text-flan-t5-base                        8.7                                  \n",
       "                   huggingface-textgeneration-bloomz-1b7                     12.6                                 \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 7.2                                  \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             13.8                                 \n",
       "                   huggingface-textgeneration1-bloom-7b1                     5.5                                  \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  12.6                                 \n",
       "                   huggingface-text2text-flan-t5-xl                          14.0                                 \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                10.5                                 \n",
       "                   huggingface-textgeneration1-bloom-3b                      12.7                                 \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               9.1                                  \n",
       "                   huggingface-text2text-flan-t5-large                       7.2                                  \n",
       "                   huggingface-text2text-qcpg-sentences                      2.4                                  \n",
       "                   huggingface-text2text-t5-one-line-summary                 2.5                                  \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    11.1                                 \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                11.6                                 \n",
       "                   huggingface-text2text-bigscience-t0pp                     9.3                                  \n",
       "                   huggingface-text2text-flan-t5-xxl                         11.0                                 \n",
       "                   huggingface-text2text-flan-t5-small                       6.2                                  \n",
       "                   huggingface-text2text-bart4csc-base-chinese               1.0                                  \n",
       "                   huggingface-text2text-pegasus-paraphrase                  1.0                                  \n",
       "                   huggingface-text2text-flan-ul2-bf16                       10.0                                 \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                9.9                                  \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            11.9                                 \n",
       "\n",
       "                                                                             WordThroughput   \n",
       "PayloadName        ModelID                                                                    \n",
       "generate_summary   huggingface-textgeneration1-gpt-neo-125m                  199.965         \\\n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             210.496          \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             81.576           \n",
       "                   huggingface-text2text-qcpg-sentences                      49.813           \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             79.540           \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 53.285           \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  72.866           \n",
       "                   huggingface-text2text-flan-t5-small                       52.759           \n",
       "                   huggingface-text2text-bart4csc-base-chinese               61.433           \n",
       "                   huggingface-textgeneration-gpt2                           64.945           \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      84.323           \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 66.124           \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  69.273           \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 42.919           \n",
       "                   huggingface-text2text-pegasus-paraphrase                  48.766           \n",
       "                   huggingface-text2text-flan-t5-base                        34.713           \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 81.951           \n",
       "                   huggingface-textgeneration1-bloom-3b                      66.456           \n",
       "                   huggingface-text2text-t5-one-line-summary                 43.051           \n",
       "                   huggingface-textgeneration-models                         22.570           \n",
       "                   huggingface-textgeneration-bloom-1b7                      22.683           \n",
       "                   huggingface-textgeneration-bloom-560m                     53.555           \n",
       "                   huggingface-textgeneration-bloom-1b1                      33.881           \n",
       "                   huggingface-textgeneration-bloomz-1b7                     37.237           \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  29.034           \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                16.613           \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               12.907           \n",
       "                   huggingface-text2text-flan-t5-large                       33.356           \n",
       "                   huggingface-textgeneration1-bloom-7b1                     23.960           \n",
       "                   huggingface-text2text-flan-t5-xl                          32.611           \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                12.606           \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             26.172           \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      42.516           \n",
       "                   huggingface-textgeneration-distilgpt2                     69.315           \n",
       "                   huggingface-textgeneration-bloomz-1b1                     33.983           \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    8.214            \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                7.619            \n",
       "                   huggingface-text2text-flan-ul2-bf16                       4.919            \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                4.263            \n",
       "                   huggingface-text2text-flan-t5-xxl                         6.072            \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            3.747            \n",
       "                   huggingface-text2text-bigscience-t0pp                     2.913            \n",
       "simple_short_input huggingface-textgeneration1-gpt-neo-125m                  199.678          \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             233.604          \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             93.851           \n",
       "                   huggingface-textgeneration-distilgpt2                     74.331           \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 69.967           \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  61.108           \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             80.667           \n",
       "                   huggingface-textgeneration-gpt2                           55.072           \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  81.064           \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 96.640           \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      83.326           \n",
       "                   huggingface-textgeneration-models                         37.361           \n",
       "                   huggingface-textgeneration-bloom-1b1                      36.045           \n",
       "                   huggingface-textgeneration-bloom-1b7                      36.041           \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 60.558           \n",
       "                   huggingface-textgeneration-bloomz-1b1                     34.799           \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      55.358           \n",
       "                   huggingface-textgeneration-bloom-560m                     32.208           \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                72.095           \n",
       "                   huggingface-text2text-flan-t5-base                        51.266           \n",
       "                   huggingface-textgeneration-bloomz-1b7                     33.601           \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 43.439           \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             29.238           \n",
       "                   huggingface-textgeneration1-bloom-7b1                     20.037           \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  26.673           \n",
       "                   huggingface-text2text-flan-t5-xl                          30.701           \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                47.225           \n",
       "                   huggingface-textgeneration1-bloom-3b                      45.618           \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               61.771           \n",
       "                   huggingface-text2text-flan-t5-large                       21.595           \n",
       "                   huggingface-text2text-qcpg-sentences                      24.177           \n",
       "                   huggingface-text2text-t5-one-line-summary                 34.204           \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    12.662           \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                13.335           \n",
       "                   huggingface-text2text-bigscience-t0pp                     8.296            \n",
       "                   huggingface-text2text-flan-t5-xxl                         11.387           \n",
       "                   huggingface-text2text-flan-t5-small                       73.165           \n",
       "                   huggingface-text2text-bart4csc-base-chinese               25.981           \n",
       "                   huggingface-text2text-pegasus-paraphrase                  27.132           \n",
       "                   huggingface-text2text-flan-ul2-bf16                       11.382           \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                4.673            \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            7.489            \n",
       "\n",
       "                                                                             Client.LatencyPerOutputWord.Average  \n",
       "PayloadName        ModelID                                                                                        \n",
       "generate_summary   huggingface-textgeneration1-gpt-neo-125m                  0.006                                \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             0.006                                \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             0.012                                \n",
       "                   huggingface-text2text-qcpg-sentences                      0.015                                \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             0.016                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 0.018                                \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  0.018                                \n",
       "                   huggingface-text2text-flan-t5-small                       0.020                                \n",
       "                   huggingface-text2text-bart4csc-base-chinese               0.021                                \n",
       "                   huggingface-textgeneration-gpt2                           0.021                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      0.022                                \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 0.023                                \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  0.023                                \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 0.025                                \n",
       "                   huggingface-text2text-pegasus-paraphrase                  0.025                                \n",
       "                   huggingface-text2text-flan-t5-base                        0.026                                \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 0.027                                \n",
       "                   huggingface-textgeneration1-bloom-3b                      0.027                                \n",
       "                   huggingface-text2text-t5-one-line-summary                 0.030                                \n",
       "                   huggingface-textgeneration-models                         0.031                                \n",
       "                   huggingface-textgeneration-bloom-1b7                      0.031                                \n",
       "                   huggingface-textgeneration-bloom-560m                     0.032                                \n",
       "                   huggingface-textgeneration-bloom-1b1                      0.032                                \n",
       "                   huggingface-textgeneration-bloomz-1b7                     0.033                                \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  0.036                                \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                0.037                                \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               0.039                                \n",
       "                   huggingface-text2text-flan-t5-large                       0.040                                \n",
       "                   huggingface-textgeneration1-bloom-7b1                     0.045                                \n",
       "                   huggingface-text2text-flan-t5-xl                          0.046                                \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                0.046                                \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             0.046                                \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      0.047                                \n",
       "                   huggingface-textgeneration-distilgpt2                     0.057                                \n",
       "                   huggingface-textgeneration-bloomz-1b1                     0.061                                \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    0.146                                \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                0.176                                \n",
       "                   huggingface-text2text-flan-ul2-bf16                       0.189                                \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                0.196                                \n",
       "                   huggingface-text2text-flan-t5-xxl                         0.219                                \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            0.256                                \n",
       "                   huggingface-text2text-bigscience-t0pp                     0.272                                \n",
       "simple_short_input huggingface-textgeneration1-gpt-neo-125m                  0.014                                \n",
       "                   huggingface-textgeneration1-gpt-neo-125m-fp16             0.015                                \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b-fp16             0.015                                \n",
       "                   huggingface-textgeneration-distilgpt2                     0.015                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl-fp16                 0.019                                \n",
       "                   huggingface-textgeneration1-gpt-neo-1-3b                  0.019                                \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b-fp16             0.020                                \n",
       "                   huggingface-textgeneration-gpt2                           0.022                                \n",
       "                   huggingface-textgeneration1-gpt-neo-2-7b                  0.026                                \n",
       "                   huggingface-textgeneration1-gpt-j-6b-fp16                 0.027                                \n",
       "                   huggingface-textgeneration1-gpt-2-xl                      0.033                                \n",
       "                   huggingface-textgeneration-models                         0.036                                \n",
       "                   huggingface-textgeneration-bloom-1b1                      0.036                                \n",
       "                   huggingface-textgeneration-bloom-1b7                      0.036                                \n",
       "                   huggingface-textgeneration1-bloom-3b-fp16                 0.037                                \n",
       "                   huggingface-textgeneration-bloomz-1b1                     0.037                                \n",
       "                   huggingface-textgeneration1-gpt-j-6b                      0.042                                \n",
       "                   huggingface-textgeneration-bloom-560m                     0.043                                \n",
       "                   huggingface-textgeneration1-bloomz-3b-fp16                0.043                                \n",
       "                   huggingface-text2text-flan-t5-base                        0.044                                \n",
       "                   huggingface-textgeneration-bloomz-1b7                     0.044                                \n",
       "                   huggingface-text2text-flan-t5-base-samsum                 0.045                                \n",
       "                   huggingface-textgeneration2-gpt-neox-20b-fp16             0.045                                \n",
       "                   huggingface-textgeneration1-bloom-7b1                     0.046                                \n",
       "                   huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16  0.049                                \n",
       "                   huggingface-text2text-flan-t5-xl                          0.054                                \n",
       "                   huggingface-textgeneration1-bloom-7b1-fp16                0.055                                \n",
       "                   huggingface-textgeneration1-bloom-3b                      0.060                                \n",
       "                   huggingface-textgeneration1-bloomz-7b1-fp16               0.070                                \n",
       "                   huggingface-text2text-flan-t5-large                       0.074                                \n",
       "                   huggingface-text2text-qcpg-sentences                      0.086                                \n",
       "                   huggingface-text2text-t5-one-line-summary                 0.097                                \n",
       "                   huggingface-text2text-flan-t5-xxl-fp16                    0.106                                \n",
       "                   huggingface-text2text-bigscience-t0pp-fp16                0.111                                \n",
       "                   huggingface-text2text-bigscience-t0pp                     0.119                                \n",
       "                   huggingface-text2text-flan-t5-xxl                         0.121                                \n",
       "                   huggingface-text2text-flan-t5-small                       0.146                                \n",
       "                   huggingface-text2text-bart4csc-base-chinese               0.167                                \n",
       "                   huggingface-text2text-pegasus-paraphrase                  0.172                                \n",
       "                   huggingface-text2text-flan-ul2-bf16                       0.179                                \n",
       "                   huggingface-text2text-flan-t5-xxl-bnb-int8                0.200                                \n",
       "                   huggingface-text2text-bigscience-t0pp-bnb-int8            0.290                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "\n",
    "df = pd.json_normalize(metrics)\n",
    "print(\"Here are the available statistics: \", list(df.columns))\n",
    "\n",
    "index_cols = [\"PayloadName\", \"ModelID\"]\n",
    "display_cols = [\"PayloadName\", \"ModelID\", \"SampleOutput\"]\n",
    "sort_cols = [\"PayloadName\"]\n",
    "display(df[display_cols].sort_values(by=sort_cols).set_index(index_cols))\n",
    "\n",
    "display_cols = [\n",
    "    \"PayloadName\",\n",
    "    \"ModelID\",\n",
    "    \"Throughput\",\n",
    "    \"ModelLatency.Average\",\n",
    "    \"Client.Latency.Average\",\n",
    "    \"Client.OutputSequenceWords.Average\",\n",
    "    \"WordThroughput\",\n",
    "    \"Client.LatencyPerOutputWord.Average\",\n",
    "]\n",
    "sort_cols = [\"PayloadName\", \"Client.LatencyPerOutputWord.Average\"]\n",
    "display(df[display_cols].sort_values(by=sort_cols).set_index(index_cols).round(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d6caad2",
   "metadata": {},
   "source": [
    "***\n",
    "Finally, we show some plots based on this latency analysis. For each payload, this cell creates a plotly figure that plots the average latency per output word versus word throughput, or the number of words in output sequences returned per second by the model. In general, throughput = 1 / latency. However, multi-model endpoints and load-balanced endpoints can improve throughput for a fixed latency. Both of these are important metrics to consider when designing requirements for model selection.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0cd06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for payload_name in PAYLOADS:\n",
    "    col_x, col_y = \"WordThroughput\", \"Client.LatencyPerOutputWord.Average\"\n",
    "    df_plot = df[df[\"PayloadName\"] == payload_name]\n",
    "    fig = px.scatter(df_plot, x=col_x, y=col_y, hover_data=[\"ModelID\"])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.linspace(1, 300, 300), y=1 / np.linspace(1, 300, 300), name=\"y=1/x\")\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_range=[0.0, df_plot[col_x].max() * 1.1],\n",
    "        yaxis_range=[0.0, df_plot[col_y].max() * 1.1],\n",
    "        title=f\"Latency per word vs. word throughput for payload {payload_name}\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50f34b58",
   "metadata": {},
   "source": [
    "### 4. Clean up\n",
    "\n",
    "***\n",
    "When you are done with the endpoints, you should delete them to avoid additional costs. In this demonstration, clean up occurs at the end of each individual benchmarking job.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
