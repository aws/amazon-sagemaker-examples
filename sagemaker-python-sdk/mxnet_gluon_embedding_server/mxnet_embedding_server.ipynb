{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building an image embedding server with Gluon\n",
    "In this notebook, we use a pre-trained model to extract image embeddings.\n",
    "* **Image embeddings** are dense, high-semantic, low-dimension vector representation of images learnt by neural networks. They can directly by learnt by a model, or obtained as a byproduct of a downstream task. In this demo, we use a pre-trained classifier from the gluon model zoo to obtain those embeddings:\n",
    " 1. We first import a model from the gluon model zoo locally on the notebook, that we then compress and send to S3\n",
    " 1. We then use the SageMaker MXNet Serving feature to deploy the embedding model to a real-time managed endpoint. It uses the model artifact that we previously loaded to S3.\n",
    " 1. We query the endpoint and visualize embeddings in a 2D scatter plot using PCA\n",
    "\n",
    "\n",
    "* **More on gluon:** [gluon](https://mxnet.incubator.apache.org/api/python/docs/api/gluon/index.html) is the imperative python front-end of the Apache MXNet deep learning framework. Gluon notably features specialized toolkits helping reproducing state-of-the-art architectures: [gluon-cv](https://gluon-cv.mxnet.io/), [gluon-nlp](https://gluon-nlp.mxnet.io/), [gluon-ts](https://gluon-ts.mxnet.io/). Gluon also features a number of excellent end-to-end tutorial mixing science with code such as [D2L.ai](https://classic.d2l.ai/) and [The Straight Dope](https://gluon.mxnet.io/)\n",
    "* This specific demo has been developed on the `conda_mxnet_p36` kernel of a SageMaker `ml.t2.medium` Notebook instance\n",
    "* For a more advanced, fully-deployed demo and an embedding server + approximate kNN pipeline see the excellent https://thomasdelteil.github.io/VisualSearch_MXNet/ from Thomas Delteil.\n",
    "\n",
    "**This sample is provided for demonstration purposes, make sure to conduct appropriate testing if derivating this code for your own use-cases!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import subprocess as sb\n",
    "import tarfile\n",
    "\n",
    "import boto3\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "import mxnet as mx\n",
    "from mxnet import image, nd\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import SageMaker tools\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.mxnet.model import MXNetModel\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = (\n",
    "    sess.default_bucket()\n",
    ")  # We use this bucket to store model weights - don't hesitate to change.\n",
    "print(\"using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "//disable autoscroll\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find couple open pics\n",
    "pics = [\n",
    "    \"https://cdn.pixabay.com/photo/2016/02/16/03/42/lasso-1202578_960_720.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2015/09/14/20/52/cowboy-940083_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2015/05/08/05/33/cowboy-757575_960_720.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/12/03/19/08/wedding-2995641_1280.jpg\",\n",
    "    \"https://www.maxpixel.net/static/photo/2x/Bride-And-Groom-Wedding-Ceremony-2729673.jpg\",\n",
    "    \"https://cdn12.picryl.com/photo/2016/12/31/wedding-the-groom-bride-nature-landscapes-2c6338-1024.jpg\",\n",
    "    \"https://www.maxpixel.net/static/photo/2x/Animal-Portrait-Fuchs-Animal-World-Wild-Animal-3532084.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2018/07/10/22/09/raccoon-3529806_1280.jpg\",\n",
    "    \"https://www.nps.gov/katm/learn/nature/images/bear-cubs-intro-pic.jpg?maxwidth=1200&maxheight=1200&autorotate=false\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/11/09/01/49/ferrari-458-spider-2932191_1280.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download pics\n",
    "sb.call([\"mkdir\", \"pics\"])\n",
    "\n",
    "path = \"/tmp/pics/\"\n",
    "\n",
    "for p in pics:\n",
    "    sb.call([\"wget\", p, \"-P\", path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading couple images with mxnet\n",
    "for p in os.listdir(path)[:3]:\n",
    "\n",
    "    picture = mx.image.imread(os.path.join(path, p))\n",
    "    plt.imshow(picture.asnumpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting embeddings from a pre-trained classifier, locally\n",
    "We take models from the gluon model zoo https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelname = \"resnet152_v2\"  # Other interesting options: resnet34_v2, mobilenetv2_0.5\n",
    "\n",
    "net = models.get_model(name=modelname, pretrained=True)\n",
    "emb = net.features  # get embeddings, not final probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    \"\"\"resize, crop, normalize\"\"\"\n",
    "    data = mx.image.resize_short(data, 256)  # resize\n",
    "    data, _ = mx.image.center_crop(data, (224, 224))  # crop\n",
    "    data = data.transpose((2, 0, 1)).expand_dims(axis=0)  # channels-first and batch size 1\n",
    "    rgb_mean = nd.array([0.485, 0.456, 0.406]).reshape((1, 3, 1, 1))\n",
    "    rgb_std = nd.array([0.229, 0.224, 0.225]).reshape((1, 3, 1, 1))\n",
    "    return (data.astype(\"float32\") / 255 - rgb_mean) / rgb_std  # ImageNet-normalize\n",
    "\n",
    "\n",
    "def embeddings(embmodel, pic):\n",
    "    \"\"\"get the image embeddings, returns an NDArray\"\"\"\n",
    "    return embmodel(transform(pic)).squeeze()  # flatten if nested dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test locally\n",
    "embeddings(emb, mx.image.imread(path + \"cowboy-940083_1280.jpg\"))[:10]  # 10 first coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write the embedding model in the SageMaker MXNet specification\n",
    "https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/mxnet/README.rst#deploying-mxnet-models\n",
    "\n",
    "Amazon SageMaker provides serving container for Sklearn, TensorFlow, PyTorch, Apache MXNet and Chainer. This is convenient, because we don't have to write web server code: the server is already written, in the case of MXNet it is Multi Model Server ([MMS](https://github.com/awslabs/multi-model-server), also used to server PyTorch in SageMaker) . We just have to provide model deserialization code and serving logic.\n",
    "\n",
    "The SageMaker MXNet model server breaks request handling into three steps. Each step involves invoking a python function, with information about the request and the return-value from the previous function in the chain:\n",
    "\n",
    "* input processing, with `input_fn(request_body, request_content_type, model)`\n",
    "* prediction, with `predict_fn(input_object, model)`\n",
    "* output processing, with `output_fn(prediction, content_type)`\n",
    "\n",
    "The full serving specification is documented here https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#deploy-mxnet-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In our specific example we don't write an `output_fn`, because `predict_fn` outputs an NDArray that can be handled to CSV or JSON by the default `output_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a serving script containing model deserialization and serving logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile embedding_server.py\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, gluon\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "\n",
    "\n",
    "# couple utilities * * * * * * * * * * * * * * * * * * * *\n",
    "\n",
    "\n",
    "def transform(data):\n",
    "    \"\"\"resize, crop, normalize\"\"\"\n",
    "    data = mx.image.resize_short(data, 256)\n",
    "    data, _ = mx.image.center_crop(data, (224, 224))\n",
    "    data = data.transpose((2, 0, 1)).expand_dims(axis=0)\n",
    "    rgb_mean = nd.array([0.485, 0.456, 0.406]).reshape((1, 3, 1, 1))\n",
    "    rgb_std = nd.array([0.229, 0.224, 0.225]).reshape((1, 3, 1, 1))\n",
    "    return (data.astype(\"float32\") / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "\n",
    "def embeddings(embmodel, pic):\n",
    "    \"\"\"get the image embeddings, returns an NDArray\"\"\"\n",
    "    return embmodel(transform(pic)).squeeze()  # flatten if nested dimensions\n",
    "\n",
    "\n",
    "# SageMaker serving functions* * * * * * * * * * * * * * *\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the gluon model. Called once when hosting service starts.\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a model (in this case a Gluon network)\n",
    "\n",
    "    assumes that the parameters artifact is {model_name}.params\n",
    "    \"\"\"\n",
    "    modelname = os.environ[\"modelname\"]\n",
    "    net = models.get_model(name=modelname, pretrained=False, ctx=mx.cpu())\n",
    "    net.load_parameters(os.path.join(model_dir, modelname + \".params\"))\n",
    "    logging.info(\"loaded parameters into model \" + modelname)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"prepares the input\"\"\"\n",
    "    output = mx.image.imdecode(request_body)\n",
    "    logging.info(\"input_fn returns NDArray of shape \" + str(output.shape))\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict_fn(input_object, model):\n",
    "    \"\"\"function used for prediction\"\"\"\n",
    "    emb = model.features\n",
    "    return embeddings(emb, input_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy the embedding server\n",
    "We first need to send model weights to S3, as we will provide the S3 model path to Amazon SageMaker endpoint creation API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### save local model, compress and send to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "weights = modelname + \".params\"\n",
    "net.save_parameters(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compress (takes couple minutes with the resnet152)\n",
    "packname = \"model.tar.gz\"\n",
    "tar = tarfile.open(packname, \"w:gz\")\n",
    "tar.add(weights)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send to s3\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3key = \"embedding-artifact\"\n",
    "s3.upload_file(packname, bucket, s3key + \"/\" + packname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instantiate model and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = MXNetModel(\n",
    "    model_data=\"s3://{}/{}/{}\".format(bucket, s3key, packname),\n",
    "    role=get_execution_role(),\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"embedding_server.py\",\n",
    "    framework_version=\"1.6.0\",\n",
    "    env={\"modelname\": modelname},\n",
    ")  # we pass model name via an environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "endpoint_key = (\n",
    "    (modelname + \"-embedding\").replace(\"_\", \"-\").replace(\".\", \"\")\n",
    "    + \"-\"\n",
    "    + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    ")\n",
    "\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=IdentitySerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submit requests to the embedding server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_emb(pic, predictor):\n",
    "    \"\"\"elementary function to send a picture to a predictor\"\"\"\n",
    "\n",
    "    with open(pic, \"rb\") as image:\n",
    "        f = image.read()\n",
    "    return predictor.predict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test with the same image as the local inference on top of notebook\n",
    "get_emb(path + \"cowboy-940083_1280.jpg\", predictor)[:10]  # first 10 coefficents of the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through images to create embeddings of all images\n",
    "\n",
    "picnames = os.listdir(path)\n",
    "\n",
    "image_embs = np.expand_dims(get_emb(os.path.join(path, picnames[0]), predictor), axis=0)\n",
    "\n",
    "for p in picnames[1:]:\n",
    "    print(\"getting embedding for \" + p)\n",
    "    image_embs = np.concatenate(\n",
    "        (image_embs, np.expand_dims(get_emb(os.path.join(path, p), predictor), axis=0))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize the semantic similarity in the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA of embedding matrix\n",
    "X_pca = PCA(2).fit_transform(image_embs)\n",
    "emb = pd.DataFrame(X_pca, columns=[\"pca1\", \"pca2\"])\n",
    "emb[\"pic\"] = picnames\n",
    "emb[\"url\"] = [os.path.join(path, p) for p in picnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scatter(data, x, y, pic_url, pic_zoom):\n",
    "    \"\"\"plots a scatter plot with image thumbnails\"\"\"\n",
    "\n",
    "    temp = data[[x, y, pic_url]].dropna().reset_index()\n",
    "\n",
    "    ax = temp.plot(kind=\"scatter\", x=x, y=y)\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        imagebox = OffsetImage(plt.imread(temp[pic_url][i]), zoom=pic_zoom)\n",
    "        ab = AnnotationBbox(\n",
    "            imagebox,\n",
    "            [temp[x][i], temp[y][i]],\n",
    "            xybox=(30.0, -30.0),\n",
    "            xycoords=\"data\",\n",
    "            boxcoords=\"offset points\",\n",
    "            bboxprops=dict(edgecolor=\"r\"),\n",
    "        )\n",
    "        ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some settings for visualisations\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-pastel\")  # set style\n",
    "plt.rcParams[\"figure.figsize\"] = [22, 20]\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "\n",
    "scatter(data=emb, x=\"pca1\", y=\"pca2\", pic_url=\"url\", pic_zoom=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Don't forget to delete the endpoint after the demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
