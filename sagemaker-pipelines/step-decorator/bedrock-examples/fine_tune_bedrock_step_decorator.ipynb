{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Automate LLM fine-tuning workflows in Amazon Bedrock and Amazon SageMaker using Python decorators.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> *This notebook has been tested with the **`Python 3`** kernel in SageMaker Studio (JupyterLab version).*\n",
    "\n",
    "This notebook addresses the scenario where a developer may have written code using Python functions for creating a custom Bedrock model and the code was tested locally. But before it can deployed, we need to convert the Python program into a SageMaker Pipeline. The @step decorator is a feature of Amamzon SageMaker pipelines that converts your local machine learning (ML) code into one or more pipeline steps. \n",
    "\n",
    "The @step decorator feature uses a yaml configuration file that includes properties that are passed to the decorator function. This file includes properties that are passed to the @step decorator. This keeps default settings seprate from the code. You will find a *config.yaml* file in the same folder as this notebook. \n",
    "\n",
    "A *config.yaml* file can be found in the same folder as this notebook. This file includes properties that are passed to the @step decorator.\n",
    "\n",
    "We will fine tune the [Amazon Titan Text Lite](#https://docs.aws.amazon.com/bedrock/latest/userguide/titan-text-models.html) model provided by Amazon Bedrock for a summarization use case. It uses a dataset from CNN that includes news articles and their summaries. The dataset called [cnn_dailymail v3.0](https://huggingface.co/datasets/cnn_dailymail) is available from Hugging Face. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> The last section in this notebook does the clean up by removing the resources created during fine tuning and testing. That includes the Bedrock provisioned throughput which is needed to access the fine tuned custom model. Note that you will continue to incur AWS charges, unless you run the cleanup step.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 1\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 2\n",
    "\n",
    "# restart kernel for the packages installed above to take effect\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "\n",
    "from datasets import load_dataset\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import jsonlines\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import time\n",
    "import pprint\n",
    "import random\n",
    "import yaml\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4\n",
    "\n",
    "# Set path to config file \"config.yaml\"\n",
    "# The config.yaml file contains the arguments that are passed to the step decorator functions.\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. This notebook uses the default S3 bucket for the user. The default Amazon S3 bucket follows the naming pattern s3://sagemaker-{Region}-{your-account-id}. It is automatically created if it does not exist.\n",
    "\n",
    "2. This notebook uses the default IAM role for the user. If your studio user role does not have AWS admininstrator access, you will need to add the necessary permissions to the role. These include:\n",
    "    - [create a training job](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html#sagemaker-roles-createtrainingjob-perms)\n",
    "    - [Access to Bedrock models](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html)\n",
    "    - [Customize Amazon Bedrock model](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-iam-role.html)\n",
    "    - [Access to SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-access.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# get the default bucket and IAM role for the user\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"IAM role: {role_arn}\")\n",
    "print(f\"S3 bucket: {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "\n",
    "# let's look at the contents of config.yaml\n",
    "# The properties in congig.yml are passed into the @step function.\n",
    "# Notice that pipeline step runs on ml.c5.2xlarge as specified in the InstanceType property\n",
    "with open(\"./config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset\n",
    "In the next cell we define the functions to load the CNN/DailyMail dataset. The CNN/DailyMail dataset is an English-language dataset containing just over 300 thousand unique news articles as written by journalists at CNN and the Daily Mail. The raw dataset includes the articles and their summaries for training, validation, and test. Before we can use the dataset, it must be formatted to include the prompt.\n",
    "\n",
    "Each entry from the dataset is included in a prompt which will be the instruction to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 7\n",
    "\n",
    "instruction = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "instruction:\n",
    "\n",
    "Summarize the news article provided below.\n",
    "\n",
    "input:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def add_prompt_to_data(dataset):\n",
    "    # Need to add prompt to the dataset in the format that is\n",
    "    # required for fine tuning by the Titan test Lite model.\n",
    "    datapoints = []\n",
    "\n",
    "    for datapoint in dataset:\n",
    "        # Add insruction prompt to each CNN article\n",
    "        # and add prefix 'response:' to the article summary.\n",
    "        temp_dict = {}\n",
    "        temp_dict[\"prompt\"] = instruction + datapoint[\"article\"]\n",
    "        temp_dict[\"completion\"] = \"response:\\n\\n\" + datapoint[\"highlights\"]\n",
    "        datapoints.append(temp_dict)\n",
    "    return datapoints\n",
    "\n",
    "\n",
    "# Define step for downloading the dataset\n",
    "@step(\n",
    "    name=\"data-load-step\",\n",
    "    keep_alive_period_in_seconds=300,\n",
    ")\n",
    "def data_load(ds_name: str, ds_version: str) -> tuple:\n",
    "    dataset = load_dataset(ds_name, ds_version)\n",
    "\n",
    "    # the dataset includes data for training, validation, and test.\n",
    "    # The raw dataset includes the article and its summary.\n",
    "    # We need to format each row with the LLM prompt.\n",
    "    datapoints_train = add_prompt_to_data(dataset[\"train\"])\n",
    "    datapoints_valid = add_prompt_to_data(dataset[\"validation\"])\n",
    "    datapoints_test = add_prompt_to_data(dataset[\"test\"])\n",
    "\n",
    "    print(f\"Number of training rows: {len(datapoints_train)}\")\n",
    "    print(f'\\nTraining prompt: {datapoints_train[0][\"prompt\"]}')\n",
    "    print(f'\\nTraining Completion: {datapoints_train[0][\"completion\"]}')\n",
    "\n",
    "    print(f\"\\nNumber of validation rows: {len(datapoints_valid)}\")\n",
    "    print(f'\\nValidation prompt: {datapoints_valid[0][\"prompt\"]}')\n",
    "    print(f'\\nValidation Completion: {datapoints_valid[0][\"completion\"]}')\n",
    "\n",
    "    print(f\"\\nNumber of test rows: {len(datapoints_test)}\")\n",
    "    print(f'\\nTest prompt: {datapoints_test[0][\"prompt\"]}')\n",
    "    print(f'\\nTest Completion: {datapoints_test[0][\"completion\"]}')\n",
    "\n",
    "    return datapoints_train, datapoints_valid, datapoints_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Split the CNN dataset into training, validation, and testing. Since this example is focused on SageMaker pipeline step decorators, we will using a very small number of rows for training and validation to reduce the training time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8\n",
    "\n",
    "\n",
    "# Restrict the number of rows and row length\n",
    "def reduce_dataset_size(data, max_row_length, max_rows):\n",
    "    datapoints = []\n",
    "    for datapoint in data:\n",
    "        if len(datapoint[\"prompt\"] + datapoint[\"completion\"]) <= max_row_length:\n",
    "            datapoints.append(datapoint)\n",
    "    random.shuffle(datapoints)\n",
    "    datapoints = datapoints[:max_rows]\n",
    "    print(f\"\\nData set size: {len(datapoints)}\")\n",
    "\n",
    "    return datapoints\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Define step for splitting the dataset into training, validation, and testing.\n",
    "We will restrict the size of each row to 3000 letters.\n",
    "We will select 100 rows for training, 10 for validation, and 5 for testing to \n",
    "keep computation costs low for this example\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@step(\n",
    "    name=\"data-split-step\",\n",
    "    keep_alive_period_in_seconds=300,\n",
    ")\n",
    "def data_split(step_load_result: tuple) -> tuple:\n",
    "    train_lines = reduce_dataset_size(step_load_result[0], 3000, 100)\n",
    "    validation_lines = reduce_dataset_size(step_load_result[1], 3000, 10)\n",
    "    test_lines = reduce_dataset_size(step_load_result[2], 3000, 5)\n",
    "\n",
    "    print(f\"\\nNumber of training rows: {len(train_lines)}\")\n",
    "    print(f\"\\nNumber of training rows: {len(validation_lines)}\")\n",
    "    print(f\"\\nNumber of training rows: {len(test_lines)}\")\n",
    "\n",
    "    return train_lines, validation_lines, test_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Upload the data to S3. We will need the S3 URI of the test data in the testing step later. To do that we save the string value of the S3 URI as a parameter in the [Amazon Simple Systems Manager (SSM)](https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "\n",
    "\n",
    "# Upload the training, validation, and test files to S3.\n",
    "def upload_file_to_s3(bucket_name: str, file_names: tuple, s3_key_names: tuple):\n",
    "    import boto3\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    for i in range(len(file_names)):\n",
    "        s3_client.upload_file(file_names[i], bucket_name, s3_key_names[i])\n",
    "\n",
    "\n",
    "# Save the training, validation, and test files in jsonl format\n",
    "# to the local file system.\n",
    "def write_jsonl_file(abs_path: str, file_name: str, data) -> str:\n",
    "    saved_file_path = f\"{abs_path}/{file_name}\"\n",
    "\n",
    "    with jsonlines.open(saved_file_path, \"w\") as writer:\n",
    "        for line in data:\n",
    "            writer.write(line)\n",
    "\n",
    "    return saved_file_path\n",
    "\n",
    "\n",
    "# Save the s3 uri for test data in SSM.\n",
    "def save_s3_uri_in_SSM(parameter_name, parameter_value):\n",
    "    ssm_client = boto3.client(\"ssm\")\n",
    "    response = ssm_client.put_parameter(\n",
    "        Name=parameter_name, Value=parameter_value, Type=\"String\", Overwrite=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Define step for uploading the training, validation, and test data to S3\n",
    "@step(\n",
    "    name=\"data-upload-to-s3-step\",\n",
    "    keep_alive_period_in_seconds=300,\n",
    ")\n",
    "# Convert the data to jsonl format and upload to S3.\n",
    "def data_upload_to_s3(data_split_response: tuple, bucket_name: str) -> tuple:\n",
    "    dataset_folder = \"fine-tuning-datasets\"\n",
    "\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        # Create the directory\n",
    "        os.makedirs(dataset_folder)\n",
    "        print(f\"Directory {dataset_folder} created successfully!\")\n",
    "    else:\n",
    "        print(f\"Directory  {dataset_folder} already exists!\")\n",
    "\n",
    "    abs_path = os.path.abspath(dataset_folder)\n",
    "    print(f\"\\nDataset folder path: {abs_path}\")\n",
    "\n",
    "    print(type(data_split_response[0]))\n",
    "    train_file = write_jsonl_file(abs_path, \"train-cnn.jsonl\", data_split_response[0])\n",
    "    val_file = write_jsonl_file(abs_path, \"validation-cnn.jsonl\", data_split_response[1])\n",
    "    test_file = write_jsonl_file(abs_path, \"test-cnn.jsonl\", data_split_response[2])\n",
    "\n",
    "    file_names = train_file, val_file, test_file\n",
    "\n",
    "    s3_keys = (\n",
    "        f\"{dataset_folder}/train/train-cnn.jsonl\",\n",
    "        f\"{dataset_folder}/validation/validation-cnn.jsonl\",\n",
    "        f\"{dataset_folder}/test/test-cnn.jsonl\",\n",
    "    )\n",
    "    print(s3_keys)\n",
    "\n",
    "    upload_file_to_s3(bucket_name, file_names, s3_keys)\n",
    "\n",
    "    # save test file S3 uri for use later while testing the model\n",
    "    save_s3_uri_in_SSM(\"s3_test_uri\", f\"s3://{bucket_name}/{s3_keys[2]}\")\n",
    "\n",
    "    # return the s3 uris for data files\n",
    "    return (\n",
    "        f\"s3://{bucket_name}/{s3_keys[0]}\",\n",
    "        f\"s3://{bucket_name}/{s3_keys[1]}\",\n",
    "        f\"s3://{bucket_name}/{s3_keys[2]}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Next we define the function to train and fine-tune the model. We will use the Amazon Titan Text Lite model provided by Amazon Bedrock for the CNN dataset summarization use case. The train function needs the S3 URIs of the training and validation.\n",
    "We will also configure the [hyperparameters for fine tuning](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-titan-text.html) the Titan Text Lite model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "\n",
    "\n",
    "# Define step for custom training the model\n",
    "@step(\n",
    "    name=\"model-training-step\",\n",
    "    keep_alive_period_in_seconds=300,\n",
    ")\n",
    "def train(\n",
    "    custom_model_name: str, training_job_name: str, step_data_upload_to_s3_result: tuple\n",
    ") -> str:\n",
    "    # Define the hyperparameters for fine-tuning Titan text model\n",
    "    hyper_parameters = {\n",
    "        \"epochCount\": \"2\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.00003\",\n",
    "    }\n",
    "\n",
    "    # Specify your data path for training, validation(optional) and output\n",
    "    training_data_config = {\"s3Uri\": step_data_upload_to_s3_result[0]}\n",
    "    print(f\"Training data config: {training_data_config}\")\n",
    "\n",
    "    validation_data_config = {\n",
    "        \"validators\": [\n",
    "            {\n",
    "                # \"name\": \"validation\",\n",
    "                \"s3Uri\": step_data_upload_to_s3_result[1]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    print(f\"Validation data config: {validation_data_config}\")\n",
    "\n",
    "    output_data_config = {\n",
    "        \"s3Uri\": f\"s3://{bucket_name}/fine-tuning-datasets/outputs/output-{custom_model_name}\"\n",
    "    }\n",
    "\n",
    "    bedrock = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "    print(\"Start training....\")\n",
    "\n",
    "    # Create the customization job\n",
    "    training_job_response = bedrock.create_model_customization_job(\n",
    "        customizationType=\"FINE_TUNING\",\n",
    "        jobName=training_job_name,\n",
    "        customModelName=custom_model_name,\n",
    "        roleArn=role_arn,\n",
    "        baseModelIdentifier=\"amazon.titan-text-lite-v1:0:4k\",\n",
    "        hyperParameters=hyper_parameters,\n",
    "        trainingDataConfig=training_data_config,\n",
    "        validationDataConfig=validation_data_config,\n",
    "        outputDataConfig=output_data_config,\n",
    "    )\n",
    "    print(training_job_response)\n",
    "\n",
    "    job_status = bedrock.get_model_customization_job(jobIdentifier=training_job_name)[\"status\"]\n",
    "    print(job_status)\n",
    "\n",
    "    while job_status == \"InProgress\":\n",
    "        time.sleep(60)\n",
    "        job_status = bedrock.get_model_customization_job(jobIdentifier=training_job_name)[\"status\"]\n",
    "        print(job_status)\n",
    "\n",
    "    fine_tune_job = bedrock.get_model_customization_job(jobIdentifier=training_job_name)\n",
    "    pprint.pp(fine_tune_job)\n",
    "    output_job_name = \"model-customization-job-\" + fine_tune_job[\"jobArn\"].split(\"/\")[-1]\n",
    "    print(f\"output_job_name: {output_job_name}\")\n",
    "\n",
    "    model_id = bedrock.get_custom_model(modelIdentifier=custom_model_name)[\"modelArn\"]\n",
    "\n",
    "    print(f\"Model id: {model_id}\")\n",
    "    return model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Define step for creating [provisioned throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html) for the Bedrock custom model. A custom model requires provisioned throughput.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "\n",
    "\n",
    "# Define step for creating Provisioned throughput for the custom model\n",
    "@step(\n",
    "    name=\"create-provisioned-throughput-step\",\n",
    "    keep_alive_period_in_seconds=300,\n",
    ")\n",
    "def create_prov_thruput(model_id: str, provisioned_model_name: str) -> str:\n",
    "    bedrock = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "    provisioned_model_id = bedrock.create_provisioned_model_throughput(\n",
    "        modelUnits=1, provisionedModelName=provisioned_model_name, modelId=model_id\n",
    "    )[\"provisionedModelArn\"]\n",
    "\n",
    "    status = bedrock.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id)[\n",
    "        \"status\"\n",
    "    ]\n",
    "\n",
    "    print(status)\n",
    "\n",
    "    while status == \"Creating\":\n",
    "        time.sleep(60)\n",
    "        status = bedrock.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id)[\n",
    "            \"status\"\n",
    "        ]\n",
    "        print(status)\n",
    "        time.sleep(60)\n",
    "\n",
    "    return provisioned_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Test the custom model. Note we get the S3 URI of the test dataset from Amazon SSM where we had stored it as a parameter in an earlier step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "\n",
    "# Test the custom model\n",
    "\n",
    "\n",
    "def get_ssm_parameter(parameter_name):\n",
    "    ssm_client = boto3.client(\"ssm\")\n",
    "    response = ssm_client.get_parameter(Name=parameter_name, WithDecryption=True)\n",
    "\n",
    "    return response[\"Parameter\"][\"Value\"]\n",
    "\n",
    "\n",
    "# Define step for testing the custom model\n",
    "@step(\n",
    "    name=\"model-testing-step\",\n",
    "    keep_alive_period_in_seconds=300,\n",
    ")\n",
    "def test_model(provisioned_model_id: str) -> tuple:\n",
    "    s3_uri = get_ssm_parameter(\"s3_test_uri\")\n",
    "\n",
    "    # Split the s3 uri into bucket name and key\n",
    "    s3_bucket = s3_uri.split(\"/\")[2]\n",
    "    s3_key = \"/\".join(s3_uri.split(\"/\")[3:])\n",
    "    print(f\"s3_bucket : {s3_bucket}, s3_key: {s3_key}\")\n",
    "\n",
    "    # down load the test file\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    s3.download_file(s3_bucket, s3_key, \"test-cnn.jsonl\")\n",
    "\n",
    "    # Invoke the model\n",
    "    with open(\"test-cnn.jsonl\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    test_prompt = json.loads(lines[0])[\"prompt\"]\n",
    "    reference_summary = json.loads(lines[0])[\"completion\"]\n",
    "    pprint.pp(test_prompt)\n",
    "    print(reference_summary)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            {test_prompt}\n",
    "            \"\"\"\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"inputText\": prompt,\n",
    "            \"textGenerationConfig\": {\n",
    "                \"maxTokenCount\": 2048,\n",
    "                \"stopSequences\": [\"User:\"],\n",
    "                \"temperature\": 0,\n",
    "                \"topP\": 0.9,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "    fine_tuned_response = bedrock_runtime.invoke_model(\n",
    "        body=body, modelId=provisioned_model_id, accept=accept, contentType=contentType\n",
    "    )\n",
    "\n",
    "    fine_tuned_response_body = json.loads(fine_tuned_response.get(\"body\").read())\n",
    "    summary = fine_tuned_response_body[\"results\"][0][\"outputText\"]\n",
    "\n",
    "    print(\"Fine tuned model response:\", summary)\n",
    "    print(\"\\nReference summary from test data: \", reference_summary)\n",
    "    return prompt, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run the SageMaker pipeline. You can view the execution of the pipeline in SageMaker Studio. It will appear as a [multi-step directed acyclic graph (DAG)](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-studio-list-pipelines.html) in the studio UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 13\n",
    "\n",
    "# Create the SageMaker pipeline\n",
    "# You can see the multi-step directed acyclic graph (DAG) in the Studio UI as a pipeline\n",
    "\n",
    "pipeline_name = \"bedrock-fine-tune-pipeline\"\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "custom_model_name = f\"finetuned-model-{ts}\"\n",
    "training_job_name = f\"model-finetune-job-{ts}\"\n",
    "provisioned_model_name = f\"summarization-model-{ts}\"\n",
    "\n",
    "param1 = ParameterString(name=\"ds_name\", default_value=\"cnn_dailymail\")\n",
    "param2 = ParameterString(name=\"ds_version\", default_value=\"3.0.0\")\n",
    "\n",
    "data_load_response = data_load(param1, param2)\n",
    "\n",
    "data_split_response = data_split(data_load_response)\n",
    "\n",
    "data_upload_to_s3_response = data_upload_to_s3(data_split_response, bucket_name)\n",
    "\n",
    "train_response = train(custom_model_name, training_job_name, data_upload_to_s3_response)\n",
    "\n",
    "create_prov_thruput_response = create_prov_thruput(train_response, provisioned_model_name)\n",
    "\n",
    "test_model_response = test_model(create_prov_thruput_response)\n",
    "\n",
    "pipeline = Pipeline(name=pipeline_name, steps=[test_model_response], parameters=[param1, param2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 14\n",
    "\n",
    "pipeline.upsert(role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 15\n",
    "\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Wait for the pipeline to finish execution.<br />\n",
    "\n",
    "**Note:** *If you get an error \"Waiter PipelineExecutionComplete failed\" in the following cell, check CloudWatch logs for error details. Most likely, you will see a ServiceQuotaExceededException for provisioned throughput units for the model. You will have to request Amazon support for quota increase. The model quota has to be reqiested for each model type, e.g. amazon.titan-text-lite-v1.*\n",
    "\n",
    "You can also see the execution status of each step in the pipeline in the output of cell 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# cell 17\n",
    "execution.wait(delay=60, max_attempts=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 18\n",
    "\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 19\n",
    "\n",
    "print(execution.result(step_name=\"model-testing-step\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Delete the resources that were created to stop incurring charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 20\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "# delete Bedrock provisioned throughput\n",
    "provisioned_model_id = execution.result(step_name=\"create-provisioned-throughput-step\")\n",
    "try:\n",
    "    bedrock.delete_provisioned_model_throughput(provisionedModelId=provisioned_model_id)\n",
    "except ClientError as e:\n",
    "    print(e.response[\"Error\"][\"Code\"])\n",
    "\n",
    "print(f\"Provisoned throughput deleted for model: {provisioned_model_id}\")\n",
    "\n",
    "# delete the custom model\n",
    "custom_model_id = execution.result(step_name=\"model-training-step\")\n",
    "try:\n",
    "    bedrock.delete_custom_model(modelIdentifier=custom_model_id)\n",
    "except ClientError as e:\n",
    "    print(e.response[\"Error\"][\"Code\"])\n",
    "\n",
    "print(f\"Custom model {custom_model_id} deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 21\n",
    "\n",
    "# delete the SSM parameter\n",
    "ssm_client = boto3.client(\"ssm\")\n",
    "ssm_client.delete_parameter(Name=\"s3_test_uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 22\n",
    "\n",
    "# Delete the SageMaker pipeline\n",
    "response = pipeline.delete()\n",
    "print(f'Deleted pipeline {response[\"PipelineArn\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 23\n",
    "\n",
    "\n",
    "# delete objects in S3\n",
    "def delete_objects_with_prefix(bucket_name, prefix):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Delimiter=\"/\", Prefix=prefix)\n",
    "\n",
    "    if \"Contents\" in response:\n",
    "        contents = response[\"Contents\"]\n",
    "        for obj in contents:\n",
    "            s3.delete_object(Bucket=bucket_name, Key=obj[\"Key\"])\n",
    "\n",
    "    while response[\"IsTruncated\"]:\n",
    "        response = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Delimiter=\"/\",\n",
    "            Prefix=prefix,\n",
    "            ContinuationToken=response[\"NextContinuationToken\"],\n",
    "        )\n",
    "        if \"Contents\" in response:\n",
    "            contents = response[\"Contents\"]\n",
    "            for obj in contents:\n",
    "                s3.delete_object(Bucket=bucket_name, Key=obj[\"Key\"])\n",
    "\n",
    "\n",
    "delete_objects_with_prefix(bucket_name, \"fine-tuning-datasets\")\n",
    "delete_objects_with_prefix(bucket_name, pipeline_name)\n",
    "\n",
    "print(f\"Objects in Bucket {bucket_name} have been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/sagemaker-pipelines|step-decorator|bedrock-examples|fine_tune_bedrock_step_decorator.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
