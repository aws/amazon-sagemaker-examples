{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0082ff",
   "metadata": {},
   "source": [
    "# Churn Prediction with Multimodality of Tabular and Text features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd706d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a3bac",
   "metadata": {},
   "source": [
    "\n",
    "Customer churn is a problem faced by a wide range of companies, from\n",
    "telecommunications to banking, where customers are typically lost to\n",
    "competitors. It's in a company's best interest to retain existing\n",
    "customer instead of acquiring new customers because it usually costs\n",
    "significantly more to attract new customers. When trying to retain\n",
    "customers, companies often focus their efforts on customers who are more\n",
    "likely to leave. User behaviour and customer support chat logs can\n",
    "contain valuable indicators on the likelihood of a customer ending the\n",
    "service. In this solution, we train and deploy a churn prediction model\n",
    "that uses state-of-the-art natural language processing model to find\n",
    "useful signals in text. In addition to textual inputs, this model uses\n",
    "traditional structured data inputs such as numerical and categorical\n",
    "fields.\n",
    "\n",
    "In this notebook, we train, deploy and use a churn prediction model\n",
    "that processes numerical, categorical and textual features to make its\n",
    "prediction.\n",
    "\n",
    "**Note**: When running this notebook on SageMaker Studio, you should make\n",
    "sure to use the `Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)` image/kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08739dfc",
   "metadata": {},
   "source": [
    "Install required packages to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b1a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d769735",
   "metadata": {},
   "source": [
    "We start by importing a variety of packages that are used throughout\n",
    "the notebook. One of the most important packages is the Amazon SageMaker\n",
    "Python SDK (i.e. `import sagemaker`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd15f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pathlib import Path\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef602a",
   "metadata": {},
   "source": [
    "Up next, we can use the SageMaker client to call SageMaker APIs\n",
    "directly, as an alternative to using the Amazon SageMaker SDK. We use\n",
    "it at the end of the notebook to delete certain resources that are\n",
    "created in this notebook. We define some naming variables that are used in the following sections, including s3 bucket prefixes and model, training job prefixes in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a0205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path\n",
    "import config\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "IAM_ROLE = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d1510",
   "metadata": {},
   "source": [
    "## 1. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf6ca2",
   "metadata": {},
   "source": [
    "Download the data from source S3 buckets for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f83f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker.s3.S3Downloader.download(\n",
    "    f\"s3://sagemaker-example-files-prod-{sagemaker_session.boto_region_name}/datasets/tabular/synthetic_churn_prediction_with_text\",\n",
    "    \"data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0af02",
   "metadata": {},
   "source": [
    "Upload the data to the S3 bucket in your own account for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b502c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_BUCKET = sagemaker_session.default_bucket()\n",
    "sagemaker.s3.S3Uploader.upload(\"data\", f\"s3://{DEFAULT_BUCKET}/{config.DATASETS_S3_PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6b5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def load_jsonl(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = pd.DataFrame(load_jsonl(\"data/train.jsonl\"))\n",
    "validation_data = pd.DataFrame(load_jsonl(\"data/validation.jsonl\"))\n",
    "test_data = load_jsonl(\"data/test.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b7a55",
   "metadata": {},
   "source": [
    "Prepare test data to be used as hold-out dataset for evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfffac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_label = []\n",
    "\n",
    "for each_example in test_data:\n",
    "    ground_truth_label.append(each_example[\"y\"])\n",
    "    del each_example[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a0fd3",
   "metadata": {},
   "source": [
    "Here are the first 10 observations of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3ace5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c62e2",
   "metadata": {},
   "source": [
    "By modern standards, it’s a medium size dataset, with only 43,000 records, where eac h record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
    "\n",
    "`CustServ Calls`: the number of calls placed to Customer Service. Positive values mean customers called customer service and negative values mean customer service called customers \n",
    "\n",
    "`Day Charge`: the billed cost of daytime calls\n",
    "\n",
    "`Day Mins`: the total number of calling minutes used during the day\n",
    "\n",
    "`Day Calls`: the total number of calls placed during the day\n",
    "\n",
    "`VMail Message`: the average number of voice mail messages per month\n",
    "\n",
    "`Eve Mins`, `Eve Calls`, `Eve Charge`: the billed cost for calls placed during the evening\n",
    "\n",
    "`Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
    "\n",
    "`Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
    "\n",
    "`Account Length`: the number of days that this account has been active\n",
    "\n",
    "`State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "\n",
    "`Location`: the location of the corresponding customer’s phone number: 'urban', 'suburban', 'rural', None, or 'other'\n",
    "\n",
    "`Phone`: the remaining seven-digit phone number\n",
    "\n",
    "`Plan`: the plan customer has with the company\n",
    "\n",
    "`Limit`: whether the customer's plan is limited or unlimited\n",
    "\n",
    "`Text`: chat record written in text\n",
    "\n",
    "\n",
    "`y`: whether the customer left the service: true/false\n",
    "\n",
    "The attribute, `y`, is known as the target attribute: the attribute that we want the ML model to predict. Because the target attribute is binary, our model performs binary prediction, also known as binary classification.\n",
    "\n",
    "**In addition, the features include missing values, which are taken cared of in the following fitting model stage.**\n",
    "\n",
    "Let’s begin exploring the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10e1b8",
   "metadata": {},
   "source": [
    "Summary statistics for train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4caa55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c6478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92887283",
   "metadata": {},
   "source": [
    "Shape of train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a2391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.shape, validation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0740d",
   "metadata": {},
   "source": [
    "## 2. Fitting a multimodality model with huggingface sentence transformer and scikit-learn random forest classifier\n",
    "\n",
    "The model consists of two components: 1. feature engineering step that processes numerical, categorical, and text features. 2. model fitting step that fits the transformed numerical, categorical, and text features into [scikit-learn RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). \n",
    "\n",
    "For the feature engineering step, we conduct following step.\n",
    "1. Fill missing values for numerical features\n",
    "2. Encode categorical features into one-hot values where the missing values are counted as one of categories for each feature.\n",
    "3. Use [HuggingFace sentence transformer](https://huggingface.co/sentence-transformers?sort_models=downloads#models) to encode the text feature to generate a X dimensional dense vector where X value depends on particular sentence transformer. \n",
    "> We choose top 3 most downloaded sentence transformer models and use them in the following model fitting and hyperparameter optimization. Specifically, they are [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2), [multi-qa-mpnet-base-dot-v1](https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1), [paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2).\n",
    "\n",
    "For hyperparameters of [scikit-learn RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), please check [github link](https://github.com/scikit-learn/scikit-learn/blob/0.24.X/sklearn/ensemble/_forest.py#L899)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0921f38",
   "metadata": {},
   "source": [
    "Here is the architecture diagram.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"diagram/architecture_rf.png\" style=\"width: 600px;\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1bb6d",
   "metadata": {},
   "source": [
    "For demonstartion purpose, we only use numerical features `CustServ Calls` and `Account Length`, categorical features `plan` and `limit` and text feature `text` to fit the model. Multiple features should be seperated by `,` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e96b1",
   "metadata": {},
   "source": [
    "Hyperparameters are explained as below.\n",
    "\n",
    "* `numerical-feature-names`: numerical feature names separted by comma `,`.\n",
    "* `categorical-feature-names`: categorical feature names separated by comma `,`.\n",
    "* `textual-feature-names`: text feature names separated by comma `,`.\n",
    "* `label-name`: target column.\n",
    "\n",
    "Hyperparameters for fandom forest\n",
    "* `n-estimators`:  the number of trees in the forest.\n",
    "* `min-impurity-decrease`: a node is the split if this split induces a decrease of the impurity greater than or equal to this value. For details, see [random forest documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "* `ccp-alpha`: complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha are chosen. By default, no pruning is performed.\n",
    "* `criterion`: the function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain.\n",
    "* `max-depth`: the maximum depth of the tree. if -1, then nodes are expanded until all leaves are pure.\n",
    "* `boostrap`: whether bootstrap samples are used when building trees. If \"False\", the whole dataset is used to build each tree.\n",
    "* `min-samples-split`: the minimum number of samples required to split an internal node.\n",
    "* `min-samples-leaf`: the minimum number of samples required to be at a leaf node.\n",
    "* `balanced-data`: whether use different weights based on the data imbalance.\n",
    "\n",
    "Hyperparameter for text sentence transformer:\n",
    "* `sentence-transformer`: Use [HuggingFace sentence transformer](https://huggingface.co/sentence-transformers?sort_models=downloads#models) to encode the text feature to generate a X dimensional dense vector where X value depends on particular sentence transformer. \n",
    "> We choose top 3 most downloaded sentence transformer models and use them in the following model fitting and hyperparameter optimization. Specifically, they are [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2), [multi-qa-mpnet-base-dot-v1](https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1), [paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2fc392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"n-estimators\": 50,\n",
    "    \"min-impurity-decrease\": 0.0,\n",
    "    \"ccp-alpha\": 0.0,\n",
    "    \"sentence-transformer\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max-depth\": 6,\n",
    "    \"boostrap\": \"True\",\n",
    "    \"min-samples-split\": 4,\n",
    "    \"min-samples-leaf\": 1,\n",
    "    \"balanced-data\": True,\n",
    "    \"numerical-feature-names\": \"CustServ Calls,Account Length\",\n",
    "    \"categorical-feature-names\": \"plan,limit\",\n",
    "    \"textual-feature-names\": \"text\",\n",
    "    \"label-name\": \"y\",\n",
    "}\n",
    "\n",
    "\n",
    "current_folder = config.get_current_folder(globals())\n",
    "estimator = PyTorch(\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"entry_point.py\",\n",
    "    source_dir=str(\n",
    "        Path(current_folder, \"containers/huggingface_transformer_randomforest\").resolve()\n",
    "    ),\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=IAM_ROLE,\n",
    "    instance_count=1,\n",
    "    instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    "    output_path=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_RF)),\n",
    "    code_location=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_RF)),\n",
    "    base_job_name=config.SOLUTION_PREFIX,\n",
    "    tags=[{\"Key\": config.TAG_KEY, \"Value\": config.SOLUTION_PREFIX}],\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea82769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    {\n",
    "        \"train\": \"s3://\" + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"train.jsonl\")),\n",
    "        \"validation\": \"s3://\"\n",
    "        + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"validation.jsonl\")),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3feb6",
   "metadata": {},
   "source": [
    "We use the unique solution prefix to name the model and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77532764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da121ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe7769",
   "metadata": {},
   "source": [
    "When calling our new endpoint from the notebook, we use a Amazon\n",
    "SageMaker SDK\n",
    "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n",
    "A `Predictor` is used to send data to an endpoint (as part of a request),\n",
    "and interpret the response. Our `estimator.deploy` command returned a\n",
    "`Predictor` but, by default, it sends and receive numpy arrays. Our\n",
    "endpoint expects to receive (and also sends) JSON formatted objects, so\n",
    "we modify the `Predictor` to use JSON instead of the PyTorch endpoint\n",
    "default of numpy arrays. JSON is used here because it is a standard\n",
    "endpoint format and the endpoint response can contain nested data\n",
    "structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e814b0",
   "metadata": {},
   "source": [
    "With our model successfully deployed and our predictor configured, we can\n",
    "try out the churn prediction model out on example inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411e379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"CustServ Calls\": -20.0,\n",
    "    \"Account Length\": 133.12,\n",
    "    \"plan\": \"D\",\n",
    "    \"limit\": \"unlimited\",\n",
    "    \"text\": \"Well, I've been dealing with TelCom for three months now, and I feel like they're very helpful and responsive to my issues, but for a month now, I've only had one technical support call and that was very long and involved. My phone number was wrong on both contracts, and they gave me a chance to work with TelCom customer service and it was extremely helpful, so I've decided to stick with it. But I would like to have more help in terms of technical support, I haven't had the kind of help with my phone line and I don't have the type of tech support I want. So I would like to negotiate a phone contract, maybe an upgrade from a Sprint plan, or maybe from a Verizon plan.\\\\nTelCom Agent: Very good.\",\n",
    "}\n",
    "response = predictor.predict(data=[data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c557db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc79b433",
   "metadata": {},
   "source": [
    "We have the response and we can print out the probability of churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76c242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"{:.2%} probability of churn\".format(response[\"probability\"][0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df69e2",
   "metadata": {},
   "source": [
    "**Caution**: the probability returned by this model has not been\n",
    "calibrated. When the model gives a probability of churn of 20%,\n",
    "for example, this does not necessarily mean that 20% of customers with\n",
    "a probability of 20% resulted in churn. Calibration is a useful\n",
    "property in certain circumstances, but is not required in cases where\n",
    "discrimination between cases of churn and non-churn is sufficient.\n",
    "[CalibratedClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html)\n",
    "from [Scikit-learn](https://scikit-learn.org/stable/modules/calibration.html) can be used to calibrate a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4912f8d",
   "metadata": {},
   "source": [
    "Now, we query each of the text example to get prediction and compute the evaluation metrics. Note, even though we send full features of each test example to the endpoint. The code script in the endpoint only looks for numerical features `CustServ Calls` and `Account Length`, categorical features `plan` and `limit` and text feature `text` to make predictions, which aligns with training process (the numerical, categorical, and text feature names are saved in the training container and loaded back in the inference container during the inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e85a9",
   "metadata": {},
   "source": [
    "Note. Even though we only use `CustServ Calls`, `Account Length`, `plan`,`limit`, and `text` features to fit the model. During inference of the random forest and transformer model, you can send an example with full features into the endpoint as the feature names are saved during training and are retrieved during the endpoint is queried and used to select the test example for generating prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59211b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "num_examples = len(test_data)\n",
    "predicted_prob = []\n",
    "\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = predictor.predict(\n",
    "        test_data[i : (i + batch_size)],\n",
    "    )\n",
    "\n",
    "    predicted_prob_batch = query_response_batch[\"probability\"]\n",
    "    predicted_prob.append(predicted_prob_batch)\n",
    "\n",
    "predicted_prob = np.concatenate(predicted_prob, axis=0)\n",
    "predicted_label = np.argmax(predicted_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21f1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Measure the prediction results quantitatively.\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "eval_accuracy = accuracy_score(ground_truth_label, predicted_label)\n",
    "eval_auc = roc_auc_score(ground_truth_label, predicted_prob[:, 1])\n",
    "\n",
    "Randomforest_BERT = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Accuracy\": eval_accuracy,\n",
    "        \"ROC AUC\": eval_auc,\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"BERT + Random Forest\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb2ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Randomforest_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54213cca",
   "metadata": {},
   "source": [
    "## 3. Fitting a multimodality model with hyperparameter optimization (HPO)\n",
    "\n",
    "In this section we further improve the model performance by adding HPO tuning with [SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html). Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. The best model and its corresponded hyperparmeters are selected on the validation data. Next, the best model is evaluated on the hold-out test data, which is the same test data created in Stage I. Finally, we show that the performance of model trained with HPO is significantly better than the one trained without HPO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436ec00",
   "metadata": {},
   "source": [
    "Below are static hyperparameters we do not tune and dynamic hyperparameters we want to tune and their searching ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181de698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    ContinuousParameter,\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"numerical-feature-names\": \"CustServ Calls,Account Length\",\n",
    "    \"categorical-feature-names\": \"plan,limit\",\n",
    "    \"textual-feature-names\": \"text\",\n",
    "    \"label-name\": \"y\",\n",
    "}\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"sentence-transformer\": CategoricalParameter(\n",
    "        [\n",
    "            \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            \"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    "            \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "        ]\n",
    "    ),\n",
    "    \"criterion\": CategoricalParameter([\"gini\", \"entropy\"]),\n",
    "    \"max-depth\": CategoricalParameter([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, -1]),\n",
    "    \"boostrap\": CategoricalParameter([\"True\", \"False\"]),\n",
    "    \"min-samples-split\": IntegerParameter(2, 10),\n",
    "    \"min-samples-leaf\": IntegerParameter(1, 5),\n",
    "    \"n-estimators\": CategoricalParameter([100, 200, 400, 800, 1000]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355b6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_name = f\"{config.SOLUTION_PREFIX}-hpo\"\n",
    "\n",
    "current_folder = config.get_current_folder(globals())\n",
    "estimator = PyTorch(\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"entry_point.py\",\n",
    "    source_dir=str(\n",
    "        Path(current_folder, \"containers/huggingface_transformer_randomforest\").resolve()\n",
    "    ),\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=IAM_ROLE,\n",
    "    instance_count=1,\n",
    "    instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    "    output_path=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_RF)),\n",
    "    code_location=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_RF)),\n",
    "    tags=[{\"Key\": config.TAG_KEY, \"Value\": config.SOLUTION_PREFIX}],\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84833020",
   "metadata": {},
   "source": [
    "Define the objective metric name, metric definition (with regex pattern), and objective type for the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef7822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_metric_name = \"roc auc\"\n",
    "metric_definitions = [{\"Name\": \"roc auc\", \"Regex\": \"roc auc score on validation data: ([0-9\\\\.]+)\"}]\n",
    "objective_type = \"Maximize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeecaa69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=18,  # increase the maximum number of jobs will likely get better performance\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=objective_type,\n",
    "    base_tuning_job_name=tuning_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f03e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.fit(\n",
    "    {\n",
    "        \"train\": \"s3://\" + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"train.jsonl\")),\n",
    "        \"validation\": \"s3://\"\n",
    "        + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"validation.jsonl\")),\n",
    "    },\n",
    "    logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c283c6c1",
   "metadata": {},
   "source": [
    "Find the tuning job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894434d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "tuning_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3848350",
   "metadata": {},
   "source": [
    "Checking the status of the tuning jobs: whether all of them are finished with 'Completed' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7db926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_result = sm_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "\n",
    "status = tuning_job_result[\"HyperParameterTuningJobStatus\"]\n",
    "if status != \"Completed\":\n",
    "    print(\"Reminder: the tuning job has not been completed.\")\n",
    "\n",
    "job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "is_minimize = (\n",
    "    tuning_job_result[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"][\"Type\"]\n",
    "    != objective_type\n",
    ")\n",
    "objective_name = tuning_job_result[\"HyperParameterTuningJobConfig\"][\n",
    "    \"HyperParameterTuningJobObjective\"\n",
    "][\"MetricName\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba429b9",
   "metadata": {},
   "source": [
    "Once the tuning job finishes, we can bring in a table of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766efa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\", ascending=True)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453045f2",
   "metadata": {},
   "source": [
    "Deploy the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46774d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name_hpo = f\"{config.SOLUTION_PREFIX}-hpo-endpoint\"\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor_hpo = tuner.deploy(\n",
    "    endpoint_name=endpoint_name_hpo,\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87541e84",
   "metadata": {},
   "source": [
    "After deploying the endpoint, we query the endpoint using the same test data, compute the evaluaton metrics, and compare with the results without HPO tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627240d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "num_examples = len(test_data)\n",
    "predicted_prob_hpo = []\n",
    "\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = predictor_hpo.predict(\n",
    "        test_data[i : (i + batch_size)],\n",
    "    )\n",
    "\n",
    "    predicted_prob_hpo_batch = query_response_batch[\"probability\"]\n",
    "    predicted_prob_hpo.append(predicted_prob_hpo_batch)\n",
    "\n",
    "predicted_prob_hpo = np.concatenate(predicted_prob_hpo, axis=0)\n",
    "predicted_label_hpo = np.argmax(predicted_prob_hpo, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136989f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Measure the prediction results quantitatively.\n",
    "\n",
    "eval_accuracy_hpo = accuracy_score(ground_truth_label, predicted_label_hpo)\n",
    "eval_auc_hpo = roc_auc_score(ground_truth_label, predicted_prob_hpo[:, 1])\n",
    "\n",
    "Randomforest_BERT_HPO = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Accuracy\": eval_accuracy_hpo,\n",
    "        \"ROC AUC\": eval_auc_hpo,\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"BERT + Random Forest with HPO\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616691f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_hpo = pd.concat([Randomforest_BERT, Randomforest_BERT_HPO], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578d7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_hpo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361cfcf",
   "metadata": {},
   "source": [
    "## 4. Fitting a AutoGluon multimodality weighted / stacked ensemble model\n",
    "\n",
    "There are two types of AutoGluon multimodality: 1. Train multiple tabular models as well as the `TextPredictor` model (utilizing `TextPredictor` model inside of `TabularPredictor`), and then combine them via either a weighted ensemble or stack ensemble, as explained in [AutoGluon Tabular Paper](https://arxiv.org/pdf/2003.06505.pdf). 2. Fuse multiple neural network models directly and handles raw text (which are also capable of handling additional numerical/categorical columns) with a diagram shown as below. \n",
    "\n",
    "We try to train a multimodality weighted / stacked ensemble model first in this section and training a fusion nerual network model in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315e89a",
   "metadata": {},
   "source": [
    "Retrieve the training image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8356dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    \"autogluon\",\n",
    "    region=boto3.Session().region_name,\n",
    "    version=\"0.5.2\",\n",
    "    py_version=\"py38\",\n",
    "    image_scope=\"training\",\n",
    "    instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ba444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342e0b5",
   "metadata": {},
   "source": [
    "Hyperparameters are explained as below.\n",
    "\n",
    "* `numerical-feature-names`: numerical feature names separted by comma `,`.\n",
    "* `categorical-feature-names`: categorical feature names separated by comma `,`.\n",
    "* `textual-feature-names`: text feature names separated by comma `,`.\n",
    "* `label-name`: target column.\n",
    "* `problem_type`: either 'classification' or 'regression'. For classification task, we identify binary or multiclass classification in the training script.\n",
    "* `eval_metric`:  evaluation metrics for validation data. For all the options, see [AutoGluon-Tabular documentation](https://auto.gluon.ai/stable/api/autogluon.predictor.html#module-0).\n",
    "* `presets`: set presets=`best_quality` means best predictive accuracy with little consideration to inference time or disk usage. `high_quality` means high predictive accuracy with fast inference. `good_quality` means good predictive accuracy with very fast inference. `medium_quality` means medium predictive accuracy with very fast inference and very fast training time. `optimize_for_deployment` means optimizing result immediately for deployment by deleting unused models and removing training artifacts. `interpretable` means fitting only interpretable rule-based models from the `imodels` package. For details, see [AutoGluon documentation](https://auto.gluon.ai/stable/api/autogluon.predictor.html#autogluon.tabular.TabularPredictor.fit).\n",
    "* `text_nn_presets`: the presets for text neural network models. Options: `medium_quality_faster_train`, `high_quality`, and `best_quality`.\n",
    "* `auto_stack`: whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy. Set this = True if you are willing to tolerate longer training times in order to maximize predictive accuracy! Automatically sets num_bag_folds and num_stack_levels arguments based on dataset properties. Note: Setting num_bag_folds and num_stack_levels arguments overrides auto_stack. Note: This can increase training time (and inference time) by up to 20x, but can greatly improve predictive performance.\n",
    "* `num_bag_folds`: number of folds used for bagging of models. When num_bag_folds = k, training time is roughly increased by a factor of k (set = 0 to disable bagging). Disabled by default (0), but we recommend values between 5-10 to maximize predictive performance. Increasing num_bag_folds will result in models with lower bias but that are more prone to overfitting. num_bag_folds = 1 is an invalid value, and raises a ValueError. Values > 10 may produce diminishing returns, and can even harm overall results due to overfitting. To further improve predictions, avoid increasing num_bag_folds much beyond 10 and instead increase num_bag_sets.\n",
    "* `num_bag_sets`: number of repeats of kfold bagging to perform (values must be >= 1). Total number of models trained during bagging = num_bag_folds * num_bag_sets. Defaults to 1 if time_limit is not specified, otherwise 20 (always disabled if num_bag_folds is not specified). Values greater than 1 will result in superior predictive performance, especially on smaller problems and with stacking enabled (reduces overall variance).\n",
    "* `num_stack_levels`: number of stacking levels to use in stack ensemble. Roughly increases model training time by factor of num_stack_levels+1 (set = 0 to disable stack ensembling). Disabled by default (0), but we recommend values between 1-3 to maximize predictive performance. To prevent overfitting, num_bag_folds >= 2 must also be set or else a ValueError will be raised.\n",
    "* `refit_full`: whether to retrain all models on all of the data (training + validation) after the normal training procedure. For details, see [AutoGluon documentation](https://auto.gluon.ai/stable/api/autogluon.predictor.html#autogluon.tabular.TabularPredictor.fit).\n",
    "* `set_best_to_refit_full`: if True, will change the default model that Predictor uses for prediction when model is not specified to the refit_full version of the model that exhibited the highest validation score. Only valid if refit_full is set.\n",
    "* `save_space`: if True, reduces the memory and disk size of predictor by deleting auxiliary model files that aren't needed for prediction on new data. This has NO impact on inference accuracy. It is recommended if the only goal is to use the trained model for prediction.\n",
    "* `verbosity`: verbosity levels range from `0` to `4` and control how much information is printed. Higher levels correspond to more detailed print statements (you can set verbosity = 0 to suppress warnings).\n",
    "* `pretrained-transformer`: the pre-trained transformer to encode the text data. The transformers can be selected from [Hugginface AutoModel](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodel). Some examples are showns as below. \n",
    "  - 'microsoft/deberta-v3-base'\n",
    "  - 'bert-base-uncased'\n",
    "  - 'google/electra-base-discriminator'\n",
    "  - 'distilroberta-base'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a86f60",
   "metadata": {},
   "source": [
    "Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluonTabular succeeds by ensembling multiple models\n",
    "and stacking them in multiple layers. Thus hyperparameter optimization is usually not required for AutoGluon ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21216a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"numerical-feature-names\": \"CustServ Calls,Account Length\",\n",
    "    \"categorical-feature-names\": \"plan,limit\",\n",
    "    \"textual-feature-names\": \"text\",\n",
    "    \"label-name\": \"y\",\n",
    "    \"problem_type\": \"classification\",  # either classification or regression. For classification, we identify binary or multiclass classification in the training script\n",
    "    \"eval_metric\": \"roc_auc\",\n",
    "    \"presets\": \"medium_quality\",\n",
    "    \"text_nn_presets\": \"medium_quality_faster_train\",\n",
    "    \"auto_stack\": \"False\",\n",
    "    \"num_bag_folds\": 0,\n",
    "    \"num_bag_sets\": 1,\n",
    "    \"num_stack_levels\": 0,\n",
    "    \"refit_full\": \"False\",\n",
    "    \"set_best_to_refit_full\": \"False\",\n",
    "    \"save_space\": \"True\",\n",
    "    \"verbosity\": 2,\n",
    "    \"pretrained-transformer\": \"google/electra-small-discriminator\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99530a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create SageMaker Estimator instance\n",
    "\n",
    "training_job_name_ag = f\"{config.SOLUTION_PREFIX}-ag\"\n",
    "\n",
    "tabular_estimator_ag = Estimator(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri=train_image_uri,\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=str(Path(current_folder, \"containers/autogluon_multimodal_ensemble\").resolve()),\n",
    "    instance_count=1,\n",
    "    instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    base_job_name=training_job_name_ag,\n",
    "    output_path=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_AG_ENSEMBLE)),\n",
    "    code_location=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_AG_ENSEMBLE)),\n",
    "    tags=[{\"Key\": config.TAG_KEY, \"Value\": config.SOLUTION_PREFIX}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531805e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular_estimator_ag.fit(\n",
    "    {\n",
    "        \"train\": \"s3://\" + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"train.jsonl\")),\n",
    "        \"validation\": \"s3://\"\n",
    "        + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"validation.jsonl\")),\n",
    "    },\n",
    "    logs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fa033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "inference_image_uri = image_uris.retrieve(\n",
    "    \"autogluon\",\n",
    "    region=boto3.Session().region_name,\n",
    "    version=\"0.5.2\",\n",
    "    py_version=\"py38\",\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    ")\n",
    "\n",
    "endpoint_name_ag = f\"{config.SOLUTION_PREFIX}-ag-endpoint\"\n",
    "current_folder = config.get_current_folder(globals())\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor_ag = tabular_estimator_ag.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=inference_image_uri,\n",
    "    source_dir=str(Path(current_folder, \"containers/autogluon_multimodal_ensemble\").resolve()),\n",
    "    endpoint_name=endpoint_name_ag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddab37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features = pd.DataFrame(test_data)\n",
    "test_features = test_features[[\"CustServ Calls\", \"Account Length\", \"plan\", \"limit\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36d465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218506c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_tabular_data, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=content_type,\n",
    "        Body=encoded_tabular_data,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    predicted_probabilities = model_predictions[\"probabilities\"]\n",
    "    return np.array(predicted_probabilities)\n",
    "\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint if test data has large size.\n",
    "batch_size = 300\n",
    "predict_prob_ag = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        test_features.iloc[i : (i + batch_size), :]\n",
    "        .to_csv(header=False, index=False)\n",
    "        .encode(\"utf-8\"),\n",
    "        endpoint_name_ag,\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob_ag.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob_ag = np.concatenate(predict_prob_ag, axis=0)\n",
    "predict_label_ag = np.argmax(predict_prob_ag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcec287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_accuracy_ag = accuracy_score(ground_truth_label, predict_label_ag)\n",
    "eval_auc_ag = roc_auc_score(ground_truth_label, predict_prob_ag[:, 1])\n",
    "\n",
    "AG_multimodality = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Accuracy\": eval_accuracy_ag,\n",
    "        \"ROC AUC\": eval_auc_ag,\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"AutoGluon Multimodality Ensemble\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f88e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_hpo_ag = pd.concat([rf_hpo, AG_multimodality], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95c4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_hpo_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a485e",
   "metadata": {},
   "source": [
    "## 5. Fitting a AutoGluon multimodality fusion model\n",
    "\n",
    "The architecture of the models are shown as below. For details, see the official [AutoGluon documentation](https://auto.gluon.ai/stable/tutorials/multimodal/multimodal_text_tabular.html).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"diagram/architecture_ag.png\" style=\"width: 600px;\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26efd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create SageMaker Estimator instance\n",
    "training_job_name_ag_fusion = f\"{config.SOLUTION_PREFIX}-ag-fusion\"\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    \"numerical-feature-names\": \"CustServ Calls,Account Length\",\n",
    "    \"categorical-feature-names\": \"plan,limit\",\n",
    "    \"textual-feature-names\": \"text\",\n",
    "    \"label-name\": \"y\",\n",
    "    \"problem_type\": \"classification\",  # either classification or regression. For classification, we identify binary or multiclass classification in the training script\n",
    "    \"eval_metric\": \"roc_auc\",\n",
    "    \"verbosity\": 2,\n",
    "    \"pretrained-transformer\": \"google/electra-small-discriminator\",\n",
    "}\n",
    "\n",
    "\n",
    "tabular_estimator_ag_fusion = Estimator(\n",
    "    role=IAM_ROLE,\n",
    "    image_uri=train_image_uri,\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=str(Path(current_folder, \"containers/autogluon_multimodal_fusion\").resolve()),\n",
    "    instance_count=1,\n",
    "    instance_type=config.TRAINING_INSTANCE_TYPE,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    base_job_name=training_job_name_ag_fusion,\n",
    "    output_path=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_AG_FUSION)),\n",
    "    code_location=\"s3://\" + str(Path(DEFAULT_BUCKET, config.OUTPUTS_S3_PREFIX_AG_FUSION)),\n",
    "    tags=[{\"Key\": config.TAG_KEY, \"Value\": config.SOLUTION_PREFIX}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a424a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular_estimator_ag_fusion.fit(\n",
    "    {\n",
    "        \"train\": \"s3://\" + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"train.jsonl\")),\n",
    "        \"validation\": \"s3://\"\n",
    "        + str(Path(DEFAULT_BUCKET, config.DATASETS_S3_PREFIX, \"validation.jsonl\")),\n",
    "    },\n",
    "    logs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e2830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name_ag_fusion = f\"{config.SOLUTION_PREFIX}-ag-fusion-endpoint\"\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor_ag_fusion = tabular_estimator_ag_fusion.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=inference_image_uri,\n",
    "    source_dir=str(Path(current_folder, \"containers/autogluon_multimodal_fusion\").resolve()),\n",
    "    endpoint_name=endpoint_name_ag_fusion,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa12edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the test data into smaller size of batches to query the endpoint if test data has large size.\n",
    "\n",
    "batch_size = 50\n",
    "predict_prob_ag_fusion = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        test_features.iloc[i : (i + batch_size), :]\n",
    "        .to_csv(header=False, index=False)\n",
    "        .encode(\"utf-8\"),\n",
    "        endpoint_name_ag_fusion,\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob_ag_fusion.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob_ag_fusion = np.concatenate(predict_prob_ag_fusion, axis=0)\n",
    "predict_label_ag_fusion = np.argmax(predict_prob_ag_fusion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527bea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_accuracy_ag_fusion = accuracy_score(ground_truth_label, predict_label_ag_fusion)\n",
    "eval_auc_ag_fusion = roc_auc_score(ground_truth_label, predict_prob_ag_fusion[:, 1])\n",
    "\n",
    "AG_multimodality_fusion = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Accuracy\": eval_accuracy_ag_fusion,\n",
    "        \"ROC AUC\": eval_auc_ag_fusion,\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"AutoGluon Multimodality Fusion\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e824a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([rf_hpo_ag, AG_multimodality_fusion], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa22f3",
   "metadata": {},
   "source": [
    "We can see all of four models deliver close performance on the hold-out test data. For your own use cases, please replace the example dataset by yours to find out the optimal model that works best for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7a859",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "When you've finished with the relationship extraction endpoint (and associated\n",
    "endpoint-config), make sure that you delete it to avoid accidental\n",
    "charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a79bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name_hpo)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name_hpo)\n",
    "\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name_ag)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name_ag)\n",
    "\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name_ag_fusion)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name_ag_fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12043f",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/introduction_to_applying_machine_learning|churn_prediction_multimodality_of_text_and_tabular|churn_prediction_multimodality_of_text_and_tabular.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
