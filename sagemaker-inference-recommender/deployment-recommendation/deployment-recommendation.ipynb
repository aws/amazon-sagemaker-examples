{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Inference Recommender for Deployment Recommendation\n",
    "\n",
    "## Contents\n",
    "[1. Introduction](#1.-Introduction)  \n",
    "[2. Download the Model & Payload](#2.-Download-the-Model-&-Payload)  \n",
    "[3. Create the Model](#3.-Create-the-Model)  \n",
    "[4. Describe the Model to Inspect Deployment Recommendations](#4.-Describe-the-Model-to-Inspect-Deployment-Recommendations)  \n",
    "[5. Deploy the Model to Endpoint with Python SDK](#5:-Deploy-the-Model-to-Endpoint-with-Python-SDK)   \n",
    "[6. Invoke the Endpoint & Produce Inference](#6.-Invoke-the-Endpoint-&-Produce-Inference)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "SageMaker Inference Recommender is a new capability of SageMaker that reduces the time required to get machine learning (ML) models in production by automating performance benchmarking and load testing models across SageMaker ML instances. You can use Inference Recommender to deploy your model to a real-time inference endpoint that delivers the best performance at the lowest cost. \n",
    "\n",
    "deployment Recommendation is a new data-driven machine learning based capability proposed for Inference Recommender that will provide a recommendation without running benchmarks. This means you donâ€™t have to wait approximately 20-40 minutes for a benchmark to run before getting a recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's update the required packages i.e. SageMaker Python SDK, `boto3`, `botocore` and `awscli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install sagemaker botocore boto3 awscli --upgrade\n",
    "!pip install --upgrade pip awscli botocore boto3  --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Client and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the Model & Payload\n",
    "\n",
    "In this example, we are using a pre-trained scikit-learn model, trained on the California Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html. The California Housing dataset was originally published in:\n",
    "\n",
    "> Pace, R. Kelley, and Ronald Barry. \"Sparse spatial auto-regressions.\" Statistics & Probability Letters 33.3 (1997): 291-297."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "export_dir = \"./model/\"\n",
    "\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "    print(\"Directory \", export_dir, \" Created \")\n",
    "else:\n",
    "    print(\"Directory \", export_dir, \" already exists\")\n",
    "\n",
    "model_archive_name = \"sk-model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/models/california-housing/model.joblib {export_dir}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tar the model and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cvpzf {model_archive_name} -C ./model \"model.joblib\" -C ../code \"inference.py\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the payload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_location = \"./sample-payload/\"\n",
    "\n",
    "if not os.path.exists(payload_location):\n",
    "    os.makedirs(payload_location)\n",
    "    print(\"Directory \", payload_location, \" Created \")\n",
    "else:\n",
    "    print(\"Directory \", payload_location, \" already exists\")\n",
    "\n",
    "payload_archive_name = \"sk_payload.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# we don't train a model, so we will need only the testing data\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "# Save testing data to CSV\n",
    "testX[data.feature_names].head(10).to_csv(\n",
    "    os.path.join(payload_location, \"test_data.csv\"), header=False, index=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tar the payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./sample-payload/ && tar czvf ../{payload_archive_name} *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Your model and payload to S3\n",
    "\n",
    "We will be uploading the pretrained model and corresponding test set as `sk-model.tar.gz` and as `sk_payload.tar.gz` to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"sagemaker/scikit-learn-inference-recommender\"\n",
    "\n",
    "model_url = sagemaker_session.upload_data(model_archive_name, key_prefix=prefix)\n",
    "sample_payload_url = sagemaker_session.upload_data(payload_archive_name, key_prefix=prefix)\n",
    "\n",
    "print(\"model uploaded to: {}\".format(model_url))\n",
    "print(\"sample payload uploaded to: {}\".format(sample_payload_url))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Model\n",
    "\n",
    "In this example we will create the model with SageMaker hosting `create_model` API, which will initiate an asynchronous workflow in the existing Inference Recommender stack. This workflow will generate recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker import image_uris\n",
    "\n",
    "model_name = \"sklearn-\" + str(round(time.time()))\n",
    "\n",
    "image = image_uris.retrieve(\n",
    "    framework=\"sklearn\", region=region, version=\"1.0-1\", image_scope=\"inference\"\n",
    ")\n",
    "primary_container = {\"Image\": image, \"ModelDataUrl\": model_url}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Describe the Model to Inspect Deployment Recommendations\n",
    "\n",
    "Deployment recommendations emitted in the SageMaker hosting `describe_model` API response itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_model_response = sm_client.describe_model(ModelName=model_name)\n",
    "\n",
    "print(describe_model_response)\n",
    "print(describe_model_response.deployment_recommendations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deploy the Model to Endpoint with Python SDK\n",
    "Each deployment recommendation is uniquely identified by `RecommendationId`. You can deploy specific recommendation with this ID with Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.sklearn.model import SKLearnPredictor\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=model_url,\n",
    "    role=role,\n",
    "    image_uri=image,\n",
    "    entry_point=\"./code/inference.py\",\n",
    "    framework_version=\"1.0-1\",\n",
    ")\n",
    "\n",
    "# Substitue recommendation_id with the one you want to deploy\n",
    "# Here we choose the first recommendation to deploy\n",
    "recommendation_id = describe_model_response[\"DeploymentRecommendation\"][\n",
    "    \"RealTimeInferenceRecommendations\"\n",
    "][0][\"RecommendationId\"]\n",
    "model.predictor_cls = SKLearnPredictor\n",
    "\n",
    "endpoint_name = \"notebook-test-\" + str(uuid.uuid4())\n",
    "predictor = model.deploy(recommendation_id=recommendation_id, endpoint_name=endpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Invoke the Endpoint & Produce Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "payload = pd.read_csv(\"./sample-payload/test_data.csv\")\n",
    "\n",
    "inference = predictor.predict(payload)\n",
    "\n",
    "print(inference)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean up the resources if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model and endpoint\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "This notebook illustrates how to use SageMaker Inference Recommender's new feature `DeploymentRecommendation` to get recommendations without running benchmarks, and use Python SDK `model.deploy` method to deploy the deployment recommendation with recommendation ID specified.\n",
    "\n",
    "The notebook works you through downloading a pre-trained scikit-learn model, creating the model which triggers deployment recommendation workflow, inspecting recommendations and deploying it, invoking endpoint to produce inference and cleaning up the resources created."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
