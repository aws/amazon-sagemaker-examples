{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Amazon SageMaker models by using the Deep Graph Library with PyTorch backend\n",
    "The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example, you train a simple graph neural network using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and the [Cora dataset](https://relational.fit.cvut.cz/dataset/CORA). The Cora dataset describes a citation network. The Cora dataset consists of 2,708 scientific publications classified into one of seven classes. The citation network consists of 5,429 links. The task is to train a node classification model using Cora dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Define a few variables that are needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to put your custom code.\n",
    "custom_code_upload_location = 'customcode'\n",
    "\n",
    "# IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "# You can use the Amazon SageMaker Python SDK to get the role from the notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training script\n",
    "The pytorch_gcn.py script provides all the code you need for training an Amazon SageMaker model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pytorch_gcn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker's  estimator class\n",
    "The Amazon SageMaker Estimator allows you to run single machine in Amazon SageMaker, using CPU or GPU-based instances.\n",
    "\n",
    "When you create the estimator, pass in the filename of the training script and the name of the IAM execution role. You can also provide a few other parameters. train_instance_count and train_instance_type determine the number and type of Amazon SageMaker instances that are used for the training job. The hyperparameters parameter is a dictionary of values that is passed to your training script as parameters so that you can use argparse to parse them. You can see how to access these values in the pytorch_gcn.py script above.\n",
    "\n",
    "Here, you can use the official Docker image for this example. For more information, see https://docs.aws.amazon.com/dlami/latest/devguide/deep-learning-containers-images.html. You should get the latest pytorch-1.3.1-gpu-py3 or pytorch-1.3.1-cpu-py3 image from official Amazon Elastic Container Registry (Amazon ECR) and push it into your own ECR.\n",
    "\n",
    "For this example, choose one ml.p3.2xlarge instance. You can also use a CPU instance such as ml.c4.2xlarge for the CPU image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "CODE_PATH = 'pytorch_gcn.py'\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "docker_name = 'beta-pytorch-training' # change this for your own ECR image name\n",
    "docker_tag = '1.3.1-py3-gpu-with-horovod-build' # change this for your own ECR image tag\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, docker_name, docker_tag)\n",
    "print(image)\n",
    "\n",
    "params = {}\n",
    "params['dataset'] = 'cora'\n",
    "estimator = PyTorch(entry_point=CODE_PATH,\n",
    "                        role=role, \n",
    "                        train_instance_count=1, \n",
    "                        train_instance_type='ml.p3.2xlarge', # 'ml.c4.2xlarge '\n",
    "                        image_name=image,\n",
    "                        hyperparameters=params,\n",
    "                        sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Training Job\n",
    "After you construct the Estimator object, fit it by using Amazon SageMaker. The dataset is automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "You can get the model training output from the Amazon Sagemaker console by searching for the training task named pytorch-gcn and looking for the address of 'S3 model artifact'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_dgl_py36_mxnet1.5",
   "language": "python",
   "name": "conda_dgl_py36_mxnet1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
