{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b12cc31-daeb-48c6-88ad-3c1ec76da1a4",
   "metadata": {},
   "source": [
    "## Use this file to compile the Stable Diffusion model using the AITemplate \n",
    "\n",
    "Alternately you can follow the method from AItemplate documented here at https://github.com/facebookincubator/AITemplate under the section docker install\n",
    "\n",
    "This below section uses the same technique except that it uses the DJL container to compile the model and so we do not need to create or download any other docker image. However this file assumes you have ECR login permissions to pull the DJL container image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9438ec0-3f16-4035-884f-9c353cce4b47",
   "metadata": {},
   "source": [
    "### Docker change data directory\n",
    "\n",
    "This is needed to ensure docker can utilize the mounted EBS volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ffeed-a507-4bf4-9de8-f6fbbc0dbbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -alrt /var/lib/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c98ec-3de8-4aea-9e7f-69861ebd9bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "#!/bin/bash\n",
    "\n",
    "rm -rf /home/ec2-user/SageMaker/docker_data_ait\n",
    "\n",
    "sudo service docker stop\n",
    "\n",
    "sudo mv /var/lib/docker /home/ec2-user/SageMaker/docker_data_ait\n",
    "\n",
    "\n",
    "sudo ln -s /home/ec2-user/SageMaker/docker_data_ait /var/lib/docker\n",
    "\n",
    "ls -alrt /var/lib/docker\n",
    "\n",
    "sudo service docker start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711f871-b2d0-4f6a-be7e-050a9ce5119e",
   "metadata": {},
   "source": [
    "### Clone the AITemplate \n",
    "\n",
    "under /home/ec2-user/SageMaker/compiled_ai_repo\n",
    "\n",
    "\n",
    "we will need to install GIT LFS needed to clone the repo. If you have the LFS installed already then run the git clone recursive command only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af4187-792f-4602-ac74-d89a1cdc1bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "\n",
    "sudo yum install git-lfs\n",
    "\n",
    "git lfs install\n",
    "\n",
    "mkdir -p /home/ec2-user/SageMaker/compiled_ai_repo/\n",
    "cd /home/ec2-user/SageMaker/compiled_ai_repo/\n",
    "git clone https://github.com/lanking520/AITemplate --recursive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded979b8-c55f-40af-994e-1b5b7e8787d5",
   "metadata": {},
   "source": [
    "### Over write the download file to remove the token \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026fd25b-0281-4e06-8414-4641f95321a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile /home/ec2-user/SageMaker/compiled_ai_repo/AITemplate/examples/05_stable_diffusion/scripts/download_pipeline.py\n",
    "#  Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "#\n",
    "import click\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--token\", default=\"\", help=\"access token\")\n",
    "@click.option(\n",
    "    \"--save_directory\",\n",
    "    default=\"./tmp/diffusers-pipeline/stabilityai/stable-diffusion-v2\",\n",
    "    help=\"pipeline files local directory\",\n",
    ")\n",
    "def download_pipeline_files(token, save_directory) -> None:\n",
    "    StableDiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-1-base\",\n",
    "        revision=\"fp16\",\n",
    "        torch_dtype=torch.float16,\n",
    "    ).save_pretrained(save_directory)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_pipeline_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b603e-c5cf-43ef-a79b-a48332ef68d1",
   "metadata": {},
   "source": [
    "### Build and install docker image  AITemplate with DJL container \n",
    "\n",
    "we wil use the DJL container to compile the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744d4b3-e99c-4afa-b408-df7d4a2419ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "\n",
    "\n",
    "djl_image_uri=\"763104351884.dkr.ecr.${region}.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.0-cu117\"\n",
    "login_img_uri=763104351884.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "echo $region\n",
    "echo $djl_image_uri\n",
    "echo $inference_image_uri\n",
    "echo \"image to used for compilations is $djl_image_uri\"\n",
    "\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin $login_img_uri\n",
    "\n",
    "docker pull $djl_image_uri\n",
    "\n",
    "docker tag $djl_image_uri djl-ait-sd\n",
    "\n",
    "docker images # this should list djl-ait-sd which can be used to login into and use as below \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666c591-dc2e-45b2-98da-3994930c598f",
   "metadata": {},
   "source": [
    "### Now compile and create the AIT weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71566add-740a-4a73-abc9-be2626adf614",
   "metadata": {},
   "source": [
    "#### To compile the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700efc1-65a7-4067-9bd1-c51f1d4ff6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cd /home/ec2-user/SageMaker/compiled_ai_repo\n",
    "sudo rm -rf tmp\n",
    "\n",
    "# to delete any previous weights\n",
    "cd /home/ec2-user/SageMaker/default_ai_repo/AITemplate/examples/05_stable_diffusion/scripts\n",
    "sudo rm -rf tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd9b55-018b-4d42-bd12-e6f9e2ef2973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile /home/ec2-user/SageMaker/compiled_ai_repo/generate_weights.sh\n",
    "\n",
    "pip3 install click\n",
    "cd /model_repository/AITemplate/examples/05_stable_diffusion/scripts \n",
    "\n",
    "# Compile models\n",
    "# -- this downloads and saves as diffusers-pipeline/ under /model_repository/AITemplate/examples/05_stable_diffusion/scripts/tmp\n",
    "# - this gets mapped too -- /home/ec2-user/SageMaker/compiled_ai_repo/AITemplate/examples/05_stable_diffusion/scripts/tmp\n",
    "python3 download_pipeline.py\n",
    "\n",
    "# - that is why --local-dir\",default=\"./tmp/diffusers-pipeline/stabilityai/stable-diffusion-v2\"  -- works\n",
    "# -- And all the weights are correctly under the ./tmp folder --\n",
    "# -- which is mapped too --  /home/ec2-user/SageMaker/default_ai_repo/AITemplate/examples/05_stable_diffusion/scripts/tmp\n",
    "python3 compile.py --local-dir ./tmp/diffusers-pipeline/stabilityai/stable-diffusion-v2 \n",
    "\n",
    "# -- use this if we were to GIT clone and use that instead -- but this creates a huge model weights size\n",
    "# python3 compile.py --local-dir /model_repository/stable-diffusion-2-1/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f890fc-8bf6-4fa3-acdf-43637499de1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# for DJL container -- use this\n",
    "\n",
    "cd /home/ec2-user/SageMaker/compiled_ai_repo\n",
    "\n",
    "docker run --gpus=all --shm-size=4G --rm -p8000:8000 -p8001:8001 -p8002:8002 -v$(pwd):/model_repository djl-ait-sd /bin/bash /model_repository/generate_weights.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f9eb5-aba1-458f-a07f-50760d26607f",
   "metadata": {},
   "source": [
    "### Copy the weights to S3 location\n",
    "\n",
    "old weights saved under s3://sagemaker-us-east-1-425576326687/raw_weights/stabilityai_working/aitemplate_g5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5e7a3-af4a-4f0d-8165-743d4f272bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls -alrt /home/ec2-user/SageMaker/compiled_ai_repo/AITemplate/examples/05_stable_diffusion/scripts/tmp\n",
    "\n",
    "cd /home/ec2-user/SageMaker/compiled_ai_repo/AITemplate/examples/05_stable_diffusion/scripts/tmp\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query \"Account\" --output text)\n",
    "\n",
    "echo $account\n",
    "echo $region\n",
    "\n",
    "aws s3 rm s3://sagemaker-${region}-${account}/raw_weights/stabilityai/aitemplate_g5/ --recursive\n",
    "aws s3 cp . s3://sagemaker-${region}-${account}/raw_weights/stabilityai/aitemplate_g5/ --recursive \n",
    "\n",
    "aws s3 ls s3://sagemaker-${region}-${account}/raw_weights/stabilityai/aitemplate_g5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb043e-e3ed-4a55-a784-917bea54e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \" please check your S3 location to ensure the weights have been copied to your S3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb45e1-b0cf-48e4-877f-f5105787fccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
