{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Images for Built-in Algorithms (Part 3/4)\n",
    "Download | Structure | **Preprocessing (Built-in)** | Train Model (Built-in)\n",
    "\n",
    "\n",
    "**Notes**: \n",
    "* This notebook should be used with the conda_amazonei_mxnet_p36 kernel\n",
    "* This notebook is part of a series of notebooks beginning with `01_download_data` and `02_structuring_data`. From here on it will focus on SageMaker's built-in algorithms. The next notebook in this series is `04a_builtin_training`.\n",
    "* You can also explore preprocessing with TensorFlow and PyTorch by running `03b_tensorflow_preprocessing` and `03c_pytorch_preprocessing`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore the different ways to format your image dataset for SageMaker's built-in algorithms. The first involves creating a manifest file for the train and validations sets and the other has you creating .REC files (RecordIO format) which are single binary files made up of all the images for the train and validation sets. Since the RecordIO format is preferred, we will upload the .REC files to S3 for training in the nedxt notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "* #### [Dependencies](#ipg3a.1)\n",
    "* #### [Application/x-image format](#ipg3a.2)\n",
    "* #### [Application/x-recordio format](#ipg3a.3) (preferred format)\n",
    "* #### [Upload the data to S3](#ipg3a.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ipg3a.1'></a>\n",
    "## Dependencies\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import boto3\n",
    "import shutil\n",
    "import urllib\n",
    "import pickle\n",
    "import pathlib\n",
    "import sagemaker\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Category Labels\n",
    "The `category_labels` file was generated from the first notebook in this series `01_download_data.ipynb`. You will need to run that notebook before running the code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_data/category_labels.pickle', 'rb') as f:\n",
    "    category_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ipg3a.2'></a>\n",
    "## Application/x-image format\n",
    "___\n",
    "\n",
    "This format is also referred to as \"Image Format\" or \"LST\" format. The benefit of using this format is that it doesn't require any modification or restructuring of your dataset. Instead, you create a manifest of the images for your training set and validation set. These two manifests are separate `.lst` files which list all the images giving each of them a unique index, the class they belong to and the relative path to the image file from the main training folder. The data in the `.lst` file is in tab separated values.\n",
    "\n",
    "While its the easiest format to use, it requires SageMaker to do more work behind the scenes. For datasets with many images, this will cause training to take longer. For datasets with fewer images, the performance difference isn't as pronounced.\n",
    "\n",
    "Below are two examples of how to create your .LST manifest files. One uses your own code and the other uses a script from MXNet. If you want to create .REC files of your images, you should skip to Option 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Manually generate the .LST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = {name: idx for idx, name in enumerate(sorted(category_labels.values()))}\n",
    "print(category_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = pathlib.Path('./data_structured').rglob('*.jpg')\n",
    "\n",
    "for idx, p in enumerate(image_paths):\n",
    "    image_id = f'{idx:010}'\n",
    "    category = category_ids[p.parts[-2]]\n",
    "    path = p.as_posix()\n",
    "    split = p.parts[-3]\n",
    "    with open(f'{split}.lst', 'a') as f:\n",
    "        line = f\"{image_id}\\t{category}\\t{path}\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the contents of the `train.lst` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head train.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Use im2rec.py script to generate the .LST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_url = 'https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py'\n",
    "urllib.request.urlretrieve(script_url, \"im2rec.py\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python im2rec.py --list --recursive LST_FILE_PREFIX DATA_DIR`\n",
    "* --list - generate an LST file\n",
    "* --recursive - looks inside subfolders for image data\n",
    "* LST_FILE_PREFIX - choose the name you want for the `.lst` file\n",
    "* DATA_DIR - relative path to directory with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py --list --recursive train data_structured/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py --list --recursive val data_structured/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the contents of the `train.lst` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head train.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ipg3a.3'></a>\n",
    "## Application/x-recordio (preferred format)\n",
    "___\n",
    "This format is commonly referred to as RecordIO. It creates a new file for your each of your training and validation datasets with the `.rec` suffix. The `.rec` file is a single file that contains all of the images in the dataset so it can be streamed directly to the SageMaker training algorithm without the overhead involved with transfering thousands of individual files. For datasets with many images this provides a huge reduction in training time because SageMaker doesn't need to download all the image files before it can run the training algorithm. If you use the `im2rec.py` script, it will also resize the images for you as well. The benefits of resizing the files before saving them in the RecordIO format is that it'll reduce the amount of data you need to transfer to s3 and will also speed up trainging by doing the resizing ahead of time instead of at training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Run Option 2 from application/x-image above and copy LST files\n",
    "Once you've run Option 2 from above then proceed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordio_dir = pathlib.Path('./data_recordio')\n",
    "recordio_dir.mkdir(exist_ok=True)\n",
    "shutil.copy('train.lst', 'data_recordio/');\n",
    "shutil.copy('val.lst', 'data_recordio/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate .rec files in the RecordIO Format\n",
    "Once the `.lst` file is generated, the same `im2rec.py` script will also generate the `.rec` file.\n",
    "\n",
    "`python im2rec.py --resize 224 --quality 90 --num-thread 16 LST_FILE_PREFIX DATA_DIR/`\n",
    "* **--resize**: Have the script resize the files before saving them all to a `.rec` file. For the image classification algorithm the default dimensions are 224x224. Resizing now will also reduce the size of your `.rec` file.\n",
    "* **--quality**: Default settings will save the image data uncompressed. Adding some compression will keep the filesize of your `.rec` down especially if you're not resizing them.\n",
    "* **--num_thread**: Set how many threads to parallelize the work\n",
    "* **--LST_FILE_PREFIX**: Name of the `.lst` you're referencing for creating the `.rec` file\n",
    "* **--DATA_DIR**: Relative path directory which holds the data listed in the `.lst` file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/train data_structured/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/val data_structured/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ipg3a.4'></a>\n",
    "## Upload the data to S3\n",
    "___\n",
    "In order for SageMaker's built-in algrorithms to train on the data, it must be stored in an S3 bucket. Here, we will create a bucket, but you can use an existing bucket if you like by replacing the `bucket_name` variable in the first line of the `else` statement below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bucket for your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pathlib.Path('pickled_data/builtin_bucket_name.pickle').exists():\n",
    "    with open('pickled_data/builtin_bucket_name.pickle', 'rb') as f:\n",
    "        bucket_name = pickle.load(f)\n",
    "        print('Bucket Name:', bucket_name)\n",
    "else:\n",
    "    bucket_name = f'sagemaker-builtin-ic-{str(uuid.uuid4())}'\n",
    "    s3 = boto3.resource('s3')\n",
    "    region = sagemaker.Session().boto_region_name\n",
    "    bucket_config = {'LocationConstraint': region}\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration=bucket_config)\n",
    "    \n",
    "    with open('pickled_data/builtin_bucket_name.pickle', 'wb') as f:\n",
    "        pickle.dump(bucket_name, f)\n",
    "    print('Bucket Name:', bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload .rec files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uploader = sagemaker.s3.S3Uploader()\n",
    "\n",
    "data_path = recordio_dir / 'train.rec'\n",
    "\n",
    "data_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), \n",
    "    desired_s3_uri=f's3://{bucket_name}/data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = recordio_dir / 'val.rec'\n",
    "\n",
    "data_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), \n",
    "    desired_s3_uri=f's3://{bucket_name}/data/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollback to default version of SDK and TensorFlow\n",
    "Only do this if you're done with this guide and want to use the same kernel for other notebooks with an incompatible version of the SageMaker SDK or TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Original version: {original_sagemaker_version[0]}')\n",
    "# print(f'Current version:  {sagemaker.__version__}')\n",
    "# print('')\n",
    "# print(f'Rolling back to {original_sagemaker_version[0]}')\n",
    "# print('Restart notebook kernel to use changes.')\n",
    "# print('')\n",
    "# s = f'sagemaker=={original_sagemaker_version[0]}'\n",
    "# !{sys.executable} -m pip install -q {s}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Now that the training and validation data has be uploaded to S3, the next notebook will use SageMaker's built-in Image Classification algorithm to train a deep learning model to classify the animal images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
