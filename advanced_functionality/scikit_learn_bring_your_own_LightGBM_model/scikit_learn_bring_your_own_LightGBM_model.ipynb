{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker `LightGBM` Bring Your Own Model\n",
    "_**Hosting a pre-trained `LightGBM` model in an Amazon SageMaker scikit-learn container**_\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon SageMaker includes functionality to support a hosted notebook environment, distributed, serverless training, and real-time hosting. We think it works best when all three of these services are used together, but they can also be used independently.  Some use cases may only require hosting.  Maybe the model was trained prior to Amazon SageMaker existing, in a different service.\n",
    "\n",
    "`LightGBM` is a gradient boosted decision tree algorithm for creating classifiers, regressors, and rankers. Although it is much like the SageMaker built-in `XGBoost` algorithm, it is reported to be the go-to algorithm for experimentation because it is faster and use less memory.\n",
    "\n",
    "We show how to use a pre-trained `LightGBM` regression model with the Amazon SageMaker scikit-learn container, including how to specify dependencies. Then, we register that model with the Amazon SageMaker model registry, which allows for version tracking. Finally, we use the registered model to batch transform test  data, as might be run from AWS Lambda, and also to create and use a real-time hosted endpoint.\n",
    "\n",
    "We use the California Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html. That dataset was originally published in:\n",
    "\n",
    "> Pace, R. Kelley, and Ronald Barry. \"Sparse spatial auto-regressions.\" Statistics & Probability Letters 33.3 (1997): 291-297.\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "Ensure we have the latest version of the SageMaker Python SDK. Also install `LightGBM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"sagemaker\", \"lightgbm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by specifying:\n",
    "\n",
    "* AWS region.\n",
    "* The IAM role arn used to give learning and hosting access to your data.\n",
    "* The S3 bucket that you want to use for training and model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role, image_uris, ModelPackage\n",
    "from sagemaker.sklearn.model import SKLearnModel, SKLearnPredictor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-sklearn-byo-model\"\n",
    "\n",
    "print(f\"bucket: {bucket}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for model inference\n",
    "\n",
    "We load the California housing dataset from sklearn, and split it into train and test datasets. We will use the former to train a regressor to predict house prices. And we will use the latter to compare model predictions to actual results. In a production situation, the model would be fine-tuned to greatly improve the quality of its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "\n",
    "testX.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pre-trained model file\n",
    "After creating the model, we use it to print predicted housing prices on a test sample of the data. Then, we print the actual values for comparison. You can use these results to compare what is later produced when the model is used for batch transformation or from a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "model = lgb.LGBMRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Predicted:\\t{model.predict(X_test[:5, :])}\")\n",
    "print(f\"Actual:\\t\\t{y_test[:5]}\")\n",
    "\n",
    "model_file_name = \"model.joblib\"\n",
    "\n",
    "joblib.dump(model, model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Inference Script\n",
    "\n",
    "When using endpoints with the Amazon SageMaker managed scikit-learn container, we need to provide an entry point script for inference that will **at least** load the saved model.\n",
    "\n",
    "After the SageMaker model server has loaded your model by calling `model_fn`, SageMaker will serve your model. Model serving is the process of responding to inference requests, received by SageMaker `InvokeEndpoint` API calls.\n",
    "\n",
    "\n",
    "We will implement also the `predict_fn()` function that takes the deserialized request object and performs inference against the loaded model.\n",
    "\n",
    "We will now create this script and call it `inference.py` and store it at the root of a directory called `code`.\n",
    "\n",
    "**Note:** You may modify the script below to implement your own inferencing logic.\n",
    "\n",
    "Additional information on model loading and model serving for scikit-learn on SageMaker can be found in the [SageMaker Scikit-learn Model Server documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#deploy-a-scikit-learn-model)\n",
    "\n",
    "There are also several functions for hosting which we won't define,\n",
    " - `input_fn()` - Takes request data and deserializes the data into an object for prediction.\n",
    " - `output_fn()` - Takes the result of prediction and serializes this according to the response content type.\n",
    "\n",
    "These will take on their default values as described in [SageMaker Scikit-learn Serve a Model documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#serve-a-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_path = \"./code\"\n",
    "model_code_inference = \"inference.py\"\n",
    "\n",
    "os.makedirs(model_code_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $model_code_path/$model_code_inference\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "\n",
    "def predict_fn(input_object, model):\n",
    "    ###########################################\n",
    "    # Do your custom preprocessing logic here #\n",
    "    ###########################################\n",
    "\n",
    "    print(\"calling model\")\n",
    "    predictions = model.predict(input_object)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print(\"loading model.joblib from: {}\".format(model_dir))\n",
    "    loaded_model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing additional Python dependencies\n",
    "\n",
    "It also may be necessary to supply a `requirements.txt` file to ensure that any necessary dependencies are installed in the container along with the script. For this script, we showcase how to install the `lightgbm` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $model_code_path/requirements.txt\n",
    "\n",
    "lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package the pre-trained model in `model.tar.gz` and upload it to S3\n",
    "The model file name must satisfy the regular expression pattern: `^[a-zA-Z0-9](-*[a-zA-Z0-9])*;`, and needs to be tar-zipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tar_name = \"model.tar.gz\"\n",
    "with tarfile.open(model_tar_name, \"w:gz\") as tar:\n",
    "    tar.add(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the model to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.path.join(prefix, model_tar_name)\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(model_tar_name, bucket, key)\n",
    "model_data = f\"s3://{bucket}/{key}\"\n",
    "print(f\"model data: {model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Here we showcase the process of creating a model from S3 artifacts. This can be used to deploy a model that was trained in a different session or even out of SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SKLearnModel(\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=model_code_path,\n",
    "    entry_point=model_code_inference,\n",
    "    sagemaker_session=sagemaker.Session(),  # Required for model.register().\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model version\n",
    "Create a model group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "model_package_group_name = \"scikit-housing-prediction\" + str(round(time.time()))\n",
    "model_package_group_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"ModelPackageGroupDescription\": \"For predicting ln(median house value)\",\n",
    "}\n",
    "\n",
    "create_model_pacakge_group_response = sm_client.create_model_package_group(\n",
    "    **model_package_group_input_dict\n",
    ")\n",
    "model_package_group_arn = create_model_pacakge_group_response[\"ModelPackageGroupArn\"]\n",
    "print(\"ModelPackageGroup Arn : {}\".format(model_package_group_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the model to the model group. Repeatedly running this cell for the same model group would register as new versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package = model.register(\n",
    "    content_types=[\"text/csv\", \"application/json\"],\n",
    "    response_types=[\"text/csv\", \"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    description=\"Predict house values\",\n",
    "    approval_status=\"Approved\",\n",
    ")\n",
    "model_package_arn = model_package.model_package_arn\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch transform data\n",
    "\n",
    "Upload the test data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_test.csv\", X_test, delimiter=\",\")\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "X_test_prefix = f\"{prefix}/input/X_test.csv\"\n",
    "s3.upload_file(\"X_test.csv\", bucket, X_test_prefix)\n",
    "X_test_S3 = f\"s3://{bucket}/{X_test_prefix}\"\n",
    "output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "print(X_test_S3)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model using a model package ARN, and use it to create a transformer to process the test data. This code could be used in an AWS Lambda function to get a model artifact, and then run it on a dataset in S3. This code will take 5-7 minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_from_package = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package_arn,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    ")\n",
    "\n",
    "transformer = model_from_package.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m5.large\", output_path=output_path\n",
    ")\n",
    "\n",
    "transformer.transform(X_test_S3, content_type=\"text/csv\", split_type=\"Line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the data will take 5-7 minutes to complete. The code in this cell can be used to wait for the data processing to complete in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the batch transform results and print them. You can compare these results to those that were obtained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket, f\"{prefix}/output/X_test.csv.out\", \"X_test.csv.out\")\n",
    "\n",
    "with open(\"X_test.csv.out\", \"r\") as f:\n",
    "    X_test_out = json.load(f)\n",
    "\n",
    "print(f\"Predicted:\\t{X_test_out[:5]}\")\n",
    "print(f\"Actual:\\t\\t{y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data using a real-time endpoint\n",
    "Create an endpoint that serves up the model through specifying a name and the model obtained from the model package ARN. The end result is an endpoint that can be validated and incorporated into production applications. This takes 5-10 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "endpoint_name = f\"scikit-housing-prediction-{str(round(time.time()))}\"\n",
    "model_from_package.deploy(\n",
    "    instance_type=\"ml.t2.medium\", initial_instance_count=1, endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a predictor to access the endpoint. Then use it to generate a prediction using the test dataset. You can compare these results to those that were obtained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "predictor = SKLearnPredictor(endpoint_name=endpoint_name)\n",
    "predictions = predictor.predict(testX[data.feature_names])\n",
    "\n",
    "print(f\"Predicted:\\t{predictions[:5]}\")\n",
    "print(f\"Actual:\\t\\t{y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In using this notebook, you've learned how to package a model created outside of SageMaker along with its dependencies for use in SageMaker. You've also learned how to register the model in the SageMaker model registry for versioning. You've seen how to use a registered model for doing a batch transform, such as you might run in a Lambda, and how to get the transform results. Finally, you've seen how to deploy a registered model to a real-time endpoint, and how to use the endpoint to make predictions, such as you might do in production.\n",
    "\n",
    "You can now apply what you've learned to manage and deploy your own models using SageMaker.\n",
    "\n",
    "## Cleanup\n",
    "If you're ready to be done with the endpoint you last created, please run the delete_endpoint line in the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
