huggingface:
  model: "meta-llama/Llama-2-70b-chat-hf"
  revision: "e9149a12809580e8602995856f8098ce973d1080"
  download: true
djl:
  engine: "MPI"
  option.entryPoint: "djl_python.tensorrt_llm"
  option.tensor_parallel_degree: 8
  option.max_input_len: 1024
  option.max_output_len: 2048
  option.use_custom_all_reduce: true
  option.dtype: "fp16"
  option.use_fused_mlp: true
  option.multi_query_mode: true
  option.model_loading_timeout: 3600
sagemaker:
  model:
    name: "llama-2-70b-chat-hf-tensorrt-llm"
    image: "807253771232.dkr.ecr.us-west-2.amazonaws.com/lmi-djl-serving:0.27.0-tensorrt-llm"
    env: 
      HUGGINGFACE_HUB_CACHE: "/tmp"
      TRANSFORMERS_CACHE: "/tmp"
  endpoint:
    name: "llama-2-70b-chat-hf-tensorrt-llm"
    instance_type: "ml.p4d.24xlarge"
    initial_instance_count: 1
    variant_name: "test"
    model_data_download_timeout_secs: 3600
    container_startup_health_check_timeout_secs: 1800
test:
  module_name: "prompt_generator"
  module_dir: "modules/inst-semeval2017"
  prompt_generator: "PromptGenerator"
  params: { "do_sample": true, "max_new_tokens": 1024, "top_k": 50 }
  warmup_iters: 1
  max_iters: 10
  output_dir: "output/llama-2-70b-chat-hf/tensorrt-llm"