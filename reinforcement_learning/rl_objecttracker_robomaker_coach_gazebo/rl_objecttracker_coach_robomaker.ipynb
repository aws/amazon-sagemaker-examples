{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Object Tracker RL training with Amazon SageMaker RL and RoboMaker\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In this notebook, we show you how you can apply reinforcement learning to train a Robot (named Waffle) track and follow another Robot (named Burger) by using the [Clipped PPO](https://coach.nervanasys.com/algorithms/policy_optimization/cppo/index.html)  algorithm implementation in [coach](https://ai.intel.com/r-l-coach/) toolkit, [Tensorflow](https://www.tensorflow.org/) as the deep learning framework, and [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) as the simulation environment.\n",
    "\n",
    "![Training in Action](./object-tracker-world.jpg)\n",
    "\n",
    "---\n",
    "## How it works?  \n",
    "\n",
    "\n",
    "The reinforcement learning agent (i.e. Waffle) learns to track and follow Burger by interacting with its environment, e.g., visual world around it, by taking an action in a given state to maximize the expected reward. The agent learns the optimal plan of actions in training by trial-and-error through multiple episodes.  \n",
    "  \n",
    "This notebook shows an example of distributed RL training across SageMaker and two RoboMaker simulation envrionments that perform the **rollouts** - execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with SageMaker for training. SageMaker updates the model policy which is then used to execute the next sequence of rollouts. This training loop continues until the model converges, i.e. the car learns to drive and stops going off-track. More formally, we can define the problem in terms of the following:  \n",
    "\n",
    "1. **Objective**: Learn to drive toward and reach the Burger.\n",
    "2. **Environment**: A simulator with Burger hosted on AWS RoboMaker.\n",
    "3. **State**: The driving POV image captured by the Waffle's head camera.\n",
    "4. **Action**: Six discrete steering wheel positions at different angles (configurable)\n",
    "5. **Reward**: Reward is inversely proportional to distance from Burger. Waffle gets more reward as it get closer to the Burger. It gets a reward of 0 if the action takes it away from Burger. \n",
    "\n",
    "---\n",
    "## Prequisites\n",
    "### Imports\n",
    "To get started, we'll import the Python libraries we need, set up the environment with a few prerequisites for permissions and configurations.\n",
    "\n",
    "You can run this notebook from your local host or from a SageMaker notebook instance. In both of these scenarios, you can run the following to launch a training job on `SageMaker` and a simulation job on `RoboMaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from IPython.display import Markdown\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "sys.path.append(\"common\")\n",
    "from misc import get_execution_role\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from markdown_helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket\n",
    "sage_session = sagemaker.session.Session()\n",
    "s3_bucket = sage_session.default_bucket()\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket) # SDK appends the job name and output folder\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables\n",
    "\n",
    "We define variables such as the job prefix for the training jobs and s3_prefix for storing metadata required for synchronization between the training and simulation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique job name \n",
    "job_name_prefix = 'rl-object-tracker'\n",
    "\n",
    "# create unique job name\n",
    "job_name = s3_prefix = job_name_prefix + \"-sagemaker-\" + strftime(\"%y%m%d-%H%M%S\", gmtime())\n",
    "\n",
    "# Duration of job in seconds (5 hours)\n",
    "job_duration_in_seconds = 3600 * 5\n",
    "\n",
    "aws_region = sage_session.boto_region_name\n",
    "print(\"S3 bucket path: {}{}\".format(s3_output_path, job_name))\n",
    "\n",
    "\n",
    "if aws_region not in [\"us-west-2\", \"us-east-1\", \"eu-west-1\"]:\n",
    "    raise Exception(\"This notebook uses RoboMaker which is available only in US East (N. Virginia), US West (Oregon) and EU (Ireland). Please switch to one of these regions.\")\n",
    "print(\"Model checkpoints and other metadata will be stored at: {}{}\".format(s3_output_path, job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an IAM role\n",
    "Either get the execution role when running from a SageMaker notebook `role = sagemaker.get_execution_role()` or, when running from local machine, use utils method `role = get_execution_role('role_name')` to create an execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except:\n",
    "    role = get_execution_role('sagemaker')\n",
    "\n",
    "print(\"Using IAM role arn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permission setup for invoking AWS RoboMaker from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to enable this notebook to be able to execute AWS RoboMaker jobs, we need to add one trust relationship to the default execution role of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(generate_help_for_robomaker_trust_relationship(role)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure VPC\n",
    "\n",
    "Since SageMaker and RoboMaker have to communicate with each other over the network, both of these services need to run in VPC mode. This can be done by supplying subnets and security groups to the job launching scripts.  \n",
    "We will use the default VPC configuration for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "default_vpc = [vpc['VpcId'] for vpc in ec2.describe_vpcs()['Vpcs'] if vpc[\"IsDefault\"] == True][0]\n",
    "\n",
    "default_security_groups = [group[\"GroupId\"] for group in ec2.describe_security_groups()['SecurityGroups'] \\\n",
    "                   if group[\"GroupName\"] == \"default\" and group[\"VpcId\"] == default_vpc]\n",
    "\n",
    "default_subnets = [subnet[\"SubnetId\"] for subnet in ec2.describe_subnets()[\"Subnets\"] \\\n",
    "                  if subnet[\"VpcId\"] == default_vpc and subnet['DefaultForAz']==True]\n",
    "\n",
    "print(\"Using default VPC:\", default_vpc)\n",
    "print(\"Using default security group:\", default_security_groups)\n",
    "print(\"Using default subnets:\", default_subnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SageMaker job running in VPC mode cannot access S3 resourcs. So, we need to create a VPC S3 endpoint to allow S3 access from SageMaker container. To learn more about the VPC mode, please visit [this link.](https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The cell below should be executed to create the VPC S3 endpoint only if your are running this example for the first time. If the execution fails due to insufficient premissions or some other reasons, please create a VPC S3 endpoint manually by following [create-s3-endpoint.md](create-s3-endpoint.md) (can be found in the same folder as this notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    route_tables = [route_table[\"RouteTableId\"] for route_table in ec2.describe_route_tables()['RouteTables']\\\n",
    "                if route_table['VpcId'] == default_vpc]\n",
    "except Exception as e:\n",
    "    if \"UnauthorizedOperation\" in str(e):\n",
    "        display(Markdown(generate_help_for_s3_endpoint_permissions(role)))\n",
    "    else:\n",
    "        display(Markdown(create_s3_endpoint_manually(aws_region, default_vpc)))\n",
    "    raise e\n",
    "\n",
    "print(\"Trying to attach S3 endpoints to the following route tables:\", route_tables)\n",
    "\n",
    "assert len(route_tables) >= 1, \"No route tables were found. Please follow the VPC S3 endpoint creation \"\\\n",
    "                              \"guide by clicking the above link.\"\n",
    "\n",
    "try:\n",
    "    ec2.create_vpc_endpoint(DryRun=False,\n",
    "                           VpcEndpointType=\"Gateway\",\n",
    "                           VpcId=default_vpc,\n",
    "                           ServiceName=\"com.amazonaws.{}.s3\".format(aws_region),\n",
    "                           RouteTableIds=route_tables)\n",
    "    print(\"S3 endpoint created successfully!\")\n",
    "except Exception as e:\n",
    "    if \"RouteAlreadyExists\" in str(e):\n",
    "        print(\"S3 endpoint already exists.\")\n",
    "    elif \"UnauthorizedOperation\" in str(e):\n",
    "        display(Markdown(generate_help_for_s3_endpoint_permissions(role)))\n",
    "        raise e\n",
    "    else:\n",
    "        display(Markdown(create_s3_endpoint_manually(aws_region, default_vpc)))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is defined in a Python file called “object_tracker_env.py” and the file can be found at `src/robomaker/environments/`. This file implements the gym interface for our Gazebo based RoboMakersimulator. This is a common environment file used by both SageMaker and RoboMaker. The environment variable - `NODE_TYPE` defines which node the code is running on. So, the expressions that have `rospy` dependencies are executed on RoboMaker only.  \n",
    "\n",
    "We can experiment with different reward functions by modifying `reward_function` in this file. Action space and steering angles can be changed by modifying the step method in `TurtleBot3ObjectTrackerAndFollowerDiscreteEnv` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the preset for RL algorithm\n",
    "The parameters that configure the RL training job are defined in `src/robomaker/presets/object_tracker.py`. Using the preset file, you can define agent parameters to select the specific agent algorithm. We suggest using Clipped PPO for this example.  \n",
    "You can edit this file to modify algorithm parameters like learning_rate, neural network structure, batch_size, discount factor etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/robomaker/presets/object_tracker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Entrypoint\n",
    "The training code is written in the file “training_worker.py” which is uploaded in the /src directory. At a high level, it does the following:\n",
    "- Uploads SageMaker node's IP address.\n",
    "- Starts a Redis server which receives agent experiences sent by rollout worker[s] (RoboMaker simulator).\n",
    "- Trains the model everytime after a certain number of episodes are received.\n",
    "- Uploads the new model weights on S3. The rollout workers then update their model to execute the next set of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see the training code\n",
    "#!pygmentize src/training_worker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using Python SDK/ script mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = \"s3://%s/%s\" % (s3_bucket, s3_prefix)\n",
    "!aws s3 rm --recursive {s3_location}\n",
    "\n",
    "\n",
    "# Make any changes to the envrironment and preset files below and upload these files if you want to use custom environment and preset\n",
    "!aws s3 cp src/robomaker/environments/ {s3_location}/environments/ --recursive --exclude \".ipynb_checkpoints*\"\n",
    "!aws s3 cp src/robomaker/presets/ {s3_location}/presets/ --recursive --exclude \".ipynb_checkpoints*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the following algorithm metrics that we want to capture from cloudwatch logs to monitor the training progress. These are algorithm specific parameters and might change for different algorithm. We use [Clipped PPO](https://coach.nervanasys.com/algorithms/policy_optimization/cppo/index.html) for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    # Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=-102.88, Steps=19019, Training iteration=1\n",
    "    {'Name': 'reward-training',\n",
    "     'Regex': '^Training>.*Total reward=(.*?),'},\n",
    "    \n",
    "    # Policy training> Surrogate loss=-0.32664725184440613, KL divergence=7.255815035023261e-06, Entropy=2.83156156539917, training epoch=0, learning_rate=0.00025\n",
    "    {'Name': 'ppo-surrogate-loss',\n",
    "     'Regex': '^Policy training>.*Surrogate loss=(.*?),'},\n",
    "     {'Name': 'ppo-entropy',\n",
    "     'Regex': '^Policy training>.*Entropy=(.*?),'},\n",
    "   \n",
    "    # Testing> Name=main_level/agent, Worker=0, Episode=19, Total reward=1359.12, Steps=20015, Training iteration=2\n",
    "    {'Name': 'reward-testing',\n",
    "     'Regex': '^Testing>.*Total reward=(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the RLEstimator for training RL jobs.\n",
    "\n",
    "1. Specify the source directory where the environment, presets and training code is uploaded.\n",
    "2. Specify the entry point as the training code\n",
    "3. Specify the choice of RL toolkit and framework. This automatically resolves to the ECR path for the RL Container.\n",
    "4. Define the training parameters such as the instance count, instance type, job name, s3_bucket and s3_prefix for storing model checkpoints and metadata. **Only 1 training instance is supported for now.**\n",
    "4. Set the RLCOACH_PRESET as \"object_tracker\" for this example.\n",
    "5. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RLCOACH_PRESET = \"object_tracker\"\n",
    "\n",
    "instance_type = \"ml.c5.4xlarge\"\n",
    "    \n",
    "estimator = RLEstimator(entry_point=\"training_worker.py\",\n",
    "                        source_dir='src',\n",
    "                        dependencies=[\"common/sagemaker_rl\"],\n",
    "                        toolkit=RLToolkit.COACH,\n",
    "                        toolkit_version='0.11',\n",
    "                        framework=RLFramework.TENSORFLOW,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        train_max_run=job_duration_in_seconds,\n",
    "                        hyperparameters={\"s3_bucket\": s3_bucket,\n",
    "                                         \"s3_prefix\": s3_prefix,\n",
    "                                         \"aws_region\": aws_region,\n",
    "                                         \"RLCOACH_PRESET\": RLCOACH_PRESET,\n",
    "                                      },\n",
    "                        metric_definitions = metric_definitions,\n",
    "                        subnets=default_subnets,\n",
    "                        security_group_ids=default_security_groups,\n",
    "                    )\n",
    "\n",
    "estimator.fit(job_name=job_name, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Robomaker job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import UnknownServiceError\n",
    "\n",
    "robomaker = boto3.client(\"robomaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simulation Application\n",
    "\n",
    "We first create a RoboMaker simulation application using the `object-tracker public bundle`. Please refer to [RoboMaker Sample Application Github Repository](https://github.com/aws-robotics/aws-robomaker-sample-application-objecttracker) if you want to learn more about this bundle or modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_s3_key = 'object-tracker/simulation_ws.tar.gz'\n",
    "bundle_source = {'s3Bucket': s3_bucket,\n",
    "                 's3Key': bundle_s3_key,\n",
    "                 'architecture': \"X86_64\"}\n",
    "simulation_software_suite={'name': 'Gazebo',\n",
    "                           'version': '7'}\n",
    "robot_software_suite={'name': 'ROS',\n",
    "                      'version': 'Kinetic'}\n",
    "rendering_engine={'name': 'OGRE',\n",
    "                  'version': '1.x'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_application_bundle_location = \"https://s3-us-west-2.amazonaws.com/robomaker-applications-us-west-2-11d8d0439f6a/object-tracker/object-tracker-1.0.80.0.1.0.130.0/simulation_ws.tar.gz\"\n",
    "\n",
    "!wget {simulation_application_bundle_location}\n",
    "!aws s3 cp simulation_ws.tar.gz s3://{s3_bucket}/{bundle_s3_key}\n",
    "!rm simulation_ws.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = \"object-tracker-sample-application\" + strftime(\"%y%m%d-%H%M%S\", gmtime())\n",
    "\n",
    "try:\n",
    "    response = robomaker.create_simulation_application(name=app_name,\n",
    "                                                   sources=[bundle_source],\n",
    "                                                   simulationSoftwareSuite=simulation_software_suite,\n",
    "                                                   robotSoftwareSuite=robot_software_suite,\n",
    "                                                   renderingEngine=rendering_engine\n",
    "                                                  )\n",
    "    simulation_app_arn = response[\"arn\"]\n",
    "    print(\"Created a new simulation app with ARN:\", simulation_app_arn)\n",
    "except Exception as e:\n",
    "    if \"AccessDeniedException\" in str(e):\n",
    "        display(Markdown(generate_help_for_robomaker_all_permissions(role)))\n",
    "        raise e\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Simulation job on RoboMaker\n",
    "\n",
    "We create [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) Simulation Jobs that simulates the environment and shares this data with SageMaker for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulation_workers = 1\n",
    "\n",
    "envriron_vars = {\n",
    "                 \"MODEL_S3_BUCKET\": s3_bucket,\n",
    "                 \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "                 \"ROS_AWS_REGION\": aws_region,\n",
    "                 \"MARKOV_PRESET_FILE\": \"object_tracker.py\",\n",
    "                 \"NUMBER_OF_ROLLOUT_WORKERS\": str(num_simulation_workers)}\n",
    "\n",
    "simulation_application = {\"application\":simulation_app_arn,\n",
    "                          \"launchConfig\": {\"packageName\": \"object_tracker_simulation\",\n",
    "                                           \"launchFile\": \"distributed_training.launch\",\n",
    "                                           \"environmentVariables\": envriron_vars}\n",
    "                         }\n",
    "                            \n",
    "vpcConfig = {\"subnets\": default_subnets,\n",
    "             \"securityGroups\": default_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "responses = []\n",
    "for job_no in range(num_simulation_workers):\n",
    "    response =  robomaker.create_simulation_job(iamRole=role,\n",
    "                                            clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                            maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                            failureBehavior=\"Continue\",\n",
    "                                            simulationApplications=[simulation_application],\n",
    "                                            vpcConfig=vpcConfig\n",
    "                                            )\n",
    "    responses.append(response)\n",
    "\n",
    "print(\"Created the following jobs:\")\n",
    "job_arns = [response[\"arn\"] for response in responses]\n",
    "for job_arn in job_arns:\n",
    "    print(\"Job ARN\", job_arn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the simulations in RoboMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visit the RoboMaker console to visualize the simulations or run the following cell to generate the hyperlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(generate_robomaker_links(job_arns, aws_region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cells below if you want to kill RoboMaker and SageMaker job. It also removes RoboMaker resources created during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_arn in job_arns:\n",
    "    robomaker.cancel_simulation_job(job=job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session.sagemaker_client.stop_training_job(TrainingJobName=estimator._current_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envriron_vars = {\"MODEL_S3_BUCKET\": s3_bucket,\n",
    "                 \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "                 \"ROS_AWS_REGION\": aws_region,\n",
    "                 \"NUMBER_OF_TRIALS\": str(20),\n",
    "                 \"MARKOV_PRESET_FILE\": \"%s.py\" % RLCOACH_PRESET\n",
    "                 }\n",
    "\n",
    "simulation_application = {\"application\":simulation_app_arn,\n",
    "                          \"launchConfig\": {\"packageName\": \"object_tracker_simulation\",\n",
    "                                           \"launchFile\": \"evaluation.launch\",\n",
    "                                           \"environmentVariables\": envriron_vars}\n",
    "                         }\n",
    "                            \n",
    "vpcConfig = {\"subnets\": default_subnets,\n",
    "             \"securityGroups\": default_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "\n",
    "\n",
    "response =  robomaker.create_simulation_job(iamRole=role,\n",
    "                                        clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                        maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                        failureBehavior=\"Continue\",\n",
    "                                        simulationApplications=[simulation_application],\n",
    "                                        vpcConfig=vpcConfig\n",
    "                                        )\n",
    "print(\"Created the following job:\")\n",
    "print(\"Job ARN\", response[\"arn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Simulation Application Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robomaker.delete_simulation_application(application=simulation_app_arn)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
