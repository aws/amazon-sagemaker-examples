{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6bb2cd",
   "metadata": {},
   "source": [
    "# SageMaker Serverless Inference\n",
    "## Sklearn Regression Example\n",
    "\n",
    "Amazon SageMaker Serverless Inference is a purpose-built inference option that makes it easy for customers to deploy and scale ML models. Serverless Inference is ideal for workloads which have idle periods between traffic spurts and can tolerate cold starts. Serverless endpoints also automatically launch compute resources and scale them in and out depending on traffic, eliminating the need to choose instance types or manage scaling policies.\n",
    "\n",
    "For this notebook we'll be working with the a custom Sklearn model to train a model and then deploy a serverless endpoint. We will be using the public S3 California housing dataset for this example.\n",
    "\n",
    "<b>Update: </b>\n",
    "SageMaker Serverless Inference is now supported by the [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-serverless-inference). This makes it very easy to deploy Serverless models that you are also training on SageMaker. As an alternative you can also use the general Boto3 Python SDK to create Serverless models, you can find an example notebook [here](https://github.com/aws/amazon-sagemaker-examples/blob/master/serverless-inference/Serverless-Inference-Walkthrough.ipynb).\n",
    "\n",
    "<b>Notebook Setting</b>\n",
    "- <b>SageMaker Classic Notebook Instance</b>: ml.m5.xlarge Notebook Instance & conda_python3 Kernel\n",
    "- <b>SageMaker Studio</b>: Python 3 (Data Science)\n",
    "- <b>Regions Available</b>: SageMaker Serverless Inference is currently available in the following regions: US East (Northern Virginia), US East (Ohio), US West (Oregon), EU (Ireland), Asia Pacific (Tokyo) and Asia Pacific (Sydney)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf1443",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Setup\n",
    "- Model Training\n",
    "- Deployment\n",
    "- Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80c3d6",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For testing you need to properly configure your Notebook Role to have <b>SageMaker Full Access</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991e661",
   "metadata": {},
   "source": [
    "Let's start by making sure to have the latest version of sagemaker, boto3, and the awscli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sagemaker botocore boto3 awscli --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5ff71",
   "metadata": {},
   "source": [
    "## SageMaker Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ac2e9",
   "metadata": {},
   "source": [
    "To begin, we import the AWS SDK for Python (Boto3) and set up our environment, including an IAM role and an S3 bucket to store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ac8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "base_job_prefix = \"sklearn-example\"\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = base_job_prefix\n",
    "\n",
    "training_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ace46e",
   "metadata": {},
   "source": [
    "Retrieve the California Housing dataset from a publicly hosted S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data\n",
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/california_housing/cal_housing.tgz .\n",
    "!tar -zxf cal_housing.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d17d7",
   "metadata": {},
   "source": [
    "Create a dataframe from the California housing dataset that we can upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1cb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "    \"medianHouseValue\",\n",
    "]\n",
    "df = pd.read_csv(\"CaliforniaHousing/cal_housing.data\", names=columns, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b9ec9",
   "metadata": {},
   "source": [
    "Split the data for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5120c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data in 80-20 split to use testing data for model inference later\n",
    "train = df.iloc[:16000,:]\n",
    "test = df.iloc[16001:,:]\n",
    "#Train and test csv\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594726e7",
   "metadata": {},
   "source": [
    "Upload data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sagemaker session to be able to upload data to s3\n",
    "prefix = \"sklearn-cal-housing\"\n",
    "training_input_path = sagemaker_session.upload_data('train.csv', key_prefix=prefix + '/training')\n",
    "training_input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify data uploaded properly\n",
    "training_data = pd.read_csv(training_input_path, sep = ',')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c03f81",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d8267",
   "metadata": {},
   "source": [
    "Now, we train a custom model using our Sklearn training script. In this example, we also provide [inference handler functions](https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html) to work with input and output functionality for inference, feel free to adjust this for how you want your endpoint to ingest and respond to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5049989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Docs: https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html\n",
    "from sagemaker.sklearn import SKLearn\n",
    "sk_estimator = SKLearn(entry_point='train.py', \n",
    "                          role=role,\n",
    "                          instance_count=1, \n",
    "                          instance_type='ml.c5.18xlarge',\n",
    "                          py_version='py3',\n",
    "                          framework_version='0.23-1',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={\n",
    "                              'estimators': 20\n",
    "                          }\n",
    "                         )\n",
    "\n",
    "#Training\n",
    "sk_estimator.fit({'train': training_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3b0ce",
   "metadata": {},
   "source": [
    "## Create Serverless Config Using The SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c236d2",
   "metadata": {},
   "source": [
    "For Serverless Inference you need two parameters: Memory Size and Max Concurrency. The current max concurrent invocations for a single endpoint, known as <b>MaxConcurrency</b>, can be any value from <b>1 to 50</b>, and <b>MemorySize</b> can be any of the following: <b>1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40207f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "serverless_config = ServerlessInferenceConfig(memory_size_in_mb=4096, max_concurrency=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c2e89f",
   "metadata": {},
   "source": [
    "## Deploy Serverless Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import gmtime, strftime\n",
    "endpoint_name = \"sklearn-serverless-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_estimator.deploy(endpoint_name = endpoint_name, serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc59e12",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Let's invoke the endpoint with a sample data point from our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sample data point\n",
    "import json\n",
    "samp = pd.read_csv('train.csv')\n",
    "samp = samp.drop('medianHouseValue', 1)\n",
    "samp = samp[:1]\n",
    "request_body = {\"Input\": samp.values.tolist()}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd921d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "content_type = \"application/json\"\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    Body=payload)\n",
    "result = json.loads(response['Body'].read().decode())['Output']\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
