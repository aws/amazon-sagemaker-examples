{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking.payload import create_test_payload\n",
    "\"\"\"\n",
    "1. Add ability to create the endpoint within the notebook considering you will run this notebook \n",
    "within the same instance where the endpoint is being hosted.\n",
    "=> problem: the cell will not end as the server starts listening.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PAYLOADS = {\n",
    "     \"input_32_output_128\": create_test_payload(input_words=32, output_tokens=128),\n",
    "    #\"input_128_output_128\": create_test_payload(input_words=128, output_tokens=128),\n",
    "    #\"input_512_output_128\": create_test_payload(input_words=512, output_tokens=128),\n",
    "    # \"input_6400_output_128\": create_test_payload(input_words=6400, output_tokens=128),\n",
    "    # \"input_128_output_512\": create_test_payload(input_words=128, output_tokens=512),\n",
    "    # \"input_512_output_512\": create_test_payload(input_words=512, output_tokens=512),\n",
    "    #\"input_512_output_1024\": create_test_payload(input_words=512, output_tokens=1024),\n",
    "}\n",
    "\n",
    "MODELS = {\n",
    "    #\"code-llama-7b-url\": {\n",
    "    #    \"endpoint_url\": \"http://127.0.0.1:8080/invocations\",\n",
    "    #    \"huggingface_model_id\": \"codellama/CodeLlama-7b-hf\",\n",
    "    #    \"instance_type\": \"ml.p4d.24xlarge\"\n",
    "    #},\n",
    "    #\"code-llama-70b-url\": {\n",
    "    #    \"endpoint_url\": \"http://127.0.0.1:8080/invocations\",\n",
    "    #    \"huggingface_model_id\": \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "    #    \"instance_type\": \"ml.p4d.24xlarge\"\n",
    "    #},\n",
    "    \"code-llama-7b-sm-url\": {\n",
    "        \"endpoint_url\": \"https://runtime.sagemaker.us-west-2.amazonaws.com/endpoints/lmi-model-2023-11-15-19-45-28-337/invocations\",\n",
    "        \"huggingface_model_id\": \"codellama/CodeLlama-7b-hf\",\n",
    "        \"instance_type\": \"ml.g5.12xlarge\"\n",
    "    },\n",
    "    #\"code-llama-70b-sm-url\": {\n",
    "    #    \"endpoint_url\": \"https://runtime.sagemaker.us-west-2.amazonaws.com/endpoints/lmi-model-2023-11-14-21-35-06-738/invocations\",\n",
    "    #    \"huggingface_model_id\": \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "    #    \"instance_type\": \"ml.p4d.24xlarge\"\n",
    "    #},\n",
    "    #\"code-llama-7b\": {\n",
    "    #    \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-codellama-7b\", \"instance_type\": \"ml.p4d.24xlarge\"}},\n",
    "    #    \"huggingface_model_id\": \"codellama/CodeLlama-7b-hf\",\n",
    "    #},\n",
    "    #\"code-llama-7b\": {\n",
    "    #    \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-codellama-7b\", \"instance_type\": \"ml.p4d.24xlarge\"}},\n",
    "    #    \"huggingface_model_id\": \"codellama/CodeLlama-7b-hf\",\n",
    "    #},\n",
    "    #\"llama-2-70b\": {\n",
    "    #    \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-70b\"}},\n",
    "    #    \"huggingface_model_id\": \"TheBloke/Llama-2-70B-fp16\",\n",
    "    #},\n",
    "    # \"mistral-7b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-mistral-7b\"}},\n",
    "    #     \"huggingface_model_id\": \"mistralai/Mistral-7B-v0.1\",\n",
    "    # },\n",
    "    # \"mistral-7b-instruct\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-mistral-7b-instruct\"}},\n",
    "    #     \"huggingface_model_id\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    # },\n",
    "    #\"falcon-7b\": {\n",
    "    #    \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-falcon-7b-bf16\"}},\n",
    "    #    \"huggingface_model_id\": \"tiiuae/falcon-7b\",\n",
    "    #},\n",
    "    # \"falcon-7b-instruct\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-falcon-7b-instruct-bf16\"}},\n",
    "    #     \"huggingface_model_id\": \"tiiuae/falcon-7b-instruct\",\n",
    "    # },\n",
    "    # \"falcon-40b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-falcon-40b-bf16\"}},\n",
    "    #     \"huggingface_model_id\": \"tiiuae/falcon-40b\",\n",
    "    # },\n",
    "    # \"falcon-40b-instruct\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-falcon-40b-instruct-bf16\"}},\n",
    "    #     \"huggingface_model_id\": \"tiiuae/falcon-40b-instruct\",\n",
    "    # },\n",
    "    # \"falcon-180b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-falcon-180b-bf16\"}},\n",
    "    #     \"huggingface_model_id\": \"tiiuae/falcon-7b\",\n",
    "    # },\n",
    "    # \"falcon-180b-chat\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"huggingface-llm-falcon-180b-chat-bf16\"}},\n",
    "    #     \"huggingface_model_id\": \"tiiuae/falcon-7b\",\n",
    "    # },\n",
    "    # \"llama-2-7b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b\"}},\n",
    "    #     \"huggingface_model_id\": \"TheBloke/Llama-2-7B-GPTQ\",\n",
    "    # },\n",
    "    # \"llama-2-13b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-13b\"}},\n",
    "    #     \"huggingface_model_id\": \"TheBloke/Llama-2-13B-GPTQ\",\n",
    "    # },\n",
    "    # \"llama-2-70b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-70b\"}},\n",
    "    #     \"huggingface_model_id\": \"TheBloke/Llama-2-70B-GPTQ\",\n",
    "    # },\n",
    "    # \"code-llama-7b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-codellama-7b\"}},\n",
    "    #     \"huggingface_model_id\": \"codellama/CodeLlama-7b-hf\",\n",
    "    # },\n",
    "    # \"code-llama-13b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-codellama-13b\"}},\n",
    "    #     \"huggingface_model_id\": \"codellama/CodeLlama-13b-hf\",\n",
    "    # },\n",
    "    # \"code-llama-34b\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-codellama-34b\"}},\n",
    "    #     \"huggingface_model_id\": \"codellama/CodeLlama-34b-hf\",\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PAYLOADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n",
      "2023-12-02 06:46:07,193 | INFO : (Model 'code-llama-7b-sm-url'): No initial_instance_count provided. Using the default count 1.\n",
      "2023-12-02 06:46:07,672 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128'): Begin concurrency probe ...\n",
      "2023-12-02 06:46:07,673 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 1): Begin throughput load test ...\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n",
      "2023-12-02 06:46:14,401 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 2): Begin throughput load test ...\n",
      "2023-12-02 06:46:21,124 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 4): Begin throughput load test ...\n",
      "2023-12-02 06:46:28,042 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 8): Begin throughput load test ...\n",
      "2023-12-02 06:46:35,794 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 16): Begin throughput load test ...\n",
      "2023-12-02 06:46:44,869 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 32): Begin throughput load test ...\n",
      "2023-12-02 06:46:57,180 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 64): Begin throughput load test ...\n",
      "2023-12-02 06:47:21,908 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 128): Begin throughput load test ...\n",
      "2023-12-02 06:48:11,992 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 256): Begin throughput load test ...\n",
      "2023-12-02 06:49:55,359 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 512): Begin throughput load test ...\n",
      "2023-12-02 06:50:57,948 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128', Concurrency 512): Cancelling and awaiting future completion: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/lmi-model-2023-11-15-19-45-28-337 in account 875423407011 for more information.\n",
      "2023-12-02 06:51:58,069 | INFO : (Model 'code-llama-7b-sm-url', Payload 'input_32_output_128'): End concurrency probe. Error occured: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/lmi-model-2023-11-15-19-45-28-337 in account 875423407011 for more information.\n",
      "2023-12-02 06:51:58,070 | INFO : (Model 'code-llama-7b-sm-url'): Skipping cleaning up resources ...\n"
     ]
    }
   ],
   "source": [
    "from benchmarking.runner import Benchmarker\n",
    "\n",
    "benchmarker = Benchmarker(payloads=PAYLOADS, run_concurrency_probe=True)\n",
    "#benchmarker = Benchmarker(payloads=PAYLOADS, run_latency_load_test=True)\n",
    "metrics = benchmarker.run_multiple_models(models=MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">p50 latency</th>\n",
       "      <th colspan=\"9\" halign=\"left\">p99 latency</th>\n",
       "      <th colspan=\"9\" halign=\"left\">Latency.p99</th>\n",
       "      <th colspan=\"9\" halign=\"left\">throughput (tokens/s)</th>\n",
       "      <th colspan=\"9\" halign=\"left\">p90 latency (ms/token)</th>\n",
       "      <th colspan=\"9\" halign=\"left\">cost to generate 1M tokens ($)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>concurrent requests</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model ID</th>\n",
       "      <th>instance type</th>\n",
       "      <th>payload</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>code-llama-7b-sm-url</th>\n",
       "      <th>ml.g5.12xlarge</th>\n",
       "      <th>input_32_output_128</th>\n",
       "      <td>2155.26</td>\n",
       "      <td>2228.81</td>\n",
       "      <td>2276.63</td>\n",
       "      <td>2520.45</td>\n",
       "      <td>2974.93</td>\n",
       "      <td>4020.93</td>\n",
       "      <td>8131.30</td>\n",
       "      <td>16529.47</td>\n",
       "      <td>34004.87</td>\n",
       "      <td>2368.86</td>\n",
       "      <td>2282.26</td>\n",
       "      <td>2360.68</td>\n",
       "      <td>2702.11</td>\n",
       "      <td>3109.24</td>\n",
       "      <td>4105.85</td>\n",
       "      <td>8239.59</td>\n",
       "      <td>16758.16</td>\n",
       "      <td>34831.28</td>\n",
       "      <td>2416.92</td>\n",
       "      <td>2286.06</td>\n",
       "      <td>2369.24</td>\n",
       "      <td>2703.55</td>\n",
       "      <td>3115.02</td>\n",
       "      <td>4232.99</td>\n",
       "      <td>8345.73</td>\n",
       "      <td>16843.22</td>\n",
       "      <td>35068.84</td>\n",
       "      <td>60.45</td>\n",
       "      <td>120.93</td>\n",
       "      <td>237.12</td>\n",
       "      <td>422.33</td>\n",
       "      <td>721.92</td>\n",
       "      <td>1064.03</td>\n",
       "      <td>1059.82</td>\n",
       "      <td>1039.79</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>263</td>\n",
       "      <td>$32.58</td>\n",
       "      <td>$16.29</td>\n",
       "      <td>$8.31</td>\n",
       "      <td>$4.55</td>\n",
       "      <td>$2.73</td>\n",
       "      <td>$1.85</td>\n",
       "      <td>$1.00</td>\n",
       "      <td>$0.89</td>\n",
       "      <td>$1.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        p50 latency           \\\n",
       "concurrent requests                                               1        2   \n",
       "model ID             instance type  payload                                    \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2155.26     2228.81   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                            4        8   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2276.63  2520.45   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                           16       32   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2974.93  4020.93   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                           64       128   \n",
       "model ID             instance type  payload                                  \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  8131.30  16529.47   \n",
       "\n",
       "                                                                  p99 latency  \\\n",
       "concurrent requests                                           256           1   \n",
       "model ID             instance type  payload                                     \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  34004.87  2368.86      \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                            2        4   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2282.26  2360.68   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                            8       16   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2702.11  3109.24   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                           32       64   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  4105.85  8239.59   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                           128       256   \n",
       "model ID             instance type  payload                                   \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  16758.16  34831.28   \n",
       "\n",
       "                                                        Latency.p99           \\\n",
       "concurrent requests                                               1        2   \n",
       "model ID             instance type  payload                                    \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2416.92     2286.06   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                            4        8   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  2369.24  2703.55   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                           16       32   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  3115.02  4232.99   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                           64       128   \n",
       "model ID             instance type  payload                                  \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  8345.73  16843.22   \n",
       "\n",
       "                                                                   \\\n",
       "concurrent requests                                           256   \n",
       "model ID             instance type  payload                         \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  35068.84   \n",
       "\n",
       "                                                        throughput (tokens/s)  \\\n",
       "concurrent requests                                                         1   \n",
       "model ID             instance type  payload                                     \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  60.45                  \n",
       "\n",
       "                                                                         \\\n",
       "concurrent requests                                           2       4   \n",
       "model ID             instance type  payload                               \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  120.93  237.12   \n",
       "\n",
       "                                                                         \\\n",
       "concurrent requests                                           8      16   \n",
       "model ID             instance type  payload                               \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  422.33  721.92   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                           32       64   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  1064.03  1059.82   \n",
       "\n",
       "                                                                           \\\n",
       "concurrent requests                                          128      256   \n",
       "model ID             instance type  payload                                 \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  1039.79  1007.00   \n",
       "\n",
       "                                                        p90 latency (ms/token)  \\\n",
       "concurrent requests                                                          1   \n",
       "model ID             instance type  payload                                      \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  17                      \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                       2   4   8  16  32   \n",
       "model ID             instance type  payload                                   \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  16  17  20  22  30   \n",
       "\n",
       "                                                                       \\\n",
       "concurrent requests                                      64  128  256   \n",
       "model ID             instance type  payload                             \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  62  126  263   \n",
       "\n",
       "                                                        cost to generate 1M tokens ($)  \\\n",
       "concurrent requests                                                                  1   \n",
       "model ID             instance type  payload                                              \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  $32.58                          \n",
       "\n",
       "                                                                               \\\n",
       "concurrent requests                                           2      4      8   \n",
       "model ID             instance type  payload                                     \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  $16.29  $8.31  $4.55   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                         16     32     64   \n",
       "model ID             instance type  payload                                    \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  $2.73  $1.85  $1.00   \n",
       "\n",
       "                                                                       \n",
       "concurrent requests                                        128    256  \n",
       "model ID             instance type  payload                            \n",
       "code-llama-7b-sm-url ml.g5.12xlarge input_32_output_128  $0.89  $1.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from benchmarking.runner import Benchmarker\n",
    "\n",
    "\n",
    "df = Benchmarker.load_metrics_pandas()\n",
    "df_pivot = Benchmarker.create_concurrency_probe_pivot_table(df)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "display(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarker.clean_up_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
