{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8a3cea",
   "metadata": {
    "papermill": {
     "duration": 0.024351,
     "end_time": "2022-04-18T00:16:05.610238",
     "exception": false,
     "start_time": "2022-04-18T00:16:05.585887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use SageMaker Batch Transform for PyTorch Batch Inference\n",
    "In this notebook, we examine how to do a Batch Transform task with PyTorch in Amazon SageMaker. \n",
    "\n",
    "First, an image classification model is built on the MNIST dataset. Then, we demonstrate batch transform by using the SageMaker Python SDK PyTorch framework with different configurations:\n",
    "- `data_type=S3Prefix`: uses all objects that match the specified S3 prefix for batch inference.\n",
    "- `data_type=ManifestFile`: a manifest file contains a list of object keys to use in batch inference.\n",
    "- `instance_count>1`: distributes the batch inference dataset to multiple inference instances.\n",
    "\n",
    "For batch transform in TensorFlow in Amazon SageMaker, you can follow other Jupyter notebooks in the [sagemaker_batch_transform](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_batch_transform) directory.\n",
    "\n",
    "### Runtime\n",
    "\n",
    "This notebook takes approximately 15 minutes to run.\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Model training](#Model-training)\n",
    "1. [Prepare batch inference data](#Prepare-batch-inference-data)\n",
    "1. [Create model transformer](#Create-model-transformer)\n",
    "1. [Batch inference](#Batch-inference)\n",
    "1. [Look at all transform jobs](#Look-at-all-transform-jobs)\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aa488",
   "metadata": {
    "papermill": {
     "duration": 0.024173,
     "end_time": "2022-04-18T00:16:05.658651",
     "exception": false,
     "start_time": "2022-04-18T00:16:05.634478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "We'll begin with some necessary installs and imports, and get an Amazon SageMaker session to help perform certain tasks, as well as an IAM role with the necessary permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347fb3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:16:05.717791Z",
     "iopub.status.busy": "2022-04-18T00:16:05.716441Z",
     "iopub.status.idle": "2022-04-18T00:17:03.392816Z",
     "shell.execute_reply": "2022-04-18T00:17:03.393220Z"
    },
    "papermill": {
     "duration": 57.710469,
     "end_time": "2022-04-18T00:17:03.393356",
     "exception": false,
     "start_time": "2022-04-18T00:16:05.682887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/lib/python3.6/site-packages (7.352.0)\n",
      "Found existing installation: torchvision 0.5.0+cpu\n",
      "Uninstalling torchvision-0.5.0+cpu:\n",
      "  Would remove:\n",
      "    /opt/conda/lib/python3.6/site-packages/torchvision-0.5.0+cpu.dist-info/*\n",
      "    /opt/conda/lib/python3.6/site-packages/torchvision/*\n",
      "Proceed (y/n)?   Successfully uninstalled torchvision-0.5.0+cpu\n",
      "yes: standard output: Broken pipe\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp36-cp36m-manylinux1_x86_64.whl (23.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.3 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.10.1\n",
      "  Downloading torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 881.9 MB 4.4 kB/s s eta 0:00:01   |█▊                              | 46.2 MB 47.4 MB/s eta 0:00:18\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.6/site-packages (from torchvision) (8.1.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.10.1->torchvision) (0.8)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "Successfully installed torch-1.10.1 torchvision-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-ml-py3\n",
    "!yes | pip uninstall torchvision\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e1a695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:17:03.931382Z",
     "iopub.status.busy": "2022-04-18T00:17:03.929944Z",
     "iopub.status.idle": "2022-04-18T00:17:05.449695Z",
     "shell.execute_reply": "2022-04-18T00:17:05.450090Z"
    },
    "papermill": {
     "duration": 1.787837,
     "end_time": "2022-04-18T00:17:05.450218",
     "exception": false,
     "start_time": "2022-04-18T00:17:03.662381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-west-2-521695447989\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-batch-inference-script\"\n",
    "print(\"Bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df34f4f",
   "metadata": {
    "papermill": {
     "duration": 0.263907,
     "end_time": "2022-04-18T00:17:05.973913",
     "exception": false,
     "start_time": "2022-04-18T00:17:05.710006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50d7ed",
   "metadata": {
    "papermill": {
     "duration": 0.263002,
     "end_time": "2022-04-18T00:17:06.498913",
     "exception": false,
     "start_time": "2022-04-18T00:17:06.235911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since the main purpose of this notebook is to demonstrate SageMaker PyTorch batch transform, we reuse a SageMaker Python SDK [PyTorch MNIST example](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_mnist) to train a PyTorch model. It takes around 7 minutes to finish the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa3102c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:17:07.036926Z",
     "iopub.status.busy": "2022-04-18T00:17:07.036319Z",
     "iopub.status.idle": "2022-04-18T00:21:04.035984Z",
     "shell.execute_reply": "2022-04-18T00:21:04.035459Z"
    },
    "papermill": {
     "duration": 237.274426,
     "end_time": "2022-04-18T00:21:04.036098",
     "exception": false,
     "start_time": "2022-04-18T00:17:06.761672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-images-idx3-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aac8b5cdde94af0bf0d4d35bb7434e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-labels-idx1-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f84a8650d54901b2a673cd86950c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71de3a71ded24916809faeadbb15b4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e858baad5749bc9590e27b052abda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-pytorch-batch-inference-script\n",
      "2022-04-18 00:17:13 Starting - Starting the training job...\n",
      "2022-04-18 00:17:33 Starting - Preparing the instances for trainingProfilerReport-1650241033: InProgress\n",
      ".........\n",
      "2022-04-18 00:19:13 Downloading - Downloading input data...\n",
      "...\n",
      "\u001b[35mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\u001b[0m\n",
      "\u001b[35m2022-04-18 00:20:14,348 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-04-18 00:20:39 Uploading - Uploading generated training model\n",
      "2022-04-18 00:20:39 Completed - Training job completed\n",
      "Training seconds: 216\n",
      "Billable seconds: 216\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "local_dir = \"data\"\n",
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "MNIST(\n",
    "    local_dir,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=local_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"model-script/mnist.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        \"backend\": \"gloo\",\n",
    "    },  # set epochs to a more realistic number for real training\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0249f",
   "metadata": {
    "papermill": {
     "duration": 0.275501,
     "end_time": "2022-04-18T00:21:04.584523",
     "exception": false,
     "start_time": "2022-04-18T00:21:04.309022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare batch inference data\n",
    "\n",
    "Convert the test data into PNG image format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343a2a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:05.137902Z",
     "iopub.status.busy": "2022-04-18T00:21:05.137342Z",
     "iopub.status.idle": "2022-04-18T00:21:05.300396Z",
     "shell.execute_reply": "2022-04-18T00:21:05.300817Z"
    },
    "papermill": {
     "duration": 0.444042,
     "end_time": "2022-04-18T00:21:05.300952",
     "exception": false,
     "start_time": "2022-04-18T00:21:04.856910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\r\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\r\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\r\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29e9c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:05.859943Z",
     "iopub.status.busy": "2022-04-18T00:21:05.859068Z",
     "iopub.status.idle": "2022-04-18T00:21:05.907742Z",
     "shell.execute_reply": "2022-04-18T00:21:05.907271Z"
    },
    "papermill": {
     "duration": 0.3314,
     "end_time": "2022-04-18T00:21:05.907858",
     "exception": false,
     "start_time": "2022-04-18T00:21:05.576458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# untar gz => png\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "with gzip.open(os.path.join(local_dir, \"MNIST/raw\", \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f0f659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:06.460135Z",
     "iopub.status.busy": "2022-04-18T00:21:06.459594Z",
     "iopub.status.idle": "2022-04-18T00:21:06.462362Z",
     "shell.execute_reply": "2022-04-18T00:21:06.461882Z"
    },
    "papermill": {
     "duration": 0.282711,
     "end_time": "2022-04-18T00:21:06.462473",
     "exception": false,
     "start_time": "2022-04-18T00:21:06.179762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test images\n"
     ]
    }
   ],
   "source": [
    "print(len(images), \"test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617160c",
   "metadata": {
    "papermill": {
     "duration": 0.272255,
     "end_time": "2022-04-18T00:21:07.005662",
     "exception": false,
     "start_time": "2022-04-18T00:21:06.733407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Randomly sample 100 test images and upload them to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f06915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:07.562604Z",
     "iopub.status.busy": "2022-04-18T00:21:07.561703Z",
     "iopub.status.idle": "2022-04-18T00:21:07.586028Z",
     "shell.execute_reply": "2022-04-18T00:21:07.585546Z"
    },
    "papermill": {
     "duration": 0.307877,
     "end_time": "2022-04-18T00:21:07.586142",
     "exception": false,
     "start_time": "2022-04-18T00:21:07.278265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image as im\n",
    "\n",
    "ids = random.sample(range(len(images)), 100)\n",
    "ids = np.array(ids, dtype=np.int)\n",
    "selected_images = images[ids]\n",
    "\n",
    "image_dir = \"data/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "for i, img in enumerate(selected_images):\n",
    "    pngimg = im.fromarray(img)\n",
    "    pngimg.save(os.path.join(image_dir, f\"{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf93b71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:08.139174Z",
     "iopub.status.busy": "2022-04-18T00:21:08.138568Z",
     "iopub.status.idle": "2022-04-18T00:21:11.816250Z",
     "shell.execute_reply": "2022-04-18T00:21:11.815819Z"
    },
    "papermill": {
     "duration": 3.95751,
     "end_time": "2022-04-18T00:21:11.816360",
     "exception": false,
     "start_time": "2022-04-18T00:21:07.858850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input S3 path: s3://sagemaker-us-west-2-000000000000/batch_transform\n"
     ]
    }
   ],
   "source": [
    "inference_prefix = \"batch_transform\"\n",
    "inference_inputs = sagemaker_session.upload_data(\n",
    "    path=image_dir, bucket=bucket, key_prefix=inference_prefix\n",
    ")\n",
    "print(\"Input S3 path: {}\".format(inference_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b9b66",
   "metadata": {
    "papermill": {
     "duration": 0.27307,
     "end_time": "2022-04-18T00:21:12.359429",
     "exception": false,
     "start_time": "2022-04-18T00:21:12.086359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create model transformer\n",
    "Now, we create a transformer object for creating and interacting with Amazon SageMaker transform jobs. We can create the transformer in two ways:\n",
    "1. Use a fitted estimator directly.\n",
    "1. First create a PyTorchModel from a saved model artifact, and then create a transformer from the PyTorchModel object.\n",
    "\n",
    "\n",
    "Here, we implement the `model_fn`, `input_fn`, `predict_fn` and `output_fn` function to override the default [PyTorch inference handler](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_inference_handler.py). \n",
    "\n",
    "In the `input_fn()` function, the inferenced images are encoded as a Python ByteArray. That's why we use the `load_from_bytearray()` function to load images from `io.BytesIO` and then use `PIL.image` to read the images.\n",
    "\n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "    \n",
    "def load_from_bytearray(request_body):\n",
    "    image_as_bytes = io.BytesIO(request_body)\n",
    "    image = Image.open(image_as_bytes)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    # if set content_type as \"image/jpg\" or \"application/x-npy\", \n",
    "    # the input is also a python bytearray\n",
    "    if request_content_type == \"application/x-image\": \n",
    "        image_tensor = load_from_bytearray(request_body)\n",
    "    else:\n",
    "        print(\"not support this type yet\")\n",
    "        raise ValueError(\"not support this type yet\")\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "def predict_fn(input_object, model):\n",
    "    output = model.forward(input_object)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    return {\"predictions\": pred.item()}\n",
    "\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "def output_fn(predictions, response_content_type):\n",
    "    return json.dumps(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86782070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:12.913699Z",
     "iopub.status.busy": "2022-04-18T00:21:12.913059Z",
     "iopub.status.idle": "2022-04-18T00:21:13.435748Z",
     "shell.execute_reply": "2022-04-18T00:21:13.435297Z"
    },
    "papermill": {
     "duration": 0.803929,
     "end_time": "2022-04-18T00:21:13.435864",
     "exception": false,
     "start_time": "2022-04-18T00:21:12.631935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use fitted estimator directly\n",
    "transformer = estimator.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09735ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:13.987215Z",
     "iopub.status.busy": "2022-04-18T00:21:13.986610Z",
     "iopub.status.idle": "2022-04-18T00:21:14.813434Z",
     "shell.execute_reply": "2022-04-18T00:21:14.813857Z"
    },
    "papermill": {
     "duration": 1.108024,
     "end_time": "2022-04-18T00:21:14.813988",
     "exception": false,
     "start_time": "2022-04-18T00:21:13.705964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also create a Transformer object from saved model artifact\n",
    "\n",
    "# Get model artifact location by estimator.model_data, or give an S3 key directly\n",
    "model_artifact_s3_location = estimator.model_data  # \"s3://<BUCKET>/<PREFIX>/model.tar.gz\"\n",
    "\n",
    "# Create PyTorchModel from saved model artifact\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artifact_s3_location,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\"model-script/\",\n",
    "    entry_point=\"mnist.py\",\n",
    ")\n",
    "\n",
    "# Create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024f81c",
   "metadata": {
    "papermill": {
     "duration": 0.27596,
     "end_time": "2022-04-18T00:21:15.362675",
     "exception": false,
     "start_time": "2022-04-18T00:21:15.086715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Batch inference\n",
    "Next, we perform inference on the sampled 100 MNIST images in a batch manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aafd66",
   "metadata": {
    "papermill": {
     "duration": 0.27709,
     "end_time": "2022-04-18T00:21:15.914136",
     "exception": false,
     "start_time": "2022-04-18T00:21:15.637046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Input images directly from S3 location\n",
    "We set `S3DataType=S3Prefix` to use all objects that match the specified S3 prefix for batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f666cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:21:16.475851Z",
     "iopub.status.busy": "2022-04-18T00:21:16.475277Z",
     "iopub.status.idle": "2022-04-18T00:26:04.809440Z",
     "shell.execute_reply": "2022-04-18T00:26:04.808894Z"
    },
    "papermill": {
     "duration": 288.620761,
     "end_time": "2022-04-18T00:26:04.809556",
     "exception": false,
     "start_time": "2022-04-18T00:21:16.188795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................\u001b[34m2022-04-18 00:25:31,379 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 948 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,409 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,427 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 5b0df4a34bfd419791760e1c82fe8572\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,437 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,461 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,623 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,627 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,627 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,627 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,640 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,656 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,663 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,663 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,663 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]50\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,664 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,664 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,664 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,666 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,664 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,667 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,668 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,672 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]49\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,673 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,673 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,673 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,679 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,679 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,683 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,683 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,683 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,683 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:31,687 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,368 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,370 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.106632232666016|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,370 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.8092803955078125|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,371 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.0|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,371 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6416.7265625|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,372 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:931.8046875|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,372 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:15.8|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,760 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 978\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,785 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 982\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,784 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1339|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,786 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:119|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,785 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1340|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,787 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:116|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,810 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 982\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,810 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1368|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,811 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:140|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,834 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1052\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,834 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1389|#Level:Host|#hostname:ad582a180490,timestamp:1650241532\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:32,834 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:93|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\n",
      "\u001b[34m2022-04-18 00:25:37,399 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:34650 \"GET /ping HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,400 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,435 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:34658 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,436 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,507 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,507 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,399 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:34650 \"GET /ping HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,400 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,435 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:34658 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,436 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,507 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,507 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[32m2022-04-18T00:25:37.442:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,507 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,508 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,508 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,509 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.01|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b991ddd1-11b8-4246-817f-e234377cde44,timestamp:1650241537\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,611 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,611 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,612 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,612 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,612 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,615 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.89|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e58006b2-3494-4f9d-b427-b2c05a48234a,timestamp:1650241537\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,507 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,508 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,508 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,509 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.01|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b991ddd1-11b8-4246-817f-e234377cde44,timestamp:1650241537\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,611 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,611 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,612 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,612 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,612 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,615 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.89|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e58006b2-3494-4f9d-b427-b2c05a48234a,timestamp:1650241537\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,738 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,738 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,739 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,739 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.53|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:d408fdeb-76de-4ce8-bd12-a1eea1dd98c8,timestamp:1650241537\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,739 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,740 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,740 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,865 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,866 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.9|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:968865ef-ce8f-457c-b5e7-05c15656c9c1,timestamp:1650241537\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:fe21acba-2b6f-4c7e-8fab-23849016df58,timestamp:1650241537\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,972 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:37,972 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,085 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,085 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b3ac9ae1-a77f-486c-98c0-55a1d973d768,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,169 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,169 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:2428a546-97b7-434d-a57d-039aec65a617,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:dc5c0414-007c-4371-be4c-f69d96ed0720,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,264 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,264 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,345 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:35432e1d-1b13-4ac8-8e91-0d1c0167946f,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,345 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,345 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,346 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,346 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,346 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,458 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,739 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,739 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.53|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:d408fdeb-76de-4ce8-bd12-a1eea1dd98c8,timestamp:1650241537\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,739 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,740 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,740 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,864 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,865 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,866 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.9|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:968865ef-ce8f-457c-b5e7-05c15656c9c1,timestamp:1650241537\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:fe21acba-2b6f-4c7e-8fab-23849016df58,timestamp:1650241537\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,971 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,972 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:37,972 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,085 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,085 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b3ac9ae1-a77f-486c-98c0-55a1d973d768,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,086 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,169 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,169 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:2428a546-97b7-434d-a57d-039aec65a617,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,170 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:dc5c0414-007c-4371-be4c-f69d96ed0720,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,263 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,264 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,264 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,345 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:35432e1d-1b13-4ac8-8e91-0d1c0167946f,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,345 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,345 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,346 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,346 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,346 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,458 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,458 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,458 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,459 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,459 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,460 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.08|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:84f54fd8-bbb2-4ab3-a3ca-610b7242dbf9,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,538 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,538 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.93|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:cae123fa-f9f3-40ad-abfd-5bc1040046ac,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,458 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,458 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,459 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,459 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,460 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.08|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:84f54fd8-bbb2-4ab3-a3ca-610b7242dbf9,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,538 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,538 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.93|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:cae123fa-f9f3-40ad-abfd-5bc1040046ac,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,539 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,670 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.71|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:80ac25bc-b2d8-4d7d-b3b6-e329488bd6ea,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,977 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,977 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:fb0b9838-d516-441e-9442-976cd42aa26a,timestamp:1650241538\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,109 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,109 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:54f2e26b-f633-41c1-8176-ea707c86c4fa,timestamp:1650241539\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,198 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a1bdb78d-2a97-4035-8f1c-3ddcffabfb32,timestamp:1650241539\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,669 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,670 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.71|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:80ac25bc-b2d8-4d7d-b3b6-e329488bd6ea,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,977 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,977 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:fb0b9838-d516-441e-9442-976cd42aa26a,timestamp:1650241538\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:38,978 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,109 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,109 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:54f2e26b-f633-41c1-8176-ea707c86c4fa,timestamp:1650241539\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,110 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,198 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a1bdb78d-2a97-4035-8f1c-3ddcffabfb32,timestamp:1650241539\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,609 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,609 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:026f3936-0c77-4f36-8e0e-56ecb4ae20c9,timestamp:1650241539\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,199 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,609 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,609 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:026f3936-0c77-4f36-8e0e-56ecb4ae20c9,timestamp:1650241539\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,610 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:2a8d0ca9-6f8e-422a-906c-b2f203a2f552,timestamp:1650241539\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,789 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,890 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,890 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:56f4d62c-2a83-48cb-98e6-6e1cfe075e9b,timestamp:1650241539\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:2a8d0ca9-6f8e-422a-906c-b2f203a2f552,timestamp:1650241539\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,788 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,789 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,890 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,890 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:56f4d62c-2a83-48cb-98e6-6e1cfe075e9b,timestamp:1650241539\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:94bf65ca-213c-4b82-a2b1-389731a59dfb,timestamp:1650241539\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:39,971 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,138 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,138 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3839c8f1-0fff-4907-b167-6e954c9b6249,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,891 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:94bf65ca-213c-4b82-a2b1-389731a59dfb,timestamp:1650241539\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,970 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:39,971 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,138 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,138 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3839c8f1-0fff-4907-b167-6e954c9b6249,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,218 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:721d9d18-93a1-4dbc-babe-098a5c83db10,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,218 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.09|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0f98f09f-a587-4c18-88c8-1c667a55fa66,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:51c658e4-bbbf-48ce-9dd4-19025f15637c,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,409 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1ee677be-3ab1-427b-bb39-cc2058eb1d5c,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,488 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,488 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e33199cc-ed87-4655-8303-4a1541c90d9a,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:c0a5cfd2-a0b5-4cd1-a471-0789f663bdc8,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,139 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,218 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:721d9d18-93a1-4dbc-babe-098a5c83db10,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,218 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,219 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.09|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0f98f09f-a587-4c18-88c8-1c667a55fa66,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,321 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:51c658e4-bbbf-48ce-9dd4-19025f15637c,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,409 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1ee677be-3ab1-427b-bb39-cc2058eb1d5c,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,487 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,488 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,488 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e33199cc-ed87-4655-8303-4a1541c90d9a,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,571 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:c0a5cfd2-a0b5-4cd1-a471-0789f663bdc8,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,663 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,662 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,663 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3f064f2b-4452-4892-986a-442e4a1bd239,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,820 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,820 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4a8d9a35-2d3f-44c9-a6b9-08754e99a96b,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,820 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3f064f2b-4452-4892-986a-442e4a1bd239,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,737 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,820 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,820 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4a8d9a35-2d3f-44c9-a6b9-08754e99a96b,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,820 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6a822bc7-0452-4d01-919f-93820a29ef52,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,889 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.21|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:9e36891e-4df0-4ef8-949b-a195ba717ce8,timestamp:1650241540\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,075 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,075 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a1ba220c-951d-46de-93d6-ba262e321037,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,175 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,175 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:635c2e75-2046-4545-a2b3-ba5bc7494a9d,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,175 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,176 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,176 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,176 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:25e16120-8982-4d72-b6ea-6f836e9b6ec0,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,314 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,314 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:afa20143-40ae-4a1a-b2e9-2b10fd63dbf8,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,403 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,403 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,503 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,503 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4d69029d-4109-4ff4-9aae-a2830028fc3a,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0d9ab440-6082-4968-ab87-056513209b41,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,610 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,610 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6a822bc7-0452-4d01-919f-93820a29ef52,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,888 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,889 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.21|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:9e36891e-4df0-4ef8-949b-a195ba717ce8,timestamp:1650241540\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:40,997 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,075 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,075 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a1ba220c-951d-46de-93d6-ba262e321037,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,076 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,175 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,175 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:635c2e75-2046-4545-a2b3-ba5bc7494a9d,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,175 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,176 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,176 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,176 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:25e16120-8982-4d72-b6ea-6f836e9b6ec0,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,313 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,314 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,314 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:afa20143-40ae-4a1a-b2e9-2b10fd63dbf8,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,402 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,403 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,403 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,503 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,503 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4d69029d-4109-4ff4-9aae-a2830028fc3a,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,504 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0d9ab440-6082-4968-ab87-056513209b41,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,609 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,610 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,610 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:37ce426c-151d-4f19-93d3-6312bb589d2a,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,787 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,787 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:155552ff-0166-491b-87a1-768065c651eb,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:37ce426c-151d-4f19-93d3-6312bb589d2a,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,684 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,787 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,787 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:155552ff-0166-491b-87a1-768065c651eb,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:efd19fcf-4c61-4b57-b1e3-ee7701885de4,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,984 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b907dd56-c939-4416-b367-4e97b4013616,timestamp:1650241541\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:92197732-5c4e-440f-953d-9d84731a8658,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3f9e9bb4-2a82-4169-af17-d6c45d523bb9,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:ac4dc55c-1762-4cee-9259-60436b74a592,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6a56fabe-4973-40be-9fd7-0484202dfae6,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,319 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,319 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:83aba925-0481-4b31-99ab-0f471176bea3,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:db6d82d7-7539-43af-b399-6b2e68e396c7,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,505 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,505 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,594 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:445b172a-d3e4-46ac-a88e-09690b0c18dc,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,788 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:efd19fcf-4c61-4b57-b1e3-ee7701885de4,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,899 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,984 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b907dd56-c939-4416-b367-4e97b4013616,timestamp:1650241541\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:41,985 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,080 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:92197732-5c4e-440f-953d-9d84731a8658,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3f9e9bb4-2a82-4169-af17-d6c45d523bb9,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,157 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:ac4dc55c-1762-4cee-9259-60436b74a592,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,230 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6a56fabe-4973-40be-9fd7-0484202dfae6,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,318 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,319 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,319 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:83aba925-0481-4b31-99ab-0f471176bea3,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,412 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:db6d82d7-7539-43af-b399-6b2e68e396c7,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,504 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,505 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,505 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,594 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:445b172a-d3e4-46ac-a88e-09690b0c18dc,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,596 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,596 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,596 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,596 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:681542c4-b2f6-4374-8fc1-1548e8649613,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:654cf5fa-63b1-4876-a975-61cfcdc68e88,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:681542c4-b2f6-4374-8fc1-1548e8649613,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,675 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:654cf5fa-63b1-4876-a975-61cfcdc68e88,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,757 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.22|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:7680909e-dbcf-480f-bb04-9873c45eccd3,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.22|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:7680909e-dbcf-480f-bb04-9873c45eccd3,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b6db0553-b1ec-414a-beb1-23e061b1454c,timestamp:1650241542\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:c9756dad-5c2e-4e3e-b5fd-00d316df8dc4,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,084 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,084 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1769f16d-29a3-482c-bd98-efde53e2ffe4,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,219 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,219 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:8bc6d547-caf2-4b33-8259-f58b7324eb3a,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0a3a5e29-be58-4d46-ba27-38458886f11c,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,400 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,400 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:2df74a80-1984-4e71-8529-dfe9cf90a8f6,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,505 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,505 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,832 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b6db0553-b1ec-414a-beb1-23e061b1454c,timestamp:1650241542\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:42,974 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:c9756dad-5c2e-4e3e-b5fd-00d316df8dc4,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,083 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,084 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,084 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1769f16d-29a3-482c-bd98-efde53e2ffe4,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,218 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,219 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,219 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:8bc6d547-caf2-4b33-8259-f58b7324eb3a,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,312 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0a3a5e29-be58-4d46-ba27-38458886f11c,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,400 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,400 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:2df74a80-1984-4e71-8529-dfe9cf90a8f6,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,504 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,505 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,505 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e3e047b3-424b-42e6-8708-d18083d36bdc,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e3e047b3-424b-42e6-8708-d18083d36bdc,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,605 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,679 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:41139c2c-6e37-44d9-b3fa-ed7a7d79b0a5,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,764 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,764 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:18e4dd2c-1358-4f16-934b-e6a349809496,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,679 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:41139c2c-6e37-44d9-b3fa-ed7a7d79b0a5,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,680 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,764 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,764 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:18e4dd2c-1358-4f16-934b-e6a349809496,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a8e94616-c8fb-4b19-bd21-4f255f0bcdff,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,918 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,918 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:41d23174-17a0-49fe-9db0-9fbd987a6f01,timestamp:1650241543\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:5756636f-71fe-4ff3-b01f-8d534f154a50,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0c9368b2-c75a-4b10-b426-1ea1e485dc96,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,140 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,140 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:5ee9406b-7a75-4941-980b-51ea5896615f,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,210 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,210 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,281 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,281 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.71|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:65fb6e50-eb8b-4e14-8db5-9cda18081118,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,281 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,282 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,282 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,383 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 8\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:5.86|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4afa65a1-2ac5-4472-8949-6234d29fd3e8,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:aec048c4-6a9e-4636-88c5-cd63fec5813b,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,765 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a8e94616-c8fb-4b19-bd21-4f255f0bcdff,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,847 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,918 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,918 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:41d23174-17a0-49fe-9db0-9fbd987a6f01,timestamp:1650241543\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:43,919 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:5756636f-71fe-4ff3-b01f-8d534f154a50,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,041 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0c9368b2-c75a-4b10-b426-1ea1e485dc96,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,139 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,140 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,140 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:5ee9406b-7a75-4941-980b-51ea5896615f,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,209 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,210 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,210 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,281 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,281 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.71|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:65fb6e50-eb8b-4e14-8db5-9cda18081118,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,281 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,282 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,282 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,383 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 8\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:5.86|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4afa65a1-2ac5-4472-8949-6234d29fd3e8,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,384 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:aec048c4-6a9e-4636-88c5-cd63fec5813b,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6718ab87-dc9b-4618-9e71-ca5ebfa50101,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:f67abd31-9d02-4990-9e51-9b6869312e3d,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,463 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6718ab87-dc9b-4618-9e71-ca5ebfa50101,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,561 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:f67abd31-9d02-4990-9e51-9b6869312e3d,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,632 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1d5575ea-c1b1-47ed-af77-ef415809b2bd,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,807 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.03|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e650aebf-2df9-4dbf-aac1-1d3d8df4d634,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,807 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e6fd38ae-8b54-41d8-9ea1-17c8527b2c9a,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1d5575ea-c1b1-47ed-af77-ef415809b2bd,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,721 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,807 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.03|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e650aebf-2df9-4dbf-aac1-1d3d8df4d634,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,807 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,808 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:e6fd38ae-8b54-41d8-9ea1-17c8527b2c9a,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.22|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3bae0c32-eb6d-4f97-a8d9-da14ec10b964,timestamp:1650241544\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,041 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,041 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b42e1c6c-fe99-4a2e-b624-676e3117b178,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:176504c4-16be-4531-9a23-2905adc479ac,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4506218e-a262-4ac3-864d-df900a919b9f,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:470bcd94-b192-4e63-a0bf-bd6a6ecb5bf0,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,876 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.22|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:3bae0c32-eb6d-4f97-a8d9-da14ec10b964,timestamp:1650241544\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:44,954 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,041 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,041 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:b42e1c6c-fe99-4a2e-b624-676e3117b178,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,042 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:176504c4-16be-4531-9a23-2905adc479ac,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,114 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:4506218e-a262-4ac3-864d-df900a919b9f,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,191 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:470bcd94-b192-4e63-a0bf-bd6a6ecb5bf0,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:db958c22-670b-4f6e-afe4-5c5a8e70e93d,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:aff03e2e-c9b6-4154-afb7-f8fee4b093ef,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,505 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,505 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1ebaea0a-c800-48d6-b3f7-206080f155ea,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,577 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:18e5d83b-bc1e-4cb5-8106-41aed195cf96,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,669 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,669 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:ec1e2a0e-1e71-4050-a7fb-314380c5ed86,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:db958c22-670b-4f6e-afe4-5c5a8e70e93d,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,345 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:aff03e2e-c9b6-4154-afb7-f8fee4b093ef,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,432 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,505 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,505 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1ebaea0a-c800-48d6-b3f7-206080f155ea,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,506 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,577 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:18e5d83b-bc1e-4cb5-8106-41aed195cf96,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,669 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,669 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:ec1e2a0e-1e71-4050-a7fb-314380c5ed86,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:75937063-aafb-4cde-82e5-ef15c109cfe0,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:598ceffc-323d-403b-996c-f18fd6163e74,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,858 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:838b4ff4-466c-477f-9f72-22c67196742b,timestamp:1650241545\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,074 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:27e0174c-e775-4c2f-b198-3a133d49259e,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6d0f88bc-3934-4555-b8c7-7a5311ffe85e,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,212 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,212 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.2|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:927937c1-8998-4686-96f0-56f4094cfeff,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:75937063-aafb-4cde-82e5-ef15c109cfe0,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,780 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:598ceffc-323d-403b-996c-f18fd6163e74,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,857 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,858 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:838b4ff4-466c-477f-9f72-22c67196742b,timestamp:1650241545\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:45,956 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,074 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:27e0174c-e775-4c2f-b198-3a133d49259e,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,075 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:6d0f88bc-3934-4555-b8c7-7a5311ffe85e,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,211 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,212 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,212 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.2|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:927937c1-8998-4686-96f0-56f4094cfeff,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:65e09797-8ede-42b7-8fee-9a62fdb8e1a5,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,472 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,472 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:9015e397-aab8-4259-8638-38703c66ad12,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:19b535b5-7e83-458e-9229-0f322798997a,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:9b087c7c-e738-453a-8f85-f6dfe6c535e7,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,286 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:65e09797-8ede-42b7-8fee-9a62fdb8e1a5,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,383 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,472 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,472 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,473 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:9015e397-aab8-4259-8638-38703c66ad12,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.25|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:19b535b5-7e83-458e-9229-0f322798997a,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,569 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:9b087c7c-e738-453a-8f85-f6dfe6c535e7,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,662 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:af1d81f6-ce62-4106-8959-532467b8dabc,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a0e9f81d-97c5-4117-8f04-c93584bdcc8d,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,817 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:af1d81f6-ce62-4106-8959-532467b8dabc,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,743 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:a0e9f81d-97c5-4117-8f04-c93584bdcc8d,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,816 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,817 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0f3e36b1-70c1-4840-b9b6-20b1401164b0,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:bce91358-0a4e-4d85-833a-cb0189043ea9,timestamp:1650241546\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1d2c82c1-91d5-48f3-b4f3-09da2d42daa5,timestamp:1650241547\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,095 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:c2609e01-7fc7-4817-b804-f7bf071f41fc,timestamp:1650241547\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,255 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,255 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:97f14871-b6bf-4d79-ada6-9183f92069ed,timestamp:1650241547\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,255 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,256 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,256 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,256 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:5fda8390-6584-499e-9af2-ea46d5c96353,timestamp:1650241547\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:0f3e36b1-70c1-4840-b9b6-20b1401164b0,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,898 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:46,994 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:bce91358-0a4e-4d85-833a-cb0189043ea9,timestamp:1650241546\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:1d2c82c1-91d5-48f3-b4f3-09da2d42daa5,timestamp:1650241547\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,094 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,095 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:c2609e01-7fc7-4817-b804-f7bf071f41fc,timestamp:1650241547\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,186 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,255 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,255 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:97f14871-b6bf-4d79-ada6-9183f92069ed,timestamp:1650241547\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,255 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,256 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,256 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,256 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.23|#ModelName:model,Level:Model|#hostname:ad582a180490,requestID:5fda8390-6584-499e-9af2-ea46d5c96353,timestamp:1650241547\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:25:47,328 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:ad582a180490,timestamp:null\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42055d",
   "metadata": {
    "papermill": {
     "duration": 0.284352,
     "end_time": "2022-04-18T00:26:05.382241",
     "exception": false,
     "start_time": "2022-04-18T00:26:05.097889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Input images by manifest file\n",
    "First, we generate a manifest file. Then we use the manifest file containing a list of object keys as inputs to batch inference. Some key points:\n",
    "- `content_type = \"application/x-image\"` (here the `content_type` is for the actual object for inference, not for the manifest file)\n",
    "- `data_type = \"ManifestFile\"`\n",
    "- Manifest file format must follow the format as [S3DataSource](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html#SageMaker-Type-S3DataSource-S3DataType) points out. We create the manifest file by using the jsonlines package.\n",
    "``` json\n",
    "[\n",
    "    {\"prefix\": \"s3://customer_bucket/some/prefix/\"},\n",
    "    \"relative/path/to/custdata-1\",\n",
    "    \"relative/path/custdata-2\",\n",
    "    ...\n",
    "    \"relative/path/custdata-N\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295c39fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:26:05.958518Z",
     "iopub.status.busy": "2022-04-18T00:26:05.957953Z",
     "iopub.status.idle": "2022-04-18T00:26:07.697465Z",
     "shell.execute_reply": "2022-04-18T00:26:07.697888Z"
    },
    "papermill": {
     "duration": 2.031783,
     "end_time": "2022-04-18T00:26:07.698024",
     "exception": false,
     "start_time": "2022-04-18T00:26:05.666241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b279b271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:26:08.281739Z",
     "iopub.status.busy": "2022-04-18T00:26:08.276996Z",
     "iopub.status.idle": "2022-04-18T00:26:08.365897Z",
     "shell.execute_reply": "2022-04-18T00:26:08.366295Z"
    },
    "papermill": {
     "duration": 0.385649,
     "end_time": "2022-04-18T00:26:08.366426",
     "exception": false,
     "start_time": "2022-04-18T00:26:07.980777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_files\n",
      " ['2.png', '43.png', '46.png', '45.png', '16.png', '4.png', '92.png', '12.png', '18.png', '75.png', '87.png', '63.png', '81.png', '78.png', '13.png', '34.png', '42.png', '19.png', '73.png', '14.png', '83.png', '3.png', '55.png', '5.png', '38.png', '86.png', '27.png', '7.png', '15.png', '80.png', '89.png', '72.png', '88.png', '99.png', '82.png', '32.png', '70.png', '36.png', '67.png', '26.png', '94.png', '41.png', '30.png', '64.png', '28.png', '59.png', '52.png', '90.png', '69.png', '31.png', '37.png', '47.png', '40.png', '56.png', '58.png', '1.png', '93.png', '61.png', '29.png', '76.png', '23.png', '50.png', '97.png', '79.png', '85.png', '6.png', '57.png', '35.png', '11.png', '22.png', '62.png', '21.png', '95.png', '71.png', '60.png', '17.png', '77.png', '25.png', '49.png', '96.png', '53.png', '54.png', '48.png', '51.png', '74.png', '20.png', '0.png', '91.png', '33.png', '24.png', '65.png', '66.png', '10.png', '68.png', '39.png', '9.png', '98.png', '84.png', '8.png', '44.png']\n",
      "manifest_content\n",
      " [{'prefix': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-pytorch-batch-inference-script/images/'}, '2.png', '43.png', '46.png', '45.png', '16.png', '4.png', '92.png', '12.png', '18.png', '75.png', '87.png', '63.png', '81.png', '78.png', '13.png', '34.png', '42.png', '19.png', '73.png', '14.png', '83.png', '3.png', '55.png', '5.png', '38.png', '86.png', '27.png', '7.png', '15.png', '80.png', '89.png', '72.png', '88.png', '99.png', '82.png', '32.png', '70.png', '36.png', '67.png', '26.png', '94.png', '41.png', '30.png', '64.png', '28.png', '59.png', '52.png', '90.png', '69.png', '31.png', '37.png', '47.png', '40.png', '56.png', '58.png', '1.png', '93.png', '61.png', '29.png', '76.png', '23.png', '50.png', '97.png', '79.png', '85.png', '6.png', '57.png', '35.png', '11.png', '22.png', '62.png', '21.png', '95.png', '71.png', '60.png', '17.png', '77.png', '25.png', '49.png', '96.png', '53.png', '54.png', '48.png', '51.png', '74.png', '20.png', '0.png', '91.png', '33.png', '24.png', '65.png', '66.png', '10.png', '68.png', '39.png', '9.png', '98.png', '84.png', '8.png', '44.png']\n",
      "manifest_obj\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "# Build image list\n",
    "manifest_prefix = f\"s3://{bucket}/{prefix}/images/\"\n",
    "\n",
    "path = image_dir\n",
    "img_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "print(\"img_files\\n\", img_files)\n",
    "\n",
    "manifest_content = [{\"prefix\": manifest_prefix}]\n",
    "manifest_content.extend(img_files)\n",
    "\n",
    "print(\"manifest_content\\n\", manifest_content)\n",
    "\n",
    "# Write jsonl file\n",
    "manifest_file = \"manifest.json\"\n",
    "with jsonlines.open(manifest_file, mode=\"w\") as writer:\n",
    "    writer.write(manifest_content)\n",
    "\n",
    "# Upload to S3\n",
    "manifest_obj = sagemaker_session.upload_data(path=manifest_file, key_prefix=prefix)\n",
    "\n",
    "print(\"manifest_obj\\n\", manifest_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58e5fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:26:08.991335Z",
     "iopub.status.busy": "2022-04-18T00:26:08.990382Z",
     "iopub.status.idle": "2022-04-18T00:26:09.315301Z",
     "shell.execute_reply": "2022-04-18T00:26:09.314768Z"
    },
    "papermill": {
     "duration": 0.634562,
     "end_time": "2022-04-18T00:26:09.315415",
     "exception": false,
     "start_time": "2022-04-18T00:26:08.680853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Batch transform with manifest file\n",
    "transform_job = transformer.transform(\n",
    "    data=manifest_obj,\n",
    "    data_type=\"ManifestFile\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaa60562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:26:09.926921Z",
     "iopub.status.busy": "2022-04-18T00:26:09.926314Z",
     "iopub.status.idle": "2022-04-18T00:26:09.929042Z",
     "shell.execute_reply": "2022-04-18T00:26:09.929418Z"
    },
    "papermill": {
     "duration": 0.315692,
     "end_time": "2022-04-18T00:26:09.929575",
     "exception": false,
     "start_time": "2022-04-18T00:26:09.613883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest transform job: pytorch-inference-2022-04-18-00-26-08-985\n"
     ]
    }
   ],
   "source": [
    "print(\"Latest transform job:\", transformer.latest_transform_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56dde353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:26:10.542067Z",
     "iopub.status.busy": "2022-04-18T00:26:10.541139Z",
     "iopub.status.idle": "2022-04-18T00:26:10.581428Z",
     "shell.execute_reply": "2022-04-18T00:26:10.581903Z"
    },
    "papermill": {
     "duration": 0.371555,
     "end_time": "2022-04-18T00:26:10.582047",
     "exception": false,
     "start_time": "2022-04-18T00:26:10.210492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 26, 9, 32000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2022-04-18-00-21-14-564',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '870',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Mon, 18 Apr 2022 00:26:09 GMT',\n",
      "                                      'x-amzn-requestid': '394fa75d-5814-41e3-a604-2a471c52c745'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '394fa75d-5814-41e3-a604-2a471c52c745',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'ManifestFile',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/pytorch-inference-2022-04-18-00-26-08-985',\n",
      " 'TransformJobName': 'pytorch-inference-2022-04-18-00-26-08-985',\n",
      " 'TransformJobStatus': 'InProgress',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-000000000000/pytorch-inference-2022-04-18-00-26-08-985'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.c5.xlarge'}}\n"
     ]
    }
   ],
   "source": [
    "# look at the status of the transform job\n",
    "import pprint as pp\n",
    "\n",
    "sm_cli = sagemaker_session.sagemaker_client\n",
    "\n",
    "job_info = sm_cli.describe_transform_job(TransformJobName=transformer.latest_transform_job.name)\n",
    "\n",
    "pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a43f63",
   "metadata": {
    "papermill": {
     "duration": 0.319318,
     "end_time": "2022-04-18T00:26:11.190554",
     "exception": false,
     "start_time": "2022-04-18T00:26:10.871236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Multiple instance\n",
    "We use `instance_count > 1` to create multiple inference instances. When a batch transform job starts, Amazon SageMaker initializes compute instances and distributes the inference or preprocessing workload between them. Batch Transform partitions the Amazon S3 objects in the input by key and maps Amazon S3 objects to instances. Given multiple files, one instance might process input1.csv, and another instance might process input2.csv. Read more at [Use Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9661fe0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:26:11.967328Z",
     "iopub.status.busy": "2022-04-18T00:26:11.966434Z",
     "iopub.status.idle": "2022-04-18T00:32:01.800681Z",
     "shell.execute_reply": "2022-04-18T00:32:01.801103Z"
    },
    "papermill": {
     "duration": 350.284513,
     "end_time": "2022-04-18T00:32:01.801239",
     "exception": false,
     "start_time": "2022-04-18T00:26:11.516726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[35m2022-04-18 00:31:23,943 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35mMax heap size: 910 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:23,983 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,005 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag c3fb4d26ffa849bbbf79ab8856e86748\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,017 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,049 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,238 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,243 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,244 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,244 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,244 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,245 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,245 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,245 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,253 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,253 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,278 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,278 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,278 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,278 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,279 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,282 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,283 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,283 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,283 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,283 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,320 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,320 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,321 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,328 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,335 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,337 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:24,337 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,106 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,108 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.10660934448242|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,109 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.809303283691406|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,110 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.0|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,111 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6271.05078125|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,112 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:922.55078125|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,112 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:16.0|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,493 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1042\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,494 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1465|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,495 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,511 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1065\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,512 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1482|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,512 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:107|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,624 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1186\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,624 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1596|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,625 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:97|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,815 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1337\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,815 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1789|#Level:Host|#hostname:6925eb526ceb,timestamp:1650241885\u001b[0m\n",
      "\u001b[35m2022-04-18 00:31:25,815 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:137|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,665 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 912 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,709 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,732 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 2eb711663c324fc78881634b94b209fd\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,744 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,771 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,975 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,976 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,976 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,976 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,991 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,992 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,992 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,993 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,995 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:26,999 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,009 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,010 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,010 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,010 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,010 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,028 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,028 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,029 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,032 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,033 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,034 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,035 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,042 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]49\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,043 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,043 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,044 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,052 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,971 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,973 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.106597900390625|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,973 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.809314727783203|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,975 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.0|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,976 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6252.3125|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,977 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:947.546875|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:27,977 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:16.3|#Level:Host|#hostname:aeaba6005455,timestamp:1650241887\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,254 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1087\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,255 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1500|#Level:Host|#hostname:aeaba6005455,timestamp:1650241888\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:122|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,345 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1166\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,345 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1590|#Level:Host|#hostname:aeaba6005455,timestamp:1650241888\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,346 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:128|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,570 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1391\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,571 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1820|#Level:Host|#hostname:aeaba6005455,timestamp:1650241888\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,572 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:133|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,579 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,579 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1825|#Level:Host|#hostname:aeaba6005455,timestamp:1650241888\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:28,579 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:127|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m2022-04-18 00:31:35,112 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:44472 \"GET /ping HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,112 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,140 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:44484 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,141 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,329 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,112 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:44472 \"GET /ping HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,112 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,140 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:44484 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,141 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,329 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,330 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,330 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,330 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.66|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:c799b9aa-9065-4c8c-ae3d-cb85d035b0f1,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,331 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,332 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,414 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,414 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,415 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,417 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,419 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.32|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:ce3f0999-05bb-4d18-870c-1f0a9c12da1f,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,583 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.5|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:40e53ea9-18f8-4664-a76e-8c45221eca14,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,585 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,661 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,662 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,662 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.35|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:4fb87cc8-2720-4456-893b-9351130db55b,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,662 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,330 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,330 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,330 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.66|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:c799b9aa-9065-4c8c-ae3d-cb85d035b0f1,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,331 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,332 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,414 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,414 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,415 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,417 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,419 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.32|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:ce3f0999-05bb-4d18-870c-1f0a9c12da1f,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,583 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,584 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.5|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:40e53ea9-18f8-4664-a76e-8c45221eca14,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,585 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,661 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,662 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,662 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.35|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:4fb87cc8-2720-4456-893b-9351130db55b,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,662 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,663 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,663 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,768 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,768 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:8f2694cc-381e-4ff7-859f-a87eeab21645,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:91728dfd-b512-4ed5-bc56-473d6bb85b95,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,868 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,868 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,973 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:86462d03-25d9-4d23-ab00-956a18a4699c,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,663 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,663 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,768 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,768 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:8f2694cc-381e-4ff7-859f-a87eeab21645,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,769 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:91728dfd-b512-4ed5-bc56-473d6bb85b95,timestamp:1650241895\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,867 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,868 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,868 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,973 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.89|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:86462d03-25d9-4d23-ab00-956a18a4699c,timestamp:1650241895\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,973 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,973 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:35,974 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,075 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,075 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.01|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:c979e5b8-d351-4866-8eb3-f23e983d5304,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,199 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,199 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:7e4887c5-77ee-437d-bb09-2c1290a0d6f4,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,075 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,075 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.01|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:c979e5b8-d351-4866-8eb3-f23e983d5304,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,076 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,199 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,199 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:7e4887c5-77ee-437d-bb09-2c1290a0d6f4,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,200 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:e1e978b5-e89b-4184-b870-f8026d93cb34,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,291 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,291 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:03bbd271-23a6-4f97-8f74-54d206a11203,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,389 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,389 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,482 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,482 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:05a39a1f-550f-46d8-a4ab-bb0bad787800,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,482 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,483 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,483 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,483 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,570 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:ca413e4c-c8d5-450f-9f5d-51be6e134530,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,570 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,699 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,699 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:09736318-febd-4e92-9ccd-fca21691dcb7,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,290 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:e1e978b5-e89b-4184-b870-f8026d93cb34,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,291 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,291 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:03bbd271-23a6-4f97-8f74-54d206a11203,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,388 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,389 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,389 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,482 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,482 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.68|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:05a39a1f-550f-46d8-a4ab-bb0bad787800,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,482 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,483 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,483 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,483 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,570 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:ca413e4c-c8d5-450f-9f5d-51be6e134530,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,570 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,571 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,699 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,699 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:09736318-febd-4e92-9ccd-fca21691dcb7,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,817 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:b3247490-10da-4d5c-b4f4-177fb67fdcab,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,817 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,909 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:71cf38d0-8082-462a-a642-61074509fe05,timestamp:1650241896\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,817 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:b3247490-10da-4d5c-b4f4-177fb67fdcab,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,817 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,818 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,909 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:71cf38d0-8082-462a-a642-61074509fe05,timestamp:1650241896\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:36,910 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,209 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:33020 \"GET /ping HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,209 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,234 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:33028 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,235 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,706 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,707 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.87|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:227b55e2-a7fa-4598-973b-72af3ff57517,timestamp:1650241896\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,707 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,708 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,708 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,708 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,789 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,789 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,789 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,790 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,790 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,793 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.16|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:66a7abd0-8acc-4a58-ab8a-4c59227c3a34,timestamp:1650241896\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,956 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,957 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,957 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.59|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:89a7c047-6e98-4831-a5ae-4ee298656d11,timestamp:1650241896\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,957 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,957 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:36,957 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,040 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,041 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,041 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,041 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,041 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,041 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.43|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:53b4927a-4681-4402-92b1-502fdee4c1cc,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,012 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,012 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:8628f76e-49d3-4ff2-9f9e-1884344a99e2,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,012 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,012 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:8628f76e-49d3-4ff2-9f9e-1884344a99e2,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:f0b859d7-9ac3-4961-8e6c-cad21445a0a6,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,089 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,089 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,170 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:372f2fa2-9630-4d4b-a336-f0c645acdf86,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,171 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,171 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,172 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,172 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,172 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:b0ef0f3e-3f59-4f9e-942c-e04d18827555,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,415 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.31|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:a725d82f-b83b-4a36-908c-357f88d93092,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:feca74ad-59b1-4059-86f4-df1a82621e25,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,499 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,499 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:97441582-f139-4090-9210-9da15b779aa3,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,610 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,610 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,721 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,013 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,088 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:f0b859d7-9ac3-4961-8e6c-cad21445a0a6,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,089 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,089 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,170 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:372f2fa2-9630-4d4b-a336-f0c645acdf86,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,171 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,171 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,172 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,172 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,172 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:b0ef0f3e-3f59-4f9e-942c-e04d18827555,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,312 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,415 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.31|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:a725d82f-b83b-4a36-908c-357f88d93092,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,417 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:feca74ad-59b1-4059-86f4-df1a82621e25,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,498 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,499 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,499 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:97441582-f139-4090-9210-9da15b779aa3,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,609 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,610 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,610 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,721 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,721 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:91586bb6-f73d-48e3-82ea-ea21f17cc195,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,808 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.99|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:fb9bb9d8-0b26-4d84-a69e-e617de0fac97,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,810 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:e8c21333-c613-46a8-b6db-f594df078bc8,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,886 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,886 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:785ba516-f3f3-43fb-a1f4-4acedd4b5f98,timestamp:1650241897\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,721 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:91586bb6-f73d-48e3-82ea-ea21f17cc195,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,808 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.99|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:fb9bb9d8-0b26-4d84-a69e-e617de0fac97,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,809 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,810 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:e8c21333-c613-46a8-b6db-f594df078bc8,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,885 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,886 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,886 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:785ba516-f3f3-43fb-a1f4-4acedd4b5f98,timestamp:1650241897\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:37,977 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,145 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:0ca92892-412d-4b4a-8f04-0f24f8449075,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,146 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,146 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,147 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,147 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,147 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.04|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:5e808b17-7077-4502-99a4-4c21b7f0ee7e,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:728c5e6c-1fe2-43a2-a1b6-ec3c604c1449,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,356 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,482 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:4438bc7d-213a-4fe4-9091-52a5f5d59367,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,483 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,483 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,483 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,484 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,484 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,576 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,576 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.62|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:50e762c0-7961-4b73-be5b-f5d8a490139d,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,576 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,576 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,576 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,577 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,675 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.95|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:c6be9d72-a3bf-485e-93fa-bc33cbbe9366,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,676 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,676 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,676 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,790 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,790 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:7dd92d30-4f50-4451-ad7a-9a2c0e5bac1f,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,790 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,791 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,791 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,791 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,868 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,868 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:2a4aa142-240d-43ee-8c48-39203f12c87a,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,869 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,869 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,869 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,870 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,956 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,956 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:ddd338ae-015d-45f5-afc8-f16a65263bbc,timestamp:1650241897\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,956 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,956 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,957 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:37,957 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,028 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,028 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.99|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:263127c6-6899-4fe7-9afb-864d21461441,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,028 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,028 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,029 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,029 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-04-18T00:31:35.166:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[36m2022-04-18T00:31:35.166:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:43b7c81a-40e5-425e-909a-950eb23214be,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,074 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,074 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:edeb3c61-bcc1-4446-80a1-8bad4fa0b859,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,199 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:43b7c81a-40e5-425e-909a-950eb23214be,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,073 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,074 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,074 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:edeb3c61-bcc1-4446-80a1-8bad4fa0b859,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,198 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,199 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:a0d1e73b-8e62-41b7-8324-715f7ab78bee,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,278 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.03|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:f2ad3be4-bb23-47af-b44d-c5bdb8000fd7,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,362 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,455 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,455 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:4b339f15-ac1c-493e-81d1-f370f551bf8f,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:a0d1e73b-8e62-41b7-8324-715f7ab78bee,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,277 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,278 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.03|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:f2ad3be4-bb23-47af-b44d-c5bdb8000fd7,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,361 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,362 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,455 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,455 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:4b339f15-ac1c-493e-81d1-f370f551bf8f,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,456 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:3fec32ed-2f82-4c16-963f-3024a80c849e,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,549 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:9fb04cfa-de2d-4e94-ad81-5294fb544348,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,634 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,714 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,714 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,715 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,715 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,715 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,714 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:56194b87-7837-4b8c-ae2b-29f0bd555db5,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:a9de82c8-4e7d-4016-bf09-1cdb32ba362c,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:e94c019b-91a6-469b-9037-7862a951b8ef,timestamp:1650241898\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,895 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:3fec32ed-2f82-4c16-963f-3024a80c849e,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,548 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,549 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:9fb04cfa-de2d-4e94-ad81-5294fb544348,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,633 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,634 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,714 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,714 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,715 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,715 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,715 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,714 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:56194b87-7837-4b8c-ae2b-29f0bd555db5,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:a9de82c8-4e7d-4016-bf09-1cdb32ba362c,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,795 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:e94c019b-91a6-469b-9037-7862a951b8ef,timestamp:1650241898\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,894 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,895 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:38,895 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,008 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:dbcd5a31-f816-41c4-9d7d-e863b9c42c41,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:38,895 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,008 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:dbcd5a31-f816-41c4-9d7d-e863b9c42c41,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,009 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,101 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,101 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.06|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:cfe34dbd-0132-470e-8fbf-510237becf25,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,102 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,102 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,102 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,102 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,180 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,180 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:2789dd8b-0aff-40e3-ad39-042e4f24c667,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,180 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,180 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,181 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,181 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,264 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.22|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:5849d060-58a6-49ca-8aa8-7c3556a73029,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,264 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,264 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,264 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,264 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,264 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,344 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.02|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:7d29b540-302f-46f6-9e0b-2d847068f85e,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,345 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,345 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,346 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,346 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,346 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,465 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,465 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.08|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:dbeb7149-b0a4-4a22-b9cf-ed56a5cde68c,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,465 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,466 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,466 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,466 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,533 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,533 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:00839105-e7cf-4333-b753-23cec06c51a3,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,534 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,534 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,534 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,535 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,619 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.97|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:979783b2-39db-4452-baae-0d8a6197d923,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,619 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,619 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,619 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,619 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,620 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,720 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,720 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:a34bab70-4653-4cad-8309-c90b88ca7abd,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,720 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,807 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,807 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:ae9ef618-36d7-45f4-a4b1-6acf15659a05,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,807 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,807 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,808 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,808 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,910 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,910 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.0|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:5d44bd8e-fccd-4037-9c1b-5cd7deec6adc,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,910 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,911 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,911 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,911 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,993 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,993 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:344973ea-fdc9-4971-bc7b-5e3bb84ac9b4,timestamp:1650241898\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,993 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,993 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,993 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:38,994 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,065 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:e6773617-7ec3-4638-b4d6-cd50946ec2df,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,066 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,066 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,066 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,067 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,067 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:14a2e880-a272-495b-b826-644e912b9e91,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,195 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.97|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:04e4bfe5-44ab-48bf-be75-378c40d7a614,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,195 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,195 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,196 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,196 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,196 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,321 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:c00fa137-4528-42c7-9c44-a6c34c080239,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,322 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,322 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,323 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,323 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,323 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:14a2e880-a272-495b-b826-644e912b9e91,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,101 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,195 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.97|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:04e4bfe5-44ab-48bf-be75-378c40d7a614,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,195 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,195 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,196 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,196 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,196 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,321 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:c00fa137-4528-42c7-9c44-a6c34c080239,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,322 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,322 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,323 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,323 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,323 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.11|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:13561332-7314-476a-ba5a-2dd08cb21559,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,399 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,399 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,466 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:bb2810fe-ff27-408c-b755-1851414fad57,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:4581545b-af0b-40e5-9cf4-1f2516283725,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,849 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:7460afef-5259-4f8b-8174-372465fec3ad,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:18f7633a-7ea7-42cd-a332-e10ef4e37459,timestamp:1650241899\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.11|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:13561332-7314-476a-ba5a-2dd08cb21559,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,398 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,399 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,399 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,466 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,465 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:bb2810fe-ff27-408c-b755-1851414fad57,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:4581545b-af0b-40e5-9cf4-1f2516283725,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,576 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,849 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:7460afef-5259-4f8b-8174-372465fec3ad,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,850 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:18f7633a-7ea7-42cd-a332-e10ef4e37459,timestamp:1650241899\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:39,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,167 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,167 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.02|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:78f258da-cbd4-4257-b8e4-21a52ac6b9e0,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,168 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,168 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,168 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,168 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,239 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,240 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,240 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,240 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,240 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,241 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.97|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:f6adc969-b682-4898-8629-70f60920769d,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,319 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:6330ed70-1bc4-48fd-9c56-54e0dabf7636,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,319 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,320 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,320 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,320 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,320 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,425 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,425 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:080bdd6c-0fb0-43f4-b7d5-55d4acb1e3ba,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,425 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,425 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,425 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,425 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,500 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,500 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,500 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,500 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,500 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,500 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.95|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:8156bf18-3b7d-4eff-929e-360271be9cea,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,576 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,576 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,576 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,576 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,576 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,576 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:e4f7270d-c86e-4870-95de-71350e989d2e,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,687 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:2c8be008-add5-498b-9e38-9be5481cbfbc,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,688 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,688 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,783 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,783 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.0|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:3b20f880-2fc4-49ae-91f9-9eec5ca7f62c,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,783 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,783 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,783 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,783 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,896 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:d69cfe35-cfa8-4bd9-b84d-d5e8713da29a,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,896 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,897 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,897 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,897 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,897 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,998 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,998 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:0ab7d0c0-6d4a-4453-82d3-b22487820980,timestamp:1650241899\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,999 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,999 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,999 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:39,999 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:fa834bd9-83db-461a-a6bd-aaa21880fde2,timestamp:1650241900\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,042 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:be1cc1e4-7046-4dcc-b30a-93e6352660ee,timestamp:1650241900\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:d09c61ab-3119-409f-9f2f-2d3219b5c57b,timestamp:1650241900\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,407 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,407 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:78e83f62-bbbe-43d6-a26b-ad673804d849,timestamp:1650241900\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:fa834bd9-83db-461a-a6bd-aaa21880fde2,timestamp:1650241900\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,041 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,042 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:be1cc1e4-7046-4dcc-b30a-93e6352660ee,timestamp:1650241900\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,228 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:d09c61ab-3119-409f-9f2f-2d3219b5c57b,timestamp:1650241900\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,326 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,407 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,407 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:aeaba6005455,requestID:78e83f62-bbbe-43d6-a26b-ad673804d849,timestamp:1650241900\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:44492 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n",
      "\u001b[32m2022-04-18 00:31:40,408 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:aeaba6005455,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2022-04-18T00:31:36.242:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,200 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,200 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.02|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:6738de45-b281-4d36-b934-b536cdfd6094,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,200 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,201 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,282 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:a3ba2aee-7ef6-4875-9e06-b0f66165ca23,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,282 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,282 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,282 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,283 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,422 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:e2aabc1b-4c78-4e3c-83f8-69b74ffa0d65,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,422 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,422 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,422 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,422 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,600 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:e5ca6928-3980-4d67-bca8-28a7db32e549,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,600 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,600 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,600 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,601 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,601 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,680 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:e7699b7f-84ac-477f-9516-8632d313c6d3,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,680 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,681 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,681 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,681 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,681 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,773 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,773 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:ca289c06-8bfb-4b08-8f13-85eb8e419afb,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,774 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,774 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,774 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,774 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,881 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,881 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:26879460-25da-42cd-9b1f-44d7167777d9,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,881 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,881 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,882 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,882 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,959 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,959 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:1f4658dd-a8df-4b59-a63d-6c8c16d77e71,timestamp:1650241900\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,960 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,960 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,960 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:40,960 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,057 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,057 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,057 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,057 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,057 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.67|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:27625aff-b3fd-40a8-8451-e4361cbc11f3,timestamp:1650241901\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,057 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,155 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:4e4901d4-b922-4479-a187-d95f1d7ffbb9,timestamp:1650241901\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,156 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,156 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,156 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,157 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,157 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,236 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,236 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:72175ab0-8de5-45dd-967a-ec7a232d0253,timestamp:1650241901\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,236 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,237 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,237 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,237 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,330 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,330 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:162df6be-8c39-416c-afce-8a67be0f4f58,timestamp:1650241901\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,331 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,331 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,331 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,331 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,451 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,451 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:c864d856-7d5b-46aa-91b1-3d454af757a4,timestamp:1650241901\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,452 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,452 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,452 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,452 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,532 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,532 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:6925eb526ceb,requestID:ced3a724-9b27-4786-b487-c40c90b89521,timestamp:1650241901\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,533 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:33038 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,533 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,533 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n",
      "\u001b[33m2022-04-18 00:31:41,533 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:6925eb526ceb,timestamp:null\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dist_transformer = estimator.transformer(instance_count=2, instance_type=\"ml.c4.xlarge\")\n",
    "\n",
    "dist_transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2f7f8",
   "metadata": {
    "papermill": {
     "duration": 0.295876,
     "end_time": "2022-04-18T00:32:02.393703",
     "exception": false,
     "start_time": "2022-04-18T00:32:02.097827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Look at all transform jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c6f2e",
   "metadata": {
    "papermill": {
     "duration": 0.292962,
     "end_time": "2022-04-18T00:32:02.978525",
     "exception": false,
     "start_time": "2022-04-18T00:32:02.685563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We list and describe the transform jobs to retrieve information about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7725d230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:32:03.573419Z",
     "iopub.status.busy": "2022-04-18T00:32:03.572840Z",
     "iopub.status.idle": "2022-04-18T00:32:03.629107Z",
     "shell.execute_reply": "2022-04-18T00:32:03.628598Z"
    },
    "papermill": {
     "duration": 0.356285,
     "end_time": "2022-04-18T00:32:03.629220",
     "exception": false,
     "start_time": "2022-04-18T00:32:03.272935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 32, 3, 162000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 32, 3, 162000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/automl-churn-sdk-18-00-20-19-dpp0-rpb-1-ab06a7aa54904c088293a6d',\n",
      " 'TransformJobName': 'automl-churn-sdk-18-00-20-19-dpp0-rpb-1-ab06a7aa54904c088293a6d',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 32, 0, 946000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 32, 1, 607000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/automl-churn-sdk-18-00-20-19-dpp8-rpb-1-9abdff16bbd34c83872e871',\n",
      " 'TransformJobName': 'automl-churn-sdk-18-00-20-19-dpp8-rpb-1-9abdff16bbd34c83872e871',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 31, 58, 909000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 31, 59, 560000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/automl-churn-sdk-18-00-20-19-dpp1-csv-1-1dd140703bb140bdaf51362',\n",
      " 'TransformJobName': 'automl-churn-sdk-18-00-20-19-dpp1-csv-1-1dd140703bb140bdaf51362',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 29, 11, 444000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 29, 11, 758000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/sagemaker-scikit-learn-2022-04-18-00-29-11-429',\n",
      " 'TransformJobName': 'sagemaker-scikit-learn-2022-04-18-00-29-11-429',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 27, 37, 320000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 31, 17, 282000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/xgboost-2022-04-18-00-27-37-309',\n",
      " 'TransformJobName': 'xgboost-2022-04-18-00-27-37-309',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 26, 41, 812000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 30, 29, 572000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/batch-transform-2022-04-18-00-26-41',\n",
      " 'TransformJobName': 'Batch-Transform-2022-04-18-00-26-41',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 26, 12, 635000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 31, 42, 971000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 4, 18, 0, 31, 42, 720000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/pytorch-training-2022-04-18-00-26-12-621',\n",
      " 'TransformJobName': 'pytorch-training-2022-04-18-00-26-12-621',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 26, 9, 32000, tzinfo=tzlocal()),\n",
      " 'FailureReason': 'ClientError: See job logs for more information',\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 30, 13, 568000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 4, 18, 0, 30, 13, 253000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/pytorch-inference-2022-04-18-00-26-08-985',\n",
      " 'TransformJobName': 'pytorch-inference-2022-04-18-00-26-08-985',\n",
      " 'TransformJobStatus': 'Failed'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 23, 34, 840000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 28, 0, 728000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 4, 18, 0, 28, 0, 359000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/r-transformer-2022-04-18-00-23-34-816',\n",
      " 'TransformJobName': 'R-Transformer-2022-04-18-00-23-34-816',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 23, 9, 974000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 4, 18, 0, 26, 38, 885000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/tensorflow-inference-2022-04-18-00-23-09-960',\n",
      " 'TransformJobName': 'tensorflow-inference-2022-04-18-00-23-09-960',\n",
      " 'TransformJobStatus': 'InProgress'}\n"
     ]
    }
   ],
   "source": [
    "transform_jobs = sm_cli.list_transform_jobs()[\"TransformJobSummaries\"]\n",
    "for job in transform_jobs:\n",
    "    pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b694abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:32:04.222511Z",
     "iopub.status.busy": "2022-04-18T00:32:04.221876Z",
     "iopub.status.idle": "2022-04-18T00:32:04.245129Z",
     "shell.execute_reply": "2022-04-18T00:32:04.245524Z"
    },
    "papermill": {
     "duration": 0.32679,
     "end_time": "2022-04-18T00:32:04.245654",
     "exception": false,
     "start_time": "2022-04-18T00:32:03.918864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 4, 18, 0, 26, 12, 635000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'Environment': {},\n",
      " 'ModelName': 'pytorch-training-2022-04-18-00-26-11-963',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '907',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Mon, 18 Apr 2022 00:32:03 GMT',\n",
      "                                      'x-amzn-requestid': 'c75d7d27-2982-45b7-b619-f04bffe72fff'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'c75d7d27-2982-45b7-b619-f04bffe72fff',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 4, 18, 0, 31, 42, 720000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-000000000000/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:000000000000:transform-job/pytorch-training-2022-04-18-00-26-12-621',\n",
      " 'TransformJobName': 'pytorch-training-2022-04-18-00-26-12-621',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-000000000000/pytorch-training-2022-04-18-00-26-12-621'},\n",
      " 'TransformResources': {'InstanceCount': 2, 'InstanceType': 'ml.c4.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 4, 18, 0, 29, 50, 865000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "job_info = sm_cli.describe_transform_job(\n",
    "    TransformJobName=dist_transformer.latest_transform_job.name\n",
    ")\n",
    "\n",
    "pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e682401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:32:04.838606Z",
     "iopub.status.busy": "2022-04-18T00:32:04.837785Z",
     "iopub.status.idle": "2022-04-18T00:32:10.200144Z",
     "shell.execute_reply": "2022-04-18T00:32:10.200553Z"
    },
    "papermill": {
     "duration": 5.663189,
     "end_time": "2022-04-18T00:32:10.200683",
     "exception": false,
     "start_time": "2022-04-18T00:32:04.537494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-521695447989 pytorch-training-2022-04-18-00-26-12-621\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_bucket_and_prefix(s3_output_path):\n",
    "    trim = re.sub(\"s3://\", \"\", s3_output_path)\n",
    "    bucket, prefix = trim.split(\"/\")\n",
    "    return bucket, prefix\n",
    "\n",
    "\n",
    "local_path = \"output\"  # Where to save the output locally\n",
    "\n",
    "bucket, output_prefix = get_bucket_and_prefix(job_info[\"TransformOutput\"][\"S3OutputPath\"])\n",
    "print(bucket, output_prefix)\n",
    "\n",
    "sagemaker_session.download_data(path=local_path, bucket=bucket, key_prefix=output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae24be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:32:10.792642Z",
     "iopub.status.busy": "2022-04-18T00:32:10.792085Z",
     "iopub.status.idle": "2022-04-18T00:32:10.946512Z",
     "shell.execute_reply": "2022-04-18T00:32:10.946025Z"
    },
    "papermill": {
     "duration": 0.452671,
     "end_time": "2022-04-18T00:32:10.946628",
     "exception": false,
     "start_time": "2022-04-18T00:32:10.493957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png.out   24.png.out\t4.png.out   55.png.out\t70.png.out  86.png.out\r\n",
      "1.png.out   25.png.out\t40.png.out  56.png.out\t71.png.out  87.png.out\r\n",
      "10.png.out  26.png.out\t41.png.out  57.png.out\t72.png.out  88.png.out\r\n",
      "11.png.out  27.png.out\t42.png.out  58.png.out\t73.png.out  89.png.out\r\n",
      "12.png.out  28.png.out\t43.png.out  59.png.out\t74.png.out  9.png.out\r\n",
      "13.png.out  29.png.out\t44.png.out  6.png.out\t75.png.out  90.png.out\r\n",
      "14.png.out  3.png.out\t45.png.out  60.png.out\t76.png.out  91.png.out\r\n",
      "15.png.out  30.png.out\t46.png.out  61.png.out\t77.png.out  92.png.out\r\n",
      "16.png.out  31.png.out\t47.png.out  62.png.out\t78.png.out  93.png.out\r\n",
      "17.png.out  32.png.out\t48.png.out  63.png.out\t79.png.out  94.png.out\r\n",
      "18.png.out  33.png.out\t49.png.out  64.png.out\t8.png.out   95.png.out\r\n",
      "19.png.out  34.png.out\t5.png.out   65.png.out\t80.png.out  96.png.out\r\n",
      "2.png.out   35.png.out\t50.png.out  66.png.out\t81.png.out  97.png.out\r\n",
      "20.png.out  36.png.out\t51.png.out  67.png.out\t82.png.out  98.png.out\r\n",
      "21.png.out  37.png.out\t52.png.out  68.png.out\t83.png.out  99.png.out\r\n",
      "22.png.out  38.png.out\t53.png.out  69.png.out\t84.png.out\r\n",
      "23.png.out  39.png.out\t54.png.out  7.png.out\t85.png.out\r\n"
     ]
    }
   ],
   "source": [
    "!ls {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c336288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:32:11.547730Z",
     "iopub.status.busy": "2022-04-18T00:32:11.546979Z",
     "iopub.status.idle": "2022-04-18T00:32:11.568317Z",
     "shell.execute_reply": "2022-04-18T00:32:11.568698Z"
    },
    "papermill": {
     "duration": 0.332156,
     "end_time": "2022-04-18T00:32:11.568824",
     "exception": false,
     "start_time": "2022-04-18T00:32:11.236668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 9}\n",
      "{'predictions': 9}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 2}\n",
      "{'predictions': 5}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 3}\n",
      "{'predictions': 8}\n",
      "{'predictions': 6}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 5}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 5}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 8}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 0}\n",
      "{'predictions': 9}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 9}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 8}\n",
      "{'predictions': 0}\n",
      "{'predictions': 6}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 9}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 0}\n",
      "{'predictions': 6}\n",
      "{'predictions': 1}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 5}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 8}\n",
      "{'predictions': 1}\n",
      "{'predictions': 6}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 9}\n",
      "{'predictions': 5}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 7}\n",
      "{'predictions': 8}\n",
      "{'predictions': 1}\n",
      "{'predictions': 8}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, \"r\") as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbd160",
   "metadata": {
    "papermill": {
     "duration": 0.29213,
     "end_time": "2022-04-18T00:32:12.153859",
     "exception": false,
     "start_time": "2022-04-18T00:32:11.861729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we trained a PyTorch model, created a transformer from it, and then performed batch inference using S3 inputs, manifest files, and on multiple instances. This shows a variety of options that are available when running SageMaker Batch Transform jobs for batch inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.388884,
   "end_time": "2022-04-18T00:32:13.173276",
   "environment_variables": {},
   "exception": null,
   "input_path": "pytorch-mnist-batch-transform.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch-mnist-batch-transform-2022-04-18-00-11-16.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:000000000000:1234abcd-12ab-34cd-56ef-1234567890ab"
   },
   "start_time": "2022-04-18T00:16:04.784392",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "083e8e6e8ee3442d9e180fb7217f94d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c0983f176954e2dbfbc19134390ce75",
       "placeholder": "​",
       "style": "IPY_MODEL_6ce2b254a3084416ba39feea20f4db50",
       "value": ""
      }
     },
     "0d31b5bf85994c1997ff5843616a1fe5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "108a724d659644f7aa963a18f30220f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "22ade62672be47228462b15640478dc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23778be2d2104b5eba74710a40863802": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "35f84a8650d54901b2a673cd86950c46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8f50cce22f994dc198b5827775bf292e",
        "IPY_MODEL_3fe082b3ccbb45de946ddb4a5f677c7b",
        "IPY_MODEL_b172ab5199b1498da586f159c3d95167"
       ],
       "layout": "IPY_MODEL_6deef4cb468347d8b315c54266198a22"
      }
     },
     "3e43540206cb40c59b33de0c6fdf7e6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3fe082b3ccbb45de946ddb4a5f677c7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_def9818bec214c23b00a2cc115a46fd5",
       "max": 28881,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_647dc83b9b51428aa0edc85034bb1762",
       "value": 28881
      }
     },
     "43863011b1534b2f90aed2c606dc1c78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4e0b9845e305426e9af70fb2b89d6e68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_611ed08651634af1a4e9af17c997458e",
       "placeholder": "​",
       "style": "IPY_MODEL_23778be2d2104b5eba74710a40863802",
       "value": ""
      }
     },
     "55e858baad5749bc9590e27b052abda9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4e0b9845e305426e9af70fb2b89d6e68",
        "IPY_MODEL_a26acf069d0746e891b3bc30766cbed2",
        "IPY_MODEL_69800d372f6a4785ba79d98f26213dd3"
       ],
       "layout": "IPY_MODEL_c0258b60d54047818cbae0d7c87bc28c"
      }
     },
     "57269fbb396e461c9f0b4e65e1029410": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5776c87e41b24ce18ee20e80b08ecea1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "611ed08651634af1a4e9af17c997458e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62f4c63a1bb24046b832bacc4935b4d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1a5b433f6a44c68838de5494af1ef8a",
       "placeholder": "​",
       "style": "IPY_MODEL_79e749c778614474ba11308b7ef5047d",
       "value": ""
      }
     },
     "647dc83b9b51428aa0edc85034bb1762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "69800d372f6a4785ba79d98f26213dd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_22ade62672be47228462b15640478dc4",
       "placeholder": "​",
       "style": "IPY_MODEL_74ba869539e04697a7c2c4974ce3f95f",
       "value": " 5120/? [00:00&lt;00:00, 229084.47it/s]"
      }
     },
     "6ce2b254a3084416ba39feea20f4db50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6deef4cb468347d8b315c54266198a22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f1077a09119486090f33988958dde5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_57269fbb396e461c9f0b4e65e1029410",
       "placeholder": "​",
       "style": "IPY_MODEL_43863011b1534b2f90aed2c606dc1c78",
       "value": " 9913344/? [00:00&lt;00:00, 16970534.49it/s]"
      }
     },
     "71de3a71ded24916809faeadbb15b4f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62f4c63a1bb24046b832bacc4935b4d4",
        "IPY_MODEL_fd83686ac3194214be8f90b2bb8a9d1f",
        "IPY_MODEL_8347f21f631642aaa100d787d3750f8c"
       ],
       "layout": "IPY_MODEL_a8e345f5c357431fb36f6866a41b452c"
      }
     },
     "74ba869539e04697a7c2c4974ce3f95f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "770b0c1f4ccf4cde8138bd1b73c93601": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79040f80b3de475fa8a880e95449a07f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79e749c778614474ba11308b7ef5047d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7b67965ead9e49d5bffe0c01426ba327": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c0983f176954e2dbfbc19134390ce75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8347f21f631642aaa100d787d3750f8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9c59a9348eff4496b412fe3b2bb99293",
       "placeholder": "​",
       "style": "IPY_MODEL_a4b9335979064476a58a8ea49c5a09ef",
       "value": " 1649664/? [00:00&lt;00:00, 3026257.05it/s]"
      }
     },
     "8aac8b5cdde94af0bf0d4d35bb7434e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_083e8e6e8ee3442d9e180fb7217f94d0",
        "IPY_MODEL_aabbd4ed501742cebbc2a3939c5f3a07",
        "IPY_MODEL_6f1077a09119486090f33988958dde5b"
       ],
       "layout": "IPY_MODEL_c5606d53f7f849b488ecc0fcb973a6f4"
      }
     },
     "8f50cce22f994dc198b5827775bf292e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_770b0c1f4ccf4cde8138bd1b73c93601",
       "placeholder": "​",
       "style": "IPY_MODEL_3e43540206cb40c59b33de0c6fdf7e6d",
       "value": ""
      }
     },
     "9c59a9348eff4496b412fe3b2bb99293": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a26acf069d0746e891b3bc30766cbed2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7b67965ead9e49d5bffe0c01426ba327",
       "max": 4542,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ba417460c2ba42e781a003380e84adfe",
       "value": 4542
      }
     },
     "a4b9335979064476a58a8ea49c5a09ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a8e345f5c357431fb36f6866a41b452c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aabbd4ed501742cebbc2a3939c5f3a07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0d31b5bf85994c1997ff5843616a1fe5",
       "max": 9912422,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e5bf7b802788492f9f3b274f42a93f0c",
       "value": 9912422
      }
     },
     "b172ab5199b1498da586f159c3d95167": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_79040f80b3de475fa8a880e95449a07f",
       "placeholder": "​",
       "style": "IPY_MODEL_ccc28938faa74efe97368eb13b079243",
       "value": " 29696/? [00:00&lt;00:00, 451461.09it/s]"
      }
     },
     "ba417460c2ba42e781a003380e84adfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c0258b60d54047818cbae0d7c87bc28c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5606d53f7f849b488ecc0fcb973a6f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccc28938faa74efe97368eb13b079243": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "def9818bec214c23b00a2cc115a46fd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5bf7b802788492f9f3b274f42a93f0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f1a5b433f6a44c68838de5494af1ef8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd83686ac3194214be8f90b2bb8a9d1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5776c87e41b24ce18ee20e80b08ecea1",
       "max": 1648877,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_108a724d659644f7aa963a18f30220f4",
       "value": 1648877
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
