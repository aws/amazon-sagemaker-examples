{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "english-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from opencv-python) (1.18.1)\n",
      "Requirement already satisfied: tensorflow-hub in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-hub) (1.18.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-hub) (3.8.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow-hub) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow-hub) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow-hub\n",
    "!apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-berry",
   "metadata": {
    "papermill": {
     "duration": 0.011217,
     "end_time": "2021-05-25T00:17:49.054305",
     "exception": false,
     "start_time": "2021-05-25T00:17:49.043088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using the SageMaker TensorFlow Serving Container\n",
    "\n",
    "The [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) makes it easy to deploy trained TensorFlow models to a SageMaker Endpoint without the need for any custom model loading or inference code.\n",
    "\n",
    "In this example, we will show how deploy one or more pre-trained models from [TensorFlow Hub](https://www.tensorflow.org/hub/) to a SageMaker Endpoint using the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk), and then use the model(s) to perform inference requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-robin",
   "metadata": {
    "papermill": {
     "duration": 0.012117,
     "end_time": "2021-05-25T00:17:56.085368",
     "exception": false,
     "start_time": "2021-05-25T00:17:56.073251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we'll get the IAM execution role from our notebook environment, so that SageMaker can access resources in your AWS account later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparable-voice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T00:17:56.113324Z",
     "iopub.status.busy": "2021-05-25T00:17:56.112780Z",
     "iopub.status.idle": "2021-05-25T00:17:57.048541Z",
     "shell.execute_reply": "2021-05-25T00:17:57.048965Z"
    },
    "papermill": {
     "duration": 0.951802,
     "end_time": "2021-05-25T00:17:57.049117",
     "exception": false,
     "start_time": "2021-05-25T00:17:56.097315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-newspaper",
   "metadata": {
    "papermill": {
     "duration": 0.012197,
     "end_time": "2021-05-25T00:17:57.073710",
     "exception": false,
     "start_time": "2021-05-25T00:17:57.061513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download and prepare a model from TensorFlow Hub\n",
    "\n",
    "The TensorFlow Serving Container works with any model stored in TensorFlow's [SavedModel format](https://www.tensorflow.org/guide/saved_model). This could be the output of your own training job or a model trained elsewhere. For this example, we will use a pre-trained version of the MobileNet V2 image classification model from [TensorFlow Hub](https://tfhub.dev/).\n",
    "\n",
    "The TensorFlow Hub models are pre-trained, but do not include a serving ``signature_def``, so we'll need to load the model into a TensorFlow session, define the input and output layers, and export it as a SavedModel. There is a helper function in this notebook's `sample_utils.py` module that will do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "challenging-conference",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-05-25T00:17:57.102079Z",
     "iopub.status.busy": "2021-05-25T00:17:57.101551Z",
     "iopub.status.idle": "2021-05-25T00:17:57.192112Z",
     "shell.execute_reply": "2021-05-25T00:17:57.191012Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.106642,
     "end_time": "2021-05-25T00:17:57.192359",
     "exception": true,
     "start_time": "2021-05-25T00:17:57.085717",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:32: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:49: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:49: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:49: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:49: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:50: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/SageMaker/batch_fix/import_error/sagemaker-python-sdk/tensorflow_serving_container/sample_utils.py:50: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: mobilenet/mobilenet_v2_140_224/00000001/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: mobilenet/mobilenet_v2_140_224/00000001/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel exported to mobilenet/mobilenet_v2_140_224/00000001\n"
     ]
    }
   ],
   "source": [
    "import sample_utils\n",
    "\n",
    "model_name = \"mobilenet_v2_140_224\"\n",
    "export_path = \"mobilenet\"\n",
    "model_path = sample_utils.tfhub_to_savedmodel(model_name, export_path)\n",
    "\n",
    "print(\"SavedModel exported to {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-reserve",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "After exporting the model, we can inspect it using TensorFlow's ``saved_model_cli`` command. In the command output, you should see \n",
    "\n",
    "```\n",
    "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
    "\n",
    "signature_def['serving_default']:\n",
    "...\n",
    "```\n",
    "\n",
    "The command output should also show details of the model inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artificial-music",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['images'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 224, 224, 3)\n",
      "        name: images:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1, 3)\n",
      "        name: TopKV2:1\n",
      "    outputs['probabilities'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 3)\n",
      "        name: TopKV2:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir {model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-cheese",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Optional: add a second model\n",
    "\n",
    "The TensorFlow Serving container can host multiple models, if they are packaged in the same model archive file. Let's prepare a second version of the MobileNet model so we can demonstrate this. The `mobilenet_v2_035_224` model is a shallower version of MobileNetV2 that trades accuracy for smaller model size and faster computation, but has the same inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "filled-auditor",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: mobilenet/mobilenet_v2_035_224/00000001/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: mobilenet/mobilenet_v2_035_224/00000001/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel exported to mobilenet/mobilenet_v2_035_224/00000001\n"
     ]
    }
   ],
   "source": [
    "second_model_name = \"mobilenet_v2_035_224\"\n",
    "second_model_path = sample_utils.tfhub_to_savedmodel(second_model_name, export_path)\n",
    "\n",
    "print(\"SavedModel exported to {}\".format(second_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-colonial",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Next we need to create a model archive file containing the exported model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-million",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Create a model archive file\n",
    "\n",
    "SageMaker models need to be packaged in `.tar.gz` files. When your endpoint is provisioned, the files in the archive will be extracted and put in `/opt/ml/model/` on the endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "through-panic",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -C \"$PWD\" -czf mobilenet.tar.gz mobilenet/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-absorption",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Upload the model archive file to S3\n",
    "\n",
    "We now have a suitable model archive ready in our notebook. We need to upload it to S3 before we can create a SageMaker Model that. We'll use the SageMaker Python SDK to handle the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "small-request",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-us-west-2-688520471316/model/mobilenet.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "model_data = Session().upload_data(path=\"mobilenet.tar.gz\", key_prefix=\"model\")\n",
    "print(\"model uploaded to: {}\".format(model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-portsmouth",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Create a SageMaker Model and Endpoint\n",
    "\n",
    "Now that the model archive is in S3, we can create a Model and deploy it to an \n",
    "Endpoint with a few lines of python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elementary-singapore",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---!"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "# Use an env argument to set the name of the default model.\n",
    "# This is optional, but recommended when you deploy multiple models\n",
    "# so that requests that don't include a model name are sent to a\n",
    "# predictable model.\n",
    "env = {\"SAGEMAKER_TFS_DEFAULT_MODEL_NAME\": \"mobilenet_v2_140_224\"}\n",
    "\n",
    "model = Model(model_data=model_data, role=sagemaker_role, framework_version=\"1.15.2\", env=env)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-bookmark",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Make predictions using the endpoint\n",
    "\n",
    "The endpoint is now up and running, and ready to handle inference requests. The `deploy` call above returned a `predictor` object. The `predict` method of this object handles sending requests to the endpoint. It also automatically handles JSON serialization of our input arguments, and JSON deserialization of the prediction results.\n",
    "\n",
    "We'll use these sample images:\n",
    "\n",
    "<img src=\"kitten.jpg\" align=\"left\" style=\"padding: 8px;\">\n",
    "<img src=\"bee.jpg\" style=\"padding: 8px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "straight-gazette",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'probabilities': [0.428937078, 0.317184091, 0.0627320185], 'classes': [283, 282, 286]}]}\n"
     ]
    }
   ],
   "source": [
    "# read the image files into a tensor (numpy array)\n",
    "kitten_image = sample_utils.image_file_to_tensor(\"kitten.jpg\")\n",
    "\n",
    "# get a prediction from the endpoint\n",
    "# the image input is automatically converted to a JSON request.\n",
    "# the JSON response from the endpoint is returned as a python dict\n",
    "result = predictor.predict(kitten_image)\n",
    "\n",
    "# show the raw result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-greene",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Add class labels and show formatted results\n",
    "\n",
    "The `sample_utils` module includes functions that can add Imagenet class labels to our results and print formatted output. Let's use them to get a better sense of how well our model worked on the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floral-strap",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4289371 n02123159 tiger cat\n",
      "0.3171841 n02123045 tabby, tabby cat\n",
      "0.0627320 n02124075 Egyptian cat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add class labels to the predicted result\n",
    "sample_utils.add_imagenet_labels(result)\n",
    "\n",
    "# show the probabilities and labels for the top predictions\n",
    "sample_utils.print_probabilities_and_labels(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-nomination",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Optional: make predictions using the second model\n",
    "\n",
    "If you added the second model (`mobilenet_v2_035_224`) in the previous optional step, then you can also send prediction requests to that model. To do that, we'll need to create a new `predictor` object.\n",
    "\n",
    "Note: if you are using local mode (by changing the instance type to `local` or `local_gpu`), you'll need to create the new predictor this way instead:\n",
    "\n",
    "```\n",
    "predictor2 = Predictor(predictor.endpoint, model_name='mobilenet_v2_035_224', \n",
    "                       sagemaker_session=predictor.sagemaker_session)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "horizontal-significance",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:The class sagemaker.tensorflow.serving.Predictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767631 n02206856 bee\n",
      "0.0039321 n02190166 fly\n",
      "0.0019624 n11879895 rapeseed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "# use values from the default predictor to set up the new one\n",
    "predictor2 = Predictor(predictor.endpoint, model_name=\"mobilenet_v2_035_224\")\n",
    "\n",
    "# make a new prediction\n",
    "bee_image = sample_utils.image_file_to_tensor(\"bee.jpg\")\n",
    "result = predictor2.predict(bee_image)\n",
    "\n",
    "# show the formatted result\n",
    "sample_utils.add_imagenet_labels(result)\n",
    "sample_utils.print_probabilities_and_labels(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-acceptance",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Additional Information\n",
    "\n",
    "The TensorFlow Serving Container supports additional features not covered in this notebook, including support for:\n",
    "\n",
    "- TensorFlow Serving REST API requests, including classify and regress requests\n",
    "- CSV input\n",
    "- Other JSON formats\n",
    "\n",
    "For information on how to use these features, refer to the documentation in the \n",
    "[SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst).\n",
    "\n",
    "## Cleaning up\n",
    "\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial, you need to delete the SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compressed-music",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.046269,
   "end_time": "2021-05-25T00:17:58.429193",
   "environment_variables": {},
   "exception": true,
   "input_path": "tensorflow_serving_container.ipynb",
   "output_path": "/opt/ml/processing/output/tensorflow_serving_container-2021-05-25-00-13-48.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-05-25T00:17:48.382924",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
