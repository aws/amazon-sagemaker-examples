{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smdebug\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from smdebug.profiler.analysis.utils.profiler_data_to_pandas import PandasFrame\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "from smdebug.profiler.analysis.utils.pytorch_dataloader_analysis import PT_dataloader_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the path to profiler output\n",
    "\n",
    "If the training job name and region are known set the appropriate variables in following cell and run the cell to obtain path.  Optionally, if path to profiler output is already known, the following cell can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = 'pt-multiworker-resnext101-2020-09-08-21-43-05-168'\n",
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()\n",
    "tj.wait_for_framework_profiling_data_to_be_available()\n",
    "framework_metrics_reader = tj.get_framework_metrics_reader()\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "\n",
    "profiler_output_path = tj.profiler_s3_output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if the profiler output path is already known.\n",
    "profiler_output_path=\"/Users/amollele/tornasole-awslabs/sagemaker-profiler-pytorch-analysis/traceevents/pt-multiworker-resnext101-2020-09-08-21-43-05-168/profiler-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf  = PandasFrame(path=profiler_output_path, use_in_memory_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_analysis = PT_dataloader_analysis(pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of DataloaderIter initializations.\n",
    "\n",
    "The following cell analyzes\n",
    "1. Which type of Dataloader iterators were initialized.\n",
    "2. The number of workers per iterator.\n",
    "3. Log the status of pin_memory.\n",
    "4. Number of times the iteratos were initilized during training.  In PYTorch, iterators are initialized every time iterations over the dataset is to be started. (i.e. typically at the beginning of every epoch.) During initialization, PyTorch spins of worker processes depending upon the configured number of workers, establishes data queue to fetch data and pin_memory thread, if pin_memory is set.\n",
    "\n",
    "The analysis outputs the median and maximum duration for these initializations. If there are outliers, (i.e duration is greater than 2 * median), the function prints the start and end times for those durations. These can be used to inspect system metrics during those time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_analysis.analyze_dataloaderIter_initialization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Dataloader worker processes\n",
    "\n",
    "In PyTorch, every time DataLoaderIterator is initalized, it spins of the worker processes that feed the data to iterator through attached data queue. These worker processes have lifetime similar to that of DataLoaderIterator.\n",
    "\n",
    "The following analysis shows \n",
    "1. The number of worker processes that were spun off during the entire training.\n",
    "2. Median and maximum duration for the worker processes.\n",
    "3. Start and end time for the worker processes that are outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pt_analysis.analyze_dataloaderWorkers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of DataLoaderIter::GetNext \n",
    "\n",
    "In PyTorch, the GetNext method is responsible for fetching the data from worker processes through the data queue.\n",
    "These calls are run in the main training thread.\n",
    "The analysis of these events show\n",
    "1. Number of GetNext calls made during the training.\n",
    "2. Median and maximum duration in micoseconds for GetNext calls.\n",
    "3. Start time, End time, duration and worker id for the outlier GetNext call duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pt_analysis.analyze_dataloader_getnext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze a specific outlier in DataLoaderIter::GetNext\n",
    "\n",
    "To analyze specific outlier, select the row index corresponding to the outlier that we want to analyze and run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting TimeLine charts for the first outlier reported in the above dataframe.\n",
    "if md is not None and md.size > 0:\n",
    "    index = 0\n",
    "    start_timestamp = pf.convert_datetime_to_timestamp(md.loc[index]['start_time'])\n",
    "    end_timestamp = pf.convert_datetime_to_timestamp(md.loc[index]['end_time'])\n",
    "    pt_analysis.plot_the_window(start_timestamp, end_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of training activity for each batch of data.\n",
    "\n",
    "Since, we have the start and end times of all the GetNext calls, we can find the amount of time spent by the training script on one batch of data.\n",
    "\n",
    "1. We will get the time spent on each data batch by finding the difference between start time of current GetNext call and subsequent GetNext call. Let's call it 'BatchTime_in_seconds'\n",
    "2. We will find the outliers in 'BatchTime_in_seconds' and start and end time for those outliers.\n",
    "3. Obtain the framework and system metrics during those timestamps. This will indicate where the time was spent.\n",
    "\n",
    "\n",
    "\n",
    "### Analyze the BatchTime_in_seconds\n",
    "\n",
    "Following cell \n",
    "1. plots the BatchTime_in_seconds\n",
    "2. Prints the median 'BatchTime_in_seconds'\n",
    "3. Creates a dataframe that contains outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_batch = pt_analysis.analyze_batchtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze a specific outlier in BatchTime_in_seconds\n",
    "\n",
    "To analyze specific outlier, select the row index corresponding to the outlier that we want to analyze and run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the TimeLine charts for the first outlier reported in the above dataframe.\n",
    "if md_batch is not None and md_batch.size > 0:\n",
    "    index = 1\n",
    "    start_timestamp = pf.convert_datetime_to_timestamp(md_batch.loc[index]['previous_batch_start'])\n",
    "    end_timestamp = pf.convert_datetime_to_timestamp(md_batch.loc[index]['start_time'])\n",
    "    view_timeline_charts=pt_analysis.plot_the_window(start_timestamp, end_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cells fetch the python profiler stats that we had cpatured during the start and end timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the python profiler stats for the given time window.\n",
    "!mkdir -p /tmp/python_stats\n",
    "from smdebug.profiler.analysis.python_profile_analysis import PythonProfileAnalysis\n",
    "pfa = PythonProfileAnalysis(s3_path=profiler_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime_sec=start_timestamp / 1000_000\n",
    "endtime_sec=end_timestamp/ 1000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pfa.fetch_profile_stats_by_time(start_time_since_epoch_in_secs=starttime_sec, end_time_since_epoch_in_secs=endtime_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = result[0].stats_path\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(html_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the timeline for the batch .\n",
    "\n",
    "The following plot indicates the window of time during which there is no specific training activity getting invoked.\n",
    "Eliminating these idle time windows can improve the overall training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned framework metrics contain events that are started but not completed within the given range.\n",
    "# Sort the dataframe based on end time and filter the eventa that are completed within the given window.\n",
    "\n",
    "sys_metrics, framework_metrics = pf.get_profiler_data_by_time(start_time_us=start_timestamp, end_time_us=end_timestamp)\n",
    "framework_metrics['start_time'] = pd.to_datetime(framework_metrics['start_time'], format='%Y-%m-%dT%H:%M:%S:%f')\n",
    "framework_metrics['end_time'] = pd.to_datetime(framework_metrics['end_time'], format='%Y-%m-%dT%H:%M:%S:%f')\n",
    "framework_metrics = framework_metrics.sort_values(by=['end_time'])\n",
    "framework_metrics_filtered = framework_metrics.loc[framework_metrics['end_time'] <= pd.to_datetime(end_timestamp, unit='us')]\n",
    "framework_metrics_filtered.sort_values(by='start_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models import ColumnDataSource, Range1d, CustomJS\n",
    "from bokeh.models.tools import HoverTool\n",
    "from datetime import datetime\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G=figure(title='TIme spent on a batch',x_axis_type='datetime',width=800,height=500,\n",
    "        x_range=Range1d(framework_metrics_filtered.start_time.min(),framework_metrics_filtered.end_time.max(), name='TimeStamp'), tools=\"crosshair,xbox_select,pan,reset,save,xwheel_zoom\")\n",
    "hover=HoverTool(tooltips=\"Task: @framework_metric<br>\\\n",
    "Start: @start_time<br>\\\n",
    "End: @end_time\")\n",
    "G.add_tools(hover)\n",
    "CDS=ColumnDataSource(framework_metrics_filtered)\n",
    "G.hbar(y = 'index', height=5, left='start_time', right='end_time', fill_color=\"#CAB2D6\", source=CDS, color=\"#CAB2D6\", )\n",
    "callback = CustomJS(\n",
    "                        args=dict(s1=CDS),\n",
    "                        code=\"\"\"\n",
    "                            console.log('Running CustomJS callback now.');\n",
    "                            var inds = s1.selected.indices;\n",
    "                            console.log(inds);\n",
    "                            var line = \"<span style=float:left;clear:left;font_size=13px><b> Selected index range: [\" + Math.min.apply(Math,inds) + \",\" + Math.max.apply(Math,inds) + \"]</b></span>\\\\n\";\n",
    "                            console.log(line);\"\"\",\n",
    "                    )\n",
    "\n",
    "G.js_on_event(\"selectiongeometry\", callback)\n",
    "show(G, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
