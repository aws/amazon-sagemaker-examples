{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7e4dca-3653-4bf6-80a0-d964492d1d91",
   "metadata": {},
   "source": [
    "# Track an experiment while training a Pytorch model locally or in your notebook\n",
    "\n",
    "This notebook shows how you can use the SageMaker SDK with the integrated SageMaker Experiments functionality to organize, track, compare and evaluate your machine learning (ML) model training experiments.\n",
    "\n",
    "With the new SageMaker SDK, you can track your experiments from anywhere. The capability is now a part of the SageMaker SDK, simplifying the Data Scientist work and eliminating the need to install an extra library to manage multiple model executions. The following new core concepts are introduced:\n",
    "\n",
    "* *Experiment:* a collection of runs that are grouped together. An experiment includes runs for multiple types that can be initiated from anywhere using the SageMaker Python SDK.\n",
    "* *Run*: each execution step of a model training process. A Run element is also enhanced with metadata for the model parameters, data sets uses, algorithms and others. Custom parameters can be logged both as input and output using the log_artifact function.\n",
    "\n",
    "This notebook provides an example of how to track a Pytorch model trained locally in this notebook.\n",
    "\n",
    "To execute this notebook in SageMaker Studio, you should select the `PyTorch 1.12 Python 3.8 CPU Optimizer image`.\n",
    "\n",
    "\n",
    "You can track artifacts for experiments, including datasets, algorithms, hyperparameters and metrics. Experiments executed on SageMaker such as SageMaker training jobs are automatically tracked and any existen SageMaker experiment on your AWS account is automatically migrated to the new UI version.\n",
    "\n",
    "In this notebook we will demonstrate the capabilities through an MNIST handwritten digits classification example. The notebook is organized as follow:\n",
    "\n",
    "1. Download and prepare the MNIST dataset\n",
    "2. Train a Convolutional Neural Network (CNN) Model and log the model training metrics\n",
    "3. Tune the hyperparameters that configures the number of hidden channels and the optimized in the model. Track teh parameter's configuration, resulting model loss and accuracy and automatically plot a confusion matrix using the Experiments capabilities of the SageMaker SDK.\n",
    "4. Analyse your model results and plot graphs comparing your model different runs generated from the tunning step 3.\n",
    "\n",
    "## Runtime\n",
    "This notebook takes approximately 45 minutes to run.\n",
    "\n",
    "## Contents\n",
    "1. [Install modules](#Install-modules)\n",
    "1. [Setup](#Setup)\n",
    "1. [Download the dataset](#Download-the-dataset)\n",
    "1. [Create experiment and log dataset information](#Create-experiment-and-log-dataset-information)\n",
    "1. [Create model training functions](#Create-model-training-functions)\n",
    "1. [Run first experiment](#Run-first-experiment)\n",
    "1. [Run multiple experiments](#Run-multiple-experiments)\n",
    "1. [Cleanup](#Cleanup)\n",
    "1. [Contact](#Contact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141d3f8-45ed-4a56-8651-8964446befac",
   "metadata": {},
   "source": [
    "## Install modules\n",
    "\n",
    "Let's ensure we have the latest SageMaker SDK available, including the SageMaker Experiments functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6534d0-316b-4227-af84-37349d39c81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368d208-aebb-4844-bf27-2b2e373ef3d2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and set logging and experiment configuration\n",
    "\n",
    "SageMaker Experiments now provides the `Run` class that allows you to create a new experiment run. You can retrieve an existent experiment run using the `load_run` function.\n",
    "\n",
    "You also define a unique name for the experiment that will be used to create and load the experiment later in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c2813-b191-4420-b37b-9c6d1cbb8057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib import pyplot as plt\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "experiment_name = \"local-experiment-example-{}\".format(datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "run_name = \"experiment-run\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc0054-d7dd-4ec8-b1e9-0b292fc7b1c0",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "Let's now use the torchvision library to download the MNIST dataset from tensorflow and apply a transformation on each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c6e08a-92d3-4819-a080-4858337813cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "# this will not only download data to ./mnist folder, but also load and transform (normalize) them\n",
    "train_set = datasets.MNIST(\n",
    "    \"mnist_data\",\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    \"mnist_data\",\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fc1d6-5b50-4a96-9e02-1d623072dd39",
   "metadata": {},
   "source": [
    "View and example image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cf8ed-5b35-4474-88b6-f98e0179d4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_set.data[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1913d9-fe5f-4cf1-aca6-c6f6c12bd21c",
   "metadata": {},
   "source": [
    "## Create experiment and log dataset information\n",
    "\n",
    "Create an experiment run to track the model training. SageMaker Experiments is a great way to organize your data science work. You can create an experiment to organize all your model runs and analyse the different model metrics with the SageMaker Experiments UI.\n",
    "\n",
    "Here we create an experiment run and log parameters for the size of our training and test datasets. We also log all the downloaded files as inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f266e0-d73d-452c-a3ed-51b0fc48075d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create an experiment and start a new run\n",
    "with Run(experiment_name=experiment_name, run_name=run_name, sagemaker_session=Session()) as run:\n",
    "    run.log_parameters({\n",
    "        \"num_train_samples\": len(train_set.data),\n",
    "        \"num_test_samples\": len(test_set.data)\n",
    "    })\n",
    "    for f in os.listdir(train_set.raw_folder):\n",
    "        print(\"Logging\", train_set.raw_folder+\"/\"+f)\n",
    "        run.log_file(train_set.raw_folder+\"/\"+f, name=f, is_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c4fca-5128-4213-8065-cb68bd50b973",
   "metadata": {},
   "source": [
    "Checking the SageMaker Experiments UI, you can observe that a new Experiment was created with the run associated to it.\n",
    "\n",
    "<img src=\"images/experiments_view.png\" width=\"50%\" style=\"float: left;\" />\n",
    "<img src=\"images/run_overview.png\" width=\"50%\" style=\"float: left;\" />\n",
    "<img src=\"images/parameters_overview1.png\" width=\"50%\" style=\"float: left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3cdd3-7b79-4ef2-a2ae-d48b3e5ae393",
   "metadata": {},
   "source": [
    "## Create model training functions\n",
    "\n",
    "Define your CNN architecture and training function. You can use `run.log_metric` with a defined step to log the metrics of your model for each epoch, in order to plot those metrics with SageMaker Experiments. With `run.log_confusion_matrix` you can automatically plot the confusion matrix of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba41e3d-c6b7-4758-81c1-7e6fc1230a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, kernel_size, drop_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, hidden_channels, kernel_size=kernel_size)\n",
    "        self.conv2 = torch.nn.Conv2d(hidden_channels, 20, kernel_size=kernel_size)\n",
    "        self.conv2_drop = torch.nn.Dropout2d(p=drop_out)\n",
    "        self.fc1 = torch.nn.Linear(320, 50)\n",
    "        self.fc2 = torch.nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d44f7-e8bb-43d6-a433-54a5912283c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_performance(model, data_loader, device, epoch, run, metric_type=\"Test\"):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += torch.nn.functional.nll_loss(\n",
    "                output, target, size_average=False\n",
    "            ).item() # sum up batch loss\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    loss /= len(data_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(data_loader.dataset)\n",
    "    # log metrics\n",
    "    run.log_metric(name=metric_type+\":loss\", value=loss, step=epoch)\n",
    "    run.log_metric(name=metric_type+\":accuracy\", value=accuracy, step=epoch) \n",
    "    logger.info(\n",
    "        \"{} Average loss: {:.4f}, {} Accuracy: {:.4f}%;\\n\".format(\n",
    "            metric_type, loss, metric_type, accuracy\n",
    "        )\n",
    "    )\n",
    "\n",
    "def train_model(run, train_set, test_set, data_dir=\"mnist_data\", \n",
    "                optimizer=\"sgd\", epochs=10, hidden_channels=10):\n",
    "    \"\"\"\n",
    "    Function that trains the CNN classifier to identify the MNIST digits.\n",
    "    Args:\n",
    "        run (sagemaker.experiments.run.Run): SageMaker Experiment run object\n",
    "        train_set (torchvision.datasets.mnist.MNIST): train dataset\n",
    "        test_set (torchvision.datasets.mnist.MNIST): test dataset\n",
    "        data_dir (str): local directory where the MNIST datasource is stored\n",
    "        optimizer (str): the optimization algorthm to use for training your CNN\n",
    "                         available options are sgd and adam\n",
    "        epochs (int): number of complete pass of the training dataset through the algorithm\n",
    "        hidden_channels (int): number of hidden channels in your model\n",
    "    \"\"\"\n",
    "    \n",
    "    # log the parameters of your model\n",
    "    run.log_parameter(\"device\", \"cpu\")\n",
    "    run.log_parameters({\n",
    "        \"data_dir\": data_dir,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"epochs\": epochs,\n",
    "        \"hidden_channels\": hidden_channels\n",
    "    })\n",
    "    \n",
    "    # train the model on the CPU (no GPU)\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # set the seed for generating random numbers\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, \n",
    "        batch_size=64, \n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size=1000,\n",
    "        shuffle=True\n",
    "    )\n",
    "    logger.info(\n",
    "        \"Processes {}/{} ({:.0f}%) of train data\".format(\n",
    "            len(train_loader.sampler),\n",
    "            len(train_loader.dataset),\n",
    "            100.0 * len(train_loader.sampler) / len(train_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        \"Processes {}/{} ({:.0f}%) of test data\".format(\n",
    "            len(test_loader.sampler),\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * len(test_loader.sampler) / len(test_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "    model = Net(hidden_channels, kernel_size=5, drop_out=0.5).to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    momentum=0.5\n",
    "    lr=0.01\n",
    "    log_interval=100\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"Training Epoch:\", epoch)\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = torch.nn.functional.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                logger.info(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)], Train Loss: {:.6f};\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(data),\n",
    "                        len(train_loader.sampler),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "        log_performance(model, train_loader, device, epoch, run, \"Train\")\n",
    "        log_performance(model, test_loader, device, epoch, run, \"Test\")\n",
    "    # log confusion matrix\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1] \n",
    "            run.log_confusion_matrix(target, pred, \"Confusion-Matrix-Test-Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a8712-f4c9-4769-8e3f-299a45869980",
   "metadata": {},
   "source": [
    "## Run first experiment\n",
    "\n",
    "You can load an existent run using the `load_run` function with `experiment_name` and `run_name` as parameters. \n",
    "Here we train the CNN with 5 hidden channels and ADAM as optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e836e-2deb-4bc4-b246-062bb1a719de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with load_run(experiment_name=experiment_name, run_name=run_name, sagemaker_session=Session()) as run:\n",
    "    train_model(\n",
    "        run=run,\n",
    "        train_set=train_set,\n",
    "        test_set=test_set,\n",
    "        epochs=10,\n",
    "        hidden_channels=2,\n",
    "        optimizer=\"adam\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df712f1f-c85d-4200-98b6-89a648e34cc7",
   "metadata": {},
   "source": [
    "In the SageMaker Experiments UI, you can observe that the new model parameters are added to the run. The model training metrics are captured and can be used to plot graphs. Additionally, the confusion matrix graph is automatically plotted in the UI.\n",
    "\n",
    "<img src=\"images/run_overview2.png\" width=\"50%\" style=\"float: left;\" />\n",
    "<img src=\"images/parameters_overview2.png\" width=\"50%\" style=\"float: left;\" />\n",
    "<img src=\"images/metrics_overview.png\" width=\"50%\" style=\"float: left;\" />\n",
    "<img src=\"images/charts_overview.png\" width=\"50%\" style=\"float: left;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef9a56-fff5-40a0-8d08-db766e66d7ec",
   "metadata": {},
   "source": [
    "## Run multiple experiments\n",
    "\n",
    "You can now create multiple runs of your experiment using the functions created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab66d9a-b2f2-4089-a450-b5c653723691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# define the list of parameters to train the model with\n",
    "num_hidden_channel_param = [5, 10, 20]\n",
    "optimizer_param = [\"adam\", \"sgd\"]\n",
    "run_id = 0\n",
    "# train the model using SageMaker Experiments to track the model parameters, \n",
    "# metrics and performance\n",
    "sm_session = Session()\n",
    "for i, num_hidden_channel in enumerate(num_hidden_channel_param):\n",
    "    for k, optimizer in enumerate(optimizer_param):\n",
    "        run_id += 1\n",
    "        run_name = \"experiment-run-\"+str(run_id)\n",
    "        print(run_name)\n",
    "        print(f\"Training model with: {num_hidden_channel} hidden channels and {optimizer} as optimizer\")\n",
    "        # Defining an experiment run for each model training run\n",
    "        with Run(experiment_name=experiment_name, run_name=run_name, sagemaker_session=sm_session) as run:\n",
    "            train_model(\n",
    "                run=run, \n",
    "                train_set=train_set,\n",
    "                test_set=test_set,\n",
    "                epochs=10, \n",
    "                hidden_channels=num_hidden_channel,\n",
    "                optimizer=optimizer\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c978f9b-eba9-4db9-bdfa-01f6ee12210f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the SageMaker Experiments UI, you can compare the different runs and analyze the metrics for those runs \n",
    "\n",
    "\n",
    "<img src=\"images/compare_experiments.png\" width=\"100%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda32ef-6aea-414a-908c-6bdd2cd09251",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Run the cells below to clean up experiment resources, including the Experiments, Run Groups and Runs created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d13866-2d20-4789-851e-ff38a6a04f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.experiments.experiment import _Experiment\n",
    "\n",
    "exp = _Experiment.load(experiment_name=experiment_name, sagemaker_session=sm_session)\n",
    "exp._delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2caf5-282c-4e58-9680-838f43fce180",
   "metadata": {},
   "source": [
    "## Contact\n",
    "\n",
    "Submit any questions or issues to https://github.com/aws/sagemaker-experiments/issues or mention @aws/sagemakerexperimentsadmin"
   ]
  }
 ],
 "metadata": {
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-1.12-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
