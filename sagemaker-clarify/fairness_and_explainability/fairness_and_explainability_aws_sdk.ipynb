{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness and Explainability with SageMaker Clarify using AWS SDK for Python (Boto3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 30 minutes to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Prerequisites and Data](#Prerequisites-and-Data)\n",
    "    1. [Import libraries](#Import-libraries)\n",
    "    1. [Set configurations](#Set-configurations)\n",
    "    1. [Download data](#Download-data)\n",
    "    1. [Loading the data: Adult Dataset](#Loading-the-data:-Adult-Dataset) \n",
    "    1. [Data inspection](#Data-inspection) \n",
    "    1. [Data encoding and upload to S3](#Encode-and-Upload-the-Data) \n",
    "1. [Train and Deploy XGBoost Model](#Train-XGBoost-Model)\n",
    "    1. [Train Model](#Train-Model)\n",
    "    1. [Create Model](#Create-Model)\n",
    "1. [Amazon SageMaker Clarify](#Amazon-SageMaker-Clarify)\n",
    "    1. [Set configurations](#Set-configurations)\n",
    "    1. [Get Started with a SageMaker Clarify Container](#Get-Started-with-a-SageMaker-Clarify-Container)\n",
    "    1. [Configure a SageMaker Clarify Processing Job Container's Input and Output Parameters ](#Configure-a-SageMaker-Clarify-Processing-Job-Container's-Input-and-Output-Parameters)\n",
    "    1. [Configure Analysis Config](#Configure-Analysis-Config)\n",
    "    1. [Run Sagemaker Clarify Processing Job](#Run-Sagemaker-Clarify-Processing-Job)\n",
    "    1. [Viewing Clarify Report](#Viewing-Clarify-Report)\n",
    "        1. [Viewing the Bias Report](#Viewing-the-Bias-Report)\n",
    "        1. [Viewing the Explainability Report](#Viewing-the-Explainability-Report)\n",
    "        1. [Analysis of local explanations](#Analysis-of-local-explanations)\n",
    "1. [Clean Up](#Clean-Up)\n",
    "\n",
    "## Overview\n",
    "Amazon SageMaker Clarify helps improve your machine learning models by detecting potential bias and helping explain how these models make predictions. The fairness and explainability functionality provided by SageMaker Clarify takes a step towards enabling AWS customers to build trustworthy and understandable machine learning models. The product comes with the tools to help you with the following tasks.\n",
    "\n",
    "* Measure biases that can occur during each stage of the ML lifecycle (data collection, model training and tuning, and monitoring of ML models deployed for inference).\n",
    "* Generate model governance reports targeting risk and compliance teams and external regulators.\n",
    "* Provide explanations of the data, models, and monitoring used to assess predictions.\n",
    "\n",
    "This sample notebook walks you through:  \n",
    "1. Key terms and concepts needed to understand SageMaker Clarify\n",
    "1. Measuring the pre-training bias of a dataset and post-training bias of a model\n",
    "1. Explaining the importance of the various input features on the model's decision\n",
    "1. Accessing the reports through SageMaker Studio if you have an instance set up.\n",
    "\n",
    "In doing so, the notebook first trains a [SageMaker XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) model using training dataset, then use SageMaker Clarify to analyze a testing dataset in CSV format. SageMaker Clarify also supports analyzing dataset in [SageMaker JSON Lines dense format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#common-in-formats), which is illustrated in [another notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/fairness_and_explainability/fairness_and_explainability_jsonlines_format.ipynb). This notebook uses AWS SDK for Python (Boto3) for clarify  processing API calls, making the same API calls using Amazon SageMaker Python SDK is illustrated in [this notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sagemaker import get_execution_role, session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize sagemaker session\n",
    "sagemaker_session = session.Session(boto3.Session())\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "role = get_execution_role()\n",
    "print(f\"Role: {role}\")\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix = \"sagemaker/DEMO-sagemaker-clarify\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "Data Source: [https://archive.ics.uci.edu/ml/machine-learning-databases/adult/](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/)\n",
    "\n",
    "Let's __download__ the data and save it in the local folder with the name adult.data and adult.test from UCI repository$^{[2]}$.\n",
    "\n",
    "$^{[2]}$Dua Dheeru, and Efi Karra Taniskidou. \"[UCI Machine Learning Repository](http://archive.ics.uci.edu/ml)\". Irvine, CA: University of California, School of Information and Computer Science (2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult_columns = [\n",
    "    \"Age\",\n",
    "    \"Workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"Education\",\n",
    "    \"Education-Num\",\n",
    "    \"Marital Status\",\n",
    "    \"Occupation\",\n",
    "    \"Relationship\",\n",
    "    \"Ethnic group\",\n",
    "    \"Sex\",\n",
    "    \"Capital Gain\",\n",
    "    \"Capital Loss\",\n",
    "    \"Hours per week\",\n",
    "    \"Country\",\n",
    "    \"Target\",\n",
    "]\n",
    "if not os.path.isfile(\"adult.data\"):\n",
    "    s3_client.download_file(\n",
    "        \"sagemaker-sample-files\", \"datasets/tabular/uci_adult/adult.data\", \"adult.data\"\n",
    "    )\n",
    "    print(\"adult.data saved!\")\n",
    "else:\n",
    "    print(\"adult.data already on disk.\")\n",
    "\n",
    "if not os.path.isfile(\"adult.test\"):\n",
    "    s3_client.download_file(\n",
    "        \"sagemaker-sample-files\", \"datasets/tabular/uci_adult/adult.test\", \"adult.test\"\n",
    "    )\n",
    "    print(\"adult.test saved!\")\n",
    "else:\n",
    "    print(\"adult.test already on disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data: Adult Dataset\n",
    "From the UCI repository of machine learning datasets, this database contains 14 features concerning demographic characteristics of 45,222 rows (32,561 for training and 12,661 for testing). The task is to predict whether a person has a yearly income that is more or less than $50,000.\n",
    "\n",
    "Here are the features and their possible values:\n",
    "1. **Age**: continuous.\n",
    "1. **Workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "1. **Fnlwgt**: continuous (the number of people the census takers believe that observation represents).\n",
    "1. **Education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "1. **Education-num**: continuous.\n",
    "1. **Marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "1. **Occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "1. **Relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "1. **Ethnic group**: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "1. **Sex**: Female, Male.\n",
    "    * **Note**: this data is extracted from the 1994 Census and enforces a binary option on Sex\n",
    "1. **Capital-gain**: continuous.\n",
    "1. **Capital-loss**: continuous.\n",
    "1. **Hours-per-week**: continuous.\n",
    "1. **Native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Next, we specify our binary prediction task:  \n",
    "15. **Target**: <=50,000, >$50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\n",
    "    \"adult.data\", names=adult_columns, sep=r\"\\s*,\\s*\", engine=\"python\", na_values=\"?\"\n",
    ").dropna()\n",
    "\n",
    "testing_data = pd.read_csv(\n",
    "    \"adult.test\", names=adult_columns, sep=r\"\\s*,\\s*\", engine=\"python\", na_values=\"?\", skiprows=1\n",
    ").dropna()\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "Plotting histograms for the distribution of the different features is a good way to visualize the data. Let's plot a few of the features that can be considered _sensitive_.  \n",
    "Let's take a look specifically at the Sex feature of a census respondent. In the first plot we see that there are fewer Female respondents as a whole but especially in the positive outcomes, where they form ~$\\frac{1}{7}$th of respondents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "training_data[\"Sex\"].value_counts().sort_values().plot(kind=\"bar\", title=\"Counts of Sex\", rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data[\"Sex\"].where(training_data[\"Target\"] == \">50K\").value_counts().sort_values().plot(\n",
    "    kind=\"bar\", title=\"Counts of Sex earning >$50K\", rot=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode and Upload the Dataset\n",
    "Here we encode the training and test data. Encoding input data is not necessary for SageMaker Clarify, but is necessary for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    encoders = {}\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object:\n",
    "            encoders[column] = preprocessing.LabelEncoder()\n",
    "            result[column] = encoders[column].fit_transform(result[column].fillna(\"None\"))\n",
    "    return result, encoders\n",
    "\n",
    "\n",
    "training_data = pd.concat([training_data[\"Target\"], training_data.drop([\"Target\"], axis=1)], axis=1)\n",
    "training_data, _ = number_encode_features(training_data)\n",
    "training_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "\n",
    "testing_data, _ = number_encode_features(testing_data)\n",
    "test_features = testing_data.drop([\"Target\"], axis=1)\n",
    "test_target = testing_data[\"Target\"]\n",
    "test_features.to_csv(\"test_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note about our encoding: the \"Female\" Sex value has been encoded as 0 and \"Male\" as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's upload the data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_uri = S3Uploader.upload(\"train_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "train_input = TrainingInput(train_uri, content_type=\"csv\")\n",
    "test_uri = S3Uploader.upload(\"test_features.csv\", \"s3://{}/{}\".format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model\n",
    "#### Train Model\n",
    "Since our focus is on understanding how to use SageMaker Clarify, we keep it simple by using a standard XGBoost model. For this section we will be using Amazon SageMaker Python SDK for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# This is references the AWS managed XGBoost container\n",
    "xgboost_image_uri = retrieve(region=region, framework=\"xgboost\", version=\"1.5-1\")\n",
    "\n",
    "xgb = Estimator(\n",
    "    xgboost_image_uri,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    disable_profiler=True,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=800,\n",
    ")\n",
    "\n",
    "xgb.fit({\"train\": train_input}, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model\n",
    "Here we create the SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"DEMO-clarify-model-{}\".format(datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Clarify\n",
    "Now that you have your model set up, let's say hello to SageMaker Clarify! We will be using AWS SDK for Python (Boto3) for all API calls here. To get an understanding of how SageMaker Clarify Processing job works refer [here](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-configure-how-it-works.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise Sagemaker boto3 client\n",
    "sagemaker_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "# Note: We will be using role fetched in section 1 for convenient/demo purpose so that the notebook\n",
    "# can be easily executed in SageMaker Studio or SageMaker Notebook Instance.\n",
    "# You can use their own execution role for their project.\n",
    "print(f\"Role: {role}\")\n",
    "\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Started with a SageMaker Clarify Container\n",
    "Amazon SageMaker provides prebuilt SageMaker Clarify container images that include the libraries and other dependencies needed to compute bias metrics and feature attributions for explainability. This image has been enabled to run SageMaker [Process Data](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html) in your account.\n",
    "\n",
    "Region wise adresses of Clarify container images can be referred [here](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-configure-container.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using retrieve API of Amazon SageMaker Python SDK for demo purposes,\n",
    "# refer list of image URIs to if you wish to skip using this API.\n",
    "clarify_image_uri = retrieve(region=region, framework=\"clarify\", version=\"1.0\")\n",
    "print(f\"Clarify Image URI: {clarify_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Bias\n",
    "SageMaker Clarify helps you detect possible pre- and post-training biases using a variety of metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a SageMaker Clarify Processing Job Container's Input and Output Parameters \n",
    "The Processing Job requires that you specify the following input parameters: a dataset files with input name \"dataset\" as Amazon S3 object or prefix, and an analysis configuration file with input name \"analysis_config\" as an Amazon S3 object. The job also requires an output parameter: the output location as an Amazon S3 prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_analysis_config_path = \"s3://{}/{}/bias_analysis_config.json\".format(bucket, prefix)\n",
    "analysis_result_path = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Analysis Config\n",
    "The inputs for the analysis are configured by the parameters of the ProcessingInput API. The \"analysis_config\" value of the input_name specifies the JSON file that contains the configuration values. The path to the JSON file is provided in the source parameter of ProcessingInput. More details on configuring an analysis config can be referred [here](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-configure-analysis.html).\n",
    "\n",
    "For our example use case we will be using the following analysis config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo\n",
    "!cat bias_analysis_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bias_analysis_config.json` here contains configuration values for detecting bias using a clarify container:\n",
    "* `dataset_type` specify the format of your dataset, for thsi example as we are using csv dataset this will be `text/csv`\n",
    "* `headers` is the list of column names in the dataset\n",
    "* `label` specified the target attribute for the model to be used for bias metrics. Specified as a column name, or as index if the dataset format is CSV\n",
    "* SageMaker Clarify also needs information on what the sensitive columns (`facets`) are, what the sensitive features (`facet: values_or_threshold`) may be, and what the desirable outcomes are (`label_values_or_threshold`).\n",
    "SageMaker Clarify can handle both categorical and continuous data for `facet: values_or_threshold` and for `label_values_or_threshold`. In this case we are using categorical data.\n",
    "* `group_variable` A column name or index to indicate the group variable to be used for the *bias metric Conditional Demographic Disparity*\n",
    "* `probability_threshold` is to indicate the threshold to select the binary label in the case of binary classification. XGBoost model outputs probabilities of samples, so SageMaker Clarify invokes the endpoint then uses `probability_threshold` to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value `1` and below or equal as label value `0`.\n",
    "* `method` is the list of methods and their parameters for the analyses and reports. If any section is omitted, then it is not computed.\n",
    "  * **Pre-training Bias**: Bias can be present in your data before any model training occurs. Inspecting your data for bias before training begins can help detect any data collection gaps, inform your feature engineering, and help you understand what societal biases the data may reflect.\n",
    "\n",
    "    Computing pre-training bias metrics does not require a trained model. One can selectively choose metrics to be calculated and added to report by using a specific `methods` list in this attribute.\n",
    "  * **Post-training Bias**: Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "    Unbiased training data (as determined by concepts of fairness measured by bias metric) may still result in biased model predictions after training. Whether this occurs depends on several factors including hyperparameter choices. One can selectively choose metrics to be calculated and added to report by using a specific `methods` list in this attribute.\n",
    "* `instance_type` and `instance_count` specify your preferred instance type and instance count used to run your model on during SageMaker Clarify's processing. The testing dataset is small so a single standard instance is good enough to run this example. If your have a large complex dataset, you may want to use a better instance type to speed up, or add more instances to enable Spark parallelization.\n",
    "* `accept_type` denotes the endpoint response payload format, and `content_type` denotes the payload format of request to the endpoint. As per the example model we created above both of these will be `text/csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the analysis_config to the concerned S3 path.\n",
    "S3Uploader.upload(\"bias_analysis_config.json\", \"s3://{}/{}\".format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Sagemaker Clarify Processing Job\n",
    "Refer this documentation to [configure a clarify procesing job](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-configure-parameters.html) for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_processing_job(analysis_config_path):\n",
    "    processing_job_name = \"DEMO-clarify-job-{}\".format(datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "\n",
    "    response = sagemaker_client.create_processing_job(\n",
    "        ProcessingJobName=processing_job_name,\n",
    "        AppSpecification={\"ImageUri\": clarify_image_uri},\n",
    "        ProcessingInputs=[\n",
    "            {\n",
    "                \"InputName\": \"analysis_config\",\n",
    "                \"S3Input\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3InputMode\": \"File\",\n",
    "                    \"S3Uri\": analysis_config_path,\n",
    "                    \"LocalPath\": \"/opt/ml/processing/input/config\",\n",
    "                    \"S3CompressionType\": \"None\",\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"InputName\": \"dataset\",\n",
    "                \"S3Input\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3InputMode\": \"File\",\n",
    "                    \"S3Uri\": train_uri,\n",
    "                    \"LocalPath\": \"/opt/ml/processing/input/data\",\n",
    "                    \"S3CompressionType\": \"None\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        ProcessingOutputConfig={\n",
    "            \"Outputs\": [\n",
    "                {\n",
    "                    \"OutputName\": \"analysis_result\",\n",
    "                    \"S3Output\": {\n",
    "                        \"S3Uri\": analysis_result_path,\n",
    "                        \"LocalPath\": \"/opt/ml/processing/output\",\n",
    "                        \"S3UploadMode\": \"EndOfJob\",\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        ProcessingResources={\n",
    "            \"ClusterConfig\": {\n",
    "                \"InstanceCount\": 1,\n",
    "                \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                \"VolumeSizeInGB\": 30,\n",
    "            }\n",
    "        },\n",
    "        StoppingCondition={\n",
    "            \"MaxRuntimeInSeconds\": 3600,\n",
    "        },\n",
    "        RoleArn=role,\n",
    "    )\n",
    "\n",
    "    return processing_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief explanation of inputs used above, for detailed documentation check [CreateProcessingJob API reference](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateProcessingJob.html):\n",
    "* AppSpecification: Here we provide the region specific clarify image uri we fethced earlier\n",
    "* ProcessingInputs: Clarify job requires that you provde two ProcessingInput parameters.\n",
    "  * The analysis configuration JSON file for a SageMaker Clarify job must be specified as an Amazon S3 object with the InputName \"analysis_config\". We will be providing the example analysis_configs that we have provided with this notebook. \n",
    "  * InputName dataset which we are providing here as an Amazon S3 object.\n",
    "* ProcessingOutputConfig: The job also requires an output parameter, the output location as an Amazon S3 prefix with the OutputName \"analysis_result\". The S3UploadMode should be set to \"EndOfJob\", because the analysis results is generated at the end of the job. We will be providing here the `analysis_result_path` that we configured earlier.\n",
    "* ProcessingResources contains the ClusterConfig specifying the ML compute instance_type we want to use and the count. SageMaker SHAP analysis is CPU-intensive, using a better instance type should speed up the analysis. The SageMaker Clarify job doesnâ€™t use GPU.\n",
    "* StoppingCondition: Using a maximum limit of 30 min for example job run. You can set the MaxRuntimeInSeconds of a SageMaker Clarify job to up to 7 days (604800 seconds). If the job cannot be completed within this time limit, it will be force-stopped and no analysis results are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_job_name = create_processing_job(bias_analysis_config_path)\n",
    "\n",
    "# Wait for processing job to complete\n",
    "status = sagemaker_client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "\n",
    "while status[\"ProcessingJobStatus\"] == \"InProgress\":\n",
    "    status = sagemaker_client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "    print(status[\"ProcessingJobStatus\"])\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the Bias Report\n",
    "In Studio, you can view the results under the experiments tab.\n",
    "\n",
    "<img src=\"./recordings/bias_report.gif\">\n",
    "\n",
    "Each bias metric has detailed explanations with examples that you can explore.\n",
    "\n",
    "<img src=\"./recordings/bias_detail.gif\">\n",
    "\n",
    "You could also summarize the results in a handy table!\n",
    "\n",
    "<img src=\"./recordings/bias_report_chart.gif\">\n",
    "\n",
    "If you're not a Studio user yet you can access the complete analysis report at the following S3 bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_result_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Predictions\n",
    "There are expanding business needs and legislative regulations that require explanations of _why_ a model made the decision it did. SageMaker Clarify uses SHAP to explain the contribution that each input feature makes to the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a SageMaker Clarify Processing Job Container's Input and Output Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainability_analysis_config_path = \"s3://{}/{}/explainability_analysis_config.json\".format(\n",
    "    bucket, prefix\n",
    ")\n",
    "analysis_result_path = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Analysis Config\n",
    "For our example use case we will be using the following analysis config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo\n",
    "!cat explainability_analysis_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`explainability_analysis_config.json` here contains configuration values for detecting bias using a clarify container:\n",
    "* `dataset_type` specify the format of your dataset, for thsi example as we are using csv dataset this will be `text/csv`\n",
    "* `headers` is the list of column names in the dataset\n",
    "* `label` specified the target attribute for the model to be used for bias metrics. Specified as a column name, or as index if the dataset format is CSV\n",
    "* `method` is the list of methods and their parameters for the analyses and reports. If any section is omitted, then it is not computed.\n",
    "  * **shap:** Kernel SHAP algorithm requires a baseline (also known as background dataset). If not provided, a baseline is calculated automatically by SageMaker Clarify using K-means or K-prototypes in the input dataset. Baseline dataset type shall be the same as `dataset_type`, and baseline samples shall only include features. By definition, `baseline` should either be a S3 URI to the baseline dataset file, or an in-place list of samples. In this case we chose the latter, and put the first sample of the test dataset to the list.\n",
    "\n",
    "* `instance_type` and `instance_count` specify your preferred instance type and instance count used to run your model on during SageMaker Clarify's processing. The testing dataset is small so a single standard instance is good enough to run this example. If your have a large complex dataset, you may want to use a better instance type to speed up, or add more instances to enable Spark parallelization.\n",
    "* `accept_type` denotes the endpoint response payload format, and `content_type` denotes the payload format of request to the endpoint. As per the example model we created above both of these will be `text/csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the analysis_config to the concerned S3 path.\n",
    "S3Uploader.upload(\"explainability_analysis_config.json\", \"s3://{}/{}\".format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Sagemaker Clarify Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_job_name = create_processing_job(explainability_analysis_config_path)\n",
    "\n",
    "# Wait for processing job to complete\n",
    "status = sagemaker_client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "\n",
    "while status[\"ProcessingJobStatus\"] == \"InProgress\":\n",
    "    status = sagemaker_client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "    print(status[\"ProcessingJobStatus\"])\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the Explainability Report\n",
    "As with the bias report, you can view the explainability report in Studio under the experiments tab.\n",
    "\n",
    "\n",
    "<img src=\"./recordings/explainability_detail.gif\">\n",
    "\n",
    "The Model Insights tab contains direct links to the report and model insights.\n",
    "\n",
    "If you're not a Studio user yet you can access the complete analysis report at the following S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_result_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of local explanations\n",
    "It is possible to visualize the the local explanations for single examples in your dataset. You can use the obtained results from running Kernel SHAP algorithm for global explanations.\n",
    "\n",
    "You can simply load the local explanations stored in your output path, and visualize the explanation (i.e., the impact that the single features have on the prediction of your model) for any single example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_explanations_out = pd.read_csv(analysis_result_path + \"/explanations_shap/out.csv\")\n",
    "feature_names = [str.replace(c, \"_label0\", \"\") for c in local_explanations_out.columns.to_series()]\n",
    "local_explanations_out.columns = feature_names\n",
    "\n",
    "selected_example = 111\n",
    "print(\n",
    "    \"Example number:\",\n",
    "    selected_example,\n",
    "    \"\\nwith model prediction:\",\n",
    "    sum(local_explanations_out.iloc[selected_example]) > 0,\n",
    ")\n",
    "print(\"\\nFeature values -- Label\", training_data.iloc[selected_example])\n",
    "local_explanations_out.iloc[selected_example].plot(\n",
    "    kind=\"bar\", title=\"Local explanation for the example number \" + str(selected_example), rot=90\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "Finally, don't forget to clean up the resources we set up and used for this demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
