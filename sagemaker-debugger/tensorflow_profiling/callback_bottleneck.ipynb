{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cutting-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-bryan",
   "metadata": {
    "papermill": {
     "duration": 0.011952,
     "end_time": "2021-06-01T00:13:00.123603",
     "exception": false,
     "start_time": "2021-06-01T00:13:00.111651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Identify a CPU bottleneck caused by a callback process with Amazon SageMaker Debugger \n",
    "\n",
    "In this notebook we demonstrate how to identify a training bottleneck that is caused by a TensorFlow Keras callback.\n",
    "To simulate this type of bottleneck, we will program the callback associated with the tensor monitoring feature of Amazon SageMaker Debugger, to collect an excessive number of tensors, and at a high frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-factory",
   "metadata": {
    "papermill": {
     "duration": 0.011776,
     "end_time": "2021-06-01T00:13:00.147143",
     "exception": false,
     "start_time": "2021-06-01T00:13:00.135367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install sagemaker\n",
    "To use the new Debugger profiling features, ensure that you have the latest version of SageMaker SDK installed. The following cell updates the library and restarts the Jupyter kernel to apply the updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-scratch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:00.175312Z",
     "iopub.status.busy": "2021-06-01T00:13:00.174799Z",
     "iopub.status.idle": "2021-06-01T00:13:00.177135Z",
     "shell.execute_reply": "2021-06-01T00:13:00.176718Z"
    },
    "papermill": {
     "duration": 0.018328,
     "end_time": "2021-06-01T00:13:00.177237",
     "exception": false,
     "start_time": "2021-06-01T00:13:00.158909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "install_needed = False  # should only be True once\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-philippines",
   "metadata": {
    "papermill": {
     "duration": 0.011722,
     "end_time": "2021-06-01T00:13:00.200769",
     "exception": false,
     "start_time": "2021-06-01T00:13:00.189047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Prepare training dataset\n",
    "\n",
    "### Tensorflow Datasets package\n",
    "\n",
    "First of all, set the notebook kernel to Tensorflow 2.x.\n",
    "\n",
    "We will use CIFAR-10 dataset for this experiment. To download CIFAR-10 datasets and convert it into TFRecord format, install `tensorflow-datasets` package, run `demo/generate_cifar10_tfrecords`, and upload tfrecord files to your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portable-earthquake",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:00.228178Z",
     "iopub.status.busy": "2021-06-01T00:13:00.227679Z",
     "iopub.status.idle": "2021-06-01T00:13:22.616547Z",
     "shell.execute_reply": "2021-06-01T00:13:22.616985Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 22.404515,
     "end_time": "2021-06-01T00:13:22.617136",
     "exception": false,
     "start_time": "2021-06-01T00:13:00.212621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-01 23:33:20.932400: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (21.1.2)\n",
      "Requirement already satisfied: tensorflow_datasets==4.1.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (4.1.0)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (0.10.0)\n",
      "Requirement already satisfied: dill in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (0.3.3)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (4.42.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (0.8)\n",
      "Requirement already satisfied: promise in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (2.3)\n",
      "Requirement already satisfied: future in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (0.18.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (0.28.0)\n",
      "Requirement already satisfied: termcolor in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (3.15.6)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (19.3.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (1.18.1)\n",
      "Requirement already satisfied: importlib-resources in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (5.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets==4.1.0) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets==4.1.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets==4.1.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets==4.1.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets==4.1.0) (1.25.10)\n",
      "Requirement already satisfied: zipp>=0.4 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from importlib-resources->tensorflow_datasets==4.1.0) (2.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-metadata->tensorflow_datasets==4.1.0) (1.53.0)\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|                                     | 0/162 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▏                            | 1/162 [00:00<01:54,  1.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   1%|▎                            | 2/162 [00:00<01:54,  1.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   2%|▌                            | 3/162 [00:00<01:53,  1.40 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▋                            | 4/162 [00:00<01:20,  1.95 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   3%|▉                            | 5/162 [00:00<01:20,  1.95 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   4%|█                            | 6/162 [00:00<01:19,  1.95 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|█▎                           | 7/162 [00:00<00:57,  2.71 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   5%|█▍                           | 8/162 [00:00<00:56,  2.71 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:   6%|█▌                           | 9/162 [00:01<00:56,  2.71 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▋                          | 10/162 [00:01<00:40,  3.71 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:   7%|█▉                          | 11/162 [00:01<00:40,  3.71 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:   7%|██                          | 12/162 [00:01<00:40,  3.71 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██▏                         | 13/162 [00:01<00:29,  5.01 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:   9%|██▍                         | 14/162 [00:01<00:29,  5.01 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:   9%|██▌                         | 15/162 [00:01<00:29,  5.01 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▊                         | 16/162 [00:01<00:22,  6.62 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  10%|██▉                         | 17/162 [00:01<00:21,  6.62 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  11%|███                         | 18/162 [00:01<00:21,  6.62 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  12%|███▎                        | 19/162 [00:01<00:16,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  12%|███▍                        | 20/162 [00:01<00:16,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  13%|███▋                        | 21/162 [00:01<00:16,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  14%|███▊                        | 22/162 [00:01<00:12, 10.78 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  14%|███▉                        | 23/162 [00:01<00:12, 10.78 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  15%|████▏                       | 24/162 [00:01<00:12, 10.78 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  15%|████▎                       | 25/162 [00:01<00:10, 13.16 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  16%|████▍                       | 26/162 [00:01<00:10, 13.16 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  17%|████▋                       | 27/162 [00:01<00:10, 13.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  17%|████▊                       | 28/162 [00:01<00:08, 15.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  18%|█████                       | 29/162 [00:01<00:08, 15.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  19%|█████▏                      | 30/162 [00:01<00:08, 15.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  19%|█████▎                      | 31/162 [00:01<00:07, 17.86 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  20%|█████▌                      | 32/162 [00:01<00:07, 17.86 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  20%|█████▋                      | 33/162 [00:01<00:07, 17.86 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\u001b[A\n",
      "Dl Size...:  21%|█████▉                      | 34/162 [00:01<00:06, 19.87 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:  22%|██████                      | 35/162 [00:01<00:06, 19.87 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  22%|██████▏                     | 36/162 [00:02<00:06, 19.87 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  23%|██████▍                     | 37/162 [00:02<00:05, 21.63 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  23%|██████▌                     | 38/162 [00:02<00:05, 21.63 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  24%|██████▋                     | 39/162 [00:02<00:05, 21.63 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  25%|██████▉                     | 40/162 [00:02<00:05, 22.35 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  25%|███████                     | 41/162 [00:02<00:05, 22.35 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  26%|███████▎                    | 42/162 [00:02<00:05, 22.35 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  27%|███████▍                    | 43/162 [00:02<00:05, 23.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  27%|███████▌                    | 44/162 [00:02<00:05, 23.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  28%|███████▊                    | 45/162 [00:02<00:04, 23.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  28%|███████▉                    | 46/162 [00:02<00:04, 24.54 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  29%|████████                    | 47/162 [00:02<00:04, 24.54 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  30%|████████▎                   | 48/162 [00:02<00:04, 24.54 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  30%|████████▍                   | 49/162 [00:02<00:04, 25.25 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  31%|████████▋                   | 50/162 [00:02<00:04, 25.25 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  31%|████████▊                   | 51/162 [00:02<00:04, 25.25 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  32%|████████▉                   | 52/162 [00:02<00:04, 25.75 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  33%|█████████▏                  | 53/162 [00:02<00:04, 25.75 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  33%|█████████▎                  | 54/162 [00:02<00:04, 25.75 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  34%|█████████▌                  | 55/162 [00:02<00:04, 26.15 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  35%|█████████▋                  | 56/162 [00:02<00:04, 26.15 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  35%|█████████▊                  | 57/162 [00:02<00:04, 26.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  36%|██████████                  | 58/162 [00:02<00:03, 26.47 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  36%|██████████▏                 | 59/162 [00:02<00:03, 26.47 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  37%|██████████▎                 | 60/162 [00:02<00:03, 26.47 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:  38%|██████████▌                 | 61/162 [00:02<00:03, 26.50 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\n",
      "Dl Size...:  38%|██████████▋                 | 62/162 [00:02<00:03, 26.50 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  39%|██████████▉                 | 63/162 [00:03<00:03, 26.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  40%|███████████                 | 64/162 [00:03<00:03, 26.18 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  40%|███████████▏                | 65/162 [00:03<00:03, 26.18 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  41%|███████████▍                | 66/162 [00:03<00:03, 26.18 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  41%|███████████▌                | 67/162 [00:03<00:03, 26.50 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  42%|███████████▊                | 68/162 [00:03<00:03, 26.50 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  43%|███████████▉                | 69/162 [00:03<00:03, 26.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  43%|████████████                | 70/162 [00:03<00:03, 26.65 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  44%|████████████▎               | 71/162 [00:03<00:03, 26.65 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  44%|████████████▍               | 72/162 [00:03<00:03, 26.65 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  45%|████████████▌               | 73/162 [00:03<00:03, 26.81 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  46%|████████████▊               | 74/162 [00:03<00:03, 26.81 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  46%|████████████▉               | 75/162 [00:03<00:03, 26.81 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  47%|█████████████▏              | 76/162 [00:03<00:03, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  48%|█████████████▎              | 77/162 [00:03<00:03, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  48%|█████████████▍              | 78/162 [00:03<00:03, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  49%|█████████████▋              | 79/162 [00:03<00:03, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  49%|█████████████▊              | 80/162 [00:03<00:03, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  50%|██████████████              | 81/162 [00:03<00:03, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  51%|██████████████▏             | 82/162 [00:03<00:02, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  51%|██████████████▎             | 83/162 [00:03<00:02, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  52%|██████████████▌             | 84/162 [00:03<00:02, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  52%|██████████████▋             | 85/162 [00:03<00:02, 26.89 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  53%|██████████████▊             | 86/162 [00:03<00:02, 26.89 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\n",
      "Dl Size...:  54%|███████████████             | 87/162 [00:03<00:02, 26.89 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  54%|███████████████▏            | 88/162 [00:03<00:02, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  55%|███████████████▍            | 89/162 [00:04<00:02, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  56%|███████████████▌            | 90/162 [00:04<00:02, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  56%|███████████████▋            | 91/162 [00:04<00:02, 27.05 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  57%|███████████████▉            | 92/162 [00:04<00:02, 27.05 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  57%|████████████████            | 93/162 [00:04<00:02, 27.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  58%|████████████████▏           | 94/162 [00:04<00:02, 27.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  59%|████████████████▍           | 95/162 [00:04<00:02, 27.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  59%|████████████████▌           | 96/162 [00:04<00:02, 27.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  60%|████████████████▊           | 97/162 [00:04<00:02, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  60%|████████████████▉           | 98/162 [00:04<00:02, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  61%|█████████████████           | 99/162 [00:04<00:02, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  62%|████████████████▋          | 100/162 [00:04<00:02, 27.09 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  62%|████████████████▊          | 101/162 [00:04<00:02, 27.09 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  63%|█████████████████          | 102/162 [00:04<00:02, 27.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  64%|█████████████████▏         | 103/162 [00:04<00:02, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  64%|█████████████████▎         | 104/162 [00:04<00:02, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  65%|█████████████████▌         | 105/162 [00:04<00:02, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  65%|█████████████████▋         | 106/162 [00:04<00:02, 27.08 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  66%|█████████████████▊         | 107/162 [00:04<00:02, 27.08 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  67%|██████████████████         | 108/162 [00:04<00:01, 27.08 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  67%|██████████████████▏        | 109/162 [00:04<00:01, 27.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  68%|██████████████████▎        | 110/162 [00:04<00:01, 27.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  69%|██████████████████▌        | 111/162 [00:04<00:01, 27.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  69%|██████████████████▋        | 112/162 [00:04<00:01, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  70%|██████████████████▊        | 113/162 [00:04<00:01, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\n",
      "Dl Size...:  70%|███████████████████        | 114/162 [00:04<00:01, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:  71%|███████████████████▏       | 115/162 [00:04<00:01, 26.94 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  72%|███████████████████▎       | 116/162 [00:05<00:01, 26.94 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  72%|███████████████████▌       | 117/162 [00:05<00:01, 26.94 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  73%|███████████████████▋       | 118/162 [00:05<00:01, 26.75 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  73%|███████████████████▊       | 119/162 [00:05<00:01, 26.75 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  74%|████████████████████       | 120/162 [00:05<00:01, 26.75 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  75%|████████████████████▏      | 121/162 [00:05<00:01, 26.81 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  75%|████████████████████▎      | 122/162 [00:05<00:01, 26.81 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  76%|████████████████████▌      | 123/162 [00:05<00:01, 26.81 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  77%|████████████████████▋      | 124/162 [00:05<00:01, 26.90 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  77%|████████████████████▊      | 125/162 [00:05<00:01, 26.90 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  78%|█████████████████████      | 126/162 [00:05<00:01, 26.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  78%|█████████████████████▏     | 127/162 [00:05<00:01, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  79%|█████████████████████▎     | 128/162 [00:05<00:01, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  80%|█████████████████████▌     | 129/162 [00:05<00:01, 26.99 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  80%|█████████████████████▋     | 130/162 [00:05<00:01, 26.97 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  81%|█████████████████████▊     | 131/162 [00:05<00:01, 26.97 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  81%|██████████████████████     | 132/162 [00:05<00:01, 26.97 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  82%|██████████████████████▏    | 133/162 [00:05<00:01, 27.04 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  83%|██████████████████████▎    | 134/162 [00:05<00:01, 27.04 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  83%|██████████████████████▌    | 135/162 [00:05<00:00, 27.04 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  84%|██████████████████████▋    | 136/162 [00:05<00:00, 27.07 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  85%|██████████████████████▊    | 137/162 [00:05<00:00, 27.07 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  85%|███████████████████████    | 138/162 [00:05<00:00, 27.07 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  86%|███████████████████████▏   | 139/162 [00:05<00:00, 26.98 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  86%|███████████████████████▎   | 140/162 [00:05<00:00, 26.98 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  87%|███████████████████████▌   | 141/162 [00:05<00:00, 26.98 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  88%|███████████████████████▋   | 142/162 [00:05<00:00, 27.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\n",
      "Dl Size...:  88%|███████████████████████▊   | 143/162 [00:05<00:00, 27.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  89%|████████████████████████   | 144/162 [00:06<00:00, 27.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:  90%|████████████████████████▏  | 145/162 [00:06<00:00, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  90%|████████████████████████▎  | 146/162 [00:06<00:00, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  91%|████████████████████████▌  | 147/162 [00:06<00:00, 27.06 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:  91%|████████████████████████▋  | 148/162 [00:06<00:00, 26.98 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  92%|████████████████████████▊  | 149/162 [00:06<00:00, 26.98 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  93%|█████████████████████████  | 150/162 [00:06<00:00, 26.98 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:  93%|█████████████████████████▏ | 151/162 [00:06<00:00, 27.03 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  94%|█████████████████████████▎ | 152/162 [00:06<00:00, 27.03 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  94%|█████████████████████████▌ | 153/162 [00:06<00:00, 27.03 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:  95%|█████████████████████████▋ | 154/162 [00:06<00:00, 27.09 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  96%|█████████████████████████▊ | 155/162 [00:06<00:00, 27.09 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  96%|██████████████████████████ | 156/162 [00:06<00:00, 27.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:  97%|██████████████████████████▏| 157/162 [00:06<00:00, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  98%|██████████████████████████▎| 158/162 [00:06<00:00, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  98%|██████████████████████████▌| 159/162 [00:06<00:00, 26.93 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:  99%|██████████████████████████▋| 160/162 [00:06<00:00, 27.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...:  99%|██████████████████████████▊| 161/162 [00:06<00:00, 27.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\n",
      "Dl Size...: 100%|███████████████████████████| 162/162 [00:06<00:00, 27.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 1/1 [00:06<00:00,  6.72s/ url]\n",
      "Dl Size...: 100%|███████████████████████████| 162/162 [00:06<00:00, 27.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 1/1 [00:06<00:00,  6.72s/ url]\n",
      "Dl Size...: 100%|███████████████████████████| 162/162 [00:06<00:00, 27.00 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                         | 0/1 [00:06<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 1/1 [00:08<00:00,  6.72s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|███████████████████████████| 162/162 [00:08<00:00, 27.00 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████| 1/1 [00:08<00:00,  8.26s/ file]\u001b[A\u001b[A\n",
      "Extraction completed...: 100%|█████████████████| 1/1 [00:08<00:00,  8.26s/ file]\n",
      "\n",
      "Dl Size...: 100%|███████████████████████████| 162/162 [00:08<00:00, 19.61 MiB/s]\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 1/1 [00:08<00:00,  8.26s/ url]\n",
      "Generating ./data/train/train.tfrecords\n",
      "Generating ./data/validation/validation.tfrecords\n",
      "Generating ./data/eval/eval.tfrecords\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python demo/generate_cifar10_tfrecords.py --data-dir=./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-adobe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:22.761207Z",
     "iopub.status.busy": "2021-06-01T00:13:22.760348Z",
     "iopub.status.idle": "2021-06-01T00:13:27.334379Z",
     "shell.execute_reply": "2021-06-01T00:13:27.334809Z"
    },
    "papermill": {
     "duration": 4.663508,
     "end_time": "2021-06-01T00:13:27.334960",
     "exception": false,
     "start_time": "2021-06-01T00:13:22.671452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset uploaded to s3://sagemaker-us-west-2-688520471316/data/cifar10-tfrecords\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "s3_bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "dataset_prefix = \"data/cifar10-tfrecords\"\n",
    "desired_s3_uri = f\"s3://{s3_bucket}/{dataset_prefix}\"\n",
    "\n",
    "dataset_location = sagemaker.s3.S3Uploader.upload(local_path=\"data\", desired_s3_uri=desired_s3_uri)\n",
    "print(f\"Dataset uploaded to {dataset_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-theory",
   "metadata": {
    "papermill": {
     "duration": 0.051662,
     "end_time": "2021-06-01T00:13:27.438637",
     "exception": false,
     "start_time": "2021-06-01T00:13:27.386975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Create a Training Job with Profiling Enabled<a class=\"anchor\" id=\"option-1\"></a>\n",
    "\n",
    "We will use the standard [SageMaker Estimator API for Tensorflow](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to create a training job. To enable profiling, we create a `ProfilerConfig` object and pass it to the `profiler_config` parameter of the `TensorFlow` estimator. For this demo, we set the the profiler to probe the system once every 500 miliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-insider",
   "metadata": {
    "papermill": {
     "duration": 0.051632,
     "end_time": "2021-06-01T00:13:27.541950",
     "exception": false,
     "start_time": "2021-06-01T00:13:27.490318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set a profiler configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valuable-richmond",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:27.650304Z",
     "iopub.status.busy": "2021-06-01T00:13:27.649576Z",
     "iopub.status.idle": "2021-06-01T00:13:27.652036Z",
     "shell.execute_reply": "2021-06-01T00:13:27.651534Z"
    },
    "papermill": {
     "duration": 0.058237,
     "end_time": "2021-06-01T00:13:27.652143",
     "exception": false,
     "start_time": "2021-06-01T00:13:27.593906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(\n",
    "        local_path=\"/opt/ml/output/profiler/\", start_step=5, num_steps=2\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-asbestos",
   "metadata": {
    "papermill": {
     "duration": 0.052106,
     "end_time": "2021-06-01T00:13:27.756284",
     "exception": false,
     "start_time": "2021-06-01T00:13:27.704178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configure Debugger hook\n",
    "We configure the debugger hook to collect an excessive number of tensors, every 50 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regional-membership",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:27.865666Z",
     "iopub.status.busy": "2021-06-01T00:13:27.864972Z",
     "iopub.status.idle": "2021-06-01T00:13:27.866970Z",
     "shell.execute_reply": "2021-06-01T00:13:27.867374Z"
    },
    "papermill": {
     "duration": 0.058783,
     "end_time": "2021-06-01T00:13:27.867516",
     "exception": false,
     "start_time": "2021-06-01T00:13:27.808733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"save_interval\": \"50\"},\n",
    "    collection_configs=[\n",
    "        CollectionConfig(name=\"outputs\"),\n",
    "        CollectionConfig(name=\"gradients\"),\n",
    "        CollectionConfig(name=\"weights\"),\n",
    "        CollectionConfig(name=\"layers\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-jerusalem",
   "metadata": {
    "papermill": {
     "duration": 0.052574,
     "end_time": "2021-06-01T00:13:27.972348",
     "exception": false,
     "start_time": "2021-06-01T00:13:27.919774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define hyperparameters\n",
    "\n",
    "The start-up script is set to [train_tf_bottleneck.py](./demo/train_tf_bottleneck.py). Define hyperparameters such as number of epochs, and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mediterranean-infection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:28.083406Z",
     "iopub.status.busy": "2021-06-01T00:13:28.082867Z",
     "iopub.status.idle": "2021-06-01T00:13:28.084843Z",
     "shell.execute_reply": "2021-06-01T00:13:28.085239Z"
    },
    "papermill": {
     "duration": 0.058554,
     "end_time": "2021-06-01T00:13:28.085393",
     "exception": false,
     "start_time": "2021-06-01T00:13:28.026839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epoch\": 2, \"batch_size\": 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-snapshot",
   "metadata": {
    "papermill": {
     "duration": 0.052114,
     "end_time": "2021-06-01T00:13:28.190111",
     "exception": false,
     "start_time": "2021-06-01T00:13:28.137997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get the image URI\n",
    "The image that we will is dependent on the region that you are running this notebook in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "associate-necessity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:28.307641Z",
     "iopub.status.busy": "2021-06-01T00:13:28.302079Z",
     "iopub.status.idle": "2021-06-01T00:13:28.312840Z",
     "shell.execute_reply": "2021-06-01T00:13:28.313237Z"
    },
    "papermill": {
     "duration": 0.071134,
     "end_time": "2021-06-01T00:13:28.313374",
     "exception": false,
     "start_time": "2021-06-01T00:13:28.242240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/tensorflow-training:2.3.1-gpu-py37-cu110-ubuntu18.04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-benjamin",
   "metadata": {
    "papermill": {
     "duration": 0.052806,
     "end_time": "2021-06-01T00:13:28.419138",
     "exception": false,
     "start_time": "2021-06-01T00:13:28.366332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define SageMaker Tensorflow Estimator\n",
    "To enable profiling, you need to pass the Debugger profiling configuration (`profiler_config`), a list of Debugger rules (`rules`), and the image URI (`image_uri`) to the estimator. Debugger enables monitoring and profiling while the SageMaker estimator requests a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complicated-duncan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:28.529298Z",
     "iopub.status.busy": "2021-06-01T00:13:28.528797Z",
     "iopub.status.idle": "2021-06-01T00:13:28.988436Z",
     "shell.execute_reply": "2021-06-01T00:13:28.988897Z"
    },
    "papermill": {
     "duration": 0.51737,
     "end_time": "2021-06-01T00:13:28.989048",
     "exception": false,
     "start_time": "2021-06-01T00:13:28.471678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "job_name = \"network-bottleneck\"\n",
    "instance_count = 1\n",
    "instance_type = \"ml.p2.xlarge\"\n",
    "entry_script = \"train_tf_bottleneck.py\"\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri=image_uri,\n",
    "    base_job_name=job_name,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    entry_point=entry_script,\n",
    "    source_dir=\"demo\",\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    script_mode=True,\n",
    "    hyperparameters=hyperparameters,\n",
    "    input_mode=\"Pipe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-advertiser",
   "metadata": {
    "papermill": {
     "duration": 0.052871,
     "end_time": "2021-06-01T00:13:29.095305",
     "exception": false,
     "start_time": "2021-06-01T00:13:29.042434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> If you see an error, `TypeError: __init__() got an unexpected keyword argument 'instance_type'`, that means SageMaker Python SDK is out-dated. Please update your SageMaker Python SDK to 2.x by executing the below command and restart this notebook.\n",
    "\n",
    "```bash\n",
    "pip install --upgrade sagemaker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-louisiana",
   "metadata": {
    "papermill": {
     "duration": 0.052919,
     "end_time": "2021-06-01T00:13:29.201150",
     "exception": false,
     "start_time": "2021-06-01T00:13:29.148231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Start training job\n",
    "\n",
    "The following `estimator.fit()` with `wait=False` argument initiates the training job in the background. You can proceed to run the dashboard or analysis notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decimal-professional",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:29.311413Z",
     "iopub.status.busy": "2021-06-01T00:13:29.310918Z",
     "iopub.status.idle": "2021-06-01T00:13:29.915090Z",
     "shell.execute_reply": "2021-06-01T00:13:29.915520Z"
    },
    "papermill": {
     "duration": 0.66101,
     "end_time": "2021-06-01T00:13:29.915670",
     "exception": false,
     "start_time": "2021-06-01T00:13:29.254660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-01 23:33:42 Starting - Starting the training job...\n",
      "2021-06-01 23:34:06 Starting - Launching requested ML instancesProfilerReport-1622590422: InProgress\n",
      "......\n",
      "2021-06-01 23:35:06 Starting - Preparing the instances for training.........\n",
      "2021-06-01 23:36:41 Downloading - Downloading input data\n",
      "2021-06-01 23:36:41 Training - Downloading the training image....................\u001b[34m2021-06-01 23:39:55.451846: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457116: I tensorflow/core/profiler/internal/smprofiler_config_reader.cc:123] PID of the process that is writing to the timeline : 1\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457827: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:121] SageMaker Profiler Timeline Writer read the following config parameters :\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457856: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:122] Base Folder : /opt/ml/output/profiler/\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457865: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:123] Node Id : 1-algo-1\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457874: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:124] Maximum file size : 10485760\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457881: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:125] Close file interval : 60\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457887: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:126] Continuous fail count threshold : 50\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.457899: I tensorflow/core/profiler/internal/smprofiler_timeline.cc:144] PID of the current Timeline Process : 1\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.665957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:55.758132: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-06-01 23:39:59,586 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-06-01 23:40:00,274 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epoch\": 2,\n",
      "        \"model_dir\": \"s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"network-bottleneck-2021-06-01-23-33-42-269\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_tf_bottleneck\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_tf_bottleneck.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":128,\"epoch\":2,\"model_dir\":\"s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_tf_bottleneck.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_tf_bottleneck\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epoch\":2,\"model_dir\":\"s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"network-bottleneck-2021-06-01-23-33-42-269\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/source/sourcedir.tar.gz\",\"module_name\":\"train_tf_bottleneck\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_tf_bottleneck.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epoch\",\"2\",\"--model_dir\",\"s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=2\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 train_tf_bottleneck.py --batch_size 128 --epoch 2 --model_dir s3://sagemaker-us-west-2-688520471316/network-bottleneck-2021-06-01-23-33-42-269/model\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2021-06-01 23:40:07 Training - Training image download completed. Training in progress.\u001b[34mRequirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (21.0.1)\u001b[0m\n",
      "\u001b[34mCollecting pip\n",
      "  Downloading pip-21.1.2-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.0.1\u001b[0m\n",
      "\u001b[34m    Uninstalling pip-21.0.1:\n",
      "      Successfully uninstalled pip-21.0.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed pip-21.1.2\u001b[0m\n",
      "\u001b[34mCollecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\u001b[0m\n",
      "\u001b[34mCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.12.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: typeguard, tensorflow-addons\u001b[0m\n",
      "\u001b[34mSuccessfully installed tensorflow-addons-0.13.0 typeguard-2.12.0\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:16.907 ip-10-0-248-127.us-west-2.compute.internal:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:17.020 ip-10-0-248-127.us-west-2.compute.internal:25 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:33.271 ip-10-0-248-127.us-west-2.compute.internal:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:33.275 ip-10-0-248-127.us-west-2.compute.internal:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:33.279 ip-10-0-248-127.us-west-2.compute.internal:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:33.280 ip-10-0-248-127.us-west-2.compute.internal:25 INFO state_store.py:75] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:33.765 ip-10-0-248-127.us-west-2.compute.internal:25 INFO hook.py:413] Monitoring the collections: weights, losses, layers, gradients, outputs, metrics, sm_metrics\u001b[0m\n",
      "\u001b[34mEpoch 1/2\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:40:33.915 ip-10-0-248-127.us-west-2.compute.internal:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/tensorflow/cprofile/25-algo-1/prestepzero-*-start-1622590817021441.8_train-0-stepstart-1622590833914246.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:41:29.478 ip-10-0-248-127.us-west-2.compute.internal:25 INFO keras.py:911] Enabling TF profiler on step: = 5\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:41:30.325 ip-10-0-248-127.us-west-2.compute.internal:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/tensorflow/cprofile/25-algo-1/train-5-stepstart-1622590889468096.0_train-5-stepend-1622590890325099.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:41:30.342 ip-10-0-248-127.us-west-2.compute.internal:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/tensorflow/cprofile/25-algo-1/train-5-stepend-1622590890330914.2_train-6-stepstart-1622590890341757.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:41:30.886 ip-10-0-248-127.us-west-2.compute.internal:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/tensorflow/cprofile/25-algo-1/train-6-stepstart-1622590890344354.2_train-6-stepend-1622590890885460.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:41:30.915 ip-10-0-248-127.us-west-2.compute.internal:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/tensorflow/cprofile/25-algo-1/train-6-stepend-1622590890902102.8_train-7-stepstart-1622590890915314.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:41:30.917 ip-10-0-248-127.us-west-2.compute.internal:25 INFO keras.py:922] Disabling TF profiler on step: =7\u001b[0m\n",
      "\u001b[34m500/500 - 117s - loss: 2.0034 - accuracy: 0.3562 - batch: 0.0000e+00\u001b[0m\n",
      "\u001b[34mEpoch 2/2\u001b[0m\n",
      "\u001b[34m500/500 - 116s - loss: 1.8404 - accuracy: 0.3855 - batch: 1.0000\u001b[0m\n",
      "\u001b[34m[2021-06-01 23:45:24.774 ip-10-0-248-127.us-west-2.compute.internal:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/tensorflow/cprofile/25-algo-1/train-999-stepend-1622591123503333.8_posthookclose-*-end-1622591124772471.8/python_stats.\u001b[0m\n",
      "\u001b[34m2021-06-01 23:40:00.691036: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-06-01 23:40:00.780334: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2021-06-01 23:40:33.776067: W tensorflow/core/framework/dataset.cc:446] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-01 23:45:26,949 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2021-06-01 23:45:26,950 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-01 23:45:48 Uploading - Uploading generated training model\n",
      "2021-06-01 23:45:48 Completed - Training job completed\n",
      "Training seconds: 538\n",
      "Billable seconds: 538\n"
     ]
    }
   ],
   "source": [
    "remote_inputs = {\"train\": dataset_location + \"/train\"}\n",
    "\n",
    "estimator.fit(remote_inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-douglas",
   "metadata": {
    "papermill": {
     "duration": 0.053011,
     "end_time": "2021-06-01T00:13:30.022207",
     "exception": false,
     "start_time": "2021-06-01T00:13:29.969196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Monitor the system resource utilization using SageMaker Studio\n",
    "\n",
    "SageMaker Studio provides the visualization tool for Sagemaker Debugger where you can find the analysis report and the system and framework resource utilization history.\n",
    "\n",
    "To access this information in SageMaker Studio, click on the last icon on the left to open `SageMaker Components and registries` and choose `Experiments and trials`. You will see the list of training jobs. Right click on the job you want to investigate shows a pop-up menu, then click on `Open Debugger for insights` which opens a new tab for SageMaker Debugger.\n",
    "\n",
    "There are two tabs, `Overview` and `Nodes`. `Overview` gives profiling summaries for quick review, and `Nodes` gives a detailed utilization information on all nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-sherman",
   "metadata": {
    "papermill": {
     "duration": 0.05283,
     "end_time": "2021-06-01T00:13:30.127965",
     "exception": false,
     "start_time": "2021-06-01T00:13:30.075135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. SageMaker Debugger profiling analysis utilities\n",
    "We can use the profiling analysis utilities to gain deeper insights into what the source of the issue is.\n",
    "For this step, we will rely on the bokeh and smdebug packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "solved-library",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:30.237604Z",
     "iopub.status.busy": "2021-06-01T00:13:30.236910Z",
     "iopub.status.idle": "2021-06-01T00:13:40.333732Z",
     "shell.execute_reply": "2021-06-01T00:13:40.334232Z"
    },
    "papermill": {
     "duration": 10.153683,
     "end_time": "2021-06-01T00:13:40.334396",
     "exception": false,
     "start_time": "2021-06-01T00:13:30.180713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bokeh==2.1.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (2.1.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (7.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (2.11.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (2.8.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (6.0.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh==2.1.1) (5.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh==2.1.1) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from packaging>=16.8->bokeh==2.1.1) (2.4.6)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from packaging>=16.8->bokeh==2.1.1) (1.14.0)\n",
      "Requirement already satisfied: smdebug in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from smdebug) (1.18.1)\n",
      "Requirement already satisfied: pyinstrument>=3.1.3 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from smdebug) (3.15.6)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from smdebug) (20.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ubuntu/.local/lib/python3.6/site-packages (from smdebug) (1.16.36)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.36 in /home/ubuntu/.local/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.19.36)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.36->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.36->boto3>=1.10.32->smdebug) (1.25.10)\n",
      "Requirement already satisfied: six>=1.9 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (1.14.0)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug) (0.2.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from packaging->smdebug) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install bokeh==2.1.1\n",
    "! pip install smdebug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-respect",
   "metadata": {
    "papermill": {
     "duration": 0.064631,
     "end_time": "2021-06-01T00:13:40.464137",
     "exception": false,
     "start_time": "2021-06-01T00:13:40.399506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use smdebug to extract gpu and framework metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recovered-williams",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T00:13:40.603797Z",
     "iopub.status.busy": "2021-06-01T00:13:40.603249Z",
     "iopub.status.idle": "2021-06-01T00:13:42.983379Z",
     "shell.execute_reply": "2021-06-01T00:13:42.982357Z"
    },
    "papermill": {
     "duration": 2.455191,
     "end_time": "2021-06-01T00:13:42.983612",
     "exception": true,
     "start_time": "2021-06-01T00:13:40.528421",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-36m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2021-06-01 23:46:05.229 ip-172-31-33-148:2728 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DescribeTrainingJob operation: Requested resource not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-529f3fb9df80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"us-east-1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_job_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler_s3_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/smdebug/profiler/analysis/notebook_utils/training_job.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, training_job_name, region)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msm_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sagemaker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         self.profiler_config, self.profiler_s3_output_path = (\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_and_profiler_s3_output_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         )\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_metrics_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/smdebug/profiler/analysis/notebook_utils/training_job.py\u001b[0m in \u001b[0;36mget_config_and_profiler_s3_output_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sm_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mattempt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DescribeTrainingJob operation: Requested resource not found."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "from smdebug.profiler.analysis.utils.profiler_data_to_pandas import PandasFrame\n",
    "\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "\n",
    "pf = PandasFrame(tj.profiler_s3_output_path)\n",
    "\n",
    "# extract gpu metrics\n",
    "system_metrics_df = pf.get_all_system_metrics()\n",
    "gpus = system_metrics_df[system_metrics_df[\"dimension\"] == \"GPUUtilization\"]\n",
    "timestamps = gpus[\"timestamp_us\"].to_numpy()\n",
    "values = gpus[\"value\"].to_numpy()\n",
    "\n",
    "# exctract framework metrics\n",
    "framework_metrics_df = pf.get_all_framework_metrics(\n",
    "    selected_framework_metrics=[\"Step:ModeKeys.TRAIN\", \"Step:ModeKeys.GLOBAL\"]\n",
    ")\n",
    "train_steps = framework_metrics_df[\n",
    "    framework_metrics_df[\"framework_metric\"].isin([\"Step:ModeKeys.TRAIN\", \"Step:ModeKeys.GLOBAL\"])\n",
    "]\n",
    "start_step = train_steps[\"start_time_us\"].to_numpy()\n",
    "end_step = train_steps[\"end_time_us\"].to_numpy()\n",
    "step_num = train_steps[\"step\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-decline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alternative-auction",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Use bokeh to plot the gpu metrics and the training progression on the same graph. This enables us to correlate between the two. We can see that the drops in gpu utilization coincide with every 50th step, which are marked in yellow. These are precisely the steps in which we have chosen to capture all of the graph tensors.\n",
    "![bokeh-graph](./images/bokeh_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-uzbekistan",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Div, HoverTool, HBar\n",
    "from bokeh.models.glyphs import Circle, Line\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "plot = figure(\n",
    "    plot_height=400,\n",
    "    plot_width=1400,\n",
    "    x_range=(timestamps[0], timestamps[-1]),\n",
    "    y_range=(-1, 110),\n",
    "    tools=\"crosshair,xbox_select,pan,reset,save,xwheel_zoom\",\n",
    ")\n",
    "x_range = plot.x_range\n",
    "\n",
    "plot.xgrid.visible = False\n",
    "plot.ygrid.visible = False\n",
    "\n",
    "colors = np.where(step_num % 50 == 0, \"yellow\", \"purple\")\n",
    "\n",
    "# pad framework metrics to match length of system metrics\n",
    "pad = values.size - step_num.size\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        x=timestamps,\n",
    "        y=values,\n",
    "        left=np.pad(start_step, (0, pad)),\n",
    "        right=np.pad(end_step, (0, pad)),\n",
    "        color=np.pad(colors, (0, pad)),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "callback = CustomJS(\n",
    "    args=dict(s1=source, div=Div(width=250, height=100, height_policy=\"fixed\")),\n",
    "    code=\"\"\"\n",
    "        console.log('Running CustomJS callback now.');\n",
    "        var inds = s1.selected.indices;\n",
    "        console.log(inds);\n",
    "        var line = \"<span style=float:left;clear:left;font_size=13px><b> Selected index range: [\" + Math.min.apply(Math,inds) + \",\" + Math.max.apply(Math,inds) + \"]</b></span>\\\\n\";\n",
    "        console.log(line)\n",
    "        var text = div.text.concat(line);\n",
    "        var lines = text.split(\"\\\\n\")\n",
    "        if (lines.length > 35)\n",
    "            lines.shift();\n",
    "        div.text = lines.join(\"\\\\n\");\"\"\",\n",
    ")\n",
    "\n",
    "plot.js_on_event(\"selectiongeometry\", callback)\n",
    "\n",
    "line = Line(x=\"x\", y=\"y\", line_color=\"white\")\n",
    "circle = Circle(x=\"x\", y=\"y\", fill_alpha=0, line_width=0)\n",
    "hbar = HBar(\n",
    "    y=105, height=5, right=\"right\", left=\"left\", fill_color=\"color\", line_cap=\"round\", line_width=0\n",
    ")\n",
    "\n",
    "\n",
    "p = plot.add_glyph(source, line)\n",
    "p = plot.add_glyph(source, circle)\n",
    "p = plot.add_glyph(source, hbar)\n",
    "\n",
    "# create tooltip for hover tool\n",
    "hover = HoverTool(renderers=[p], tooltips=[(\"index\", \"$index\"), (\"(x,y)\", \"($x, $y)\")])\n",
    "\n",
    "plot.xaxis.axis_label = \"Time in ms\"\n",
    "plot.yaxis.axis_label = \"GPU Utilization\"\n",
    "plot.add_tools(hover)\n",
    "show(plot, notebook_handle=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 45.057723,
   "end_time": "2021-06-01T00:13:44.310180",
   "environment_variables": {},
   "exception": true,
   "input_path": "callback_bottleneck.ipynb",
   "output_path": "/opt/ml/processing/output/callback_bottleneck-2021-06-01-00-09-21.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-01T00:12:59.252457",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
