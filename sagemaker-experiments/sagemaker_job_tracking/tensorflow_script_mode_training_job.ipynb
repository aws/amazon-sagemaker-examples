{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Train an TensorFlow model with a SageMaker Training Job and track it using SageMaker Experiments\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://j2wyeq0ytc.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "This notebook shows how you can use the SageMaker SDK to track a Machine Learning experiment. \n", "\n", "We introduce two concepts in this notebook -\n", "\n", "* *Experiment:* An experiment is a collection of runs. When you initialize a run in your training loop, you include the name of the experiment that the run belongs to. Experiment names must be unique within your AWS account. \n", "* *Run:* A run consists of all the inputs, parameters, configurations, and results for one iteration of model training. Initialize an experiment run for tracking a training job with Run(). \n", "\n", "In this notebook we train a Keras model using the MNIST dataset on a remote SageMaker instance using a training job."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Note:** To run this notebook, use the `Python 3 (Data Science) Image`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# update boto3 and sagemaker to ensure latest SDK version\n", "!{sys.executable} -m pip install --upgrade pip\n", "!{sys.executable} -m pip install --upgrade boto3\n", "!{sys.executable} -m pip install --upgrade sagemaker\n", "!{sys.executable} -m pip install --upgrade tensorflow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import boto3\n", "import json\n", "import sagemaker\n", "from sagemaker.session import Session\n", "from sagemaker import get_execution_role\n", "from sagemaker.experiments.run import Run\n", "from sagemaker.utils import unique_name_from_base"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sagemaker_session = Session()\n", "boto_sess = boto3.Session()\n", "\n", "role = get_execution_role()\n", "default_bucket = sagemaker_session.default_bucket()\n", "\n", "\n", "sm = boto_sess.client(\"sagemaker\")\n", "region = boto_sess.region_name"]}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": ["### Prepare the training script\n", "\n", "Here we use a SageMaker Training job to train the model on a remote instance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p script"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%writefile ./script/train.py\n", "\n", "import os\n", "\n", "os.system(\"pip install -U sagemaker\")\n", "\n", "import numpy as np\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "import pandas as pd\n", "import argparse\n", "\n", "from sagemaker.session import Session\n", "from sagemaker.experiments import load_run\n", "\n", "import boto3\n", "\n", "boto_session = boto3.session.Session(region_name=os.environ[\"REGION\"])\n", "sagemaker_session = Session(boto_session=boto_session)\n", "s3 = boto3.client(\"s3\")\n", "\n", "\n", "def parse_args():\n", "\n", "    parser = argparse.ArgumentParser()\n", "\n", "    parser.add_argument(\"--epochs\", type=int, default=1)\n", "    parser.add_argument(\"--batch_size\", type=int, default=64)\n", "    parser.add_argument(\"--dropout\", type=float, default=0.01)\n", "\n", "    return parser.parse_known_args()\n", "\n", "\n", "class ExperimentCallback(keras.callbacks.Callback):\n", "    \"\"\" \"\"\"\n", "\n", "    def __init__(self, run, model, x_test, y_test):\n", "        \"\"\"Save params in constructor\"\"\"\n", "        self.run = run\n", "        self.model = model\n", "        self.x_test = x_test\n", "        self.y_test = y_test\n", "\n", "    def on_epoch_end(self, epoch, logs=None):\n", "        \"\"\" \"\"\"\n", "        keys = list(logs.keys())\n", "        for key in keys:\n", "            self.run.log_metric(name=key, value=logs[key], step=epoch)\n", "            print(\"{} -> {}\".format(key, logs[key]))\n", "\n", "\n", "def load_data():\n", "    num_classes = 10\n", "    input_shape = (28, 28, 1)\n", "\n", "    train_path = \"input_train.npy\"\n", "    test_path = \"input_test.npy\"\n", "    train_labels_path = \"input_train_labels.npy\"\n", "    test_labels_path = \"input_test_labels.npy\"\n", "\n", "    # Load the data and split it between train and test sets\n", "    s3.download_file(\n", "        \"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_train.npy\", train_path\n", "    )\n", "    s3.download_file(\n", "        \"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_test.npy\", test_path\n", "    )\n", "    s3.download_file(\n", "        \"sagemaker-sample-files\",\n", "        \"datasets/image/MNIST/numpy/input_train_labels.npy\",\n", "        train_labels_path,\n", "    )\n", "    s3.download_file(\n", "        \"sagemaker-sample-files\",\n", "        \"datasets/image/MNIST/numpy/input_test_labels.npy\",\n", "        test_labels_path,\n", "    )\n", "\n", "    x_train = np.load(train_path)\n", "    x_test = np.load(test_path)\n", "    y_train = np.load(train_labels_path)\n", "    y_test = np.load(test_labels_path)\n", "\n", "    # Reshape the arrays\n", "    x_train = np.reshape(x_train, (60000, 28, 28))\n", "    x_test = np.reshape(x_test, (10000, 28, 28))\n", "    y_train = np.reshape(y_train, (60000,))\n", "    y_test = np.reshape(y_test, (10000,))\n", "\n", "    # Scale images to the [0, 1] range\n", "    x_train = x_train.astype(\"float32\") / 255\n", "    x_test = x_test.astype(\"float32\") / 255\n", "\n", "    # Make sure images have shape (28, 28, 1)\n", "    x_train = np.expand_dims(x_train, -1)\n", "    x_test = np.expand_dims(x_test, -1)\n", "    print(\"x_train shape:\", x_train.shape)\n", "    print(x_train.shape[0], \"train samples\")\n", "    print(x_test.shape[0], \"test samples\")\n", "\n", "    # convert class vectors to binary class matrices\n", "    y_train = keras.utils.to_categorical(y_train, num_classes)\n", "    y_test = keras.utils.to_categorical(y_test, num_classes)\n", "\n", "    return x_train, x_test, y_train, y_test\n", "\n", "\n", "def main():\n", "    \"\"\" \"\"\"\n", "    args, _ = parse_args()\n", "    print(\"Args are : \", args)\n", "    num_classes = 10\n", "    input_shape = (28, 28, 1)\n", "    x_train, x_test, y_train, y_test = load_data()\n", "\n", "    model = keras.Sequential(\n", "        [\n", "            keras.Input(shape=input_shape),\n", "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n", "            layers.MaxPooling2D(pool_size=(2, 2)),\n", "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n", "            layers.MaxPooling2D(pool_size=(2, 2)),\n", "            layers.Flatten(),\n", "            layers.Dropout(args.dropout),\n", "            layers.Dense(num_classes, activation=\"softmax\"),\n", "        ]\n", "    )\n", "\n", "    model.summary()\n", "\n", "    batch_size = args.batch_size\n", "    epochs = args.epochs\n", "\n", "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n", "\n", "    ###\n", "    # `load_run` will use the run defined when calling the estimator\n", "    ###\n", "    with load_run(sagemaker_session=sagemaker_session) as run:\n", "        model.fit(\n", "            x_train,\n", "            y_train,\n", "            batch_size=batch_size,\n", "            epochs=epochs,\n", "            validation_split=0.1,\n", "            callbacks=[ExperimentCallback(run, model, x_test, y_test)],\n", "        )\n", "\n", "        score = model.evaluate(x_test, y_test, verbose=0)\n", "        print(\"Test loss:\", score[0])\n", "        print(\"Test accuracy:\", score[1])\n", "\n", "        run.log_metric(name=\"Final Test Loss\", value=score[0])\n", "        run.log_metric(name=\"Final Test Accuracy\", value=score[1])\n", "\n", "        model.save(\"/opt/ml/model\")\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Create an Experiment and launch a training job\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["from sagemaker.tensorflow.estimator import TensorFlow\n", "from sagemaker.experiments.run import Run\n", "\n", "exp_name = \"tensorflow-script-mode-experiment\"\n", "\n", "batch_size = 256\n", "epochs = 5\n", "dropout = 0.1\n", "\n", "with Run(\n", "    experiment_name=exp_name,\n", "    sagemaker_session=sagemaker_session,\n", ") as run:\n", "\n", "    run.log_parameter(\"batch_size\", batch_size)\n", "    run.log_parameter(\"epochs\", epochs)\n", "    run.log_parameter(\"dropout\", dropout)\n", "\n", "    est = TensorFlow(\n", "        entry_point=\"./script/train.py\",\n", "        role=role,\n", "        model_dir=False,\n", "        hyperparameters={\"epochs\": epochs, \"batch_size\": batch_size, \"dropout\": dropout},\n", "        framework_version=\"2.8\",\n", "        py_version=\"py39\",\n", "        instance_type=\"ml.m5.xlarge\",\n", "        instance_count=1,\n", "        keep_alive_period_in_seconds=3600,\n", "        environment={\"REGION\": region},\n", "    )\n", "\n", "    est.fit()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["est.model_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Register the trained model in the Model Registry\n", "\n", "This is an optional step users can take if they want to keep track of their models in a central model catalog."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["from sagemaker.tensorflow.model import TensorFlowModel\n", "\n", "\n", "model = TensorFlowModel(model_data=est.model_data, role=role, framework_version=\"2.8\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ["model.register(\n", "    model_package_group_name=\"tensorflow-script-mode-model\",\n", "    content_types=[\"text/csv\"],\n", "    inference_instances=[\"ml.m5.xlarge\"],\n", "    transform_instances=[\"ml.m5.xlarge\"],\n", "    response_types=[\"text/csv\"],\n", "    approval_status=\"PendingManualApproval\",\n", ")"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## Notebook CI Test Results\n", "\n", "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-3/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n", "\n", "![This badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker-experiments|sagemaker_job_tracking|tensorflow_script_mode_training_job.ipynb)\n"]}], "metadata": {"instance_type": "ml.m5.large", "kernelspec": {"display_name": "Python 3 (Data Science)", "language": "python", "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 4}