{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineage Tracking and Traversal Example\n",
    "\n",
    "SageMaker Lineage makes it easy to track all the artifacts created in a machine learning workflow\n",
    " from start to finish.\n",
    "\n",
    "The [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable) is an SDK to train and \n",
    "deploy Apache MXNet models. In this example, we train a simple neural network using the Apache MXNet [Module API](https://mxnet.apache.org/api/python/module/module.html) and the MNIST dataset. \n",
    "\n",
    "\n",
    "Make sure you selected `conda_mxnet_p36` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure:\n",
    "* your account has been whitelisted\n",
    "* your execution role has the appropriate trusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Import Private Beta SDK.\n",
    "!{sys.executable} -m pip install -q -U pip\n",
    "!{sys.executable} -m pip install -q sagemaker-2.6.1.dev0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "#may need to restart the kernel after initial install of beta sdk\n",
    "#IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.lineage import context, artifact, association, action\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lineage beta only available in CMH\n",
    "region = 'us-east-2'\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = Session().default_bucket()\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Bucket location where your custom code will be saved in the tar.gz format.\n",
    "custom_code_upload_location = 's3://{}/mxnet-mnist-example/code'.format(bucket)\n",
    "list_response = list(artifact.Artifact.list(source_uri=custom_code_upload_location, sagemaker_boto_client=sagemaker_client))\n",
    "\n",
    "if len(list_response):\n",
    "    code_artifact_arn = list_response[0].artifact_arn\n",
    "else:\n",
    "    code_artifact_arn = artifact.Artifact.create(\n",
    "        artifact_name='SourceCodeLocation',\n",
    "        source_uri=custom_code_upload_location,\n",
    "        artifact_type='codelocation',\n",
    "        sagemaker_boto_client=sagemaker_client\n",
    "    ).artifact_arn\n",
    "\n",
    "# Bucket location where results of model training are saved.\n",
    "model_artifacts_location = 's3://{}/mxnet-mnist-example/artifacts'.format(bucket)\n",
    "list_response = list(artifact.Artifact.list(source_uri=model_artifacts_location, sagemaker_boto_client=sagemaker_client))\n",
    "if len(list_response):\n",
    "    model_location_artifact_arn = list_response[0].artifact_arn\n",
    "else:\n",
    "    model_location_artifact_arn = artifact.Artifact.create(\n",
    "        artifact_name='model-artifacts-location',\n",
    "        source_uri=model_artifacts_location,\n",
    "        artifact_type='model-artifacts-location',\n",
    "        sagemaker_boto_client=sagemaker_client,\n",
    "    ).artifact_arn\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training script\n",
    "\n",
    "The `mnist.py` script provides all the code we need for training and hosting a SageMaker model. The script also checkpoints the model at the end of every epoch and saves the model graph, params and optimizer state in the folder `/opt/ml/checkpoints`. If the folder path does not exist then it skips checkpointing. The script we use is adaptated from Apache MXNet [MNIST tutorial](https://mxnet.incubator.apache.org/tutorials/python/mnist.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker's MXNet estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "mnist_estimator = MXNet(entry_point='mnist.py',\n",
    "                        role=role,\n",
    "                        output_path=model_artifacts_location,\n",
    "                        code_location=custom_code_upload_location,\n",
    "                        instance_count=1,\n",
    "                        instance_type='ml.m4.xlarge',\n",
    "                        framework_version='1.4.1',\n",
    "                        py_version='py3',\n",
    "                        #distributions={'parameter_server': {'enabled': True}},\n",
    "                        hyperparameters={'learning-rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our MXNet object, we can fit it using data stored in S3. Below we run SageMaker training on two input channels: **train** and **test**.\n",
    "\n",
    "During training, SageMaker makes this data stored in S3 available in the local filesystem where the mnist script is running. The ```mnist.py``` script simply loads the train and test data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18 19:11:17 Starting - Starting the training job...\n",
      "2020-09-18 19:11:19 Starting - Launching requested ML instances......\n",
      "2020-09-18 19:12:24 Starting - Preparing the instances for training......\n",
      "2020-09-18 19:13:39 Downloading - Downloading input data\n",
      "2020-09-18 19:13:39 Training - Downloading the training image...\n",
      "2020-09-18 19:13:59 Training - Training image download completed. Training in progress.\u001b[34m2020-09-18 19:14:00,197 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:00,201 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:00,215 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"learning-rate\":0.1}', 'SM_USER_ENTRY_POINT': 'mnist.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"test\",\"train\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'mnist', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-2-707662012936/mxnet-mnist-example/code/mxnet-training-2020-09-18-19-11-17-138/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"learning-rate\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-09-18-19-11-17-138\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-707662012936/mxnet-mnist-example/code/mxnet-training-2020-09-18-19-11-17-138/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}', 'SM_USER_ARGS': '[\"--learning-rate\",\"0.1\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TEST': '/opt/ml/input/data/test', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_HP_LEARNING-RATE': '0.1'}\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:00,481 sagemaker-containers INFO     Module mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:00,481 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:00,481 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:00,481 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mInstalling collected packages: mnist\n",
      "  Running setup.py install for mnist: started\n",
      "    Running setup.py install for mnist: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed mnist-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.1.1, however version 20.2.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:02,203 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:02,220 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"learning-rate\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mxnet-training-2020-09-18-19-11-17-138\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-707662012936/mxnet-mnist-example/code/mxnet-training-2020-09-18-19-11-17-138/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"learning-rate\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-707662012936/mxnet-mnist-example/code/mxnet-training-2020-09-18-19-11-17-138/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"learning-rate\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-09-18-19-11-17-138\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-707662012936/mxnet-mnist-example/code/mxnet-training-2020-09-18-19-11-17-138/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--learning-rate\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m mnist --learning-rate 0.1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Batch [0-100]#011Speed: 48537.71 samples/sec#011accuracy=0.105248\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Batch [100-200]#011Speed: 52232.08 samples/sec#011accuracy=0.117400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Batch [200-300]#011Speed: 52729.16 samples/sec#011accuracy=0.112400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Batch [300-400]#011Speed: 58271.46 samples/sec#011accuracy=0.111800\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Batch [400-500]#011Speed: 51936.64 samples/sec#011accuracy=0.111900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Train-accuracy=0.132550\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Time cost=1.159\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0] Validation-accuracy=0.350200\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Batch [0-100]#011Speed: 46740.22 samples/sec#011accuracy=0.473168\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Batch [100-200]#011Speed: 59956.92 samples/sec#011accuracy=0.666000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Batch [200-300]#011Speed: 59902.97 samples/sec#011accuracy=0.763500\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Batch [300-400]#011Speed: 57584.56 samples/sec#011accuracy=0.799100\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Batch [400-500]#011Speed: 59448.98 samples/sec#011accuracy=0.829800\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Train-accuracy=0.727917\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Time cost=1.065\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1] Validation-accuracy=0.859700\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Batch [0-100]#011Speed: 47147.88 samples/sec#011accuracy=0.857723\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Batch [100-200]#011Speed: 48038.83 samples/sec#011accuracy=0.868600\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Batch [200-300]#011Speed: 51587.54 samples/sec#011accuracy=0.889400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Batch [300-400]#011Speed: 54230.68 samples/sec#011accuracy=0.899400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Batch [400-500]#011Speed: 49632.21 samples/sec#011accuracy=0.905200\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Train-accuracy=0.888900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Time cost=1.195\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2] Validation-accuracy=0.920000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Batch [0-100]#011Speed: 39163.75 samples/sec#011accuracy=0.920594\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Batch [100-200]#011Speed: 55325.51 samples/sec#011accuracy=0.920200\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Batch [200-300]#011Speed: 58630.19 samples/sec#011accuracy=0.928000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Batch [300-400]#011Speed: 57232.00 samples/sec#011accuracy=0.929900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Batch [400-500]#011Speed: 58584.25 samples/sec#011accuracy=0.930200\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Train-accuracy=0.927933\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Time cost=1.152\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3] Validation-accuracy=0.937500\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Batch [0-100]#011Speed: 47603.31 samples/sec#011accuracy=0.943762\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Batch [100-200]#011Speed: 54678.19 samples/sec#011accuracy=0.944800\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Batch [200-300]#011Speed: 55427.86 samples/sec#011accuracy=0.943600\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Batch [300-400]#011Speed: 52224.08 samples/sec#011accuracy=0.947500\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Batch [400-500]#011Speed: 59256.14 samples/sec#011accuracy=0.949900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Train-accuracy=0.947067\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Time cost=1.113\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4] Validation-accuracy=0.951700\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Batch [0-100]#011Speed: 48969.19 samples/sec#011accuracy=0.956238\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Batch [100-200]#011Speed: 61169.63 samples/sec#011accuracy=0.955600\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Batch [200-300]#011Speed: 51660.99 samples/sec#011accuracy=0.955900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Batch [300-400]#011Speed: 50272.49 samples/sec#011accuracy=0.959100\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Batch [400-500]#011Speed: 56537.68 samples/sec#011accuracy=0.959400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Train-accuracy=0.957833\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Time cost=1.135\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5] Validation-accuracy=0.957800\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Batch [0-100]#011Speed: 48367.56 samples/sec#011accuracy=0.965644\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Batch [100-200]#011Speed: 52162.12 samples/sec#011accuracy=0.964000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Batch [200-300]#011Speed: 42420.57 samples/sec#011accuracy=0.965700\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Batch [300-400]#011Speed: 58030.24 samples/sec#011accuracy=0.963800\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Batch [400-500]#011Speed: 59894.67 samples/sec#011accuracy=0.967100\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Train-accuracy=0.965133\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Time cost=1.186\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6] Validation-accuracy=0.964100\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Batch [0-100]#011Speed: 45140.09 samples/sec#011accuracy=0.971188\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Batch [100-200]#011Speed: 52699.15 samples/sec#011accuracy=0.966600\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Batch [200-300]#011Speed: 49742.93 samples/sec#011accuracy=0.969700\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Batch [300-400]#011Speed: 55433.43 samples/sec#011accuracy=0.968400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Batch [400-500]#011Speed: 49421.79 samples/sec#011accuracy=0.968600\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Train-accuracy=0.969383\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Time cost=1.210\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7] Validation-accuracy=0.965900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Batch [0-100]#011Speed: 46661.86 samples/sec#011accuracy=0.973168\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Batch [100-200]#011Speed: 55705.76 samples/sec#011accuracy=0.971900\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Batch [200-300]#011Speed: 57230.98 samples/sec#011accuracy=0.974000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Batch [300-400]#011Speed: 60181.19 samples/sec#011accuracy=0.974400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Batch [400-500]#011Speed: 59841.18 samples/sec#011accuracy=0.971400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Train-accuracy=0.973050\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Time cost=1.087\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8] Validation-accuracy=0.969000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Batch [0-100]#011Speed: 37346.64 samples/sec#011accuracy=0.977228\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Batch [100-200]#011Speed: 60791.24 samples/sec#011accuracy=0.976100\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Batch [200-300]#011Speed: 56732.68 samples/sec#011accuracy=0.975800\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Batch [300-400]#011Speed: 56863.21 samples/sec#011accuracy=0.976400\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Batch [400-500]#011Speed: 43948.87 samples/sec#011accuracy=0.976000\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Train-accuracy=0.976433\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Time cost=1.205\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9] Validation-accuracy=0.969100\u001b[0m\n",
      "\u001b[34m2020-09-18 19:14:21,054 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-09-18 19:14:32 Uploading - Uploading generated training model\n",
      "2020-09-18 19:14:32 Completed - Training job completed\n",
      "Training seconds: 71\n",
      "Billable seconds: 71\n",
      "CPU times: user 534 ms, sys: 33.9 ms, total: 567 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/train'.format(region)\n",
    "test_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/test'.format(region)\n",
    "\n",
    "mnist_estimator.fit({'train': train_data_location, 'test': test_data_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_response = list(artifact.Artifact.list(source_uri=train_data_location, sagemaker_boto_client=sagemaker_client))\n",
    "if len(list_response):\n",
    "    train_data_location_artifact_arn = list_response[0].artifact_arn\n",
    "else:\n",
    "    train_data_location_artifact_arn = artifact.Artifact.create(\n",
    "        artifact_name='train-data',\n",
    "        artifact_type='TrainingData',\n",
    "        source_uri=train_data_location,\n",
    "        sagemaker_boto_client=sagemaker_client,\n",
    "    ).artifact_arn\n",
    "\n",
    "list_response = list(artifact.Artifact.list(source_uri=test_data_location, sagemaker_boto_client=sagemaker_client))\n",
    "if len(list_response):\n",
    "    test_data_location_artifact_arn = list_response[0].artifact_arn\n",
    "else:\n",
    "    test_data_location_artifact_arn = artifact.Artifact.create(\n",
    "        artifact_name='test-data',\n",
    "        artifact_type='TestData',\n",
    "        source_uri=test_data_location,\n",
    "        sagemaker_boto_client=sagemaker_client,\n",
    "    ).artifact_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# associate the artifacts\n",
    "\n",
    "training_job_name = mnist_estimator.latest_training_job.job_name\n",
    "\n",
    "trial_component = sagemaker_client.describe_trial_component(TrialComponentName=training_job_name + '-aws-training-job')\n",
    "trial_component_arn=trial_component['TrialComponentArn']\n",
    "\n",
    "input_artifacts = [code_artifact_arn, train_data_location_artifact_arn, test_data_location_artifact_arn]\n",
    "for artifact_arn in input_artifacts:\n",
    "    try:\n",
    "        association.Association.create(\n",
    "            source_arn=artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='ContributedTo',\n",
    "            sagemaker_boto_client=sagemaker_client,\n",
    "        )\n",
    "    except:\n",
    "        logging.info('association between {} and {} already exists', artifact_arn, trial_component_arn)\n",
    "\n",
    "output_artifacts = [model_location_artifact_arn]\n",
    "for artifact_arn in output_artifacts:\n",
    "    try:\n",
    "         association.Association.create(\n",
    "            source_arn=trial_component_arn,\n",
    "            destination_arn=artifact_arn,\n",
    "            association_type='Produced',\n",
    "            sagemaker_boto_client=sagemaker_client,\n",
    "        )\n",
    "    except:\n",
    "        logging.info('association between {} and {} already exists', artifact_arn, trial_component_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an inference Endpoint\n",
    "\n",
    "After training, we use the ``MXNet estimator`` object to build and deploy an ``MXNetPredictor``. This creates a Sagemaker **Endpoint** -- a hosted prediction service that we can use to perform inference. \n",
    "\n",
    "The arguments to the ``deploy`` function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances. Here we will deploy the model to a single ``ml.m4.xlarge`` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 368 ms, sys: 12.5 ms, total: 380 ms\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Association(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7ff40a982d68>,source_arn='arn:aws:sagemaker:us-east-2:707662012936:experiment-trial-component/mxnet-training-2020-09-18-19-07-09-802-aws-training-job',destination_arn='arn:aws:sagemaker:us-east-2:707662012936:context/mxnet-training-2020-09-18-19-21-54-609',association_type=None,response_metadata={'RequestId': 'd6391fc9-edd2-43b9-8338-d996287f1140', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd6391fc9-edd2-43b9-8338-d996287f1140', 'content-type': 'application/x-amz-json-1.1', 'content-length': '246', 'date': 'Fri, 18 Sep 2020 19:28:54 GMT'}, 'RetryAttempts': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.lineage import context\n",
    "\n",
    "endpoint = sagemaker_client.describe_endpoint(EndpointName=predictor.endpoint_name)\n",
    "endpoint_arn = endpoint['EndpointArn']\n",
    "\n",
    "list_response = list(context.Context.list(source_uri=endpoint_arn, sagemaker_boto_client=sagemaker_client))\n",
    "if len(list_response):\n",
    "    endpoint_context_arn = list_response[0].context_arn\n",
    "else:\n",
    "    endpoint_context_arn = context.Context.create(\n",
    "        context_name=predictor.endpoint_name,\n",
    "        context_type='Endpoint',\n",
    "        source_uri=endpoint_arn,\n",
    "        sagemaker_boto_client=sagemaker_client, \n",
    "    ).context_arn\n",
    "\n",
    "association.Association.create(\n",
    "    source_arn=trial_component_arn,\n",
    "    destination_arn=endpoint_context_arn,\n",
    "    sagemaker_boto_client=sagemaker_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lineage_visualizer.py\n",
    "\n",
    "import lineage_visualizer\n",
    "\n",
    "vis = LineageVisualizer(sagemaker_client)\n",
    "vis.both(endpoint_context_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = vis.write_yaml()\n",
    "f = open(file_name, \"r\")\n",
    "print(f.read())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}