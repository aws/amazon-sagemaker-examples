{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Graph Convolutional Matrix Completion by using the Deep Graph Library with MXNet backend on Amazon SageMaker\n",
    "The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example, you train [Graph Convolutional Matrix Completion](https://arxiv.org/abs/1706.02263) network using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and the [MovieLens dataset](https://grouplens.org/datasets/movielens/). Three datasets are supported:\n",
    " * MovieLens 100K Dataset, MovieLens 100K movie ratings. Stable benchmark dataset. 100,000 ratings from 1,000 users on 1,700 movies.\n",
    " * MovieLens 1M Dataset, MovieLens 1M movie ratings. Stable benchmark dataset. 1 million ratings from 6,000 users on 4,000 movies.\n",
    " * MovieLens 10M Dataset, MovieLens 10M movie ratings. Stable benchmark dataset. 10 million ratings and 100,000 tag applications applied to 10,000 movies by 72,000 users.\n",
    "\n",
    "### Prerequisites\n",
    "To get started, install necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y boto3\n",
    "!conda install -c anaconda -y botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to put your custom code.\n",
    "custom_code_upload_location = 'customcode'\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "model_artifacts_location = 's3://{}/artifacts'.format(bucket)\n",
    "\n",
    "# IAM role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "# You can use the Amazon SageMaker Python SDK to get the role from your notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training script\n",
    "The train.py script provides all the code you need for training an Amazon SageMaker model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build GCMC Docker image\n",
    "AWS provides basic Docker images in https://docs.aws.amazon.com/dlami/latest/devguide/deep-learning-containers-images.html. For both PyTorch 1.3 and MXNet 1.6, DGL is preinstalled. As this example needs additional dependencies, you can download a Docker file to build a new image. You should build a GCMC-specific Docker image and push it into your Amazon Elastic Container Registry (Amazon ECR).\n",
    "\n",
    "Note: Do change the GCMC.Dockerfile with the latest MXNet GPU deep learning containers images name with py3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo $account\n",
    "region=$(aws configure get region)\n",
    "\n",
    "docker_name=sagemaker-dgl-gcmc\n",
    "\n",
    "$(aws ecr get-login --no-include-email --region ${region} --registry-ids 763104351884)\n",
    "docker build -t $docker_name -f GCMC.Dockerfile .\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${docker_name}:latest\"\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${docker_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${docker_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "docker tag ${docker_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon SageMaker's estimator class\n",
    "With the Amazon SageMaker Estimator, you can run a single machine in Amazon SageMaker, using CPU or GPU-based instances.\n",
    "\n",
    "When you create the estimator, pass-in the file name of the training script and the name of the IAM execution role. You can also use a few other parameters. train_instance_count and train_instance_type determine the number and type of Amazon SageMaker instances that will be used for the training job.  The hyperparameters parameter is a dictionary of values that is passed to your training script as parameters so that you can use argparse to parse them. You can see how to access these values in the train.py script above.\n",
    "\n",
    "In this example, you upload the whole code base (including train.py) into an Amazon SageMaker container and run the GCMC training using the MovieLens dataset.\n",
    "\n",
    "You can also add a task_tag with value 'DGL' to help tracking the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.estimator import MXNet\n",
    "\n",
    "# Set target dgl-docker name\n",
    "docker_name='sagemaker-dgl-gcmc'\n",
    "\n",
    "CODE_PATH = '../dgl_gcmc'\n",
    "CODE_ENTRY = 'train.py'\n",
    "#code_location = sess.upload_data(CODE_PATH, bucket=bucket, key_prefix=custom_code_upload_location)\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, docker_name)\n",
    "print(image)\n",
    "\n",
    "params = {}\n",
    "params['data_name'] = 'ml-1m'\n",
    "# set output to SageMaker ML output\n",
    "params['save_dir'] = '/opt/ml/model/'\n",
    "task_tags = [{'Key':'ML Task', 'Value':'DGL'}]\n",
    "\n",
    "estimator = MXNet(entry_point=CODE_ENTRY,\n",
    "                  source_dir=CODE_PATH,\n",
    "                  role=role,\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.p3.2xlarge',\n",
    "                  image_name=image,\n",
    "                  hyperparameters=params,\n",
    "                  tags=task_tags,\n",
    "                  sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Training Job\n",
    "After you construct the Estimator object, fit it using Amazon SageMaker. The dataset is automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "You can get the model training output from the Amazon Sagemaker console by searching for the training task and looking for the address of 'S3 model artifact'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
