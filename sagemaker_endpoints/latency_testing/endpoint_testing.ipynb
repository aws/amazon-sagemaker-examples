{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9373624e-e98e-4647-adfe-909c807c88e6",
   "metadata": {},
   "source": [
    "# Comparing Inference Latency of Models Served with Flask and FastAPI on SageMaker Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe11afb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec9835-9d01-4752-a320-1a766e81bfe5",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This notebook will demontrate how the inference latency of the same model varies when one model is served with [Python Flask](https://flask.palletsprojects.com/en/2.3.x/), [FastAPI](https://fastapi.tiangolo.com/) and [SageMaker pre-built container](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html). In all cases, we use a [decision tree](https://scikit-learn.org/stable/modules/tree.html) algorithm from [scikit-learn](https://scikit-learn.org/stable/) package which is trained on the famous [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). \n",
    "\n",
    "The scripts and this notebook can be used to load test and compare latency for any endpoint that you deploy on SageMaker. You can either test a [pre-built SageMaker container](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html) or [bring your own container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-byoc-containers.html). [This GitHub repo](https://github.com/aws/amazon-sagemaker-examples/tree/main/advanced_functionality/scikit_bring_your_own) provides a more detailed example on how to bring your own container to SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841ed5e-bd78-4972-92da-9d821b7da453",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Running this notebook requires `SageMakerFullAccess` permissions. Additionally you will need permissions to publish to Amazon ECR. You can achieve this by adding the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86868f-fe43-44f4-a462-1bfe2f0e4234",
   "metadata": {},
   "source": [
    "## The experiment\n",
    "\n",
    "Load testing is carried out on `ml.c5d.18xlarge` SageMaker Notebook Instance type. It is recommended to use a large instance type for load testing in order to be able to provide the adeqate load on the Inference Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87961e89-de75-4db5-8e44-428d759dbcfd",
   "metadata": {},
   "source": [
    "# Part 1: Bundling and Pushing Models to Amazon ECR\n",
    "\n",
    "There is a script inside each model folder to build and push a model image to ECR. The script logs in to ECR, builds and tags an image and pushes the image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa3507-fe1f-415d-9edf-cf6449c6e6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"flask-model\", \"fastapi-model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edde22-31e0-400c-96eb-9738940a857c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        result = subprocess.run([\"./build_and_push.sh\", f\"{model}\"],\n",
    "                                capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Successfully built and pushed {model} to Amazon ECR\")\n",
    "        else:\n",
    "            print(f\"Error building and pushing {model}:\", result.stderr)\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f09aee-02cd-401b-86a7-2aa2919ecec9",
   "metadata": {},
   "source": [
    "# Part 2: Training and Deploying models to SageMaker Inference Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55cf59-f88e-4986-8913-6d4ffcc13d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"sagemaker-endpoint-testing-example\"\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a85c24-8ea9-4030-889a-a4bdb5091898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data location\n",
    "WORK_DIRECTORY = \"data\"\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b93cdc-9d7f-49b8-8fbd-005b118cf636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and deploy each model\n",
    "for model in models:\n",
    "    image = f\"{account}.dkr.ecr.{region}.amazonaws.com/{model}:latest\"\n",
    "\n",
    "    tree = sage.estimator.Estimator(\n",
    "        image,\n",
    "        role,\n",
    "        1,\n",
    "        \"ml.c4.2xlarge\",\n",
    "        output_path=f\"s3://{sess.default_bucket()}/output\",\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "\n",
    "    tree.fit(data_location)\n",
    "\n",
    "    tree.deploy(1, \"ml.m4.xlarge\", serializer=CSVSerializer(),\n",
    "                endpoint_name=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4623c-bb75-4490-bf73-7f3303eb4d8d",
   "metadata": {},
   "source": [
    "# Part 3: Deploying SageMaker Pre-built Scikit-learn container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945183d-cbec-455e-bf85-c9299c5f10e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd3285-48f9-4f47-a882-4b7f03bc5da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# A sample training component that trains a simple scikit-learn decision tree model.\n",
    "# This implementation works in File mode and makes no assumptions about the input file names.\n",
    "# Input is specified as CSV with a data point in each row and the labels in the first column.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "# These are the paths to where SageMaker mounts interesting things in your container.\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = prefix + 'input/data'\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "param_path = os.path.join(prefix, 'input/config/hyperparameters.json')\n",
    "\n",
    "# This algorithm has a single channel of input data called 'training'. Since we run in\n",
    "# File mode, the input files are copied to the directory specified here.\n",
    "channel_name='training'\n",
    "training_path = os.path.join(input_path, channel_name)\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    #Load Model\n",
    "    with open(os.path.join(model_dir, \"decision-tree-model.pkl\"), \"rb\") as inp:\n",
    "        clf = pickle.load(inp)\n",
    "    return clf\n",
    "\n",
    "\n",
    "# The function to execute the training.\n",
    "def train():\n",
    "    print('Starting the training.')\n",
    "    try:\n",
    "        # Read in any hyperparameters that the user passed with the training job\n",
    "        with open(param_path, 'r') as tc:\n",
    "            trainingParams = json.load(tc)\n",
    "\n",
    "        # Take the set of files and read them all into a single pandas dataframe\n",
    "        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]\n",
    "        if len(input_files) == 0:\n",
    "            raise ValueError(('There are no files in {}.\\n' +\n",
    "                              'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                              'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                              'does not have permission to access the data.').format(training_path, channel_name))\n",
    "        raw_data = [ pd.read_csv(file, header=None) for file in input_files if file.endswith(\".csv\")]\n",
    "        train_data = pd.concat(raw_data)\n",
    "\n",
    "        # labels are in the first column\n",
    "        train_y = train_data.iloc[:,0]\n",
    "        train_X = train_data.iloc[:,1:]\n",
    "\n",
    "        # Here we only support a single hyperparameter. Note that hyperparameters are always passed in as\n",
    "        # strings, so we need to do any necessary conversions.\n",
    "        max_leaf_nodes = trainingParams.get('max_leaf_nodes', None)\n",
    "        if max_leaf_nodes is not None:\n",
    "            max_leaf_nodes = int(max_leaf_nodes)\n",
    "\n",
    "        # Now use scikit-learn's decision tree classifier to train the model.\n",
    "        clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n",
    "        clf = clf.fit(train_X, train_y)\n",
    "        \n",
    "        model_dir = os.environ['SM_MODEL_DIR']\n",
    "\n",
    "        # save the model\n",
    "        with open(os.path.join(model_dir, 'decision-tree-model.pkl'), 'wb') as out:\n",
    "            pickle.dump(clf, out)\n",
    "        print('Training complete.')\n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(model_dir, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print('Exception during training: ' + str(e) + '\\n' + trc, file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68942456-b23e-475c-b54d-09dce7581f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_built_enpoint_name = 'sagemaker-scikit-pre-built'\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"sagemaker-scikit-tree\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c1773-d3ab-40ed-bb96-e0e9604ee4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3174ff-2e4e-48ce-9da9-1842e20a39f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = sklearn_estimator.deploy(1, \"ml.m4.xlarge\", serializer=CSVSerializer(),\n",
    "                endpoint_name=pre_built_enpoint_name)\n",
    "\n",
    "# Adding new endpoint to our models list\n",
    "models.append(pre_built_enpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee4d3a-fc48-4a8d-b2b0-8a0bd95eaf83",
   "metadata": {},
   "source": [
    "# Part 4: Load Testing and Measuring Latency of Each Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec71076-79eb-48fc-a329-625ea9985cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "!pip install locust\n",
    "\n",
    "if output.stderr:\n",
    "    print(\"An error occurred:\", output.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ab561-4c23-42d1-9f04-0c049f13b416",
   "metadata": {},
   "source": [
    "## Launch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea4143-32a2-4a1c-98d5-b93b066b48cb",
   "metadata": {},
   "source": [
    "A test for each endpoint takes around 5 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb987c-92ad-4f3f-8d4d-7c234351388b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "for model in models:\n",
    "    try:\n",
    "        result = subprocess.run([\"./load-testing/run_locust.sh\", f\"{model}\"],\n",
    "                                capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Finished load testing for {model} endpoint\")\n",
    "        else:\n",
    "            print(f\"Error load testing {model} endpoint:\", result.stderr)\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b620e-e0fa-4c4e-b5ba-68f3980d2c79",
   "metadata": {},
   "source": [
    "# Part 5: Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a90c36-fc36-4dae-b63c-bf2b6967fb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latency_dict = {}\n",
    "\n",
    "# for each endpoint get latency from the load test results\n",
    "for model in models:\n",
    "    df = pd.read_csv(f\"./load-testing/results_{model}_stats.csv\")\n",
    "\n",
    "    min_latency = round(df.tail(1)['Min Response Time'].values[0] / 1000, 1)\n",
    "    avg_latency = round(df.tail(1)['Average Response Time'].values[0] / 1000, 1)\n",
    "    max_latency = round(df.tail(1)['Max Response Time'].values[0] / 1000, 1)\n",
    "\n",
    "    latency_dict.update({\n",
    "        model: [min_latency, avg_latency, max_latency]\n",
    "    })\n",
    "\n",
    "# generate a data frame of the results and plot a box plot\n",
    "results = pd.DataFrame(latency_dict)\n",
    "res_plot = results.plot(legend=True, figsize=(12, 7), kind='box',\n",
    "            title=\"Request Latency Across Model Types\",\n",
    "            xlabel=\"Model Type\",\n",
    "            ylabel=\"Latency in Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24aaf1",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_endpoints_latency_testing|endpoint_testing.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
