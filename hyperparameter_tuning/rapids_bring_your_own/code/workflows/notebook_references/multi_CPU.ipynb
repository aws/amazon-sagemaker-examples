{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#8735fb'> **Dask Multi-CPU Workflow - XGBoost @ Airline Delays** </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/rapidsai/cloud-ml-examples/main/aws/img/airline_dataset.png' width='1250px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **1. Mount S3 Dataset**\n",
    "\n",
    "> **2. Data Ingestion**\n",
    "\n",
    "> **3. ETL**\n",
    "-> handle missing -> split\n",
    "\n",
    "> **4. Train Classifier**\n",
    "-> XGBoost\n",
    "\n",
    "> **5. Inference**\n",
    "-> FIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dask.distributed import LocalCluster\n",
    "from dask.distributed import wait, Client\n",
    "import dask\n",
    "\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from cuml.dask.common.utils import persist_across_workers\n",
    "\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "try:\n",
    "    from cuml import ForestInference\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "    \n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Mount S3 Dataset** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://sagemaker-rapids-hpo-us-west-2.s3-us-west-2.amazonaws.com/2_year_2020.tar.gz\n",
    "!tar xvzf 2_year_2020.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Create Cluster** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=os.cpu_count())\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Ingest Parquet Data** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of our analysis will be domestic carrier on-time reporting data that has been kept for decades by the U.S. Bureau of Transportation.\n",
    "\n",
    "This rich source of data allows us to scale, so while in this notebook (ML_100.ipynb) we only use 1 GPU and 1 year of data, in the next notebook (ML200.ipynb) we'll use 10 years of data and multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Dataset**: [US.DoT - Reporting Carrier On-Time Performance, 1987-Present](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The public dataset contains logs/features about flights in the United States (17 airlines) including:\n",
    "\n",
    "* locations and distance  ( `Origin`, `Dest`, `Distance` )\n",
    "* airline / carrier ( `Reporting_Airline` )\n",
    "* scheduled departure and arrival times ( `CRSDepTime` and `CRSArrTime` )\n",
    "* actual departure and arrival times ( `DpTime` and `ArrTime` )\n",
    "* difference between scheduled & actual times ( `ArrDelay` and `DepDelay` )\n",
    "* binary encoded version of late, aka our target variable ( `ArrDelay15` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_feature_columns = ['Year', 'Quarter', 'Month', 'DayOfWeek', \n",
    "                           'Flight_Number_Reporting_Airline', 'DOT_ID_Reporting_Airline',\n",
    "                           'OriginCityMarketID', 'DestCityMarketID',\n",
    "                           'DepTime', 'DepDelay', 'DepDel15', 'ArrDel15',\n",
    "                           'AirTime', 'Distance']\n",
    "airline_label_column = 'ArrDel15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = \"2_year_2020/*.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = dask.dataframe.read_parquet(data_target,  \n",
    "                                   columns=airline_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson : data is a future/lazy dataframe\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson : data is also a compute graph\n",
    "data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Handle Missing** [ ETL ] </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson : note that now our compute graph has been extended\n",
    "data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson: by adding operations we increase the complexity of the graph\n",
    "data.sum().visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson: graphs can become really intricate but we'll let dask worry about that\n",
    "data.mean().visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Split** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = airline_label_column\n",
    "\n",
    "train, test = train_test_split(data, random_state=0, shuffle=True)\n",
    "\n",
    "# build X [ features ], y [ labels ] for the train and test subsets\n",
    "y_train = train[label_column]\n",
    "X_train = train.drop(label_column, axis=1)\n",
    "\n",
    "y_test = test[label_column]\n",
    "X_test = test.drop(label_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson: let's check in on our compute graph so far [ nothing has been evaluated yet ]\n",
    "X_train.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Persist** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force execution\n",
    "X_train, y_train, X_test, y_test = client.persist([X_train, y_train, X_test, y_test])\n",
    "wait([X_train, y_train, X_test, y_test]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask lesson: once we trigger computation via persist, the graph collapses to fully realized results\n",
    "X_train.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Train/Fit** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {            \n",
    "    'max_depth': 10,\n",
    "    'num_boost_round': 300,\n",
    "    'learning_rate': .25,\n",
    "    'gamma': 0,\n",
    "    'lambda': 1,\n",
    "    'random_state': 0,\n",
    "    'verbosity': 0,\n",
    "    'seed': 0,   \n",
    "    'objective': 'binary:logistic',\n",
    "    'tree_method': 'hist',\n",
    "    'nthreads': os.cpu_count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtrain = xgboost.dask.DaskDMatrix(client, X_train, y_train)\n",
    "xgboost_output = xgboost.dask.train(client, model_params, dtrain, \n",
    "                                    num_boost_round = model_params['num_boost_round'])\n",
    "trained_model = xgboost_output['booster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Predict & Score** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ensure that the inference target data (X_test, y_test) is computed [i.e., concrete values in local memory ]\n",
    "y_test_computed = y_test.compute()\n",
    "X_test_computed = X_test.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **XGBoost Native Predict & Score** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "dtest = xgboost.dask.DaskDMatrix(client, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = xgboost.dask.predict(client, trained_model, dtest).compute()\n",
    "predictions = (predictions > threshold ) * 1.0\n",
    "score = accuracy_score(y_test_computed.astype('float32'),\n",
    "                       predictions.astype('float32'))\n",
    "\n",
    "print(f'score = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'trained-model.xgb'\n",
    "trained_model.save_model(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **ForestInference Predict & Score** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = ForestInference.load(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "fil_predictions = reloaded_model.predict( X_test_computed)\n",
    "fil_predictions = (fil_predictions > threshold ) * 1.0\n",
    "score = accuracy_score(y_test_computed.astype('float32'),\n",
    "                       fil_predictions.astype('float32'))\n",
    "print(f'fil score = {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#8735fb'> **Additional References** </font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://distributed.dask.org/en/latest/diagnosing-performance.html\n",
    "https://distributed.dask.org/en/latest/manage-computation.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
