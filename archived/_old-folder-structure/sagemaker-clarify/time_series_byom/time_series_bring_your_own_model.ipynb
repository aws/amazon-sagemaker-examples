{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6b3a4e",
   "metadata": {},
   "source": [
    "# TimeSeries Bring Your Own Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f85a11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5967044",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 30 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683bcbd",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb226e",
   "metadata": {},
   "source": [
    "### Install Mercury\n",
    "\n",
    "If not already installed, the following cell will install the `mercury` package in order to display the `analysis_config.json` and explainability job output within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3ffd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: dj-rest-auth 3.0.0 does not provide the extra 'with-social'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: '/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages/PyYAML-6.0.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for boto3: [Errno 2] No such file or directory: '/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages/boto3-1.34.101.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for botocore: [Errno 2] No such file or directory: '/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages/botocore-1.34.101.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for s3transfer: [Errno 2] No such file or directory: '/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages/s3transfer-0.10.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: No metadata found in /local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: No metadata found in /local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: No metadata found in /local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: No metadata found in /local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.31.7 requires botocore==1.33.7, but you have botocore 1.29.165 which is incompatible.\n",
      "awscli 1.31.7 requires s3transfer<0.9.0,>=0.8.0, but you have s3transfer 0.6.2 which is incompatible.\n",
      "sagemaker 2.219.0 requires boto3<2.0,>=1.33.3, but you have boto3 1.26.83 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mercury -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cacaa47",
   "metadata": {},
   "source": [
    "### Install SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50ac60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sagemaker\n",
      "  Using cached sagemaker-2.219.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting boto3<2.0,>=1.33.3 (from sagemaker)\n",
      "  Using cached boto3-1.34.103-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting google-pasta (from sagemaker)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting numpy<2.0,>=1.9.0 (from sagemaker)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting protobuf<5.0,>=3.12 (from sagemaker)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker)\n",
      "  Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker)\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting packaging>=20.0 (from sagemaker)\n",
      "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas (from sagemaker)\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pathos (from sagemaker)\n",
      "  Using cached pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting schema (from sagemaker)\n",
      "  Using cached schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting PyYAML~=6.0 (from sagemaker)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema (from sagemaker)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting platformdirs (from sagemaker)\n",
      "  Using cached platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tblib<4,>=1.7.0 (from sagemaker)\n",
      "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting urllib3<3.0.0,>=1.26.8 (from sagemaker)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting requests (from sagemaker)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting docker (from sagemaker)\n",
      "  Using cached docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tqdm (from sagemaker)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting psutil (from sagemaker)\n",
      "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.103 (from boto3<2.0,>=1.33.3->sagemaker)\n",
      "  Using cached botocore-1.34.103-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.33.3->sagemaker)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.33.3->sagemaker)\n",
      "  Using cached s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker)\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->sagemaker)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->sagemaker)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->sagemaker)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting six (from google-pasta->sagemaker)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->sagemaker)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->sagemaker)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->sagemaker)\n",
      "  Using cached rpds_py-0.18.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->sagemaker)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->sagemaker)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->sagemaker)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->sagemaker)\n",
      "  Using cached ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.8 (from pathos->sagemaker)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->sagemaker)\n",
      "  Using cached pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->sagemaker)\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting urllib3<3.0.0,>=1.26.8 (from sagemaker)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Using cached sagemaker-2.219.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached boto3-1.34.103-py3-none-any.whl (139 kB)\n",
      "Using cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "Using cached platformdirs-4.2.1-py3-none-any.whl (17 kB)\n",
      "Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "Using cached schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached botocore-1.34.103-py3-none-any.whl (12.2 MB)\n",
      "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Using cached pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Using cached ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.18.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -otocore (/local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: schema, pytz, zipp, urllib3, tzdata, tqdm, tblib, smdebug-rulesconfig, six, rpds-py, PyYAML, psutil, protobuf, ppft, pox, platformdirs, packaging, numpy, jmespath, idna, dill, cloudpickle, charset-normalizer, certifi, attrs, requests, referencing, python-dateutil, multiprocess, importlib-metadata, google-pasta, pathos, pandas, jsonschema-specifications, docker, botocore, s3transfer, jsonschema, boto3, sagemaker\n",
      "  Attempting uninstall: schema\n",
      "    Found existing installation: schema 0.7.7\n",
      "    Uninstalling schema-0.7.7:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled schema-0.7.7\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.18.1\n",
      "    Uninstalling zipp-3.18.1:\n",
      "      Successfully uninstalled zipp-3.18.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.1\n",
      "    Uninstalling tzdata-2024.1:\n",
      "      Successfully uninstalled tzdata-2024.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: tblib\n",
      "    Found existing installation: tblib 3.0.0\n",
      "    Uninstalling tblib-3.0.0:\n",
      "      Successfully uninstalled tblib-3.0.0\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.1\n",
      "    Uninstalling smdebug-rulesconfig-1.0.1:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.18.1\n",
      "    Uninstalling rpds-py-0.18.1:\n",
      "      Successfully uninstalled rpds-py-0.18.1\n",
      "  Attempting uninstall: PyYAML\n",
      "\u001b[33m    WARNING: No metadata found in /local/home/zicanl/.virtualenvs/venv/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pyyaml 6.0\n",
      "    Can't uninstall 'pyyaml'. No files were found to uninstall.\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.8\n",
      "    Uninstalling psutil-5.9.8:\n",
      "      Successfully uninstalled psutil-5.9.8\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: ppft\n",
      "    Found existing installation: ppft 1.7.6.8\n",
      "    Uninstalling ppft-1.7.6.8:\n",
      "      Successfully uninstalled ppft-1.7.6.8\n",
      "  Attempting uninstall: pox\n",
      "    Found existing installation: pox 0.3.4\n",
      "    Uninstalling pox-0.3.4:\n",
      "      Successfully uninstalled pox-0.3.4\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.2.1\n",
      "    Uninstalling platformdirs-4.2.1:\n",
      "      Successfully uninstalled platformdirs-4.2.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.1\n",
      "    Uninstalling cloudpickle-2.2.1:\n",
      "      Successfully uninstalled cloudpickle-2.2.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.2.2\n",
      "    Uninstalling certifi-2024.2.2:\n",
      "      Successfully uninstalled certifi-2024.2.2\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.2.0\n",
      "    Uninstalling attrs-23.2.0:\n",
      "      Successfully uninstalled attrs-23.2.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.35.1\n",
      "    Uninstalling referencing-0.35.1:\n",
      "      Successfully uninstalled referencing-0.35.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.11.0\n",
      "    Uninstalling importlib-metadata-6.11.0:\n",
      "      Successfully uninstalled importlib-metadata-6.11.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: pathos\n",
      "    Found existing installation: pathos 0.3.2\n",
      "    Uninstalling pathos-0.3.2:\n",
      "      Successfully uninstalled pathos-0.3.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2023.12.1\n",
      "    Uninstalling jsonschema-specifications-2023.12.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2023.12.1\n",
      "  Attempting uninstall: docker\n",
      "    Found existing installation: docker 7.0.0\n",
      "    Uninstalling docker-7.0.0:\n",
      "      Successfully uninstalled docker-7.0.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.165\n",
      "    Uninstalling botocore-1.29.165:\n",
      "      Successfully uninstalled botocore-1.29.165\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.2\n",
      "    Uninstalling s3transfer-0.6.2:\n",
      "      Successfully uninstalled s3transfer-0.6.2\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.22.0\n",
      "    Uninstalling jsonschema-4.22.0:\n",
      "      Successfully uninstalled jsonschema-4.22.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.83\n",
      "    Uninstalling boto3-1.26.83:\n",
      "      Successfully uninstalled boto3-1.26.83\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.219.0\n",
      "    Uninstalling sagemaker-2.219.0:\n",
      "      Successfully uninstalled sagemaker-2.219.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.31.7 requires botocore==1.33.7, but you have botocore 1.34.103 which is incompatible.\n",
      "awscli 1.31.7 requires s3transfer<0.9.0,>=0.8.0, but you have s3transfer 0.10.1 which is incompatible.\n",
      "mercury 2.3.7 requires boto3==1.26.83, but you have boto3 1.34.103 which is incompatible.\n",
      "mercury 2.3.7 requires pyyaml==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "numba 0.58.0 requires numpy<1.26,>=1.21, but you have numpy 1.26.4 which is incompatible.\n",
      "sphinx 6.1.3 requires docutils<0.20,>=0.18, but you have docutils 0.16 which is incompatible.\n",
      "tox 4.4.6 requires colorama>=0.4.6, but you have colorama 0.4.4 which is incompatible.\n",
      "virtualenv 20.20.0 requires platformdirs<4,>=2.4, but you have platformdirs 4.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 attrs-23.2.0 boto3-1.34.103 botocore-1.34.103 certifi-2024.2.2 charset-normalizer-3.3.2 cloudpickle-2.2.1 dill-0.3.8 docker-7.0.0 google-pasta-0.2.0 idna-3.7 importlib-metadata-6.11.0 jmespath-1.0.1 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 multiprocess-0.70.16 numpy-1.26.4 packaging-24.0 pandas-2.2.2 pathos-0.3.2 platformdirs-4.2.1 pox-0.3.4 ppft-1.7.6.8 protobuf-4.25.3 psutil-5.9.8 python-dateutil-2.9.0.post0 pytz-2024.1 referencing-0.35.1 requests-2.31.0 rpds-py-0.18.1 s3transfer-0.10.1 sagemaker-2.219.0 schema-0.7.7 six-1.16.0 smdebug-rulesconfig-1.0.1 tblib-3.0.0 tqdm-4.66.4 tzdata-2024.1 urllib3-1.26.18 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7597402",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "The model used in this example notebook is the bring your own time series model which uses a model.pth and inference.py to handle the model invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc63eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/zicanl/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "import mercury\n",
    "import pprint\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = boto3.Session()\n",
    "s3_client = session.client(\"s3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker.Session().default_bucket()\n",
    "region = session.region_name\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"timeseries-byom-endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2f679",
   "metadata": {},
   "source": [
    "Compress the model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b1341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\r\n",
      "code/inference.py\r\n",
      "code/requirements.txt\r\n",
      "model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!cd model && tar -czvf ../model.tar.gz code/ model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b6f4f",
   "metadata": {},
   "source": [
    "Upload model to S3. The example model is the linear regression model from [darts](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.linear_regression_model.html#linear-regression-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21f88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_prefix = \"linear_ts\"\n",
    "model_file_path = \"model.tar.gz\"\n",
    "model_s3_suffix = f\"{bucket_prefix}/\" + model_file_path\n",
    "\n",
    "s3_client.upload_file(model_file_path, s3_bucket, model_s3_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4c0deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "sagemaker_model = PyTorchModel(\n",
    "    model_data=f\"s3://{s3_bucket}/{model_s3_suffix}\",  # specify S3 location of model.tar.gz\n",
    "    entry_point=\"inference.py\",  # specify entry point\n",
    "    framework_version=\"1.10.2\",\n",
    "    py_version=\"py38\",\n",
    "    role=sagemaker_role,\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = sagemaker_model.deploy(\n",
    "    initial_instance_count=1,  # number of instances\n",
    "    instance_type=\"ml.m5.4xlarge\",  # ec2 instance type\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b742fda",
   "metadata": {},
   "source": [
    "### Verify the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d8871e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': {'target': [1008.89, 1008.76, 1008.66],\n",
       "  'start': '2020-01-01 16:20:00',\n",
       "  'dynamic_feat': [[0.23, 0.21, 0.19, 0.16, 0.13, 0.08, 0.0, 0.0, 0.0],\n",
       "   [0.71, 0.75, 0.73, 0.37, 0.33, 0.34, 0.19, 0.03, 0.11]]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_instances = {\n",
    "    \"target\": [1008.89, 1008.76, 1008.66],\n",
    "    \"start\": \"2020-01-01 16:20:00\",\n",
    "    \"dynamic_feat\": [\n",
    "        [0.23, 0.21, 0.19, 0.16, 0.13, 0.08, 0.0, 0.0, 0.0],\n",
    "        [0.71, 0.75, 0.73, 0.37, 0.33, 0.34, 0.19, 0.03, 0.11],\n",
    "    ],\n",
    "}\n",
    "predictor_input = {\n",
    "    \"instances\": input_instances,\n",
    "}\n",
    "predictor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45105933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': {'mean': [1008.5656193655171, 1008.511339974418, 1008.4186285678663, 1008.3432658290359, 1008.2426915722609, 1008.1615810491433, 1008.1274301835906, 1008.0939011448609, 1008.0749872974072, 1008.0284006424769]}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session, serializer=JSONSerializer()\n",
    ")\n",
    "prediction = predictor.predict(predictor_input)\n",
    "print(json.loads(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734a7e8",
   "metadata": {},
   "source": [
    "## Time Series Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f08b5",
   "metadata": {},
   "source": [
    "### Import Components\n",
    "\n",
    "Import the components needed to make a TSX call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57dfe975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.clarify import (\n",
    "    AsymmetricShapleyValueConfig,  # config for the explainability algorithm\n",
    "    DataConfig,  # general-purpose DataConfig. time series-specific data config object is provided to this\n",
    "    ModelConfig,  # general-purpose ModelConfig. time series-specific data config object is provided to this\n",
    "    SageMakerClarifyProcessor,  # processor object, the job call is made via this\n",
    "    TimeSeriesDataConfig,  # time series-specific data config object\n",
    "    TimeSeriesModelConfig,  # time series-specific predictor config object\n",
    "    TimeSeriesJSONDatasetFormat,  # time series-specific dataset format\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579eaf7f",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "Here is an example of `content_template` and `record_template` for time series for more information: please check: https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-data-format-time-series-request-jsonlines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a87b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"time_series_byom_mock_data.json\"\n",
    "\n",
    "# Content template\n",
    "c_template = '{\"instances\": $record}'\n",
    "# Record template\n",
    "r_template = (\n",
    "    '{\"start\": $start_time, \"target\": $target_time_series, \"dynamic_feat\": $related_time_series}'\n",
    ")\n",
    "\n",
    "s3 = boto3.client(\"s3\")  # s3 client\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_uri = \"s3://\" + bucket_name + \"/byom/\"\n",
    "\n",
    "s3_client.upload_file(dataset_name, bucket_name, f\"byom/data/{dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da63ec1",
   "metadata": {},
   "source": [
    "### Asymmetric Shapley value\n",
    "\n",
    "Our time series forecasting explainability algorithm hinges on the application of the asymmetric Shapley values (ASV) from the theory of cooperative games. The ASV is a modification of the well-known Shapley value (e.g SHAP) that discards the symmetry axiom, but retains the efficiency exioms (i.e. attributions sum up to the predictions). Coalitions of features are generated based on a given probability distribution over feature *permutations* (rather than over *subsets* in the case of the Shapley value). In the case of time series, the distributions we use puts zero probability on permutations of features that do not respect the temporal dependencies, i.e. that have \"holes\". \n",
    "\n",
    "**References:**\n",
    "- Our main scientific reference is https://arxiv.org/abs/1910.06358. We scale the approach of the paper to include also static covariates, related time series and implement a stochastic estimator for efficiency.\n",
    "- A very useful math reference is [Probabilistic values by RJ Weber](http://www.library.fa.ru/files/Roth2.pdf#page=109);  specifically, section 8 about random-order values (these are the same mathematical construction of ASV). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f38cc4",
   "metadata": {},
   "source": [
    "### Create `AsymmetricShapleyValueConfig`\n",
    "\n",
    "An `AsymmetricShapleyValueConfig` is used to configure the algorithm Clarify uses for time series explainability. It takes the following arguments:\n",
    "\n",
    "- `direction`: direction of explanation to be used. Available explanation types are `\"chronological\"`, `\"anti_chronological\"`, `\"bidirectional\"`. The cronological direction highlights the effect of older timesteps over more recent one, while the anti-chronological direction higlights the effect of timesteps closer to the forecasting. Bidirectional is a combination of the previous two modes. \n",
    "- `granularity`: Granularity of explanation to be used. Available granularities are `\"timewise\"` and `\"fine_grained\"`. The first granularity is fast and computes the attribution of individual timesteps toward the forecast, not making distinctions of related time series. The fine-grained mode is slower, but computes an attribution for every timestep and every feature dynamic, distinguishing between related and target TS.\n",
    "- `num_samples`: Number of samples to be used in the Asymmetric Shapley Value forecasting algorithm. Only applicable when using `\"fine_grained\"`  explanations. This represents the number of permutations sampled for computing the ASV. \n",
    "- `baseline`: baseline configuration (dictionary). The baseline config is used to replace out-of-coalition values for the corresponding datasets (also known as background data). For temporal data (target time series, related time series), the baseline value types are `\"zero\"`, where all out-of-coalition values will be replaced with `0.0`, or `\"mean\"`, all out-of-coalition values will be replaced with the average of a time series. For static data(static covariates), a baseline value for each covariate should be provided for each possible item_id. An example config follows, where ``item1`` and ``item2`` are item ids::\n",
    "```\n",
    "{\n",
    " \"target_time_series\": \"zero\",\n",
    " \"related_time_series\": \"zero\",\n",
    " \"static_covariates\":\n",
    "  \"item1\": [1, 1],\n",
    "  \"item2\": [0, 1],\n",
    " }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b78d1",
   "metadata": {},
   "source": [
    "The notebook sets `explanation_direction` and `granularity` as variables for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4322e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = \"chronological\"\n",
    "granularity = \"fine_grained\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f9665",
   "metadata": {},
   "source": [
    "Only then does the notebook create the `AsymmetricShapleyValueConfig` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7ab365",
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_shap_val_config = AsymmetricShapleyValueConfig(\n",
    "    direction=direction,\n",
    "    granularity=granularity,\n",
    "    num_samples=2,  # (dimension of target_time_series + dimension of related_time_series) ^ 2\n",
    "    baseline={\n",
    "        \"target_time_series\": \"zero\",\n",
    "        \"related_time_series\": \"zero\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99216f4e",
   "metadata": {},
   "source": [
    "### Create `TimeSeriesDataConfig`\n",
    "\n",
    "A `TimeSeriesDataConfig` object is used to configure data I/O settings specific to TSX. It takes the following arguments:\n",
    "\n",
    "- `target_time_series`: A string or a zero-based integer index. Used to locate the target time series in the shared input dataset. If this parameter is a string, then all other parameters must also be strings or lists of strings. If this parameter is an int, then all others must be ints or lists of ints.\n",
    "- `item_id`: A string or a zero-based integer index. Used to locate item id in the shared input dataset.\n",
    "- `timestamp`: A string or a zero-based integer index. Used to locate timestamp in the shared input dataset.\n",
    "- `related_time_series`: Optional. An array of strings or array of zero-based integer indices. Used to locate all related time series in the shared input dataset (if present).\n",
    "- `static_covariates`: Optional. An array of strings or array of zero-based integer indices. Used to locate all item metadata fields in the shared input dataset (if present).\n",
    "- `dataset_format`: Optional. A string which describes the format of the data files provided for analysis. Should only be provided when dataset is in JSON format. Currently, we support `columns` and `timestamp_records` where example mock data files `ts_cols.json` and `time_series_mock_data.json` are provided respectively.\n",
    "\n",
    "This `TimeSeriesDataConfig` helps the container to parse the data needed for the analysis. Any additional data columns will be excluded if not providing corresponding Jmes_path to locate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba8c01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data_config = TimeSeriesDataConfig(\n",
    "    target_time_series=\"[].p_mbar\",\n",
    "    item_id=\"[].item_id\",\n",
    "    timestamp=\"[].timestamp\",\n",
    "    related_time_series=[\"[].rain_mm\", \"[].T_degC\"],\n",
    "    dataset_format=TimeSeriesJSONDatasetFormat.TIMESTAMP_RECORDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe3c76",
   "metadata": {},
   "source": [
    "### Create `TimeSeriesModelConfig`\n",
    "\n",
    "A `TimeSeriesModelConfig` is used to configure model settings specific to TSX. At the moment it has only one argument:\n",
    "\n",
    "- `forecast`: JMESPath expression to extract the forecast result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5293be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model_config = TimeSeriesModelConfig(\n",
    "    forecast=\"predictions.mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db05a3",
   "metadata": {},
   "source": [
    "### Create DataConfig\n",
    "\n",
    "General information about the dataset the TimeSeries model uses is provided to `DataConfig`. Here, we are providing where to retrieve the dataset, where to output the explainability job results, what format the dataset is in, and our TSX specific data settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beb1d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_uri = bucket_uri + \"data/\" + dataset_name\n",
    "output_path = bucket_uri + \"output_byom\"\n",
    "\n",
    "data_config = DataConfig(\n",
    "    s3_data_input_path=input_uri,\n",
    "    s3_output_path=output_path,\n",
    "    dataset_type=\"application/json\",\n",
    "    time_series_data_config=ts_data_config,\n",
    "    headers=[\"item_id\", \"timestamp\", \"p_mbar\", \"rain_mm\", \"T_degC\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79d536",
   "metadata": {},
   "source": [
    "### Create ModelConfig\n",
    "\n",
    "With `ModelConfig` is configured here, Clarify will deploy the specified model to a new endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989c3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    endpoint_name=endpoint_name,\n",
    "    content_type=\"application/json\",\n",
    "    accept_type=\"application/json\",\n",
    "    content_template=c_template,\n",
    "    record_template=r_template,\n",
    "    time_series_model_config=ts_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b842dd",
   "metadata": {},
   "source": [
    "It is also possible to specify an existing endpoint for Clarify to use with the following modifications to the `ModifyConfig` call:\n",
    "\n",
    "1. Omitting `model_name`, `instance_count`, `instance_type`, and `endpoint_name_prefix`.\n",
    "2. Provided `endpoint_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51a3d5",
   "metadata": {},
   "source": [
    "### Setup Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff26353",
   "metadata": {},
   "source": [
    "Create the `Processor` object that will setup the explainability job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbb9d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.c5.2xlarge\"\n",
    "\n",
    "clarify_processor = SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    job_name_prefix=\"clarify-tsx-byom-job-demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51509d50",
   "metadata": {},
   "source": [
    "### Run Explainability Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "217a97a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name clarify-tsx-byom-job-demo-2024-05-10-23-11-14-749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................WARNING:root:logging.conf not found when configuring logging, using default logging configuration.\n",
      "INFO:sagemaker-clarify-processing:Starting SageMaker Clarify Processing job\n",
      "INFO:analyzer.data_loading.data_loader_util:Analysis config path: /opt/ml/processing/input/config/analysis_config.json\n",
      "INFO:analyzer.data_loading.data_loader_util:Analysis result path: /opt/ml/processing/output\n",
      "INFO:analyzer.data_loading.data_loader_util:This host is algo-1.\n",
      "INFO:analyzer.data_loading.data_loader_util:This host is the leader.\n",
      "INFO:analyzer.data_loading.data_loader_util:Number of hosts in the cluster is 1.\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/10 23:16:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "#015[Stage 0:>                                                          (0 + 8) / 8]#015#015                                                                                #015#015[Stage 4:===================================================>       (7 + 1) / 8]#015#015                                                                                #015INFO:analyzer.predictor.managed_endpoint:Using endpoint timeseries-byom-endpoint-1715382341-39c2\n",
      "INFO:analyzer.predictor.managed_endpoint:Checking endpoint status:\n",
      "Legend:\n",
      "(OutOfService: x, Creating: -, Updating: -, InService: !, RollingBack: <, Deleting: o, Failed: *)\n",
      "INFO:analyzer.predictor.managed_endpoint:Endpoint is in service after 0 seconds\n",
      "INFO:analyzer.predictor.predictor:Stop using endpoint: timeseries-byom-endpoint-1715382341-39c2\n",
      "INFO:analyzer.predictor.managed_endpoint:Model endpoint delivered 14.42070 requests per second and a total of 1 requests over 0 seconds\n",
      "#015[Stage 12:>                                                         (0 + 1) / 1]#015#015                                                                                #015INFO:sagemaker-clarify-processing:Wrote 2 lines to /opt/ml/processing/output/asymmetric_shapley_value/fine_grained_chronological/out.jsonl\n",
      "INFO:sagemaker-clarify-processing:Collected analyses: \n",
      "{'version': '1.0', 'explanations': {'asymmetric_shapley_value': {'direction': 'chronological', 'granularity': 'fine_grained', 'explanation_results_path': 's3://sagemaker-us-west-2-678264136642/byom/output_byom/asymmetric_shapley_value/fine_grained_chronological/out.jsonl'}}}\n",
      "INFO:analyzer.utils.system_util:exit_message: Completed: SageMaker XAI Analyzer ran successfully\n",
      "INFO:py4j.clientserver:Closing down clientserver connection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clarify_processor.run_explainability(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=asym_shap_val_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c356dc",
   "metadata": {},
   "source": [
    "## Analysis Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac331d5b",
   "metadata": {},
   "source": [
    "### Retrieve Config From s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1687d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, \"byom/output_byom/analysis_config.json\", \"analysis_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f223ac",
   "metadata": {},
   "source": [
    "### Display Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407a475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_type': 'application/json',\n",
      " 'headers': ['item_id', 'timestamp', 'p_mbar', 'rain_mm', 'T_degC'],\n",
      " 'methods': {'asymmetric_shapley_value': {'baseline': {'related_time_series': 'zero', 'target_time_series': 'zero'}, 'direction': 'chronological', 'granularity': 'fine_grained', 'num_samples': 2},\n",
      "             'report': {'name': 'report', 'title': 'Analysis Report'}},\n",
      " 'predictor': {'accept_type': 'application/json',\n",
      "               'content_template': '{\"instances\": $record}',\n",
      "               'content_type': 'application/json',\n",
      "               'endpoint_name': 'timeseries-byom-endpoint-1715382341-39c2',\n",
      "               'record_template': '{\"start\": $start_time, \"target\": $target_time_series, \"dynamic_feat\": $related_time_series}',\n",
      "               'time_series_predictor_config': {'forecast': 'predictions.mean'}},\n",
      " 'time_series_data_config': {'dataset_format': 'timestamp_records',\n",
      "                             'item_id': '[].item_id',\n",
      "                             'related_time_series': ['[].rain_mm', '[].T_degC'],\n",
      "                             'target_time_series': '[].p_mbar',\n",
      "                             'timestamp': '[].timestamp'}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./analysis_config.json\", \"r\") as analyis_config_file:\n",
    "    analysis_config = json.load(analyis_config_file)\n",
    "    # mercury.JSON(analysis_config, level=3)\n",
    "    config_printer = pprint.PrettyPrinter(width=200, compact=False)\n",
    "    config_printer.pprint(analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1565873",
   "metadata": {},
   "source": [
    "## Explainability Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58809d08",
   "metadata": {},
   "source": [
    "### Retrieve Results From s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b51a4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_result_path = f\"byom/output_byom/asymmetric_shapley_value/{granularity}_{direction}/out.jsonl\"\n",
    "\n",
    "s3.download_file(bucket_name, full_result_path, \"results.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b1a00",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc177c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'explanations': [{'feature_name': 'p_mbar',\n",
      "                    'scores': [161.99614546052845,\n",
      "                               266.016195372142,\n",
      "                               171.9754724539663,\n",
      "                               -171.07476604383538,\n",
      "                               -313.6433436163125,\n",
      "                               -239.94510772430738,\n",
      "                               -85.12952959394124,\n",
      "                               -57.90547536857707,\n",
      "                               -207.1411908350123,\n",
      "                               -379.59127645091314],\n",
      "                    'timestamp': '2020-01-01 16:20:00'},\n",
      "                   {'feature_name': 'p_mbar',\n",
      "                    'scores': [-242.53171819948116,\n",
      "                               -178.51561960848613,\n",
      "                               20.504771980246744,\n",
      "                               283.65833398610687,\n",
      "                               116.71883538707854,\n",
      "                               -102.86798765521405,\n",
      "                               -146.4874269981686,\n",
      "                               8.14449669685348,\n",
      "                               194.95205623712206,\n",
      "                               223.11109391304643],\n",
      "                    'timestamp': '2020-01-01 16:30:00'},\n",
      "                   {'feature_name': 'p_mbar',\n",
      "                    'scores': [1010.1941985733024,\n",
      "                               795.0553673348827,\n",
      "                               642.8274810307071,\n",
      "                               682.7588591520664,\n",
      "                               942.0005592421893,\n",
      "                               1034.9501875444607,\n",
      "                               882.5456028112928,\n",
      "                               669.6075075328768,\n",
      "                               607.9790225048051,\n",
      "                               718.9410031751296],\n",
      "                    'timestamp': '2020-01-01 16:40:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:20:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:30:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:40:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:50:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:00:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:10:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:20:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:30:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:40:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [-0.08714719958848605,\n",
      "                               0.07035004670223088,\n",
      "                               0.057821527911926296,\n",
      "                               0.09521297487265201,\n",
      "                               0.2316662672997154,\n",
      "                               0.35016081212063455,\n",
      "                               0.5944301743015217,\n",
      "                               0.7031256598847904,\n",
      "                               0.7530252031138502,\n",
      "                               0.8773061468182846],\n",
      "                    'timestamp': '2020-01-01 16:20:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [0.25522850377080886,\n",
      "                               -0.023008325401406182,\n",
      "                               0.08935537901516,\n",
      "                               0.07432224632441375,\n",
      "                               -0.02099284843376381,\n",
      "                               0.03808045819243944,\n",
      "                               -0.12744614800971021,\n",
      "                               -0.044815576172311467,\n",
      "                               0.007387391643192132,\n",
      "                               -0.07124181014808073],\n",
      "                    'timestamp': '2020-01-01 16:30:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [-0.28369788212489766,\n",
      "                               0.0005212027526795282,\n",
      "                               -0.15772370675017555,\n",
      "                               -0.0051055361683438605,\n",
      "                               -0.03238935407966892,\n",
      "                               -0.21258560003138882,\n",
      "                               -0.15587474690755698,\n",
      "                               -0.2650242940226235,\n",
      "                               -0.12797639289135532,\n",
      "                               -0.022552261672558416],\n",
      "                    'timestamp': '2020-01-01 16:40:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [0.10025229473171748,\n",
      "                               -0.20299805713239039,\n",
      "                               0.0036295981972216396,\n",
      "                               -0.15789278404247398,\n",
      "                               -0.04784570674723909,\n",
      "                               -0.011186161681962403,\n",
      "                               -0.16199305896884653,\n",
      "                               -0.120134946101075,\n",
      "                               -0.23073982878611332,\n",
      "                               -0.13886565144207452],\n",
      "                    'timestamp': '2020-01-01 16:50:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [-0.05089328385463432,\n",
      "                               0.016269546530566004,\n",
      "                               -0.18819813736070046,\n",
      "                               -0.22929538149924156,\n",
      "                               -0.37628273091195297,\n",
      "                               -0.4463468139155111,\n",
      "                               -0.47193314366836603,\n",
      "                               -0.6292941653790649,\n",
      "                               -0.7734106313403117,\n",
      "                               -1.0187577778201558],\n",
      "                    'timestamp': '2020-01-01 17:00:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:10:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:20:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:30:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:40:00'}],\n",
      "  'item_id': 'sanjose',\n",
      "  'offset': [47.44921461578576,\n",
      "             100.62646867069782,\n",
      "             152.21050681227143,\n",
      "             191.15803860751862,\n",
      "             234.3224739726919,\n",
      "             284.7873864453612,\n",
      "             330.3183057947489,\n",
      "             367.38654787214057,\n",
      "             393.2080365560922,\n",
      "             423.5261096178664]},\n",
      " {'explanations': [{'feature_name': 'p_mbar',\n",
      "                    'scores': [162.6069955165382,\n",
      "                               267.01928101581973,\n",
      "                               172.62395224761923,\n",
      "                               -171.7198494816089,\n",
      "                               -314.82602023784847,\n",
      "                               -240.84988531686048,\n",
      "                               -85.45053339173353,\n",
      "                               -58.12382354452666,\n",
      "                               -207.92227243213168,\n",
      "                               -381.02262749832033],\n",
      "                    'timestamp': '2020-01-01 16:20:00'},\n",
      "                   {'feature_name': 'p_mbar',\n",
      "                    'scores': [-243.41488016208197,\n",
      "                               -179.16567151154757,\n",
      "                               20.57943864570069,\n",
      "                               284.6912555883247,\n",
      "                               117.14385870567043,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               -103.24257409916794,\n",
      "                               -147.02085052101535,\n",
      "                               8.174154300982877,\n",
      "                               195.66196025247172,\n",
      "                               223.92353705673543],\n",
      "                    'timestamp': '2020-01-01 16:30:00'},\n",
      "                   {'feature_name': 'p_mbar',\n",
      "                    'scores': [1041.9487078011975,\n",
      "                               820.0471887434583,\n",
      "                               663.0341612978904,\n",
      "                               704.2207449201605,\n",
      "                               971.6114652376746,\n",
      "                               1067.4828781174288,\n",
      "                               910.2875978931187,\n",
      "                               690.6559928706965,\n",
      "                               627.0902740916401,\n",
      "                               741.5402407790272],\n",
      "                    'timestamp': '2020-01-01 16:40:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:20:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:30:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:40:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 16:50:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:00:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:10:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:20:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:30:00'},\n",
      "                   {'feature_name': 'rain_mm', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:40:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [-0.024949399882189027,\n",
      "                               0.020140537563975158,\n",
      "                               0.016553743877977922,\n",
      "                               0.02725855329015303,\n",
      "                               0.06632381039628399,\n",
      "                               0.10024765185710294,\n",
      "                               0.17017960635243412,\n",
      "                               0.2012980719831603,\n",
      "                               0.21558382831082668,\n",
      "                               0.25116425977461176],\n",
      "                    'timestamp': '2020-01-01 16:20:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [0.07942795760502008,\n",
      "                               -0.007160267241090423,\n",
      "                               0.027807690564884524,\n",
      "                               0.023129329769005835,\n",
      "                               -0.006533044118384623,\n",
      "                               0.011850764997632268,\n",
      "                               -0.03966166431837337,\n",
      "                               -0.013946756070254196,\n",
      "                               0.0022989808018110125,\n",
      "                               -0.022170687805441958],\n",
      "                    'timestamp': '2020-01-01 16:30:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [-0.0873837358444689,\n",
      "                               0.0001605392446890619,\n",
      "                               -0.0485815636825464,\n",
      "                               -0.0015725913092410337,\n",
      "                               -0.00997646771224936,\n",
      "                               -0.06547995275241192,\n",
      "                               -0.048012052844796926,\n",
      "                               -0.08163195554277536,\n",
      "                               -0.039418888949739994,\n",
      "                               -0.006946477224005321],\n",
      "                    'timestamp': '2020-01-01 16:40:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [0.015455562104534692,\n",
      "                               -0.03129553380813377,\n",
      "                               0.0005595630553898445,\n",
      "                               -0.02434180420652865,\n",
      "                               -0.007376213123507114,\n",
      "                               -0.0017245332592210616,\n",
      "                               -0.024973929924499316,\n",
      "                               -0.018520804190529816,\n",
      "                               -0.03557239027111336,\n",
      "                               -0.02140845459734919],\n",
      "                    'timestamp': '2020-01-01 16:50:00'},\n",
      "                   {'feature_name': 'T_degC',\n",
      "                    'scores': [-0.006968789905386075,\n",
      "                               0.0022277802303278804,\n",
      "                               -0.0257698694310875,\n",
      "                               -0.03139729290239757,\n",
      "                               -0.051524191369708205,\n",
      "                               -0.061118028461464746,\n",
      "                               -0.06462155079282184,\n",
      "                               -0.08616891061205934,\n",
      "                               -0.10590270055695328,\n",
      "                               -0.1394979529795819],\n",
      "                    'timestamp': '2020-01-01 17:00:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:10:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:20:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:30:00'},\n",
      "                   {'feature_name': 'T_degC', 'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'timestamp': '2020-01-01 17:40:00'}],\n",
      "  'item_id': 'seattle',\n",
      "  'offset': [47.44921461578576,\n",
      "             100.62646867069782,\n",
      "             152.21050681227143,\n",
      "             191.15803860751862,\n",
      "             234.3224739726919,\n",
      "             284.7873864453612,\n",
      "             330.3183057947489,\n",
      "             367.38654787214057,\n",
      "             393.2080365560922,\n",
      "             423.5261096178664]}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results.jsonl\", \"r\") as results_file:\n",
    "    results_lines = results_file.readlines()\n",
    "    explainability_results = [json.loads(jsonline) for jsonline in results_lines]\n",
    "    # mercury.JSON(explainability_results, level=5)\n",
    "    results_printer = pprint.PrettyPrinter(width=200, depth=5, compact=False)\n",
    "    results_printer.pprint(explainability_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614fa80c",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Remove downloaded/installed files and deployed resources as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1319d577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ab60df21-91b8-4ccd-9c45-c8115eb4c454',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ab60df21-91b8-4ccd-9c45-c8115eb4c454',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 10 May 2024 23:17:38 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the model, endpoint_config and endpoint from sagemaker\n",
    "boto3.client(\"sagemaker\").delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "boto3.client(\"sagemaker\").delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437eccbf",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/sagemaker-clarify|time_series_byom|time_series_bring_your_own_model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
