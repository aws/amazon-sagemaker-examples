{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California Housing Regression Experiment\n",
    "\n",
    "This demo shows how you can use SageMaker Experiments Management Python SDK to organize, track, compare, and evaluate your machine learning (ML) model training experiments.\n",
    "\n",
    "You can track artifacts for experiments, including data sets, algorithms, hyper-parameters, and metrics. Experiments executed on SageMaker such as SageMaker Autopilot jobs and training jobs will be automatically tracked. You can also track artifacts for additional steps within an ML workflow that come before/after model training e.g. data pre-processing or post-training model evaluation.\n",
    "\n",
    "The APIs also let you search and browse your current and past experiments, compare experiments, and identify best performing models.\n",
    "\n",
    "Now we will demonstrate these capabilities through a `California Housing` regression example. The experiment will be organized as follows:\n",
    "\n",
    "1. Download and prepare the `California Housing` dataset.\n",
    "2. Train an Artificial Neural Network (ANN) Model. Tune the hyper parameter that configures the number of `epochs` and the `learning_rate` in the model. Track the parameter configurations and resulting model `validation loss` using SageMaker Experiments Python SDK.\n",
    "3. Finally, use the search and analytics capabilities of Python SDK to search, compare, evaluate and visualize the performance of all model versions generated from model tuning in Step 2.\n",
    "\n",
    "Make sure you selected `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"tf2-california-housing-experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download California Housing dataset and upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), \"data/train\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "test_dir = os.path.join(os.getcwd(), \"data/test\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "data_set = fetch_california_housing()\n",
    "\n",
    "X = pd.DataFrame(data_set.data, columns=data_set.feature_names)\n",
    "Y = pd.DataFrame(data_set.target)\n",
    "\n",
    "# We partition the dataset into 2/3 training and 1/3 test set.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "np.save(os.path.join(train_dir, \"x_train.npy\"), x_train)\n",
    "np.save(os.path.join(test_dir, \"x_test.npy\"), x_test)\n",
    "np.save(os.path.join(train_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(test_dir, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_inputs_train = sagemaker.Session().upload_data(\n",
    "    path=\"data/train\", bucket=bucket, key_prefix=prefix + \"/train\"\n",
    ")\n",
    "s3_inputs_test = sagemaker.Session().upload_data(\n",
    "    path=\"data/test\", bucket=bucket, key_prefix=prefix + \"/test\"\n",
    ")\n",
    "inputs = {\"train\": s3_inputs_train, \"test\": s3_inputs_test}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Set up the Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : [1] a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or [2] a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or [3] a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing_experiment = Experiment.create(\n",
    "    experiment_name=f\"tf2-california-housing-{int(time.time())}\",\n",
    "    description=\"Training on california housing dataset\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "print(california_housing_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment\n",
    "### Now create a Trial for each training run to track its inputs, parameters, and metrics.\n",
    "While training the ResNet-50 CNN model on SageMaker, you will experiment with several values for the number of hidden channel in the model. You will create a Trial to track each training job run. You will also create a `TrialComponent` from the tracker we created before, and add to the Trial. This will enrich the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_options = {\"learning_rate\": [0.1, 0.5, 0.9], \"epochs\": [100, 200]}\n",
    "\n",
    "hypnames, hypvalues = zip(*hyperparam_options.items())\n",
    "trial_hyperparameter_set = [dict(zip(hypnames, h)) for h in itertools.product(*hypvalues)]\n",
    "trial_hyperparameter_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run the following training jobs asynchronously, you may need to increase your resource limit. Otherwise, you can run them sequentially.\n",
    "\n",
    "<b>Note the execution of the following code takes around half an hour.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "run_number = 1\n",
    "for trial_hyp in trial_hyperparameter_set:\n",
    "    # Combine static hyperparameters and trial specific hyperparameters\n",
    "    hyperparams = trial_hyp\n",
    "\n",
    "    # Create unique job name with hyperparameter and time\n",
    "    time_append = int(time.time())\n",
    "    hyp_append = \"-\".join([str(elm).replace(\".\", \"-\") for elm in trial_hyp.values()])\n",
    "    training_job_name = f\"tf2-california-housing-training-{hyp_append}-{time_append}\"\n",
    "    trial_name = f\"trial-tf2-california-housing-training-{hyp_append}-{time_append}\"\n",
    "    trial_desc = f\"my-tensorflow2-california-housing-run-{run_number}\"\n",
    "\n",
    "    # Create a new Trial and associate Tracker to it\n",
    "    tf2_california_housing_trial = Trial.create(\n",
    "        trial_name=trial_name,\n",
    "        experiment_name=california_housing_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "        tags=[{\"Key\": \"trial-desc\", \"Value\": trial_desc}],\n",
    "    )\n",
    "\n",
    "    # Create an experiment config that associates training job to the Trial\n",
    "    experiment_config = {\n",
    "        \"ExperimentName\": california_housing_experiment.experiment_name,\n",
    "        \"TrialName\": tf2_california_housing_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": training_job_name,\n",
    "    }\n",
    "\n",
    "    metric_definitions = [\n",
    "        {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "    ]\n",
    "\n",
    "    # Create a TensorFlow Estimator with the Trial specific hyperparameters\n",
    "    tf2_california_housing_estimator = TensorFlow(\n",
    "        entry_point=\"california_housing_tf2.py\",\n",
    "        source_dir=\"code\",\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        framework_version=\"2.4.1\",\n",
    "        hyperparameters=hyperparams,\n",
    "        py_version=\"py37\",\n",
    "        metric_definitions=metric_definitions,\n",
    "        enable_sagemaker_metrics=True,\n",
    "        tags=[{\"Key\": \"trial-desc\", \"Value\": trial_desc}],\n",
    "    )\n",
    "\n",
    "    # Launch a training job\n",
    "    tf2_california_housing_estimator.fit(\n",
    "        inputs, job_name=training_job_name, experiment_config=experiment_config\n",
    "    )\n",
    "\n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)\n",
    "    run_number = run_number + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now you will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "experiment_name = california_housing_experiment.experiment_name\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, experiment_name=experiment_name\n",
    ")\n",
    "trial_comp_ds_jobs = trial_component_analytics.dataframe()\n",
    "trial_comp_ds_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the accuracy, epochs and optimizer.\n",
    "You will sort the results by accuracy descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_comp_ds_jobs = trial_comp_ds_jobs.sort_values(\"val_loss - Last\", ascending=False)\n",
    "trial_comp_ds_jobs[[\"TrialComponentName\", \"val_loss - Last\", \"epochs\", \"learning_rate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize experiment\n",
    "\n",
    "Now we visualize the epochs/learning_rate vs. loss in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trial_comp_ds_jobs[\"col_names\"] = (\n",
    "    trial_comp_ds_jobs[\"epochs\"].astype(\"Int64\").astype(\"str\")\n",
    "    + \"-0.\"\n",
    "    + ((trial_comp_ds_jobs[\"learning_rate\"]) * 10).astype(\"Int64\").astype(\"str\")\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches([15, 10])\n",
    "trial_comp_ds_jobs.plot.bar(\"col_names\", \"val_loss - Last\", ax=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Experiments, Trials, and Trial Components in Amazon SageMaker Studio\n",
    "\n",
    "You can compare experiments, trials, and trial components by selecting the entities and opening them in the trial components list. The trial components list is referred to as the Studio Leaderboard. In the Leaderboard you can do the following:\n",
    "- View detailed information about the entities\n",
    "- Compare entities\n",
    "- Stop a training job\n",
    "- Deploy a model\n",
    "\n",
    "<b>To compare experiments, trials, and trial components</b>\n",
    "- In the left sidebar of SageMaker Studio, choose the <b>SageMaker Experiment List icon</b>.\n",
    "- In the <b>Experiments</b> browser, choose either the experiment or trial list. \n",
    "- Choose the experiments or trials that you want to compare, right-click the selection, and then choose <b>Open in trial component list</b>. The Leaderboard opens and lists the associated Experiments entities as shown in the following screenshot.\n",
    "\n",
    "![studio_trial_component_list](./images/studio_trial_component_list.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Run the following cell to clean up the sample experiment. If you are working on your own experiment, please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(experiment):\n",
    "    for trial_summary in experiment.list_trials():\n",
    "        trial = Trial.load(sagemaker_boto_client=sm, trial_name=trial_summary.trial_name)\n",
    "        for trial_component_summary in trial.list_trial_components():\n",
    "            tc = TrialComponent.load(\n",
    "                sagemaker_boto_client=sm,\n",
    "                trial_component_name=trial_component_summary.trial_component_name,\n",
    "            )\n",
    "            trial.remove_trial_component(tc)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                tc.delete()\n",
    "            except:\n",
    "                # tc is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(0.5)\n",
    "        trial.delete()\n",
    "    experiment.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(california_housing_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
