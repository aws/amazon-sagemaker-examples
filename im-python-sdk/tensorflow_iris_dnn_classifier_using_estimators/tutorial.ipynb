{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating, training and serving Estimators in IM\n",
    "\n",
    "The **IM Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in IM. The IM Python SDK is easy to use, modular, extensible and compatible with TensorFlow and MXNet. This tutorial focuses on **TensorFlow** and shows how we can train and host a tensorflow DNNClassifier estimator in IM using the Python SDK.\n",
    "\n",
    "\n",
    "TensorFlow's high-level machine learning API (tf.estimator) makes it easy to\n",
    "configure, train, and evaluate a variety of machine learning models.\n",
    "\n",
    "\n",
    "In this\n",
    "tutorial, you'll use tf.estimator to construct a\n",
    "[neural network](https://en.wikipedia.org/wiki/Artificial_neural_network)\n",
    "classifier and train it on the\n",
    "[Iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) to\n",
    "predict flower species based on sepal/petal geometry. You'll write code to\n",
    "perform the following five steps:\n",
    "\n",
    "1.  Deploy a tensorflow container in IM\n",
    "2.  Load CSVs containing Iris training/test data from a S3 bucket into a TensorFlow `Dataset`\n",
    "3.  Construct a `tf.estimator.DNNClassifier` neural network classifier\n",
    "4.  Train the model using the training data\n",
    "5.  Host the model in an endpoint\n",
    "6.  Classify new samples invoking the endpoint\n",
    "\n",
    "This tutorial is a simplified version of TensorFlow's [get_started/estimator](https://www.tensorflow.org/get_started/estimator#fit_the_dnnclassifier_to_the_iris_training_data) tutorial **but using IM and the IM Python SDK** to simplify training and hosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does that work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A](demo1.jpg)\n",
    "![A](demo2.jpg)\n",
    "![A](demo3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris dataset\n",
    "\n",
    "The [Iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) contains\n",
    "150 rows of data, comprising 50 samples from each of three related Iris species:\n",
    "*Iris setosa*, *Iris virginica*, and *Iris versicolor*.\n",
    "\n",
    "![Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor](https://www.tensorflow.org/images/iris_three_species.jpg) **From left to right,\n",
    "[*Iris setosa*](https://commons.wikimedia.org/w/index.php?curid=170298) (by\n",
    "[Radomil](https://commons.wikimedia.org/wiki/User:Radomil), CC BY-SA 3.0),\n",
    "[*Iris versicolor*](https://commons.wikimedia.org/w/index.php?curid=248095) (by\n",
    "[Dlanglois](https://commons.wikimedia.org/wiki/User:Dlanglois), CC BY-SA 3.0),\n",
    "and [*Iris virginica*](https://www.flickr.com/photos/33397993@N05/3352169862)\n",
    "(by [Frank Mayfield](https://www.flickr.com/photos/33397993@N05), CC BY-SA\n",
    "2.0).**\n",
    "\n",
    "Each row contains the following data for each flower sample:\n",
    "[sepal](https://en.wikipedia.org/wiki/Sepal) length, sepal width,\n",
    "[petal](https://en.wikipedia.org/wiki/Petal) length, petal width, and flower\n",
    "species. Flower species are represented as integers, with 0 denoting *Iris\n",
    "setosa*, 1 denoting *Iris versicolor*, and 2 denoting *Iris virginica*.\n",
    "\n",
    "Sepal Length | Sepal Width | Petal Length | Petal Width | Species\n",
    ":----------- | :---------- | :----------- | :---------- | :-------\n",
    "5.1          | 3.5         | 1.4          | 0.2         | 0\n",
    "4.9          | 3.0         | 1.4          | 0.2         | 0\n",
    "4.7          | 3.2         | 1.3          | 0.2         | 0\n",
    "&hellip;     | &hellip;    | &hellip;     | &hellip;    | &hellip;\n",
    "7.0          | 3.2         | 4.7          | 1.4         | 1\n",
    "6.4          | 3.2         | 4.5          | 1.5         | 1\n",
    "6.9          | 3.1         | 4.9          | 1.5         | 1\n",
    "&hellip;     | &hellip;    | &hellip;     | &hellip;    | &hellip;\n",
    "6.5          | 3.0         | 5.2          | 2.0         | 2\n",
    "6.2          | 3.4         | 5.4          | 2.3         | 2\n",
    "5.9          | 3.0         | 5.1          | 1.8         | 2\n",
    "\n",
    "For this tutorial, the Iris data has been randomized and split into two separate\n",
    "CSVs:\n",
    "\n",
    "*   A training set of 120 samples\n",
    "    iris_training.csv\n",
    "*   A test set of 30 samples\n",
    "    iris_test.csv\n",
    "    \n",
    "These files are located under the data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start by setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import im\n",
    "\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-2'\n",
    "\n",
    "ims = im.Session()\n",
    "\n",
    "# Replace with a role that gives IM access to s3 and cloudwatch\n",
    "role='IMRole'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading to S3\n",
    "\n",
    "The IM Python SDK will deploy a container with the tensorflow model in IM. This container needs access to the training data. We will put the training data in a S3 bucket, and later, give its access to container:\n",
    "\n",
    "The IM Session will create a default S3 bucket to store the data in, with the name:\n",
    "\n",
    "im-{Your AWS account ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = ims.upload_data(path='data', key_prefix='data/iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.estimator framework makes it easy to construct and train machine learning models via its high-level Estimator API. Estimator offers classes you can instantiate to quickly configure common model types such as regressors and classifiers:\n",
    "\n",
    "\n",
    "*   **```tf.estimator.LinearClassifier```**:\n",
    "    Constructs a linear classification model.\n",
    "*   **```tf.estimator.LinearRegressor```**:\n",
    "    Constructs a linear regression model.\n",
    "*   **```tf.estimator.DNNClassifier```**:\n",
    "    Construct a neural network classification model.\n",
    "*   **```tf.estimator.DNNRegressor```**:\n",
    "    Construct a neural network regression model.\n",
    "*   **```tf.estimator.DNNLinearCombinedClassifier```**:\n",
    "    Construct a neural network and linear combined classification model.\n",
    "*   **```tf.estimator.DNNRegressor```**:\n",
    "    Construct a neural network and linear combined regression model.\n",
    "    \n",
    "More information about estimators can be found [here](https://www.tensorflow.org/extend/estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Neural Network Source Code \n",
    "Here is the full code for the neural network classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "import os\r\n",
      "import tensorflow as tf\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "\r\n",
      "\r\n",
      "def estimator_fn(run_config, params):\r\n",
      "    feature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\r\n",
      "    return tf.estimator.DNNClassifier(feature_columns=feature_columns,\r\n",
      "                                      hidden_units=[10, 20, 10],\r\n",
      "                                      n_classes=3,\r\n",
      "                                      config=run_config)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    feature_spec = {INPUT_TENSOR_NAME: tf.FixedLenFeature(dtype=tf.float32, shape=[4])}\r\n",
      "    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    \"\"\"Returns input function that would feed the model during training\"\"\"\r\n",
      "    return _generate_input_fn(training_dir, 'iris_training.csv')\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\r\n",
      "    return _generate_input_fn(training_dir, 'iris_test.csv')\r\n",
      "\r\n",
      "\r\n",
      "def _generate_input_fn(training_dir, training_filename):\r\n",
      "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n",
      "        filename=os.path.join(training_dir, training_filename),\r\n",
      "        target_dtype=np.int,\r\n",
      "        features_dtype=np.float32)\r\n",
      "\r\n",
      "    return tf.estimator.inputs.numpy_input_fn(\r\n",
      "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\r\n",
      "        y=np.array(training_set.target),\r\n",
      "        num_epochs=None,\r\n",
      "        shuffle=True)()\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"iris-dnn-classifier.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With few lines of code, using IM and TensorFlow, you can create a deep neural network model, ready for training and hosting. Let's give a deeper look at the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a tf.estimator in IM\n",
    "Using an estimator in IM is very easy, you can create one with few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimator(model_path):\n",
    "    feature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\n",
    "    return tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                      hidden_units=[10, 20, 10],\n",
    "                                      n_classes=3,\n",
    "                                      model_dir=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above first defines the model's feature columns, which specify the data\n",
    "type for the features in the data set. All the feature data is continuous, so\n",
    "`tf.feature_column.numeric_column` is the appropriate function to use to\n",
    "construct the feature columns. There are four features in the data set (sepal\n",
    "width, sepal height, petal width, and petal height), so accordingly `shape`\n",
    "must be set to `[4]` to hold all the data.\n",
    "\n",
    "Then, the code creates a `DNNClassifier` model using the following arguments:\n",
    "\n",
    "*   `feature_columns=feature_columns`. The set of feature columns defined above.\n",
    "*   `hidden_units=[10, 20, 10]`. Three\n",
    "    [hidden layers](http://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw),\n",
    "    containing 10, 20, and 10 neurons, respectively.\n",
    "*   `n_classes=3`. Three target classes, representing the three Iris species.\n",
    "*   `model_dir=model_path`. The directory in which TensorFlow will save\n",
    "    checkpoint data during model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the training input pipeline\n",
    "\n",
    "The `tf.estimator` API uses input functions, which create the TensorFlow\n",
    "operations that generate data for the model.\n",
    "We can use `tf.estimator.inputs.numpy_input_fn` to produce the input pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(training_dir):\n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=os.path.join(training_dir, 'iris_training.csv'),\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32)\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\n",
    "        y=np.array(training_set.target),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the serving input pipeline:\n",
    "\n",
    "After traininng your model, IM will host it in a tensorflow serving. You need to describe a serving input function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    feature_spec = {INPUT_TENSOR_NAME: tf.FixedLenFeature(dtype=tf.float32, shape=[4])}\n",
    "    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to submit the script for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running TensorFlow training on IM\n",
    "\n",
    "We can use the SDK to run our local training script on IM infrastructure.\n",
    "\n",
    "1. Pass the path to the iris-dnn-classifier.py file, which contains the functions for defining your estimator, to the im.TensorFlow init method.\n",
    "2. Pass the S3 location that we uploaded our data to previously to the fit() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from im.tensorflow import TensorFlow\n",
    "\n",
    "iris_estimator = TensorFlow(entry_point='iris-dnn-classifier.py',\n",
    "                               role=role,\n",
    "                               hyperparameters={'training_steps': 100},\n",
    "                               train_instance_count=1,\n",
    "                               train_instance_type='ml.c4.xlarge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iris_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_predictor = iris_estimator.deploy(initial_instance_count=1,\n",
    "                                       instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "Invoking prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_predictor.predict([6.4, 3.2, 4.5, 1.5]) #expected label to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_predictor.predict([5.8, 3.1, 5.0, 1.7]) #expected label to be 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPythonSDK TensorFlow naming conventions\n",
    "\n",
    "To be able to deploy and train the TensorFlow estimator, the deployed script must implement the following functions:\n",
    "\n",
    "```python\n",
    "   def estimator(model_path): \n",
    "    \"\"\"Constructs an `Estimator` instance.\n",
    "\n",
    "    Args:\n",
    "      * `model_path`: Location in the container where the model will be saved.\n",
    "    Returns:\n",
    "      An instance of Estimator\n",
    "    \"\"\"\n",
    "```    \n",
    "See [programmers_guide/estimators](https://www.tensorflow.org/programmers_guide/estimators) on how to create estimators.\n",
    "\n",
    "```python    \n",
    "    def train_input_fn(training_dir):\n",
    "    \"\"\"Creates an input function that will be invoked for training\n",
    "\n",
    "        * Args:\n",
    "\n",
    "          * `training_dir`: Path where the training data is located in the container\n",
    "\n",
    "        * Returns:\n",
    "            `input_fn`: Input function returning a tuple of:\n",
    "              features - `Tensor` or dictionary of string feature name to `Tensor`.\n",
    "              labels - `Tensor` or dictionary of `Tensor` with labels.\n",
    "     \"\"\"\n",
    "     \n",
    "     def serving_input_receiver_fn():\n",
    "    \"\"\"Creates an input function that will be invoked for serving\n",
    "\n",
    "        * Returns:\n",
    "            `ServingInputReceiver`: A return type for a serving_input_receiver_fn.\n",
    "\n",
    "            The expected return values are:\n",
    "            features: A dict of string to `Tensor` or `SparseTensor`, specifying the\n",
    "              features to be passed to the model.\n",
    "            receiver_tensors: a `Tensor`, or a dict of string to `Tensor`, specifying\n",
    "              input nodes where this receiver expects to be fed.  Typically, this is a\n",
    "              single placeholder expecting serialized `tf.Example` protos.\n",
    "     \"\"\"\n",
    "```\n",
    "See [get_started/input_fn](https://www.tensorflow.org/get_started/input_fn) on how to input functions for estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p27]",
   "language": "python",
   "name": "conda-env-tensorflow_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
