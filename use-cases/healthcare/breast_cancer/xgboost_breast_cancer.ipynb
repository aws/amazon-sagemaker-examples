{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to Predict breast cancer with features derived from breast mass images**_\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "2. [Notebook Setup](#notebook_setup)\n",
    "3. [Data Wrangling](#data_wrangling)\n",
    "4. [Dataset Preparation](#dataset_preparation)\n",
    "5. [Training](#Training)\n",
    "6. [Hosting](#Hosting)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "7. [(Optional) Clean-up](#cleanup)\n",
    "8. [Extensions](#Extensions)\n",
    "  1. [Hyperparameter Optimization](#hyperparameter_optimization)\n",
    "  1. [(Optional) Final Clean-up](#cleanupfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id = \"Background\"></a>\n",
    "\n",
    "## Background\n",
    "\n",
    "This notebook illustrates the use of SageMaker's built-in XGBoost algorithm for binary classification.\n",
    "XGBoost uses decision trees to build a predictive model.\n",
    "\n",
    "Also demonstrated is Hyperparameter optimization as well as using the best model from HPO to instantiate a new endpoint.\n",
    "\n",
    "### Why XGBoost and not Logistic Regression?\n",
    "\n",
    "Whilst logistic regression is often used for classification exercises, it has some drawbacks. For example, additional feature engineering is required to deal with non-linear features.\n",
    "\n",
    "XGBoost (an implementation of Gradient Boosted Trees) offers several benefits including naturally accounting for non-linear relationships between features and the target variable, as well as accommodating complex interactions between features.\n",
    "Decision Tree algorithms such as XGBoost also have the added benefit of being able to deal with missing values in both the training dataset and unseen samples that are being used for inference.\n",
    "\n",
    "Amazon SageMaker provides an XGBoost container that we can use to train in a managed, distributed setting, and then host as a real-time prediction endpoint\n",
    "\n",
    "The model lifecycle can be viewed below:\n",
    "\n",
    "![`SageMaker` Model Lifecycle](images/ml-concepts.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id = \"notebook_setup\"></a>\n",
    "\n",
    "## Notebook Setup\n",
    "\n",
    "_This notebook was created and tested on a ml.t2.medium notebook instance._\n",
    "\n",
    "Amazon SageMaker Studio is the first fully integrated development environment (IDE) for ML. It provides a single, web-based visual interface where you can perform all ML development steps required to build, train, tune, debug, deploy, and monitor models. It gives data scientists all the tools you need to take ML models from experimentation to production without leaving the IDE.\n",
    "\n",
    "Studio notebooks are one-click Jupyter notebooks that can be spun up quickly. The underlying compute resources are fully elastic, so you can easily dial up or down the available resources, and the changes take place automatically in the background without interrupting your work. You can also share notebooks with others in a few clicks. They get the exact same notebook, saved in the same place.\n",
    "\n",
    "To learn more about SageMaker Studio architecture, refer to this [blog](https://aws.amazon.com/blogs/machine-learning/dive-deep-into-amazon-sagemaker-studio-notebook-architecture/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "You will be using the AWS SDK for Python ([Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) to create, configure, and manage AWS services, such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3). The SDK provides an object-oriented API as well as low-level access to AWS services. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The SageMaker role arn used to give learning and hosting access to your data. The snippet below will use the same role used by your SageMaker notebook instance. If you wish to use a different role, specify the full ARN of a role with the `SageMakerFullAccess` policy attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# bucket = ''  # <uncomment and change to your own bucket if you don't want to use the default bucket>\n",
    "bucket = session.default_bucket()\n",
    "print(\"The role is {} and default bucket is {}\".format(role, sagemaker.Session().default_bucket()))\n",
    "prefix = \"sagemaker/xgboost-bc\"  # modify to your own path if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for examining our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # For munging tabular data\n",
    "import matplotlib.pyplot as plt  # For charts and visualizations\n",
    "from IPython.display import Image  # For displaying images in the notebook\n",
    "from IPython.display import display  # For displaying outputs in the notebook\n",
    "import time  # For labeling SageMaker models, endpoints, etc.\n",
    "from time import gmtime, strftime  # For labeling SageMaker models, endpoints, etc.\n",
    "import sys  # For writing outputs to notebook\n",
    "import math  # For ceiling function\n",
    "import json  # For parsing hosting outputs\n",
    "import os  # For manipulating filepath names\n",
    "import zipfile  # Amazon SageMaker's Python SDK provides many helper functions\n",
    "from datetime import datetime  # Date time library to log time\n",
    "import re  # Regular expression\n",
    "import seaborn as sn  # Seaborn is used to pli=ot confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data_wrangling'></a>\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "For this illustration, we have taken an example for breast cancer prediction using UCI'S breast cancer diagnostic data set available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on `Kaggle` at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictive model of whether a breast mass image indicates benign or malignant tumor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out all the details of this dataset here: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "Let's download the data and save it in the local folder so that we can take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rfv wdbc.data train.csv validation.csv\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we downloaded does not have column headings; however this information is available at the source\n",
    "\n",
    "More information about this dataset can be found here: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "Sample images used in this dataset can be seen here: ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images\n",
    "\n",
    "- `id`: ID number\n",
    "- `diagnosis`: The diagnosis of breast tissues (M = malignant, B = benign)\n",
    "- `radius_mean`: mean of distances from center to points on the perimeter\n",
    "- `texture_mean`: standard deviation of gray-scale values\n",
    "- `perimeter_mean`: mean size of the core tumor\n",
    "- `area_mean`: area of the core tumor\n",
    "- `smoothness_mean`: mean of local variation in radius lengths\n",
    "- `compactness_mean`: mean of perimeter^2 / area - 1.0\n",
    "- `concavity_mean`: mean of severity of concave portions of the contour\n",
    "- `concave points_mean`: mean for number of concave portions of the contour\n",
    "- `symmetry_mean`: mean for symmetry between left and right breasts\n",
    "- `fractal_dimension_mean`: mean for \"coastline approximation\" - 1\n",
    "- `radius_se`: standard error for the mean of distances from center to points on the perimeter\n",
    "- `texture_se`: standard error for standard deviation of gray-scale values\n",
    "- `perimeter_se`: standard error for size of the core tumor\n",
    "- `area_se`: standard error for area of the core tumor\n",
    "- `smoothness_se`: standard error for local variation in radius lengths\n",
    "- `compactness_se`: standard error for perimeter^2 / area - 1.0\n",
    "- `concavity_se`: standard error for severity of concave portions of the contour\n",
    "- `concave points_se`: standard error for number of concave portions of the contour\n",
    "- `symmetry_se`: standard error for symmetry between left and right breasts\n",
    "- `fractal_dimension_se`: standard error for \"coastline approximation\" - 1\n",
    "- `radius_worst`: \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n",
    "- `texture_worst`: \"worst\" or largest mean value for standard deviation of gray-scale values\n",
    "- `perimeter_worst`: \"worst\" or largest mean value for size of the core tumor\n",
    "- `area_worst`: \"worst\" or largest mean value for area of the core tumor\n",
    "- `smoothness_worst`: \"worst\" or largest mean value for local variation in radius lengths\n",
    "- `compactness_worst`: \"worst\" or largest mean value for perimeter^2 / area - 1.0\n",
    "- `concavity_worst`: \"worst\" or largest mean value for severity of concave portions of the contour\n",
    "- `concave points_worst`: \"worst\" or largest mean value for number of concave portions of the contour\n",
    "- `symmetry_worst`: \"worst\" or largest mean value for standard error for symmetry between left and right breasts\n",
    "- `fractal_dimension_worst`: \"worst\" or largest mean value for \"coastline approximation\" - 1\n",
    "\n",
    "\n",
    "If we load this CSV data into a pandas dataframe, we can easily take a closer look\n",
    "\n",
    "Note that this dataset doesn't have a header line, so we will add the column names to the pandas dataframe ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = [\n",
    "    \"id\",\n",
    "    \"diagnosis\",\n",
    "    \"radius_mean\",\n",
    "    \"texture_mean\",\n",
    "    \"perimeter_mean\",\n",
    "    \"area_mean\",\n",
    "    \"smoothness_mean\",\n",
    "    \"compactness_mean\",\n",
    "    \"concavity_mean\",\n",
    "    \"concave points_mean\",\n",
    "    \"symmetry_mean\",\n",
    "    \"fractal_dimension_mean\",\n",
    "    \"radius_se\",\n",
    "    \"texture_se\",\n",
    "    \"perimeter_se\",\n",
    "    \"area_se\",\n",
    "    \"smoothness_se\",\n",
    "    \"compactness_se\",\n",
    "    \"concavity_se\",\n",
    "    \"concave points_se\",\n",
    "    \"symmetry_se\",\n",
    "    \"fractal_dimension_se\",\n",
    "    \"radius_worst\",\n",
    "    \"texture_worst\",\n",
    "    \"perimeter_worst\",\n",
    "    \"area_worst\",\n",
    "    \"smoothness_worst\",\n",
    "    \"compactness_worst\",\n",
    "    \"concavity_worst\",\n",
    "    \"concave points_worst\",\n",
    "    \"symmetry_worst\",\n",
    "    \"fractal_dimension_worst\",\n",
    "]\n",
    "breastcancer = pd.read_csv(\"./wdbc.data\", header=None, names=col_names)\n",
    "\n",
    "breastcancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset is quite small, with only 569 records, where each record uses 32 attributes to describe the profile of a breast mass.\n",
    "Features are computed from a digitized image of a [Fine Needle Aspirate (FNA)](https://www.cancer.org/cancer/breast-cancer/screening-tests-and-early-detection/breast-biopsy/fine-needle-aspiration-biopsy-of-the-breast.html) of a breast mass. They describe characteristics of the cell nuclei present in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagnosis column is our target column. Let us take a look at the diagnosis distribution in both absolute and normalized forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.crosstab(index=breastcancer[\"diagnosis\"], columns=\"% observations\"))\n",
    "display(pd.crosstab(index=breastcancer[\"diagnosis\"], columns=\"% observations\", normalize=\"columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 63% of our samples are benign and 37% are malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Distribution\n",
    "\n",
    "Let's have a look at the distribution of the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "hist = breastcancer.hist(bins=30, sharey=False, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these histograms we can see that:\n",
    "- Most of the numeric features are following a Gaussian distribution\n",
    "- `id` should not be included as a feature as it is irrelevant for predicting a diagnosis (Note: if we were going to keep `id`, it should be converted to non-numeric) \n",
    "\n",
    "\n",
    "We will drop the `id` column from the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer = breastcancer.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note for future reference:\n",
    "There may be scenarios where you have a numeric field like `id` that did add some non-numeric value.\n",
    "A good example would be if the first N characters of patient ID indicated the country or state where the patient was located, and you wanted to see if this location had any bearing on the diagnosis.\n",
    "In such a case you would convert the field to a string and extract the pertinent information.\n",
    "\n",
    "`breastcancer['id'] = breastcancer['id'].astype(object)`\n",
    "\n",
    "You would then treat that field as a categorical field.\n",
    "These categorical fields would later be converted to indicator variables using the pandas 'get_dummies' method\n",
    "\n",
    "\n",
    "To take a look at the relationship between any categorical fields and the final diagnosis, you would use the following cross-tabulation report: \n",
    "\n",
    "```python\n",
    "for column in breastcancer.select_dtypes(include=['object']).columns:``\n",
    "    if column != 'diagnosis':\n",
    "        display(pd.crosstab(index=breastcancer[column], columns=breastcancer['diagnosis'], normalize='columns'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct relationship between features and diagnosis\n",
    "\n",
    "Now we will look at the direct relationship between numeric (non-object) values and diagnosis. We do this by plotting a histogram for every numeric value.\n",
    "We divide our samples into `bins`. The X-axis represents the bins and the Y-axis represents how many samples fall into each bin.\n",
    "By forcing the benign and malignant graphs to share the same X and Y scale it is easier to visualize which bins are more populated between the two diagnoses.\n",
    "\n",
    "Feel free to adjust the number of bins being plotted by the histogram and view the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in breastcancer.select_dtypes(exclude=[\"object\"]).columns:\n",
    "    print(column)\n",
    "    hist = breastcancer[[column, \"diagnosis\"]].hist(\n",
    "        by=\"diagnosis\", sharey=True, sharex=True, bins=30\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we infer from these relationships?\n",
    "\n",
    "We see that malignant diagnosis appear to have higher values (extend further to the right on the X axis) for the following features:\n",
    "- radius_mean\n",
    "- perimeter_mean\n",
    "- area_mean\n",
    "- compactness_mean\n",
    "- concavity_mean\n",
    "- concave points_mean\n",
    "- `radius_se`\n",
    "- `area_se`\n",
    "- radius_worst\n",
    "- texture_worst\n",
    "- perimeter_worst\n",
    "- area_worst\n",
    "- compactness_worst\n",
    "- concavity_worst\n",
    "- concave points_worst\n",
    "\n",
    "We see similar distributions for features such as `radius_mean`, `perimeter_mean` and `area_mean` for both malignant and benign diagnosis. This makes sense as each of these features are related to the size of the tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at correlations using a scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the matrix\n",
    "display(breastcancer.corr())\n",
    "\n",
    "# Plot the matrix\n",
    "axes = pd.plotting.scatter_matrix(breastcancer, figsize=(30, 30))\n",
    "for ax in axes.flatten():\n",
    "    ax.xaxis.label.set_rotation(90)\n",
    "    ax.yaxis.label.set_rotation(0)\n",
    "    ax.yaxis.label.set_ha(\"right\")\n",
    "plt.tight_layout()\n",
    "plt.gcf().subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scatter matrix, such strongly correlated features are indicated by a diagonal line running from bottom left to top right. In the correlation matrix, such relationships are indicated by a correlation value close to 1.\n",
    "\n",
    "In many cases it can be a good idea to remove one element of a highly correlated feature pair. \n",
    "\n",
    "`radius_mean` has high correlation (>98%) with both `perimeter_mean` and `area_mean`\n",
    "`radius_worst` has high correlation (>98%) with both `perimeter_worst` and `area_worst`\n",
    "\n",
    "To simplify our model, we will drop `perimeter_mean`, `area_mean`, `perimeter_worst` and `area_worst`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer = breastcancer.drop(\n",
    "    [\"perimeter_mean\", \"area_mean\", \"perimeter_worst\", \"area_worst\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='dataset_preparation'></a>\n",
    "\n",
    "## Dataset Preparation For XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a clean dataset (and have potentially removed some unnecessary columns), we can prepare the dataset for XGBoost. \n",
    "\n",
    "Amazon SageMaker XGBoost can train on data in either a CSV or LibSVM format.  For this example, we'll stick with CSV.  It should:\n",
    "- Contain only numeric values\n",
    "- Have the predictor variable in the first column\n",
    "- Not have a header row\n",
    "\n",
    "We will also\n",
    "- Shuffle the dataset\n",
    "- Split the dataset into training, validation and testing sets\n",
    "\n",
    "### Step 1: Convert our label (the field we are trying to predict) to numeric - where 0 means B (benign) and 1 means M (malignant)\n",
    "\n",
    "Ref: [Pandas Categorical](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Categorical.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer.diagnosis = pd.Categorical(breastcancer.diagnosis).codes\n",
    "breastcancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert any categorical features into numeric features using the \"get_dummies\" function which will automatically convert categorical variable into dummy/indicator variables.\n",
    "\n",
    "This dataset does not contain any categorical features (essentially string labels), so we can skip this step.\n",
    "If your dataset does contain numeric features, you would convert these features to numeric indicator values using the following command:\n",
    "\n",
    "`model_data = pd.get_dummies(breastcancer)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Shuffle and split the dataset\n",
    "\n",
    "And now let's split the data into training, validation, and test sets.  This will help prevent us from overfitting the model, and allow us to test the model's accuracy on data it hasn't already seen.\n",
    "We will use the train_test_split function provided within sklearn to simplify this process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio we will use is:\n",
    "- Training dataset - 70%\n",
    "- Validation dataset - 20%\n",
    "- Test dataset - 10%\n",
    "\n",
    "What is random_state?\n",
    "Whenever randomization is part of a Scikit-learn algorithm, a random_state parameter may be provided to control the random number generator used. Note that the mere presence of random_state doesnâ€™t mean that randomization is always used, as it may be dependent on another parameter, e.g. shuffle, being set.\n",
    "\n",
    "The passed value will have an effect on the reproducibility of the results returned by the function (fit, split, or any other function like k_means). To learn more about random_state refer [documentation](https://scikit-learn.org/stable/glossary.html#term-random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    breastcancer, shuffle=True, test_size=0.10, random_state=42\n",
    ")\n",
    "train_data, validation_data = train_test_split(\n",
    "    train_data, shuffle=True, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data sample size:\", len(train_data))\n",
    "print(\"Validation data sample size:\", len(validation_data))\n",
    "print(\"Test data sample size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the training dataset and validation dataset to CSV and upload to S3 for consumption by the containers running the XGBoost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train.csv\", header=False, index=False)\n",
    "validation_data.to_csv(\"validation.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train/train.csv\")\n",
    ").upload_file(\"train.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation/validation.csv\")\n",
    ").upload_file(\"validation.csv\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "url = \"https://s3.console.aws.amazon.com/s3/buckets/{}?region={}&prefix={}/&showversions=false\".format(\n",
    "    bucket, session.boto_region_name, prefix\n",
    ")\n",
    "display(\n",
    "    HTML(\n",
    "        'Click <a target=\"_blank\" href=\"{}\">here</a> to view training and validation sets in S3'.format(\n",
    "            url\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us review the stages:\n",
    "\n",
    "![`SageMaker` Model Lifecycle](images/ml-concepts.png)\n",
    "\n",
    "\n",
    "---\n",
    "## Training\n",
    "\n",
    "To learn more about SageMaker Training see this [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html).\n",
    "\n",
    "First we will need to specify the locations of the [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, version=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create TrainingInput references to point to our training and validation data files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/train\".format(bucket, prefix), content_type=\"csv\"\n",
    ")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/validation/\".format(bucket, prefix), content_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our estimator\n",
    "We will name our estimator `xgb` (because it is using the XGBoost container provided by SageMaker)\n",
    "We will run our training job on a single m5.xlarge instance\n",
    "To reduce costs, we will utilize spot instances (however if a spot instance is not available within 15 minutes, training will stop)\n",
    "\n",
    "For instance types refer the [documentation](https://aws.amazon.com/sagemaker/pricing/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    use_spot_instances=True,\n",
    "    max_wait=900,\n",
    "    max_run=600,\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set our hyperparameters\n",
    "Now, we can specify a few parameters like what type of training instances we'd like to use and how many, as well as our XGBoost hyperparameters.  \n",
    "A few key hyperparameters are:\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between numerous shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "More detail on XGBoost's hyperparameters can be found on the GitHub [page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(\n",
    "    max_depth=7,\n",
    "    eta=0.1,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The total time of this step is about 4 minutes, the trainig job takes about 50 seconds using an ml5.xlarge instance\n",
    "xgb.fit({\"train\": s3_input_train, \"validation\": s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hosting\n",
    "\n",
    "Now that we've trained the `xgboost` algorithm on our data, let's deploy a model that's hosted behind a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# The total time of this step is about 6 minutes\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model by calling the `predict` method.  But first, we'll need to set up serializers and deserializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "xgb_predictor.deserializer = sagemaker.deserializers.StringDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Extract the features for each sample \n",
    "1. Retrieve the prediction for each sample by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from a python list to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array\n",
    "dtest = test_data.to_numpy()\n",
    "\n",
    "# As expected, the numpy array has 57 rows (57 samples in the test dataset), and 27 columns (26 features + 1 label)\n",
    "print(dtest.shape)\n",
    "\n",
    "# Create a list to hold all of our predictions\n",
    "predictions = []\n",
    "\n",
    "# Loop through the matrix of our test data samples, pulling out the features for each sample and running inference\n",
    "# Note: dtest[i:i+1, 1:] is an vector of all the features for the sample i (without the first entry which is the label)\n",
    "for i in range(dtest.shape[0]):\n",
    "    sample_features = dtest[i : i + 1, 1:]\n",
    "    prediction = xgb_predictor.predict(sample_features)\n",
    "    predictions.append(float(prediction))\n",
    "\n",
    "# Convert our list of predictions to a numpy array\n",
    "predictions = np.asarray(predictions)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of this machine learning model on the test dataset, we will use a simple confusion matrix to compare actual to predicted values.\n",
    "\n",
    "This [article](https://www.frontiersin.org/articles/10.3389/fpubh.2017.00307/full) outlines sensitivity, specificity and predictive values in medical research.\n",
    "\n",
    "\n",
    "In this case, we're predicting whether the tumor was malignant (`1`) or benign (`0`).\n",
    "\n",
    "- We get the actual values from the first column (column 0) of the dataset: `test_data.iloc[:, 0]`\n",
    "- We get the predicted values from our array of predictions: `predictions`. We will simply round the predictions to the nearest integer (so a prediction < 0.5 will be 0 - benign and a prediction; 0.5 will be 1 - malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(\n",
    "    index=test_data.iloc[:, 0],\n",
    "    columns=np.round(predictions, 0),  # change 0 to 1 to see distribution\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"predictions\"],\n",
    "    #     margins = True, # Enable to see All count\n",
    ")\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 57 samples in the test dataset, 39 were for benign tumors and indeed we've correctly predicted 39 of them.\n",
    "1 of the benign samples were incorrectly predicted as malignant\n",
    "\n",
    "16 of the samples were malignant, and we correctly predicted 16 of them.\n",
    "1 of the malignant samples was incorrectly predicted as benign\n",
    "\n",
    "An important point here is that because of the `np.round()` function above we are using a simple threshold (or cutoff) of 0.5.  Our predictions from `xgboost` come out as continuous values between 0 and 1, and we force them into the binary classes that we began with.  \n",
    "\n",
    "However, because we would rather err on the side of a false positive than a false negative, we will adjust this cutoff. \n",
    "\n",
    "To get a rough intuition here, let's look at the continuous values of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous valued predictions coming from our model are generally quite decisive so tend to skew toward 0 or 1; however there are a few values between 0.1 and 0.9 where the model is less confident.\n",
    "\n",
    "How you adjust the cutoff is completely dependent upon the problem space you are addressing and whether you want to have more likelihood of false positives or false negatives.\n",
    "\n",
    "In the case of predicting malignant tumors we would rather err on the side of false positives than false negatives, so we will be extremely conservative and report any prediction greater than 0.1 as malignant \n",
    "\n",
    "Where you define this cutoff is going be based on your problem domain and whether you would prefer to err on the side of false negatives or false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(\n",
    "    index=test_data.iloc[:, 0],\n",
    "    columns=np.where(predictions > 0.1, 1, 0),\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"predictions\"],\n",
    ")\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our confusion matrix is very interesting. We now have fewer correct predictions overall; however, for our problem domain this is a better result.\n",
    "\n",
    "Of the 40 benign tumors, our model has correctly predicted 36 of them. The remaining 4 would be predicted as malignant. These are our false positives\n",
    "Of the 17 malignant tumors, our model has correctly predicted 16 of them. We have 1 false negatives within this test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='cleanup'></a>\n",
    "\n",
    "## (Optional) Clean-up\n",
    "\n",
    "If you're finished with this predictor, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up model endpoints\n",
    "xgb_predictor.delete_model()\n",
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id ='hyperparameter_optimization'></a>\n",
    "\n",
    "\n",
    "# Extensions\n",
    "\n",
    "## Hyperparameter Optimization (HPO)\n",
    "\n",
    "Machine learning is great at finding parameters which define patterns in our data, however there are many hyperparameters which govern how our machine learning algorithm will go about finding those parameters.\n",
    "\n",
    "SageMaker's Hyperparameter optimization can assist in finding the best set of hyperparameters. To learn more about how HPO work, refer to this [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html)\n",
    "\n",
    "> Note that our current results are excellent, so hyperparameter optimization is unlikely to improve these; however, we will run through the process of hyperparameter optimization as it could be very relevant to your own dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure HPO job\n",
    "First we set the hyperparameters that we do not want SageMaker Hyperparameter optimization to experiment with. These are the static hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_hyperparameters = {\"objective\": \"binary:logistic\", \"num_round\": \"100\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an estimator that we will use for training and set the static hyperparameters for the training job\n",
    "\n",
    "Again we will utilize spot instances to reduce costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, version=\"latest\")\n",
    "\n",
    "xgb_hpo = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    use_spot_instances=True,\n",
    "    max_wait=900,\n",
    "    max_run=600,\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "xgb_hpo.set_hyperparameters(**static_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tell SageMaker which hyperparameters we want it to experiment with the goal of finding the hyperparameter combination that yields the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0.1, 0.5),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"subsample\": ContinuousParameter(0.5, 1),\n",
    "    \"max_depth\": IntegerParameter(5, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    xgb_hpo,\n",
    "    objective_metric_name=\"validation:auc\",\n",
    "    objective_type=\"Maximize\",\n",
    "    hyperparameter_ranges=tuned_hyperparameter_ranges,\n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime(\"-%Y%m%d%H%M\", time.gmtime())\n",
    "\n",
    "%time\n",
    "tuner.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    job_name=\"HPObreastCancer\" + timestamp,\n",
    "    include_cls_metadata=False,\n",
    ")\n",
    "\n",
    "### Check job name and status of HPO job\n",
    "sage_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "hpo_job_name = tuner.latest_tuning_job.job_name\n",
    "print(hpo_job_name)\n",
    "\n",
    "sage_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=hpo_job_name)[\n",
    "    \"HyperParameterTuningJobStatus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze tuning job results - after tuning job is completed\n",
    "Please refer to `HPO_Analyze_TuningJob_Results.ipynb` to see example code to analyze the tuning job results.\n",
    "\n",
    "However, if the job status is `Completed` and you really don't care about analyzing the results of all the different hyperparameter combinations, the code below will return you the best job name and the best combination of hyperparameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=hpo_job_name\n",
    ")\n",
    "best_job = tuning_job_result.get(\"BestTrainingJob\", None)\n",
    "\n",
    "best_job_name = best_job.get(\"TrainingJobName\", None)\n",
    "tuned_hyperparams = best_job.get(\"TunedHyperParameters\", None)\n",
    "print(\"Best job had name:\", best_job_name)\n",
    "print(\"Best hyperparameter combination:\", tuned_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a hosted endpoint from the best job results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the S3 path to the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = sage_client.describe_training_job(TrainingJobName=best_job_name)\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SageMaker model from the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\"Image\": container, \"ModelDataUrl\": model_data}\n",
    "\n",
    "model_name = best_job_name + \"-model\"\n",
    "\n",
    "create_model_response = sage_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a configuration for a SageMaker hosted endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = \"HPO-XGBoostEndpointConfig-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sage_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SageMaker hosted endpoint using the configuration created above.\n",
    "We will poll every 60 seconds until the endpoint is `InService`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"HPO-XGBoostEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sage_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sage_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sage_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a predictor (this is an object to make it simpler to make requests to an endpoint). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor_hpo = sagemaker.predictor.Predictor(\n",
    "    endpoint_name,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.StringDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with our previous endpoint, we'll use a simple function to:\n",
    "  - Loop over our test dataset\n",
    "  - Extract the features for each sample\n",
    "  - Retrieve the prediction for each sample by invoking the XGBoost endpoint\n",
    "  - Collect predictions and convert from a python list to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold all of our predictions using the HPO model\n",
    "predictions_hpo = []\n",
    "\n",
    "# Loop through the matrix of our test data samples, pulling out the features for each sample and running inference\n",
    "# Note: dtest[i:i+1, 1:] is an vector of all the features for the sample i (without the first entry which is the label)\n",
    "for i in range(dtest.shape[0]):\n",
    "    sample_features = dtest[i : i + 1, 1:]\n",
    "    prediction = xgb_predictor_hpo.predict(sample_features)\n",
    "    predictions_hpo.append(float(prediction))\n",
    "\n",
    "# Convert our list of predictions to a numpy array\n",
    "predictions_hpo = np.asarray(predictions_hpo)\n",
    "display(predictions_hpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our new model go at making predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(\n",
    "    index=test_data.iloc[:, 0],\n",
    "    columns=np.round(predictions_hpo, 0),\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"predictions\"],\n",
    ")\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting the same results as we had in our initial model.\n",
    "This is not unexpected, as our initial model had excellent results\n",
    "\n",
    "What about if we shift the cutoff point for a positive result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(\n",
    "    index=test_data.iloc[:, 0],\n",
    "    columns=np.where(predictions_hpo > 0.1, 1, 0),\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"predictions\"],\n",
    ")\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no better than our result before Hyperparameter Optimization.\n",
    "At this point we probably can't improve our model any further by optimizing the hyperparameters, so we know we need to look at the data. \n",
    "Perhaps we need to use domain knowledge to include extra relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='cleanupfinal'></a>\n",
    "### (Optional) Final Clean-up\n",
    "\n",
    "If you're finished with this notebook, please run the cell below.  This will remove the hosted endpoint you created after the hyperparameter optimization stage; and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up model endpoints\n",
    "xgb_predictor_hpo.delete_model()\n",
    "xgb_predictor_hpo.delete_endpoint(delete_endpoint_config=True)\n",
    "\n",
    "# Clean up files\n",
    "!rm -rfv wdbc.data train.csv validation.csv"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (SageMaker JumpStart Data Science 1.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:163294280517:image/sagemaker-jumpstart-data-science-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
