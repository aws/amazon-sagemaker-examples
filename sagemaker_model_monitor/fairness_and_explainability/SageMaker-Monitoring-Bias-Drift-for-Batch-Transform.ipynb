{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify Model Bias Monitor for Batch Transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 60 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [General Setup](#General-Setup)\n",
    "    * [Imports](#Imports)\n",
    "    * [Handful of configuration](#Handful-of-configuration)\n",
    "    * [Data files](#Data-files)\n",
    "    * [SageMaker model](#SageMaker-model)\n",
    "* [Batch Transform Job](#Batch-Transform-Job)\n",
    "    * [Captured data](#Captured-data)\n",
    "    * [Transform output](#Transform-output)\n",
    "* [Ground Truth Data](#Ground-Truth-Data)\n",
    "* [Model Bias Monitor](#Model-Bias-Monitor)\n",
    "    * [Baselining job](#Baselining-job)\n",
    "        * [Configurations](#Configurations)\n",
    "        * [Kick off baselining job](#Kick-off-baselining-job)\n",
    "    * [Monitoring Schedule](#Monitoring-Schedule)\n",
    "        * [Wait for the first execution](#Wait-for-the-first-execution)\n",
    "        * [Wait for the execution to finish](#Wait-for-the-execution-to-finish)\n",
    "        * [Merged data](#Merged-data)\n",
    "        * [Inspect execution results](#Inspect-execution-results)\n",
    "* [Cleanup](#Cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "[Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) continuously monitors the quality of Amazon SageMaker machine learning models in production. It enables developers to set alerts for when there are deviations in the model quality. Early and pro-active detection of these deviations enables corrective actions, such as retraining models, auditing upstream systems, or fixing data quality issues without having to monitor models manually or build additional tooling. \n",
    "\n",
    "[Amazon SageMaker Clarify Model Bias Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html) is a model monitor that helps data scientists and ML engineers monitor predictions for bias on a regular basis. Bias can be introduced or exacerbated in deployed ML models when the training data differs from the data that the model sees during deployment (that is, the live data). These kinds of changes in the live data distribution might be temporary (for example, due to some short-lived, real-world events) or permanent. In either case, it might be important to detect these changes. For example, the outputs of a model for predicting home prices can become biased if the mortgage rates used to train the model differ from current, real-world mortgage rates. With bias drift detection capabilities in model monitor, when SageMaker detects bias beyond a certain threshold, it automatically generates metrics that you can view in SageMaker Studio and through Amazon CloudWatch alerts. \n",
    "\n",
    "This notebook demonstrates the process for setting up a model monitor for continuous monitoring of bias drift of the data and model used by a regularly running [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) job. The model input and output are in CSV format.\n",
    "\n",
    "In general, you can use the model bias monitor for batch transform in this way,\n",
    "\n",
    "1. Schedule a model bias monitor to monitor a data capture S3 location and a ground truth S3 location\n",
    "1. Regularly run transform jobs with data capture enabled, the jobs save captured data to the data capture S3 URI\n",
    "1. Regularly label the captured data, and then upload the ground truth labels to the ground truth S3 URI\n",
    "\n",
    "The monitor executes processing jobs regularly to merge the captured data and ground truth data, do bias analysis for the merged data, and then generate analysis reports and publish metrics to CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook uses the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk). The following cell upgrades the SDK and its dependencies. Then you may need to restart the kernel and rerun the notebook to pick up the up-to-date APIs, if the notebook is executed in the SageMaker Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker\n",
    "!pip install -U boto3\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following cell imports the APIs to be used by the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handful of configuration\n",
    "\n",
    "To begin, ensure that these prerequisites have been completed.\n",
    "\n",
    "* Specify an AWS Region to host the model.\n",
    "* Specify an IAM role to execute jobs.\n",
    "* Define the S3 URIs that stores the model file, input data and output data. For demonstration purposes, this notebook uses the same bucket for them. In reality, they could be separated with different security policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS region: us-west-2\n",
      "RoleArn: arn:aws:iam::000000000000:role/service-role/AmazonSageMaker-ExecutionRole-20200714T163791\n",
      "Demo Bucket: sagemaker-us-west-2-000000000000\n",
      "Demo Prefix: sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2\n",
      "Demo S3 key: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2\n",
      "The transform job will save the results to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/transform-output\n",
      "The transform job will save the captured data to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/data-capture\n",
      "You should upload the ground truth data to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/ground-truth\n",
      "The baselining job will save the analysis results to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/baselining-output\n",
      "The monitor will save the analysis results to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f\"AWS region: {region}\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"RoleArn: {role}\")\n",
    "\n",
    "# A different bucket can be used, but make sure the role for this notebook has\n",
    "# the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Demo Bucket: {bucket}\")\n",
    "prefix = sagemaker.utils.unique_name_from_base(\"sagemaker/DEMO-ClarifyModelMonitor\")\n",
    "print(f\"Demo Prefix: {prefix}\")\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "print(f\"Demo S3 key: {s3_key}\")\n",
    "\n",
    "data_capture_s3_uri = f\"{s3_key}/data-capture\"\n",
    "ground_truth_s3_uri = f\"{s3_key}/ground-truth\"\n",
    "transform_output_s3_uri = f\"{s3_key}/transform-output\"\n",
    "baselining_output_s3_uri = f\"{s3_key}/baselining-output\"\n",
    "monitor_output_s3_uri = f\"{s3_key}/monitor-output\"\n",
    "\n",
    "print(f\"The transform job will save the results to: {transform_output_s3_uri}\")\n",
    "print(f\"The transform job will save the captured data to: {data_capture_s3_uri}\")\n",
    "print(f\"You should upload the ground truth data to: {ground_truth_s3_uri}\")\n",
    "print(f\"The baselining job will save the analysis results to: {baselining_output_s3_uri}\")\n",
    "print(f\"The monitor will save the analysis results to: {monitor_output_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data files\n",
    "\n",
    "This example includes two dataset files, both in CSV format.\n",
    "\n",
    "* The train dataset has header row, and it has a target column followed by the feature columns.\n",
    "* The test dataset is not headers, and it only has feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "isConfigCell": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_path = \"test_data/validation-dataset-with-header.csv\"\n",
    "test_dataset_path = \"test_data/test-dataset-input-cols.csv\"\n",
    "dataset_type = \"text/csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>...</th>\n",
       "      <th>State_WI</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "      <th>Area Code_408</th>\n",
       "      <th>Area Code_415</th>\n",
       "      <th>Area Code_510</th>\n",
       "      <th>Int'l Plan_no</th>\n",
       "      <th>Int'l Plan_yes</th>\n",
       "      <th>VMail Plan_no</th>\n",
       "      <th>VMail Plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>141.3</td>\n",
       "      <td>94</td>\n",
       "      <td>168.0</td>\n",
       "      <td>108</td>\n",
       "      <td>113.5</td>\n",
       "      <td>84</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>247.4</td>\n",
       "      <td>107</td>\n",
       "      <td>175.9</td>\n",
       "      <td>76</td>\n",
       "      <td>287.4</td>\n",
       "      <td>90</td>\n",
       "      <td>11.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>32</td>\n",
       "      <td>165.9</td>\n",
       "      <td>126</td>\n",
       "      <td>216.5</td>\n",
       "      <td>93</td>\n",
       "      <td>173.1</td>\n",
       "      <td>86</td>\n",
       "      <td>14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>240.9</td>\n",
       "      <td>108</td>\n",
       "      <td>167.4</td>\n",
       "      <td>91</td>\n",
       "      <td>322.2</td>\n",
       "      <td>109</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "      <td>78.5</td>\n",
       "      <td>109</td>\n",
       "      <td>210.5</td>\n",
       "      <td>101</td>\n",
       "      <td>179.7</td>\n",
       "      <td>102</td>\n",
       "      <td>11.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Account Length  VMail Message  Day Mins  Day Calls  Eve Mins  \\\n",
       "0      0              47             28     141.3         94     168.0   \n",
       "1      0              30              0     247.4        107     175.9   \n",
       "2      0             106             32     165.9        126     216.5   \n",
       "3      0             131              0     240.9        108     167.4   \n",
       "4      0              83             37      78.5        109     210.5   \n",
       "\n",
       "   Eve Calls  Night Mins  Night Calls  Intl Mins  ...  State_WI  State_WV  \\\n",
       "0        108       113.5           84        7.8  ...         0         0   \n",
       "1         76       287.4           90       11.3  ...         0         0   \n",
       "2         93       173.1           86       14.1  ...         0         0   \n",
       "3         91       322.2          109       14.7  ...         0         0   \n",
       "4        101       179.7          102       11.8  ...         0         1   \n",
       "\n",
       "   State_WY  Area Code_408  Area Code_415  Area Code_510  Int'l Plan_no  \\\n",
       "0         0              1              0              0              1   \n",
       "1         0              0              1              0              1   \n",
       "2         0              1              0              0              1   \n",
       "3         0              1              0              0              1   \n",
       "4         0              0              1              0              1   \n",
       "\n",
       "   Int'l Plan_yes  VMail Plan_no  VMail Plan_yes  \n",
       "0               0              0               1  \n",
       "1               0              1               0  \n",
       "2               0              0               1  \n",
       "3               0              1               0  \n",
       "4               0              0               1  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_dataset_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read headers\n",
    "all_headers = list(df.columns)\n",
    "label_header = all_headers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the execution role for this notebook has the necessary permissions to proceed, put a simple test object into the S3 bucket specified above. If this command fails, update the role to have `s3:PutObject` permission on the bucket and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We are all set to proceed with uploading to S3.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.s3.S3Uploader.upload_string_as_file_body(\n",
    "    body=\"hello\",\n",
    "    desired_s3_uri=f\"{s3_key}/upload-test-file.txt\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(\"Success! We are all set to proceed with uploading to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then upload the data files to S3 so that they can be used by SageMaker jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is uploaded to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/validation-dataset-with-header.csv\n",
      "Test data is uploaded to: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/test-dataset-input-cols.csv\n"
     ]
    }
   ],
   "source": [
    "train_data_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=train_dataset_path,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Train data is uploaded to: {train_data_s3_uri}\")\n",
    "test_data_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=test_dataset_path,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Test data is uploaded to: {test_data_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker model\n",
    "\n",
    "This example includes a pre-built [SageMaker XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) model file trained by [XGBoost Churn Prediction Notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn.ipynb). The following cell uploads the file to S3 and then creates a SageMaker model using it. The model support CSV data format, the input are customer attributes, and the output is the probability of customer churn (a float number between zero and one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file has been uploaded to s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/xgb-churn-prediction-model.tar.gz\n",
      "SageMaker model name: DEMO-xgb-churn-pred-model-monitor-1674106772-58f3\n",
      "SageMaker XGBoost image: 246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3\n",
      "SageMaker model created\n"
     ]
    }
   ],
   "source": [
    "model_file = \"model/xgb-churn-prediction-model.tar.gz\"\n",
    "model_url = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=model_file,\n",
    "    desired_s3_uri=s3_key,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Model file has been uploaded to {model_url}\")\n",
    "\n",
    "model_name = sagemaker.utils.unique_name_from_base(\"DEMO-xgb-churn-pred-model-monitor\")\n",
    "print(f\"SageMaker model name: {model_name}\")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region, \"0.90-1\")\n",
    "print(f\"SageMaker XGBoost image: {image_uri}\")\n",
    "\n",
    "model = sagemaker.model.Model(image_uri=image_uri, model_data=model_url, role=role)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)\n",
    "print(\"SageMaker model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch Transform Job\n",
    "\n",
    "For continuous monitoring, batch transform jobs should be executed regularly with the latest data. But for demonstration purpose, the following cell only executes the job once before the monitor is scheduled, so that the first monitoring execution has captured data to process. \n",
    "\n",
    "See [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html#sagemaker.transformer.Transformer.transform) for the API reference. Highlights,\n",
    "\n",
    "* `destination_s3_uri` is used to specify the data capture S3 URI which is a key connection between the job and the monitor.\n",
    "* `join_source` must be set to \"Input\" for the transform output to include predictions (model output) as well as features (model input), because model bias monitor requires both.\n",
    "* `generate_inference_id` must be set to True for the transform output to include a unique ID for each record. Model bias monitor requires both predicted labels and ground truth labels, so it needs the ID to join the captured data and the ground truth data.\n",
    "\n",
    "**NOTE**: The following cell takes about 5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................!\n"
     ]
    }
   ],
   "source": [
    "transfomer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    accept=dataset_type,  # The transform output data format\n",
    "    assemble_with=\"Line\",  # CSV records are terminated by new lines\n",
    "    output_path=transform_output_s3_uri,\n",
    ")\n",
    "\n",
    "transfomer.transform(\n",
    "    data=test_data_s3_uri,\n",
    "    content_type=dataset_type,  # The transform input format\n",
    "    split_type=\"Line\",  # CSV records are terminated by new lines\n",
    "    join_source=\"Input\",  # Include model input (features) in transform output\n",
    "    batch_data_capture_config=sagemaker.inputs.BatchDataCaptureConfig(\n",
    "        destination_s3_uri=data_capture_s3_uri,\n",
    "        generate_inference_id=True,  # Inference ID is mandatory to join the captured data and the ground truth data\n",
    "    ),\n",
    "    wait=True,  # In real world you don't have to wait, but for demo purpose we wait for the output\n",
    "    logs=False,  # You can change it to True to view job logs inline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transform job completed, an \"output\" folders is created under `data_capture_s3_uri`, to includes the captured data files of transform output. Note that, batch transform data capture is unlike endpoint data capture, it does not capture the data for real as it will create tremendous amount of duplications. Instead, it generates [manifest](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html#sagemaker-Type-S3DataSource-S3Uri) files which refer to the transform output S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now list the captured data files stored in Amazon S3. There should be different files from different time periods organized based on the hour in which the batch transformation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{data_capture_s3_uri}/output/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found capture data files:\n",
      "s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/data-capture/output/2023/01/19/05/626c6b2e-23cd-4232-94c5-299e69009738.json\n"
     ]
    }
   ],
   "source": [
    "data_capture_output = f\"{data_capture_s3_uri}/output\"\n",
    "captured_data_files = sorted(\n",
    "    sagemaker.s3.S3Downloader.list(\n",
    "        s3_uri=data_capture_output,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")\n",
    "print(\"Found capture data files:\")\n",
    "print(\"\\n \".join(captured_data_files[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"prefix\": \"s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/transform-output/\"\n",
      "    },\n",
      "    \"test-dataset-input-cols.csv.out\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "data_capture_output_dict = json.loads(\n",
    "    sagemaker.s3.S3Downloader.read_file(\n",
    "        s3_uri=captured_data_files[-1],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")\n",
    "print(json.dumps(data_capture_output_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform output\n",
    "\n",
    "The captured data file refers to the transform output `.out` file. The cell below shows the first few records of the file.\n",
    "\n",
    "* The first columns are the feature columns (the model input), because the `join_source` parameter is set to \"Input\".\n",
    "* Then there is the prediction column (the model output).\n",
    "* The second last element is the inference ID, and the last is the inference time (the start time of the transform job). They are available because the `generate_inference_id` parameter is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>0.1</td>\n",
       "      <td>137.8</td>\n",
       "      <td>97</td>\n",
       "      <td>187.7</td>\n",
       "      <td>118</td>\n",
       "      <td>146.4</td>\n",
       "      <td>85</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>bd6c3be0-5902-4008-afc2-538b3be3bf2c</td>\n",
       "      <td>2023-01-19T05:40:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>25.0</td>\n",
       "      <td>113.2</td>\n",
       "      <td>96</td>\n",
       "      <td>269.9</td>\n",
       "      <td>107</td>\n",
       "      <td>229.1</td>\n",
       "      <td>87</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>58cd9844-a37e-4d80-9372-319ca6d876f6</td>\n",
       "      <td>2023-01-19T05:40:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>17.0</td>\n",
       "      <td>183.2</td>\n",
       "      <td>95</td>\n",
       "      <td>252.8</td>\n",
       "      <td>125</td>\n",
       "      <td>156.7</td>\n",
       "      <td>95</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>dba5c2f8-3203-4dd6-aa6e-69a4dd8279b7</td>\n",
       "      <td>2023-01-19T05:40:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>24.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>112</td>\n",
       "      <td>183.4</td>\n",
       "      <td>128</td>\n",
       "      <td>240.7</td>\n",
       "      <td>133</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.171978</td>\n",
       "      <td>09b7b0e0-fbd6-4168-8c43-9a384f363f8b</td>\n",
       "      <td>2023-01-19T05:40:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>107</td>\n",
       "      <td>166.5</td>\n",
       "      <td>93</td>\n",
       "      <td>202.3</td>\n",
       "      <td>96</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>8d240e95-415b-428a-b669-368aa4945f10</td>\n",
       "      <td>2023-01-19T05:40:55Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1      2    3      4    5      6    7    8   9   ...    62    63  \\\n",
       "0  186   0.1  137.8   97  187.7  118  146.4   85  8.7   6  ...  0.52  0.53   \n",
       "1  132  25.0  113.2   96  269.9  107  229.1   87  7.1   7  ...  0.00  1.00   \n",
       "2  112  17.0  183.2   95  252.8  125  156.7   95  9.7   3  ...  0.00  1.00   \n",
       "3   91  24.0   93.5  112  183.4  128  240.7  133  9.9   3  ...  0.00  0.00   \n",
       "4   22   0.0  110.3  107  166.5   93  202.3   96  9.5   5  ...  1.00  0.00   \n",
       "\n",
       "    64   65    66   67    68        69                                    70  \\\n",
       "0  1.2  1.3  0.54  1.4  0.55  0.015842  bd6c3be0-5902-4008-afc2-538b3be3bf2c   \n",
       "1  0.0  1.0  0.00  0.0  1.00  0.010764  58cd9844-a37e-4d80-9372-319ca6d876f6   \n",
       "2  0.0  1.0  0.00  0.0  1.00  0.008151  dba5c2f8-3203-4dd6-aa6e-69a4dd8279b7   \n",
       "3  1.0  0.0  1.00  0.0  1.00  0.171978  09b7b0e0-fbd6-4168-8c43-9a384f363f8b   \n",
       "4  0.0  1.0  0.00  1.0  0.00  0.007273  8d240e95-415b-428a-b669-368aa4945f10   \n",
       "\n",
       "                     71  \n",
       "0  2023-01-19T05:40:55Z  \n",
       "1  2023-01-19T05:40:55Z  \n",
       "2  2023-01-19T05:40:55Z  \n",
       "3  2023-01-19T05:40:55Z  \n",
       "4  2023-01-19T05:40:55Z  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_output = os.path.join(data_capture_output_dict[0][\"prefix\"], data_capture_output_dict[1])\n",
    "transform_output_content = sagemaker.s3.S3Downloader.read_file(\n",
    "    s3_uri=transform_output,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "transform_output_df = pd.read_csv(io.StringIO(transform_output_content), header=None)\n",
    "transform_output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ground Truth Data\n",
    "\n",
    "Besides captured data, bias drift monitoring execution also requires ground truth data. In real use cases, you should regularly label the captured data, then upload the ground truth data (labels) to designated S3 location. For demonstration purpose, this example notebook generates fake ground truth data following [this schema](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html), and then uploads it to `ground_truth_s3_uri` which is another key input to the monitor. The bias drift monitoring execution will first merge the captured data and the ground truth data, and then do bias analysis for the merged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    # format required by the merge job and bias monitoring job\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": \"1\"\n",
    "            if random.random() < 0.7\n",
    "            else \"0\",  # randomly generate positive labels 70% of the time\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(\n",
    "                inference_id\n",
    "            ),  # the id is used to join the captured data and the ground truth data\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(upload_time, upload_path, inference_ids):\n",
    "    records = [ground_truth_with_id(inference_id) for inference_id in inference_ids]\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    sagemaker.s3.S3Uploader.upload_string_as_file_body(\n",
    "        body=data_to_upload,\n",
    "        desired_s3_uri=target_s3_uri,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 334 records to s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/ground-truth/2023/01/19/04/4341.jsonl\n",
      "Uploading 334 records to s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/ground-truth/2023/01/19/05/4341.jsonl\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.utcnow()\n",
    "inference_ids = list(transform_output_df.iloc[:, -2])  # get inference ID from the captured data\n",
    "# Generate data for the last hour, in case the first monitoring execution is in this hour\n",
    "upload_ground_truth(\n",
    "    upload_time=now - datetime.timedelta(hours=1),\n",
    "    upload_path=ground_truth_s3_uri,\n",
    "    inference_ids=inference_ids,\n",
    ")\n",
    "# Generate data for this hour, in case the first monitoring execution will be in the next hour\n",
    "upload_ground_truth(\n",
    "    upload_time=now,\n",
    "    upload_path=ground_truth_s3_uri,\n",
    "    inference_ids=inference_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Bias Monitor\n",
    "\n",
    "Similar to the other monitoring types, the standard procedure of creating a [bias drift monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html) is first run a baselining job, and then schedule the monitor.\n",
    "\n",
    "A bias drift monitoring execution starts a merge job that joins the captured data and ground truth data together using the inference ID. Then a SageMaker Clarify bias analysis job is started to compute all the [pre-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) and [post-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html). on the merged data. The max execution time is divided equally between two jobs, the notebook is scheduling an hourly model bias monitor, so the `max_runtime_in_seconds` parameter should not exceed 1800 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_bias_monitor = sagemaker.model_monitor.ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselining job\n",
    "\n",
    "A baselining job runs predictions on training dataset and suggests constraints. The `suggest_baseline()` method of `ModelBiasMonitor` starts a SageMaker Clarify processing job to generate the constraints.\n",
    "\n",
    "The step is not mandatory, but providing constraints file to the monitor can enable violations file generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurations\n",
    "\n",
    "Information about the input data need to be provided to the processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataConfig` stores information about the dataset to be analyzed. For example, the dataset file, its format (like CSV), headers and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_s3_uri,\n",
    "    s3_output_path=baselining_output_s3_uri,\n",
    "    label=label_header,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelConfig` is configuration related to model to be used for inferencing. In order to compute post-training bias metrics, the computation needs to get inferences for the SageMaker model. To accomplish this, the processing job will use the model to create an ephemeral endpoint (also known as \"shadow endpoint\"). The processing job will delete the shadow endpoint after the computations are completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_name,  # The name of the SageMaker model\n",
    "    instance_type=\"ml.m5.xlarge\",  # The instance type of the shadow endpoint\n",
    "    instance_count=1,  # The instance count of the shadow endpoint\n",
    "    content_type=dataset_type,  # The data format of the model input\n",
    "    accept_type=dataset_type,  # The data format of the model output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelPredictedLabelConfig` specifies how to extract predicted label from the model output. The example model returns a single probability value between `0` and `1`. So,\n",
    "\n",
    "* The `probability` parameter is set to zero, which is the index of the probability value in the CSV model output. \n",
    "* The `probability_threshold` parameter is used by post-training analysis to convert the probability/score to binary predicted label (`0` or `1`). The default value is 0.5. Here choose an arbitrary 0.8 cutoff, i.e. a probability value > 0.8 means customer will churn (predicted label `1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predicted_label_config = sagemaker.clarify.ModelPredictedLabelConfig(\n",
    "    probability=0,  # The zero-based index of the probability (score) in model output\n",
    "    probability_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BiasConfig` is the configuration of the sensitive groups in the dataset. Typically, bias is measured by computing a metric and comparing it across groups. The group of interest is specified using the `facet` configuration. With the following facet, the baselining job will check if the model favors new customers (accounts created not far ago)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1],\n",
    "    facet_name=\"Account Length\",\n",
    "    facet_values_or_threshold=[100],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kick off baselining job\n",
    "\n",
    "Call the `suggest_baseline()` method to start the baselining job. The job computes all [pre-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) and [post-training bias metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2023-01-19-05-43-42-284\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/validation-dataset-with-header.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/baselining-output/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/baselining-output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f73f2285450>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bias_monitor.suggest_baseline(\n",
    "    bias_config=bias_config,\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=model_predicted_label_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell waits until the baselining job is completed (in about 10 minutes). It then inspects the suggested constraints. This step can be skipped, because the monitor to be scheduled will automatically pick up baselining job name and wait for it before monitoring execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................!\n",
      "Suggested constraints: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/baselining-output/analysis.json\n",
      "{\n",
      "    \"version\": \"1.0\",\n",
      "    \"post_training_bias_metrics\": {\n",
      "        \"label\": \"Churn\",\n",
      "        \"facets\": {\n",
      "            \"Account Length\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"(100, 225]\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"AD\",\n",
      "                            \"description\": \"Accuracy Difference (AD)\",\n",
      "                            \"value\": 0.03416521605801226\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"CDDPL\",\n",
      "                            \"description\": \"Conditional Demographic Disparity in Predicted Labels (CDDPL)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Group variable is empty or not provided\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DAR\",\n",
      "                            \"description\": \"Difference in Acceptance Rates (DAR)\",\n",
      "                            \"value\": 0.0\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DCA\",\n",
      "                            \"description\": \"Difference in Conditional Acceptance (DCA)\",\n",
      "                            \"value\": -0.4137931034482758\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DCR\",\n",
      "                            \"description\": \"Difference in Conditional Rejection (DCR)\",\n",
      "                            \"value\": -0.03722943722943728\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DI\",\n",
      "                            \"description\": \"Disparate Impact (DI)\",\n",
      "                            \"value\": 0.9762611275964392\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DPPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Predicted Labels (DPPL)\",\n",
      "                            \"value\": 0.0020924841936269395\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DRR\",\n",
      "                            \"description\": \"Difference in Rejection Rates (DRR)\",\n",
      "                            \"value\": -0.03722943722943728\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"FT\",\n",
      "                            \"description\": \"Flip Test (FT)\",\n",
      "                            \"value\": 0.04154302670623145\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"GE\",\n",
      "                            \"description\": \"Generalized Entropy (GE)\",\n",
      "                            \"value\": 0.04234527687296418\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"RD\",\n",
      "                            \"description\": \"Recall Difference (RD)\",\n",
      "                            \"value\": 0.1164268986283038\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"SD\",\n",
      "                            \"description\": \"Specificity Difference (SD)\",\n",
      "                            \"value\": 0.0\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"TE\",\n",
      "                            \"description\": \"Treatment Equality (TE)\",\n",
      "                            \"value\": 0.0\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"1\"\n",
      "    },\n",
      "    \"pre_training_bias_metrics\": {\n",
      "        \"label\": \"Churn\",\n",
      "        \"facets\": {\n",
      "            \"Account Length\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"(100, 225]\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"CDDL\",\n",
      "                            \"description\": \"Conditional Demographic Disparity in Labels (CDDL)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Group variable is empty or not provided\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"CI\",\n",
      "                            \"description\": \"Class Imbalance (CI)\",\n",
      "                            \"value\": -0.012012012012012012\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Labels (DPL)\",\n",
      "                            \"value\": -0.03207273186438539\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"JS\",\n",
      "                            \"description\": \"Jensen-Shannon Divergence (JS)\",\n",
      "                            \"value\": 0.0009346452720882569\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"KL\",\n",
      "                            \"description\": \"Kullback-Liebler Divergence (KL)\",\n",
      "                            \"value\": 0.003645914387951369\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"KS\",\n",
      "                            \"description\": \"Kolmogorov-Smirnov Distance (KS)\",\n",
      "                            \"value\": 0.03207273186438542\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"LP\",\n",
      "                            \"description\": \"L-p Norm (LP)\",\n",
      "                            \"value\": 0.04535769238496956\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"TVD\",\n",
      "                            \"description\": \"Total Variation Distance (TVD)\",\n",
      "                            \"value\": 0.032072731864385404\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"1\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_bias_monitor.latest_baselining_job.wait(logs=False)\n",
    "print()\n",
    "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
    "print(f\"Suggested constraints: {model_bias_constraints.file_s3_uri}\")\n",
    "print(\n",
    "    sagemaker.s3.S3Downloader.read_file(\n",
    "        s3_uri=model_bias_constraints.file_s3_uri,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With above constraints collected, now call `create_monitoring_schedule()` method to schedule an hourly model bias monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a baselining job has been submitted, then the monitor object will automatically pick up the analysis configuration from the baselining job. But if the baselining step is skipped, or if the capture dataset has different nature than the training dataset, then analysis configuration has to be provided.\n",
    "\n",
    "`BiasAnalysisConfig` is a subset of the configuration of the baselining job, many options are not needed because,\n",
    "\n",
    "* Model bias monitor will merge the captured data and the ground truth data, and then use the merged data as the input dataset.\n",
    "* Capture data already includes predictions, so there is no need to create shadow endpoint.\n",
    "* Attributes like probability threshold are provided as part of `BatchTransformInput`.\n",
    "\n",
    "Highlights,\n",
    "\n",
    "* `data_capture_s3_uri` is the location of data captured by the batch transform job\n",
    "* `ground_truth_s3_uri` is the location of ground truth data\n",
    "* `probability_attribute` stores the index of the probability value in model output. (Similar to the `probability` parameter of `ModelPredictedLabelConfig`.)\n",
    "* `probability_threshold_attribute` is the same as the `probability_threshold` parameter of `ModelPredictedLabelConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule_expression = sagemaker.model_monitor.CronExpressionGenerator.hourly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bias monitoring schedule: monitoring-schedule-2023-01-19-05-52-05-332\n"
     ]
    }
   ],
   "source": [
    "model_bias_analysis_config = None\n",
    "if not model_bias_monitor.latest_baselining_job:\n",
    "    model_bias_analysis_config = sagemaker.clarify.BiasAnalysisConfig(\n",
    "        bias_config,\n",
    "        headers=all_headers,\n",
    "        label=label_header,\n",
    "    )\n",
    "model_bias_monitor.create_monitoring_schedule(\n",
    "    analysis_config=model_bias_analysis_config,\n",
    "    batch_transform_input=sagemaker.model_monitor.BatchTransformInput(\n",
    "        data_captured_destination_s3_uri=data_capture_s3_uri,\n",
    "        destination=\"/opt/ml/processing/transform\",\n",
    "        dataset_format=sagemaker.model_monitor.MonitoringDatasetFormat.csv(header=False),\n",
    "        probability_attribute=\"0\",\n",
    "        probability_threshold_attribute=0.8,\n",
    "        # look back 6 hour for transform job output.\n",
    "        start_time_offset=\"-PT6H\",\n",
    "        end_time_offset=\"-PT0H\",\n",
    "    ),\n",
    "    ground_truth_input=ground_truth_s3_uri,\n",
    "    output_s3_uri=monitor_output_s3_uri,\n",
    "    schedule_cron_expression=schedule_expression,\n",
    ")\n",
    "print(f\"Model bias monitoring schedule: {model_bias_monitor.monitoring_schedule_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for the first execution\n",
    "\n",
    "The schedule starts jobs at the previously specified intervals. Code below waits until time crosses the hour boundary (in UTC) to see executions kick off.\n",
    "\n",
    "Note: Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule executions. The execution might start in anywhere from zero to ~20 minutes from the hour boundary. This is expected and done for load balancing in the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_execution_to_start(model_monitor):\n",
    "    print(\n",
    "        \"An hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\"\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for the first execution to happen\", end=\"\")\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    while \"LastMonitoringExecutionSummary\" not in schedule_desc:\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(60)\n",
    "    print()\n",
    "    print(\"Done! Execution has been created\")\n",
    "\n",
    "    print(\"Now waiting for execution to start\", end=\"\")\n",
    "    while schedule_desc[\"LastMonitoringExecutionSummary\"][\"MonitoringExecutionStatus\"] in \"Pending\":\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(10)\n",
    "\n",
    "    print()\n",
    "    print(\"Done! Execution has started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell waits until the first monitoring execution is started. As explained above, the wait could take more than 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\n",
      "Waiting for the first execution to happen..........\n",
      "Done! Execution has been created\n",
      "Now waiting for execution to start.\n",
      "Done! Execution has started\n"
     ]
    }
   ],
   "source": [
    "wait_for_execution_to_start(model_bias_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real world, a monitoring schedule is supposed to be active all the time. But in this example, it can be stopped to avoid incurring extra charges. A stopped schedule will not trigger further executions, but the ongoing execution will continue. And if needed, the schedule can be restarted by `start_monitoring_schedule()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping Monitoring Schedule with name: monitoring-schedule-2023-01-19-05-52-05-332\n"
     ]
    }
   ],
   "source": [
    "model_bias_monitor.stop_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for the execution to finish\n",
    "\n",
    "In the previous cell, the first execution has started. This section waits for the execution to finish so that its analysis results are available. Here are the possible terminal states and what each of them mean:\n",
    "\n",
    "* `Completed` - This means the monitoring execution completed, and no issues were found in the violations report.\n",
    "* `CompletedWithViolations` - This means the execution completed, but constraint violations were detected.\n",
    "* `Failed` - The monitoring execution failed, maybe due to client error (perhaps incorrect role permissions) or infrastructure issues. Further examination of `FailureReason` and `ExitMessage` is necessary to identify what exactly happened.\n",
    "* `Stopped` - job exceeded max runtime or was manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Waits for the schedule to have last execution in a terminal status.\n",
    "def wait_for_execution_to_finish(model_monitor):\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "    if execution_summary is not None:\n",
    "        print(\"Waiting for execution to finish\", end=\"\")\n",
    "        while execution_summary[\"MonitoringExecutionStatus\"] not in [\n",
    "            \"Completed\",\n",
    "            \"CompletedWithViolations\",\n",
    "            \"Failed\",\n",
    "            \"Stopped\",\n",
    "        ]:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(60)\n",
    "            schedule_desc = model_monitor.describe_schedule()\n",
    "            execution_summary = schedule_desc[\"LastMonitoringExecutionSummary\"]\n",
    "        print()\n",
    "        print(f\"Done! Execution Status: {execution_summary['MonitoringExecutionStatus']}\")\n",
    "    else:\n",
    "        print(\"Last execution not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The following cell takes about 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution to finish.........\n",
      "Done! Execution Status: CompletedWithViolations\n"
     ]
    }
   ],
   "source": [
    "wait_for_execution_to_finish(model_bias_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged data\n",
    "\n",
    "Merged data is the intermediate results of bias drift monitoring execution. It is saved to JSON Lines files under the \"merge\" folder of `monitor_output_s3_uri`. Each line is a valid JSON object which combines the captured data and the ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found merged data files:\n",
      "s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/merge/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/05/part-00000-93afd657-9941-49cb-9dc5-86ce85dee312.c000.jsonl\n"
     ]
    }
   ],
   "source": [
    "merged_data_s3_uri = f\"{monitor_output_s3_uri}/merge\"\n",
    "merged_data_files = sorted(\n",
    "    sagemaker.s3.S3Downloader.list(\n",
    "        s3_uri=merged_data_s3_uri,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    ")\n",
    "print(\"Found merged data files:\")\n",
    "print(\"\\n \".join(merged_data_files[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell prints a single line of a merged data file.\n",
    "\n",
    "* `eventId` is the inference ID from the captured data and the ground truth data\n",
    "* `groundTruthData` is from the ground truth data\n",
    "* `captureData` is from the captured data. In this case, the `data` of `batchTransformOutput` is from the transform output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"eventMetadata\": {\n",
      "        \"eventId\": \"bd6c3be0-5902-4008-afc2-538b3be3bf2c\"\n",
      "    },\n",
      "    \"eventVersion\": \"0\",\n",
      "    \"groundTruthData\": {\n",
      "        \"data\": \"1\",\n",
      "        \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"captureData\": {\n",
      "        \"batchTransformOutput\": {\n",
      "            \"data\": \"186,0.1,137.8,97,187.7,118,146.4,85,8.7,6,1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,1.1,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,1.2,1.3,0.54,1.4,0.55,0.01584203727543354\",\n",
      "            \"encoding\": \"CSV\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "merged_record = sagemaker.s3.S3Downloader.read_file(\n",
    "    s3_uri=merged_data_files[-1],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ").splitlines()[0]\n",
    "print(json.dumps(json.loads(merged_record), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect execution results\n",
    "\n",
    "List the generated reports,\n",
    "\n",
    "* analysis.json includes all the bias metrics.\n",
    "* report.* files are static report files to visualize the bias metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report URI: s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/06\n",
      "Found Report Files:\n",
      "s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/06/analysis.json\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/06/constraint_violations.json\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/06/report.html\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/06/report.ipynb\n",
      " s3://sagemaker-us-west-2-000000000000/sagemaker/DEMO-ClarifyModelMonitor-1674106771-acb2/monitor-output/monitoring-schedule-2023-01-19-05-52-05-332/2023/01/19/06/report.pdf\n"
     ]
    }
   ],
   "source": [
    "schedule_desc = model_bias_monitor.describe_schedule()\n",
    "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
    "    \"Completed\",\n",
    "    \"CompletedWithViolations\",\n",
    "]:\n",
    "    last_model_bias_monitor_execution = model_bias_monitor.list_executions()[-1]\n",
    "    last_model_bias_monitor_execution_report_uri = (\n",
    "        last_model_bias_monitor_execution.output.destination\n",
    "    )\n",
    "    print(f\"Report URI: {last_model_bias_monitor_execution_report_uri}\")\n",
    "    last_model_bias_monitor_execution_report_files = sorted(\n",
    "        sagemaker.s3.S3Downloader.list(\n",
    "            s3_uri=last_model_bias_monitor_execution_report_uri,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "        )\n",
    "    )\n",
    "    print(\"Found Report Files:\")\n",
    "    print(\"\\n \".join(last_model_bias_monitor_execution_report_files))\n",
    "else:\n",
    "    last_model_bias_monitor_execution = None\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any violations compared to the baseline, they are listed here. See [Bias Drift Violations](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift-violations.html) for the schema of the file, and how violations are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'version': '1.0',\n",
      "    'violations': [   {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': 'Metric value -0.2777777777777778 '\n",
      "                                         \"doesn't meet the baseline constraint \"\n",
      "                                         'requirement 0.0',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'DAR'},\n",
      "                      {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': 'Metric value 2.916666666666666 '\n",
      "                                         \"doesn't meet the baseline constraint \"\n",
      "                                         'requirement -0.4137931034482758',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'DCA'},\n",
      "                      {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': 'Metric value 1.3174603174603174 '\n",
      "                                         \"doesn't meet the baseline constraint \"\n",
      "                                         'requirement 0.9762611275964392',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'DI'},\n",
      "                      {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': 'Metric value -0.017211703958691905 '\n",
      "                                         \"doesn't meet the baseline constraint \"\n",
      "                                         'requirement 0.0020924841936269395',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'DPPL'},\n",
      "                      {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': 'Metric value 0.9771071800208119 '\n",
      "                                         \"doesn't meet the baseline constraint \"\n",
      "                                         'requirement 0.04234527687296418',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'GE'},\n",
      "                      {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': 'Metric value 0.037707390648567096 '\n",
      "                                         \"doesn't meet the baseline constraint \"\n",
      "                                         'requirement 0.0',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'SD'},\n",
      "                      {   'constraint_check_type': 'bias_drift_check',\n",
      "                          'description': \"Metric value 26.25 doesn't meet the \"\n",
      "                                         'baseline constraint requirement 0.0',\n",
      "                          'facet': 'Account Length',\n",
      "                          'facet_value': '(100, 232]',\n",
      "                          'metric_name': 'TE'}]}\n"
     ]
    }
   ],
   "source": [
    "violations = model_bias_monitor.latest_monitoring_constraint_violations()\n",
    "if violations is not None:\n",
    "    pprint.PrettyPrinter(indent=4).pprint(violations.body_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the analysis results are also published to CloudWatch, see [CloudWatch Metrics for Bias Drift Analysis](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift-cw.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "If there is no plan to collect more data for bias drift monitoring, then the monitor should be stopped (and deleted) to avoid incurring additional charges. Note that deleting the monitor does not delete the data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping Monitoring Schedule with name: monitoring-schedule-2023-01-19-05-52-05-332\n",
      "Waiting for execution to finish\n",
      "Done! Execution Status: CompletedWithViolations\n",
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2023-01-19-05-52-05-332\n"
     ]
    }
   ],
   "source": [
    "model_bias_monitor.stop_monitoring_schedule()\n",
    "wait_for_execution_to_finish(model_bias_monitor)\n",
    "model_bias_monitor.delete_monitoring_schedule()\n",
    "sagemaker_session.delete_model(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_model_monitor|fairness_and_explainability|SageMaker-Monitoring-Bias-Drift-for-Batch-Transform.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}