{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895bc64c",
   "metadata": {},
   "source": [
    "# Train a Pre-trained Huggingface Model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c7e2d73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ec9bc",
   "metadata": {},
   "source": [
    "\n",
    "This is a end-to-end binary Text-Classification example. In this demo, we will use the Hugging Faces transformers and datasets library to fine-tune a pre-trained transformer on binary text classification. In particular, the pre-trained model will be fine-tuned using the IMDb dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78ccd4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7caa8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689eea09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794dff21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sm_session = sagemaker.Session()\n",
    "\n",
    "s3_root_folder = f\"s3://{sm_session.default_bucket()}/remote_function_demo/huggingface\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3bb58df",
   "metadata": {},
   "source": [
    "## Setup Configuration file path\n",
    "We are setting the directory in which the config.yaml file resides so that remote decorator can make use of the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166cac06",
   "metadata": {},
   "source": [
    "## Load and process the data set\n",
    "\n",
    "We load our imdb datasets from HuggingFace and upload the data to S3 so we can reuse it without needing to load it from HuggingFace and do our transforms each time we want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03107f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer used in preprocessing\n",
    "tokenizer_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff54938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e30bad9d",
   "metadata": {},
   "source": [
    "**[ACTION REQUIRED]** In order to run the following cells successfully, you will need to download the \"imdb\" dataset\n",
    "from HuggingFace (https://huggingface.co/datasets/imdb) and populate the following two variables `train_dataset` and\n",
    "`test_dataset` with train and test data respectively.\n",
    "\n",
    "You can use HuggingFace datasets library to load dataset (https://huggingface.co/docs/datasets/loading)\n",
    "```\n",
    "from datasets import load_dataset\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c643cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for demo, smaller the size of the datasets\n",
    "test_dataset = test_dataset.shuffle().select(range(5000))\n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# set format for pytorch\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed32ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(s3_root_folder, \"data\", \"train\")\n",
    "test_data_path = os.path.join(s3_root_folder, \"data\", \"test\")\n",
    "\n",
    "train_dataset.save_to_disk(train_data_path)\n",
    "test_dataset.save_to_disk(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceaa51b",
   "metadata": {},
   "source": [
    "## Run the training remotely with a GPU instance\n",
    "\n",
    "\n",
    "The following method is used to compute metrics that evaluate the binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2589b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39871063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import json\n",
    "\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "\n",
    "@remote(s3_root_uri=s3_root_folder, keep_alive_period_in_seconds=600)\n",
    "def train_hf_model(\n",
    "    train_input_path,\n",
    "    test_input_path,\n",
    "    s3_output_path=None,\n",
    "    *,\n",
    "    epochs=1,\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "):\n",
    "    model_dir = \"model\"\n",
    "\n",
    "    train_dataset = load_from_disk(train_input_path, keep_in_memory=True)\n",
    "    test_dataset = load_from_disk(test_input_path, keep_in_memory=True)\n",
    "\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=train_batch_size,\n",
    "        per_device_eval_batch_size=eval_batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_dir=\"logs/\",\n",
    "        learning_rate=float(learning_rate),\n",
    "    )\n",
    "\n",
    "    # create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    print(\"Starting model training..\")\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model(model_dir)\n",
    "\n",
    "    print(\"Evaluating the model...\")\n",
    "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "    if s3_output_path:\n",
    "        fs = s3fs.S3FileSystem()\n",
    "        with fs.open(os.path.join(s3_output_path, \"eval_results.txt\"), \"w\") as file:\n",
    "            json.dump(eval_result, file)\n",
    "\n",
    "        fs.put(model_dir, os.path.join(s3_output_path, model_dir), recursive=True)\n",
    "\n",
    "    return os.path.join(s3_output_path, model_dir), eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aeb935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Train the model\n",
    "model_path, evaluation = train_hf_model(\n",
    "    train_data_path, test_data_path, os.path.join(s3_root_folder, \"run_1/output\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7a4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e248da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classify text using our trained model\n",
    "\n",
    "The text classification model we just trained will return a label based on the sentiment of the text sent to the model for inference.\n",
    "`LABEL-0` is for Negative sentiment and `LABEL-1` is for Positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3b021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "fs.get(model_path, \"model\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632c5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model = AutoModelForSequenceClassification.from_pretrained(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2480f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = \"I love using SageMaker.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16029167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=trained_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f06ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f2e1420",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/sagemaker-remote-function|huggingface_text_classification|huggingface.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-base-python-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
