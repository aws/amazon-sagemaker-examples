{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Job (Hyperparamter Injection) \n",
    "\n",
    "In this notebook, we discuss more complicated set ups for `CreateTrainingJob` API. It assumes you are confortable with the set ups discussed in [the notebook on basics of `CreateTrainingJob`](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create_training_job.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Hyperparameter Injection?\n",
    "\n",
    "With hyperparamter injection, you don't need to hard code hyperparameters of your ML training in the training image, instead you can pass your hyperparamters through `CreateTrainingJob` API and SageMaker will makes them available to your training container. This way you can experiment a list of hyperparameters for your training job without rebuilding the image for each experiment. More importantly, this is the mechanism used by `CreateHyperParameterTuningJob` API to (you guessed right) create many training jobs to search for the best hyperparameters. We will discuss `CreateHyperParameterTuningJob` in a different notebook. \n",
    "\n",
    "If you remember from [the notebook on basics of `CreateTrainingJob`](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create_training_job.ipynb), SageMaker reserves `/opt/ml` directory \"to talk to your container\", i.e. provide training information to your training job and retrieve output from it. \n",
    "\n",
    "You will pass hyperparamters of your training job as a dictionary to the `create_training_job` of boto3 SageMaker client, and it will become availble in `/opt/ml/input/config/hyperparameters.json`. See [reference in the official docs](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set ups\n",
    "\n",
    "You will build a training image and push it to ECR like in [the notebook on basics of `CreateTrainingJob`](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create_training_job.ipynb). The only difference is, the python script for runing the training will print out the hyperparamters in `/opt/ml/input/config/hyperparameters.json` to confirm that container does have access to the hyperparamters you passed to `CreateTrainingJob` API. \n",
    "\n",
    "This training job does not require any data. Therefore, you don't need to confgure `InputDataConfig` parameter for `CreateTrainingJob`. However, SageMaker always needs an S3 URI to save your model artifact, i.e. you still need to configure `OutputDataConfig` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # your gateway to AWS APIs\n",
    "import datetime\n",
    "import pprint\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "iam = boto3.client('iam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "def current_time():\n",
    "    ct = datetime.datetime.now() \n",
    "    return str(ct.now()).replace(\":\", \"-\").replace(\" \", \"-\")[:19]\n",
    "\n",
    "def account_id():\n",
    "    return boto3.client('sts').get_caller_identity()['Account']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a service role for SageMaker\n",
    "\n",
    "Review [notebook on execution role](https://github.com/hsl89/amazon-sagemaker-examples/blob/execution-role/sagemaker-fundamentals/execution-role/execution-role.ipynb) for step-by-step instructions on how to create an IAM Role.\n",
    "\n",
    "The service role is intended to be assumed by the SageMaker service to procure resources in your AWS account on your behalf. \n",
    "\n",
    "1. If you are running this this notebook on SageMaker infrastructure like Notebook Instances or Studio, then we will use the role you used to spin up those resources\n",
    "\n",
    "2. If you are running this notebook on an EC2 instance, then we will create a service role attach `AmazonSageMakerFullAccess` to it. If you already have a SageMaker service role, you can paste its `role_arn` here. \n",
    "\n",
    "First, let's get some helper functions for creating execution role. We discussed those functions in the [notebook on execution role](https://github.com/hsl89/amazon-sagemaker-examples/blob/execution-role/sagemaker-fundamentals/execution-role/execution-role.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-03-23 23:35:37--  https://raw.githubusercontent.com/hsl89/amazon-sagemaker-examples/sagemaker-fundamentals/sagemaker-fundamentals/execution-role/iam_helpers.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3659 (3.6K) [text/plain]\n",
      "Saving to: ‘iam_helpers.py’\n",
      "\n",
      "     0K ...                                                   100% 63.4M=0s\n",
      "\n",
      "2021-03-23 23:35:37 (63.4 MB/s) - ‘iam_helpers.py’ saved [3659/3659]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "file=$(ls . | grep iam_helpers.py)\n",
    "\n",
    "if [ -f \"$file\" ]\n",
    "then\n",
    "    rm $file\n",
    "fi\n",
    "\n",
    "wget https://raw.githubusercontent.com/hsl89/amazon-sagemaker-examples/sagemaker-fundamentals/sagemaker-fundamentals/execution-role/iam_helpers.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up service role for SageMaker\n",
    "from iam_helpers import create_execution_role\n",
    "\n",
    "sts = boto3.client('sts')\n",
    "caller = sts.get_caller_identity()\n",
    "\n",
    "if ':user/' in caller['Arn']: # as IAM user\n",
    "    # either paste in a role_arn with or create a new one and attach \n",
    "    # AmazonSageMakerFullAccess\n",
    "    role_name = 'sm'\n",
    "    role_arn = create_execution_role(role_name=role_name)['Role']['Arn']\n",
    "    \n",
    "    # attach the permission to the role\n",
    "    # skip it if you want to use a SageMaker service that \n",
    "    # already has AmazonFullSageMakerFullAccess\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess'\n",
    "    )\n",
    "elif 'assumed-role' in caller['Arn']: # on SageMaker infra\n",
    "    assumed_role = caller['Arn']\n",
    "    role_arn = re.sub(r\"^(.+)sts::(\\d+):assumed-role/(.+?)/.*$\", r\"\\1iam::\\2:role/\\3\", assumed_role)\n",
    "else:\n",
    "    print(\"I assume you are on an EC2 instance launched with an IAM role\")\n",
    "    role_arn = caller['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a training image and push to ECR\n",
    "\n",
    "You will build a training image here like in [the notebook on basics of `CreateTrainingJob`](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create_training_job.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM continuumio/miniconda:latest \n",
      "\n",
      "# SageMaker uses /opt/ml for input / output data \n",
      "# throughout the training \n",
      "RUN mkdir -p /opt/ml\n",
      "\n",
      "# Copy the training script into /usr/bin \n",
      "# as an executable\n",
      "COPY train.py /usr/bin/train\n",
      "\n",
      "# make /opt/ml/program/train an executable\n",
      "RUN chmod +x /usr/bin/train\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the Dockerfile\n",
    "!cat container_hyperparameter_injection/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env python\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# A sample script for training an ML model\u001b[39;49;00m\n",
      "\u001b[37m# It does 2 things\u001b[39;49;00m\n",
      "\u001b[37m# load csv data in /opt/ml/data\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[37m# where SageMaker injects training info inside container\u001b[39;49;00m\n",
      "input_dir=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/input/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# SageMaker treat \"/opt/ml/model\" as checkpoint direcotry\u001b[39;49;00m\n",
      "\u001b[37m# and it will send everything there to S3 output path you \u001b[39;49;00m\n",
      "\u001b[37m# specified \u001b[39;49;00m\n",
      "model_dir=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m== Loading hyperparamters ===\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(input_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mconfig/hyperparamters.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f\n",
      "        hyp = json.load(f)\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m== Hyperparamters: ==\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mfor\u001b[39;49;00m k, v \u001b[35min\u001b[39;49;00m hyp.items():\n",
      "        \u001b[36mprint\u001b[39;49;00m(k,\u001b[33m\"\u001b[39;49;00m\u001b[33m : \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,v)\n",
      "    \n",
      "    \u001b[37m# define your training logic here\u001b[39;49;00m\n",
      "    \u001b[37m# import tensorflow as pd\u001b[39;49;00m\n",
      "    \u001b[37m# import pandas as tf\u001b[39;49;00m\n",
      "\n",
      "    model = \u001b[34mNone\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m== Saving model checkpoint ==\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        pickle.dump(model, f)\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m== training completed ==\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "# View the \"training alogrithm\"\n",
    "!pygmentize container_hyperparameter_injection/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm simply print out hyperparameters in the json file `/opt/ml/input/config/hyperparameters.json` as a verification that it can indeed access those hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  14.34kB\n",
      "Step 1/4 : FROM continuumio/miniconda:latest\n",
      " ---> b8ea69b5c41c\n",
      "Step 2/4 : RUN mkdir -p /opt/ml\n",
      " ---> Using cache\n",
      " ---> a170cc3fed03\n",
      "Step 3/4 : COPY train.py /usr/bin/train\n",
      " ---> 5bc823c42a18\n",
      "Step 4/4 : RUN chmod +x /usr/bin/train\n",
      " ---> Running in 52bd1de8fba4\n",
      "Removing intermediate container 52bd1de8fba4\n",
      " ---> 888c36fefde2\n",
      "Successfully built 888c36fefde2\n",
      "Successfully tagged example-image:latest\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# build the image\n",
    "cd container_hyperparameter_injection/\n",
    "\n",
    "# tag it as example-image:latest\n",
    "docker build -t example-image:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the container locally\n",
    "Before pushing the image to ECR, it is always a good practice to test it locally. You need to create a `hyperparameters.json` file and make it available to the container at `/opt/ml/input/config/hyperparameters.json`. To do so, you can mount a local directory to `/opt/ml` as a docker volume like in [the notebook on basics of `CreateTrainingJob`](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create_training_job.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout the test we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# This script tests the your own container before running\u001b[39;49;00m\n",
      "\u001b[37m# on SageMaker infrastructure. It mimics how SageMaker provides\u001b[39;49;00m\n",
      "\u001b[37m# training info to your container and how it executes it. \u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdocker\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\n",
      "dirname = os.path.dirname(\n",
      "    os.path.realpath(\u001b[31m__file__\u001b[39;49;00m)\n",
      "    )\n",
      "\n",
      "client = docker.from_env()\n",
      "\n",
      "container = client.containers.run(\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mexample-image:latest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m# docker run example-image:latest train \u001b[39;49;00m\n",
      "    volumes={\n",
      "        \u001b[37m# mount ml/ to /opt/ml as volume\u001b[39;49;00m\n",
      "        \u001b[37m# it's a mechanism for the operating \u001b[39;49;00m\n",
      "        \u001b[37m# system to communicate with inside of\u001b[39;49;00m\n",
      "        \u001b[37m# a docker container\u001b[39;49;00m\n",
      "        os.path.join(dirname, \u001b[33m'\u001b[39;49;00m\u001b[33mml\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) : {\u001b[33m'\u001b[39;49;00m\u001b[33mbind\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mrw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}, \n",
      "        },\n",
      "    stderr=\u001b[34mTrue\u001b[39;49;00m,\n",
      "    detach=\u001b[34mTrue\u001b[39;49;00m,\n",
      "    )\n",
      "\n",
      "\u001b[37m# wait the execution to finish\u001b[39;49;00m\n",
      "container.wait()\n",
      "\n",
      "\u001b[37m# retrieve logs\u001b[39;49;00m\n",
      "byte_str=container.logs()\n",
      "\n",
      "\u001b[37m# decode byte string to utf-8 encoding\u001b[39;49;00m\n",
      "\u001b[36mprint\u001b[39;49;00m(byte_str.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n"
     ]
    }
   ],
   "source": [
    "!pygmentize container_hyperparameter_injection/local_test/test_container.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made some realistic looking hyperparameters in `container_hyperparameter_injection/local_test/ml/input/config/hyperparameters.json` and mounted `container_hyperparamter_injection/local_test/ml` to `/opt/ml` as a docker volume to the container, so that the file container can access the hyperparamters at `/opt/ml/input/config/hyperparameters.json`. \n",
    "\n",
    "Note that the json file `container_hyperparameter_injection/local_test/ml/input/config/hyperparameters.json` is not nested and the values are all strings, even they meant to be other data types. This is because when calling `CreateTrainingJob` with hyperparameter injection, the hyperparameters can only be a dictionary of key-value pairs, and both key and value need to be a string. See [API reference](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Loading hyperparamters ===\n",
      "== Hyperparamters: ==\n",
      "{u'batch_size': 128,\n",
      " u'epochs': 100,\n",
      " u'learning_rate': 0.0001,\n",
      " u'optional': {u'activation_fn': u'sigmoid',\n",
      "               u'drop_out': 0.3,\n",
      "               u'grad_clip': 0.01},\n",
      " u'weight_decay': 0.01}\n",
      "== Saving model checkpoint ==\n",
      "== training completed ==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the test\n",
    "!python container_hyperparameter_injection/local_test/test_container.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you tested your container, you can push it to ECR and be confident that it will work for a SageMaker training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'example-image' already exists in the registry with id '688520471316'\n"
     ]
    }
   ],
   "source": [
    "# create a repo in ECR called example-image\n",
    "ecr = boto3.client('ecr')\n",
    "\n",
    "try:\n",
    "    # The repository might already exist\n",
    "    # in your ECR\n",
    "    cr_res = ecr.create_repository(\n",
    "        repositoryName='example-image')\n",
    "    pp.pprint(cr_res)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [688520471316.dkr.ecr.us-west-2.amazonaws.com/example-image]\n",
      "c48ea44f521c: Preparing\n",
      "42c8a091b042: Preparing\n",
      "88674bdc7fd9: Preparing\n",
      "78db50750faa: Preparing\n",
      "805309d6b0e2: Preparing\n",
      "2db44bce66cd: Preparing\n",
      "2db44bce66cd: Waiting\n",
      "78db50750faa: Layer already exists\n",
      "805309d6b0e2: Layer already exists\n",
      "88674bdc7fd9: Layer already exists\n",
      "2db44bce66cd: Layer already exists\n",
      "42c8a091b042: Pushed\n",
      "c48ea44f521c: Pushed\n",
      "latest: digest: sha256:a4fc409a81a13c7f6c913a1a6d7a5fb3066c1dd2b9da25c84db5b82507441e2e size: 1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "account=$(aws sts get-caller-identity --query Account | sed -e 's/^\"//' -e 's/\"$//')\n",
    "region=$(aws configure get region)\n",
    "ecr_account=${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "# Give docker your ECR login password\n",
    "aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $ecr_account\n",
    "\n",
    "# Fullname of the repo\n",
    "fullname=$ecr_account/example-image:latest\n",
    "\n",
    "#echo $fullname\n",
    "# Tag the image with the fullname\n",
    "docker tag example-image:latest $fullname\n",
    "\n",
    "# Push to ECR\n",
    "docker push $fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPHeaders': {'content-length': '2197',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Wed, 24 Mar 2021 19:03:24 GMT',\n",
      "                                      'x-amzn-requestid': '3f2d5c18-27a0-4f11-ad79-e81d5eb82df3'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '3f2d5c18-27a0-4f11-ad79-e81d5eb82df3',\n",
      "                      'RetryAttempts': 0},\n",
      " 'imageDetails': [{'artifactMediaType': 'application/vnd.docker.container.image.v1+json',\n",
      "                   'imageDigest': 'sha256:9d58547ed7516607ad53e13ca7b41e8a90138b95f994bf5eafee6dbe95c34739',\n",
      "                   'imageManifestMediaType': 'application/vnd.docker.distribution.manifest.v2+json',\n",
      "                   'imagePushedAt': datetime.datetime(2021, 3, 16, 23, 49, 3, tzinfo=tzlocal()),\n",
      "                   'imageSizeInBytes': 1023214837,\n",
      "                   'registryId': '688520471316',\n",
      "                   'repositoryName': 'example-image'},\n",
      "                  {'artifactMediaType': 'application/vnd.docker.container.image.v1+json',\n",
      "                   'imageDigest': 'sha256:d1f3a5e6dee36e7f26d45a2756b784bc4e1a884a819d8cb871aaef4119d526dd',\n",
      "                   'imageManifestMediaType': 'application/vnd.docker.distribution.manifest.v2+json',\n",
      "                   'imagePushedAt': datetime.datetime(2021, 3, 16, 20, 9, 35, tzinfo=tzlocal()),\n",
      "                   'imageSizeInBytes': 1023214834,\n",
      "                   'registryId': '688520471316',\n",
      "                   'repositoryName': 'example-image'},\n",
      "                  {'artifactMediaType': 'application/vnd.docker.container.image.v1+json',\n",
      "                   'imageDigest': 'sha256:8071e089fbd85ee8eab3d9d80010d5c69bd43f59b64d6a0060bd2d50346a57fe',\n",
      "                   'imageManifestMediaType': 'application/vnd.docker.distribution.manifest.v2+json',\n",
      "                   'imagePushedAt': datetime.datetime(2021, 3, 17, 0, 4, 56, tzinfo=tzlocal()),\n",
      "                   'imageSizeInBytes': 150950340,\n",
      "                   'registryId': '688520471316',\n",
      "                   'repositoryName': 'example-image'},\n",
      "                  {'artifactMediaType': 'application/vnd.docker.container.image.v1+json',\n",
      "                   'imageDigest': 'sha256:00da6c645b4f0f3595a6e672fe406d4cfa9b1546ab25e698ae8ad17a293e2c9f',\n",
      "                   'imageManifestMediaType': 'application/vnd.docker.distribution.manifest.v2+json',\n",
      "                   'imagePushedAt': datetime.datetime(2021, 3, 17, 0, 10, 15, tzinfo=tzlocal()),\n",
      "                   'imageSizeInBytes': 150950338,\n",
      "                   'registryId': '688520471316',\n",
      "                   'repositoryName': 'example-image'},\n",
      "                  {'artifactMediaType': 'application/vnd.docker.container.image.v1+json',\n",
      "                   'imageDigest': 'sha256:1cdec6ded7ad6d3bae92564e28985c7e02c80666e1b6d61ef9b7c0b6a4c8489a',\n",
      "                   'imageManifestMediaType': 'application/vnd.docker.distribution.manifest.v2+json',\n",
      "                   'imagePushedAt': datetime.datetime(2021, 3, 24, 19, 3, 21, tzinfo=tzlocal()),\n",
      "                   'imageSizeInBytes': 150950326,\n",
      "                   'imageTags': ['latest'],\n",
      "                   'registryId': '688520471316',\n",
      "                   'repositoryName': 'example-image'},\n",
      "                  {'artifactMediaType': 'application/vnd.docker.container.image.v1+json',\n",
      "                   'imageDigest': 'sha256:ec224219553c62f74b951ce57bc71525eb4f8b9cce0e61bb4edca0e601592be2',\n",
      "                   'imageManifestMediaType': 'application/vnd.docker.distribution.manifest.v2+json',\n",
      "                   'imagePushedAt': datetime.datetime(2021, 3, 24, 18, 25, 28, tzinfo=tzlocal()),\n",
      "                   'imageSizeInBytes': 150950334,\n",
      "                   'registryId': '688520471316',\n",
      "                   'repositoryName': 'example-image'}]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the ECR repository\n",
    "repo_res = ecr.describe_images(\n",
    "    repositoryName='example-image')\n",
    "pp.pprint(repo_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare an S3 bucket for model artifact\n",
    "Even you are not training a real model, SageMaker still requires you to give it an S3 URI to upload model artifact in `/opt/ml/model`. So let's create a temporary bucket for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bucket\n",
    "def create_tmp_bucket():\n",
    "    \"\"\"Create an S3 bucket that is intended to be used for short term\"\"\"\n",
    "    bucket = f\"sagemaker-{current_time()}\" # accessible by SageMaker\n",
    "    region = boto3.Session().region_name\n",
    "    boto3.client('s3').create_bucket(\n",
    "        Bucket=bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': region\n",
    "        })\n",
    "    return bucket\n",
    "\n",
    "bucket = create_tmp_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put everything together\n",
    "\n",
    "Now you have everything you need to create a training job that can ingest hyperparamters from the boto3 call. Let's review what you have done. You have \n",
    "* created an execution role for SageMaker service\n",
    "* built and tested a docker image that includes the runtime and logic of your model training\n",
    "* made the image accessible to SageMaker by hosting it on ECR\n",
    "* created an S3 bucket for saving model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import json\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "# name training job\n",
    "training_job_name = 'example-training-job-{}'.format(current_time())\n",
    "\n",
    "\n",
    "\n",
    "# location that SageMaker saves the model artifacts\n",
    "output_prefix = 'example/output/'\n",
    "output_path = \"s3://\" + bucket + '/' + output_prefix\n",
    "\n",
    "# ECR URI of your image\n",
    "region = boto3.Session().region_name\n",
    "account = account_id()\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/example-image:latest\".format(account, region)\n",
    "\n",
    "algorithm_specification = {\n",
    "    'TrainingImage': image_uri,\n",
    "    'TrainingInputMode': 'File',\n",
    "}\n",
    "\n",
    "# inject the following hyperparamters to your container\n",
    "# you can define `hyperparameters` in whatever way\n",
    "# you want as long as it can be parsed to a json file (not nested)\n",
    "# and both key and value are strings\n",
    "\n",
    "hyperparamters = {\n",
    "    \"num_trees\" : \"15\",\n",
    "    \"max_depth\" : \"4\",\n",
    "    \"n_iter\": \"30\",\n",
    "    \"your_parameter_1\": \"1\",\n",
    "    \"your_parameter_2\" : \"0.01\"\n",
    "}\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': output_path\n",
    "}\n",
    "\n",
    "resource_config = {\n",
    "    'InstanceType': 'ml.m5.large',\n",
    "    'InstanceCount':1,\n",
    "    'VolumeSizeInGB':10\n",
    "}\n",
    "\n",
    "stopping_condition={\n",
    "    'MaxRuntimeInSeconds':120,\n",
    "}\n",
    "\n",
    "enable_network_isolation=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_res = sm_boto3.create_training_job(\n",
    "    TrainingJobName=training_job_name,\n",
    "    AlgorithmSpecification=algorithm_specification,\n",
    "    HyperParameters=hyperparameters, # look here\n",
    "    RoleArn=role_arn,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    ResourceConfig=resource_config,\n",
    "    StoppingCondition=stopping_condition,\n",
    "    EnableNetworkIsolation=enable_network_isolation,\n",
    "    EnableManagedSpotTraining=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress\n",
      "Training in progress\n",
      "Training in progress\n",
      "Training in progress\n",
      "Training in progress\n",
      "Training in progress\n",
      "Training job completed\n"
     ]
    }
   ],
   "source": [
    "# check training job status every 30 seconds\n",
    "stopped = False\n",
    "while not stopped:\n",
    "    tj_state = sm_boto3.describe_training_job(\n",
    "        TrainingJobName=training_job_name)\n",
    "    if tj_state['TrainingJobStatus'] in ['Completed', 'Stopped', 'Failed']:\n",
    "        stopped=True\n",
    "    else:\n",
    "        print(\"Training in progress\")\n",
    "        time.sleep(30)\n",
    "\n",
    "if tj_state['TrainingJobStatus'] == 'Failed':\n",
    "    print(\"Training job failed \")\n",
    "    print(\"Failed Reason: {}\".tj_state['FailedReason'])\n",
    "else:\n",
    "    print(\"Training job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the trained model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Output config:\n",
      "{'KmsKeyId': '', 'S3OutputPath': 's3://sagemaker-2021-03-24-18-39-57/example/output/'}\n",
      "\n",
      "== Model artifact:\n",
      "{'Contents': [{'ETag': '\"9a969992b9afe3717d2d31dfded7958d\"',\n",
      "               'Key': 'example/output/example-training-job-2021-03-24-19-33-59/output/model.tar.gz',\n",
      "               'LastModified': datetime.datetime(2021, 3, 24, 19, 36, 57, tzinfo=tzlocal()),\n",
      "               'Size': 122,\n",
      "               'StorageClass': 'STANDARD'}],\n",
      " 'EncodingType': 'url',\n",
      " 'IsTruncated': False,\n",
      " 'KeyCount': 1,\n",
      " 'MaxKeys': 1000,\n",
      " 'Name': 'sagemaker-2021-03-24-18-39-57',\n",
      " 'Prefix': 'example/output/',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-type': 'application/xml',\n",
      "                                      'date': 'Wed, 24 Mar 2021 19:41:02 GMT',\n",
      "                                      'server': 'AmazonS3',\n",
      "                                      'transfer-encoding': 'chunked',\n",
      "                                      'x-amz-bucket-region': 'us-west-2',\n",
      "                                      'x-amz-id-2': '4dG71u5c61SZRxK8fIEuxA2ZngcVu88iWmS3mhH0Rzc8DuxjMplqWFw7ZdqXS+w+R4FAyKBZb/o=',\n",
      "                                      'x-amz-request-id': '9BK9BVWWA8VKW7K0'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'HostId': '4dG71u5c61SZRxK8fIEuxA2ZngcVu88iWmS3mhH0Rzc8DuxjMplqWFw7ZdqXS+w+R4FAyKBZb/o=',\n",
      "                      'RequestId': '9BK9BVWWA8VKW7K0',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(\"== Output config:\")\n",
    "print(tj_state['OutputDataConfig'])\n",
    "\n",
    "print()\n",
    "s3 = boto3.client('s3')\n",
    "print(\"== Model artifact:\")\n",
    "pp.pprint(s3.list_objects_v2(Bucket=bucket, Prefix=output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Loading hyperparamters ===\n",
      "== Hyperparamters: ==\n",
      "{u'max_depth': u'4', u'n_iter': u'30', u'num_trees': u'15'}\n",
      "== Saving model checkpoint ==\n",
      "== training completed ==\n"
     ]
    }
   ],
   "source": [
    "# print out logs from Cloud Watch\n",
    "logs = boto3.client('logs')\n",
    "\n",
    "log_res= logs.describe_log_streams(\n",
    "    logGroupName='/aws/sagemaker/TrainingJobs',\n",
    "    logStreamNamePrefix=training_job_name)\n",
    "\n",
    "for log_stream in log_res['logStreams']:\n",
    "    # get one log event\n",
    "    log_event = logs.get_log_events(\n",
    "        logGroupName='/aws/sagemaker/TrainingJobs',\n",
    "        logStreamName=log_stream['logStreamName'])\n",
    "    \n",
    "    # print out messages from the log event\n",
    "    for ev in log_event['events']:\n",
    "        for k, v in ev.items():\n",
    "            if k == 'message':\n",
    "                print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You now understand how to avoid hard-code hyperparamters in your training image. To recap, \n",
    "\n",
    "- Hyperparamter injection allows you to quickly experiment your ML algorithm with different hyperparameters\n",
    "- When calling `CreateTrainingJob` with hyperparamter injection, the hyperparameters you passed to `HyperParameter` needs to be a dictionary of string : string\n",
    "- To avoid hating yourself, always test your container before pushing it to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPHeaders': {'content-length': '289',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Wed, 24 Mar 2021 19:48:32 GMT',\n",
      "                                      'x-amzn-requestid': '773042de-4abb-41fa-893d-7e919fae658d'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '773042de-4abb-41fa-893d-7e919fae658d',\n",
      "                      'RetryAttempts': 0},\n",
      " 'repository': {'createdAt': datetime.datetime(2021, 3, 16, 20, 7, 17, tzinfo=tzlocal()),\n",
      "                'imageTagMutability': 'MUTABLE',\n",
      "                'registryId': '688520471316',\n",
      "                'repositoryArn': 'arn:aws:ecr:us-west-2:688520471316:repository/example-image',\n",
      "                'repositoryName': 'example-image',\n",
      "                'repositoryUri': '688520471316.dkr.ecr.us-west-2.amazonaws.com/example-image'}}\n"
     ]
    }
   ],
   "source": [
    "# delete the ECR repo\n",
    "del_repo_res = ecr.delete_repository(\n",
    "    repositoryName='example-image',\n",
    "    force=True)\n",
    "pp.pprint(del_repo_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPHeaders': {'date': 'Wed, 24 Mar 2021 19:48:28 GMT',\n",
      "                                      'server': 'AmazonS3',\n",
      "                                      'x-amz-id-2': '2ZmF3NwIarE8M3XibzrMf5l2QpKBjp5oBLr6AXyUwPz2bcEOkX6usAJQVkfdp8EFs3G/ykPmILI=',\n",
      "                                      'x-amz-request-id': 'WQ4864KNX1XG5BXG'},\n",
      "                      'HTTPStatusCode': 204,\n",
      "                      'HostId': '2ZmF3NwIarE8M3XibzrMf5l2QpKBjp5oBLr6AXyUwPz2bcEOkX6usAJQVkfdp8EFs3G/ykPmILI=',\n",
      "                      'RequestId': 'WQ4864KNX1XG5BXG',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# delete the S3 bucket\n",
    "def delete_bucket_force(bucket_name):\n",
    "    objs = s3.list_objects_v2(Bucket=bucket_name)['Contents']\n",
    "    for obj in objs:\n",
    "        s3.delete_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=obj['Key'])\n",
    "    \n",
    "    return s3.delete_bucket(Bucket=bucket_name)\n",
    "\n",
    "del_buc_res = delete_bucket_force(bucket)\n",
    "\n",
    "pp.pprint(del_buc_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
