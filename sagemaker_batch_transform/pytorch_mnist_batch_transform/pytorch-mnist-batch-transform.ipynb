{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solar-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchvision 0.9.1\n",
      "Uninstalling torchvision-0.9.1:\n",
      "  Would remove:\n",
      "    /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.9.1.dist-info/*\n",
      "    /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libcudart.459720b2.so.10.2\n",
      "    /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
      "    /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
      "    /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision.libs/libz.1328edc3.so.1\n",
      "    /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/*\n",
      "Proceed (y/n)?   Successfully uninstalled torchvision-0.9.1\n",
      "yes: standard output: Broken pipe\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.9.1-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.18.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.8.1->torchvision) (0.7)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall torchvision\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-clerk",
   "metadata": {
    "papermill": {
     "duration": 0.009489,
     "end_time": "2021-06-03T00:10:10.266437",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.256948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Batch Inference\n",
    "In this notebook, we'll examine how to do batch transform task with PyTorch in Amazon SageMaker. \n",
    "\n",
    "First, an image classification model is build on MNIST dataset. Then, we demonstrate batch transform by using SageMaker Python SDK PyTorch framework with different configurations\n",
    "- `data_type=S3Prefix`: uses all objects that match the specified S3 key name prefix for batch inference.\n",
    "- `data_type=ManifestFile`: a manifest file containing a list of object keys that you want to batch inference.\n",
    "- `instance_count>1`: distribute the batch inference dataset to multiple inference instance\n",
    "\n",
    "For batch transform in TensorFlow in Amazon SageMaker, you can follow other Jupyter notebooks [here](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-emission",
   "metadata": {
    "papermill": {
     "duration": 0.009319,
     "end_time": "2021-06-03T00:10:10.285106",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.275787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "We'll begin with some necessary imports, and get an Amazon SageMaker session to help perform certain tasks, as well as an IAM role with the necessary permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-provider",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:10.310480Z",
     "iopub.status.busy": "2021-06-03T00:10:10.309977Z",
     "iopub.status.idle": "2021-06-03T00:10:11.972019Z",
     "shell.execute_reply": "2021-06-03T00:10:11.971547Z"
    },
    "papermill": {
     "duration": 1.677667,
     "end_time": "2021-06-03T00:10:11.972131",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.294464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:\n",
      "sagemaker-us-west-2-688520471316\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-batch-inference-script\"\n",
    "print(\"Bucket:\\n{}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-grove",
   "metadata": {
    "papermill": {
     "duration": 0.009748,
     "end_time": "2021-06-03T00:10:11.992188",
     "exception": false,
     "start_time": "2021-06-03T00:10:11.982440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-grammar",
   "metadata": {
    "papermill": {
     "duration": 0.009924,
     "end_time": "2021-06-03T00:10:12.012090",
     "exception": false,
     "start_time": "2021-06-03T00:10:12.002166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since the main purpose of this notebook is to demonstrate SageMaker PyTorch batch transform, **we reuse this SageMaker Python SDK [PyTorch example](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_mnist) to train a PyTorch model**. It takes around 7 minutes to finish the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broken-peoples",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:12.038135Z",
     "iopub.status.busy": "2021-06-03T00:10:12.037362Z",
     "iopub.status.idle": "2021-06-03T00:15:42.451109Z",
     "shell.execute_reply": "2021-06-03T00:15:42.449969Z"
    },
    "papermill": {
     "duration": 330.429296,
     "end_time": "2021-06-03T00:15:42.451328",
     "exception": true,
     "start_time": "2021-06-03T00:10:12.022032",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script\n",
      "2021-06-04 02:16:50 Starting - Starting the training job...\n",
      "2021-06-04 02:17:13 Starting - Launching requested ML instancesProfilerReport-1622773010: InProgress\n",
      "......\n",
      "2021-06-04 02:18:14 Starting - Preparing the instances for training......\n",
      "2021-06-04 02:19:14 Downloading - Downloading input data......\n",
      "2021-06-04 02:20:14 Training - Downloading the training image..\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:25,865 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:25,867 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:25,875 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:26,675 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:26,677 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:26,685 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:27,315 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:27,295 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:30,903 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:30,914 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:30,924 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:30,934 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-06-04-02-16-49-322\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-06-04-02-16-49-322\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:31,017 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:31,028 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:31,038 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:31,047 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2021-06-04-02-16-49-322\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2021-06-04-02-16-49-322\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[32mbash: no job control in this shell\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,339 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,341 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,349 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,356 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,847 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,858 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,869 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:27,878 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[32mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[32m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2021-06-04-02-16-49-322\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[32m}\n",
      "\u001b[0m\n",
      "\u001b[32mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[32mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[32mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[32mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[32mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[32mSM_RESOURCE_CONFIG={\"current_host\":\"algo-3\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[32mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[32mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[32mSM_CURRENT_HOST=algo-3\u001b[0m\n",
      "\u001b[32mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[32mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[32mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[32mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[32mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[32mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[32mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[32mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[32mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-3\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2021-06-04-02-16-49-322\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-16-49-322/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-3\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[32mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[32mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[32mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[32mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[32mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[32mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[32m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mDistributed training - True\u001b[0m\n",
      "\u001b[32mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:33.769 algo-1:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mGet train data loader\u001b[0m\n",
      "\u001b[35mGet test data loader\u001b[0m\n",
      "\u001b[35mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:33.743 algo-2:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.082 algo-2:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.082 algo-2:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.082 algo-2:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.083 algo-2:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.083 algo-2:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.127 algo-2:26 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.128 algo-2:26 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.128 algo-2:26 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[35m[2021-06-04 02:20:34.128 algo-2:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[32mInitialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 2. Number of gpus: 0\u001b[0m\n",
      "\u001b[32mGet train data loader\u001b[0m\n",
      "\u001b[32mGet test data loader\u001b[0m\n",
      "\u001b[32mProcesses 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[32mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:33.761 algo-3:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.162 algo-3:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.162 algo-3:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.162 algo-3:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.163 algo-3:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.163 algo-3:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.195 algo-1:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.195 algo-1:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.195 algo-1:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.196 algo-1:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.196 algo-1:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.252 algo-1:25 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.252 algo-1:25 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.252 algo-1:25 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.252 algo-1:25 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.253 algo-1:25 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.253 algo-1:25 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.253 algo-1:25 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.253 algo-1:25 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.253 algo-1:25 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[34m[2021-06-04 02:20:34.253 algo-1:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.214 algo-3:26 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[32m[2021-06-04 02:20:34.215 algo-3:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/20000 (32%)] Loss: 1.830737\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [6400/20000 (32%)] Loss: 1.944218\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [6400/20000 (32%)] Loss: 2.076494\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [12800/20000 (64%)] Loss: 1.229461\u001b[0m\n",
      "\n",
      "2021-06-04 02:20:49 Uploading - Uploading generated training model\u001b[34mTrain Epoch: 1 [12800/20000 (64%)] Loss: 1.132146\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [12800/20000 (64%)] Loss: 0.970919\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.892621\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.714048\u001b[0m\n",
      "\u001b[32mTrain Epoch: 1 [19200/20000 (96%)] Loss: 0.667853\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 1.830737\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 1.132146\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.892621\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-04 02:20:43,509 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[35mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[35mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 1.944218\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 0.970919\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.714048\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[35mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-06-04 02:20:43,502 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[32mTest set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:__main__:Initialized the distributed environment: 'gloo' backend on 3 nodes. Current host rank is 2. Number of gpus: 0\u001b[0m\n",
      "\u001b[32mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[32mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[32mDEBUG:__main__:Processes 20000/60000 (33%) of train data\u001b[0m\n",
      "\u001b[32mDEBUG:__main__:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [6400/20000 (32%)] Loss: 2.076494\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [12800/20000 (64%)] Loss: 1.229461\u001b[0m\n",
      "\u001b[32mINFO:__main__:Train Epoch: 1 [19200/20000 (96%)] Loss: 0.667853\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[32mINFO:__main__:Test set: Average loss: 0.4341, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-04 02:20:43,461 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-04 02:21:14 Completed - Training job completed\n",
      "Training seconds: 342\n",
      "Billable seconds: 342\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "local_dir = 'data'\n",
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "MNIST(\n",
    "    local_dir,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=local_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"mnist.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version='py3',\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"}, # set epochs to a more realistic number for real training\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-monitoring",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Prepare batch inference data\n",
    "\n",
    "First, convert the test data into png image; second, upload to your default S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "criminal-connection",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls data/MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "subject-password",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# untar gz => png\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "with gzip.open(os.path.join(local_dir, 'MNIST/raw','t10k-images-idx3-ubyte.gz'),  'rb') as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjusted-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "determined-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 100 of test images and upload them to S3\n",
    "\n",
    "import random\n",
    "from PIL import Image as im\n",
    "\n",
    "ids = random.sample(range(len(images)), 100)\n",
    "ids = np.array(ids, dtype=np.int)\n",
    "selected_images = images[ids]\n",
    "\n",
    "image_dir = 'data/images'\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "for i, img in enumerate(selected_images):\n",
    "    pngimg = im.fromarray(img)\n",
    "    pngimg.save(os.path.join(image_dir, f'{i}.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fancy-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['78.png',\n",
       " '2.png',\n",
       " '21.png',\n",
       " '59.png',\n",
       " '85.png',\n",
       " '97.png',\n",
       " '37.png',\n",
       " '27.png',\n",
       " '20.png',\n",
       " '47.png',\n",
       " '48.png',\n",
       " '18.png',\n",
       " '68.png',\n",
       " '94.png',\n",
       " '46.png',\n",
       " '62.png',\n",
       " '43.png',\n",
       " '82.png',\n",
       " '33.png',\n",
       " '80.png',\n",
       " '57.png',\n",
       " '83.png',\n",
       " '70.png',\n",
       " '35.png',\n",
       " '10.png',\n",
       " '17.png',\n",
       " '52.png',\n",
       " '26.png',\n",
       " '92.png',\n",
       " '75.png',\n",
       " '56.png',\n",
       " '32.png',\n",
       " '79.png',\n",
       " '15.png',\n",
       " '7.png',\n",
       " '51.png',\n",
       " '9.png',\n",
       " '34.png',\n",
       " '74.png',\n",
       " '5.png',\n",
       " '72.png',\n",
       " '8.png',\n",
       " '93.png',\n",
       " '69.png',\n",
       " '31.png',\n",
       " '96.png',\n",
       " '11.png',\n",
       " '28.png',\n",
       " '24.png',\n",
       " '84.png',\n",
       " '55.png',\n",
       " '81.png',\n",
       " '64.png',\n",
       " '65.png',\n",
       " '39.png',\n",
       " '76.png',\n",
       " '67.png',\n",
       " '66.png',\n",
       " '1.png',\n",
       " '98.png',\n",
       " '77.png',\n",
       " '30.png',\n",
       " '58.png',\n",
       " '71.png',\n",
       " '73.png',\n",
       " '86.png',\n",
       " '89.png',\n",
       " '44.png',\n",
       " '91.png',\n",
       " '99.png',\n",
       " '13.png',\n",
       " '19.png',\n",
       " '14.png',\n",
       " '0.png',\n",
       " '60.png',\n",
       " '49.png',\n",
       " '61.png',\n",
       " '36.png',\n",
       " '38.png',\n",
       " '42.png',\n",
       " '3.png',\n",
       " '88.png',\n",
       " '53.png',\n",
       " '22.png',\n",
       " '63.png',\n",
       " '40.png',\n",
       " '54.png',\n",
       " '87.png',\n",
       " '95.png',\n",
       " '4.png',\n",
       " '25.png',\n",
       " '6.png',\n",
       " '90.png',\n",
       " '50.png',\n",
       " '12.png',\n",
       " '16.png',\n",
       " '23.png',\n",
       " '29.png',\n",
       " '41.png',\n",
       " '45.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "standard-mechanism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-688520471316/batch_transform\n"
     ]
    }
   ],
   "source": [
    "inference_prefix = 'batch_transform'\n",
    "inference_inputs = sagemaker_session.upload_data(path=image_dir, bucket=bucket, key_prefix=inference_prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inference_inputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-three",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Create model transformer\n",
    "Now, we will create a transformer object for handling creating and interacting with Amazon SageMaker transform jobs. We can create the transformer in two ways as shown in the following notebook cells.\n",
    "- use fitted estimator directly\n",
    "- first create PyTorchModel from saved model artefect, then create transformer from PyTorchModel object\n",
    "\n",
    "\n",
    "Here, we implement the `model_fn`, `input_fn`, `predict_fn` and `output_fn` function to override the default [PyTorch inference handler](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_inference_handler.py). \n",
    "\n",
    "It is noted that in `input_fn` function, the inferenced images are encoded as a Python ByteArray. That's why we use `load_from_bytearray` function to load image from `io.BytesIO` then use `PIL.image` to read.\n",
    "\n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "    \n",
    "def load_from_bytearray(request_body):\n",
    "    image_as_bytes = io.BytesIO(request_body)\n",
    "    image = Image.open(image_as_bytes)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    # if set content_type as 'image/jpg' or 'applicaiton/x-npy', \n",
    "    # the input is also a python bytearray\n",
    "    if request_content_type == 'application/x-image': \n",
    "        image_tensor = load_from_bytearray(request_body)\n",
    "    else:\n",
    "        print(\"not support this type yet\")\n",
    "        raise ValueError(\"not support this type yet\")\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "def predict_fn(input_object, model):\n",
    "    output = model.forward(input_object)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    return {'predictions':pred.item()}\n",
    "\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "def output_fn(predictions, response_content_type):\n",
    "    return json.dumps(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brave-redhead",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use fitted estimator directly\n",
    "transformer = estimator.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passive-radiation",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also create a Transformer object from saved model artefect\n",
    "\n",
    "# get model artefect location by estimator.model_data, or give a S3 key directly\n",
    "model_artefect_s3_location = estimator.model_data  #'s3://BUCKET/PREFIX/model.tar.gz'\n",
    "\n",
    "# create PyTorchModel from saved model artefect\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artefect_s3_location,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\".\",\n",
    "    entry_point=\"mnist.py\",\n",
    ")\n",
    "\n",
    "# then create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-drama",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Batch inference\n",
    "Next, we will inference the sampled 100 MNIST images in a batch manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-angle",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### input images directly from S3 location\n",
    "We set `S3DataType=S3Prefix` to uses all objects that match the specified S3 key name prefix for batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inner-alarm",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\u001b[34m2021-06-04 02:26:06,034 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 948 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,064 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,083 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 96b58220845b4c68a86326681b76deff\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,095 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,123 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,296 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,299 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,300 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,304 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,307 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,307 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,308 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,309 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,310 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,311 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,311 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,316 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,318 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,335 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,337 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,337 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,337 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,338 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,351 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,351 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,356 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,373 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,374 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,373 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:06,374 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,057 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,058 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.47443389892578|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,058 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.441478729248047|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,059 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.3|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,059 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6421.52734375|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,059 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:928.01953125|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,060 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:15.8|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,455 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 977\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,455 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1348|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,456 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:94|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,506 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1014\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,507 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1400|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,507 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:109|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,557 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1077\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,557 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1453|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,558 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:96|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,702 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1595|#Level:Host|#hostname:48befd686e86,timestamp:1622773567\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:07,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:89|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,623 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:36094 \"GET /ping HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,623 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,646 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:36102 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,647 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,720 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:6f9cdfa9-7930-4bd9-9e70-b53ff5fbadbf,timestamp:1622773571\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,721 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,800 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,801 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,801 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.03|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4b18c979-2654-4beb-993a-7bb5d2bf924f,timestamp:1622773571\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,801 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,802 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:11,802 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,003 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,004 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.96|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:25d6b3bd-f851-4506-be6f-22dc7a8fa158,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,005 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,005 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,005 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,006 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,264 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,264 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,264 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,267 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.61|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:930ae658-417d-4cb7-a9d8-7cefb2ff3195,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,339 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,339 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.52|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2b6c3824-b36a-42a1-aaf6-2317370fe2d7,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,340 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,340 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,340 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,340 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,422 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,422 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,423 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,423 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,423 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.75|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:001f3a0d-dcd7-4cd2-8bb9-fcf0f5ab8590,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,423 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,517 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,517 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:1b378d98-c491-4f80-8dc7-fdea2b086362,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,517 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,517 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,518 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,518 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,616 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,616 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f96c6620-480d-4f1f-9fb8-5db67ff9c2a3,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,688 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,616 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,616 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f96c6620-480d-4f1f-9fb8-5db67ff9c2a3,timestamp:1622773572\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,617 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,688 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,688 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:bb8fc413-7410-4cf6-8144-26a286d353d9,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,793 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.94|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9654a17d-d3d4-41b3-a932-d4b690dbfa2e,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,793 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:c37c8491-38f9-464c-9312-383fd201a2b3,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,901 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,901 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,996 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,996 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8b935231-14b9-4c79-9100-24d9c7422d35,timestamp:1622773572\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,688 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:bb8fc413-7410-4cf6-8144-26a286d353d9,timestamp:1622773572\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,689 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,793 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.94|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9654a17d-d3d4-41b3-a932-d4b690dbfa2e,timestamp:1622773572\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,793 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,794 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,900 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:c37c8491-38f9-464c-9312-383fd201a2b3,timestamp:1622773572\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,901 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,901 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,996 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,996 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8b935231-14b9-4c79-9100-24d9c7422d35,timestamp:1622773572\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,112 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3c617b92-9815-4712-9a50-fa84d969e471,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:12,997 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,112 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.58|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3c617b92-9815-4712-9a50-fa84d969e471,timestamp:1622773573\u001b[0m\n",
      "\u001b[32m2021-06-04T02:26:11.654:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,213 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f70ad06f-2cf4-423b-b168-97ff4b871b22,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,214 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,214 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,335 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,335 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f0cf29ff-dc9b-46d0-ad4c-ed30da3367a7,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,335 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,336 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,336 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,336 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:cb31f9da-f623-4f5e-9a04-0e1e6805662a,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:53db78e2-d64f-4485-98e6-d35f39380d37,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,113 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,213 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f70ad06f-2cf4-423b-b168-97ff4b871b22,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,214 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,214 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,335 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,335 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f0cf29ff-dc9b-46d0-ad4c-ed30da3367a7,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,335 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,336 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,336 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,336 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:cb31f9da-f623-4f5e-9a04-0e1e6805662a,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,439 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:53db78e2-d64f-4485-98e6-d35f39380d37,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,554 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:ad13d9ce-9f38-470f-a766-c4b1e67b4452,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,742 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:76ba99ce-e9da-4da1-9a04-effbe338d0e2,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,744 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:b82672e9-f349-401b-b8f2-2b61adb43fd8,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.92|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:ad13d9ce-9f38-470f-a766-c4b1e67b4452,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,653 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,742 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:76ba99ce-e9da-4da1-9a04-effbe338d0e2,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,744 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,745 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:b82672e9-f349-401b-b8f2-2b61adb43fd8,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,826 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,826 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,927 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,927 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:c6651804-7cfb-4746-94e2-9e32154793cb,timestamp:1622773573\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e37f3095-65c4-4688-a234-437f8e7f53f7,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,147 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:1c8c6671-58b1-4e88-8603-c7bf9c3d1615,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:870e5df4-23a9-4958-b8c0-0bfcfd790942,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,255 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,255 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,334 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,334 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:66261ceb-0102-413e-bb3d-9b63d70564ef,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,825 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,826 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,826 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,927 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,927 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:c6651804-7cfb-4746-94e2-9e32154793cb,timestamp:1622773573\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:13,928 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e37f3095-65c4-4688-a234-437f8e7f53f7,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,070 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,147 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:1c8c6671-58b1-4e88-8603-c7bf9c3d1615,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,148 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,254 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.44|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:870e5df4-23a9-4958-b8c0-0bfcfd790942,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,255 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,255 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,334 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,334 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:66261ceb-0102-413e-bb3d-9b63d70564ef,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,335 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,435 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,435 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.95|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:aa390b5c-fdb2-4563-9987-87c32994edf8,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,435 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,436 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,436 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,436 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:81186fee-22c1-436f-85ce-101eccf4dd3b,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,435 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,435 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.95|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:aa390b5c-fdb2-4563-9987-87c32994edf8,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,435 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,436 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,436 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,436 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:81186fee-22c1-436f-85ce-101eccf4dd3b,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,675 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,676 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,676 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:fdd137b7-3f01-461d-871c-f601872fc21c,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,762 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,762 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:08f6f65a-587e-422f-acda-130709c82623,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,762 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,763 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,763 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,763 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,675 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,676 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,676 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:fdd137b7-3f01-461d-871c-f601872fc21c,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,762 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,762 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:08f6f65a-587e-422f-acda-130709c82623,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,762 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,763 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,763 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,763 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:143e8ec8-0858-4368-a0dc-9947d185630a,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,939 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:006e231b-85ad-41bf-9dde-8d5e69a23176,timestamp:1622773574\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,939 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,019 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4b6c5791-d915-4c4c-8f15-e7e9b7d5ce7d,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,019 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,099 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,099 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.52|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:20bcb766-d286-43c7-8bd9-77f2d05b7598,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,099 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,100 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,100 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,100 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,217 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2fbc0e8e-fc3f-47b6-9826-0e80014227ae,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:5013cd95-e0d1-47c8-a62b-e215cc370027,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,311 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,311 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,387 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:52e28495-8b2d-413d-b18e-bc4205be17a8,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:0081a6d3-b72d-4de5-9d72-dad3f8164e96,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.66|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:143e8ec8-0858-4368-a0dc-9947d185630a,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,857 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,939 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:006e231b-85ad-41bf-9dde-8d5e69a23176,timestamp:1622773574\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,939 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:14,940 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,019 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4b6c5791-d915-4c4c-8f15-e7e9b7d5ce7d,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,019 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,020 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,099 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,099 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.52|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:20bcb766-d286-43c7-8bd9-77f2d05b7598,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,099 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,100 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,100 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,100 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,217 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2fbc0e8e-fc3f-47b6-9826-0e80014227ae,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:5013cd95-e0d1-47c8-a62b-e215cc370027,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,310 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,311 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,311 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,387 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:52e28495-8b2d-413d-b18e-bc4205be17a8,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,388 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:0081a6d3-b72d-4de5-9d72-dad3f8164e96,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,496 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,611 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8871b214-d4a5-47d1-a3f8-2c204ced75d2,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:6aebcf77-38ee-4923-a690-3f4bf5e8547a,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,884 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,884 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2d6f9a0f-cd7b-43c9-9063-4c81b4ddc919,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,884 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,885 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,885 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,885 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,966 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,966 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e50f6f33-bdfd-4319-8ec2-27bb3554611d,timestamp:1622773575\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d16a0f8f-96b8-4b3c-8ddf-2b347fdba7cf,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:be4cae2d-eb16-4455-86ed-f3a697fb8cf8,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,136 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,136 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,267 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e2361442-7f0e-4996-bcdc-5e20c9fda7a5,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,348 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3357c403-c316-4121-8a85-3088de4d796c,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,611 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8871b214-d4a5-47d1-a3f8-2c204ced75d2,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,612 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:6aebcf77-38ee-4923-a690-3f4bf5e8547a,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,747 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,884 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,884 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2d6f9a0f-cd7b-43c9-9063-4c81b4ddc919,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,884 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,885 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,885 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,885 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,966 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,966 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e50f6f33-bdfd-4319-8ec2-27bb3554611d,timestamp:1622773575\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:15,967 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d16a0f8f-96b8-4b3c-8ddf-2b347fdba7cf,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,059 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:be4cae2d-eb16-4455-86ed-f3a697fb8cf8,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,135 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,136 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,136 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,267 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e2361442-7f0e-4996-bcdc-5e20c9fda7a5,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,268 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,348 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.64|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3357c403-c316-4121-8a85-3088de4d796c,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:bc0b8ae8-08e6-44fc-9c69-ace1254565b4,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,350 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:bc0b8ae8-08e6-44fc-9c69-ace1254565b4,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,480 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,595 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,595 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8731f7f2-9864-4e8c-a489-f877b1291b01,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9bc0128b-3ba4-4e63-9af1-7e9eca5b8a77,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2332a516-4472-4416-80ca-124ed5699e96,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,798 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,798 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e4de7100-c297-4299-a252-64372e36cbcf,timestamp:1622773576\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:16,899 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:55fe0459-38ab-489b-94f4-019eb1640232,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,595 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,595 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8731f7f2-9864-4e8c-a489-f877b1291b01,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,596 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9bc0128b-3ba4-4e63-9af1-7e9eca5b8a77,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,686 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2332a516-4472-4416-80ca-124ed5699e96,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,797 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,798 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,798 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e4de7100-c297-4299-a252-64372e36cbcf,timestamp:1622773576\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,898 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:16,899 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:55fe0459-38ab-489b-94f4-019eb1640232,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,003 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,004 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,004 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,100 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,101 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.11|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:7ea5e64f-bc7b-41c1-8cfa-2bb35d0e7fa3,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,238 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,238 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:62ec143c-bab7-4943-95a2-4858dd634307,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,344 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:0f8bbc41-c0cd-46dc-85b6-40244dafe13c,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,459 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,459 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:cffcdcd8-451b-4cf3-8935-fbc67d869833,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,459 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,460 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,460 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,460 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4779bc59-4004-4b5c-bd4d-e05c48a63999,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,561 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,561 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,004 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,004 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,099 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,100 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,101 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.11|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:7ea5e64f-bc7b-41c1-8cfa-2bb35d0e7fa3,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,238 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,238 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:62ec143c-bab7-4943-95a2-4858dd634307,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,239 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,343 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,344 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:0f8bbc41-c0cd-46dc-85b6-40244dafe13c,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,459 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,459 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:cffcdcd8-451b-4cf3-8935-fbc67d869833,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,459 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,460 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,460 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,460 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,560 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4779bc59-4004-4b5c-bd4d-e05c48a63999,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,561 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,561 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,639 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,639 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2f8bcc5a-b067-4624-acaf-767fc0c33a74,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8cc1eaaf-02b0-4437-9767-9acfbae14447,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,639 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,639 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:2f8bcc5a-b067-4624-acaf-767fc0c33a74,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,640 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:8cc1eaaf-02b0-4437-9767-9acfbae14447,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e10bf879-beb1-45b0-a743-05baf45dbd6e,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:086903ca-48d0-425c-ba78-f0229c0772ad,timestamp:1622773577\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:82a2ff1a-75dd-4945-8d99-7846b1a05d65,timestamp:1622773578\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,064 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,064 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,724 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e10bf879-beb1-45b0-a743-05baf45dbd6e,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,815 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:086903ca-48d0-425c-ba78-f0229c0772ad,timestamp:1622773577\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:17,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.61|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:82a2ff1a-75dd-4945-8d99-7846b1a05d65,timestamp:1622773578\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,063 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,064 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,064 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.15|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:ff531513-8db1-4fce-b4d4-cc2387ac4d9e,timestamp:1622773578\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.15|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:ff531513-8db1-4fce-b4d4-cc2387ac4d9e,timestamp:1622773578\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,847 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,847 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,982 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.86|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:27b05d9a-7b85-4c0d-98c5-d4e2307a9489,timestamp:1622773578\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,108 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:fc3d0366-ee63-4110-8146-fccb5c5500c8,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,207 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,207 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:aeb001ef-023f-4baa-aa3c-603c33b2b2f7,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,294 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:5a663b95-9e95-4229-b73d-3f3fbb374d27,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:256c5c0b-8eba-4e62-8eeb-fb46d64c2a40,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,846 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,847 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,847 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,982 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.86|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:27b05d9a-7b85-4c0d-98c5-d4e2307a9489,timestamp:1622773578\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:18,983 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,108 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.85|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:fc3d0366-ee63-4110-8146-fccb5c5500c8,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,109 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,207 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,207 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:aeb001ef-023f-4baa-aa3c-603c33b2b2f7,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,208 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,294 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:5a663b95-9e95-4229-b73d-3f3fbb374d27,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:256c5c0b-8eba-4e62-8eeb-fb46d64c2a40,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:52712226-d19d-4de5-a1a9-49fcbde31dcc,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,500 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:29550e4c-435d-4145-8bdd-7f8ca137f263,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,394 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:52712226-d19d-4de5-a1a9-49fcbde31dcc,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,499 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,500 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.83|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:29550e4c-435d-4145-8bdd-7f8ca137f263,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,574 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,651 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:15c55a68-ad9e-409b-868d-7314fed33cd6,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d98f9f52-3c47-4d0b-b44f-afdc81ffe470,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,782 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,906 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:a486a0c0-e06e-4f38-9463-a3629e4816bb,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:600a3ac7-0793-497c-9202-a96797df80fc,timestamp:1622773579\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:76d4f958-3122-4b0a-8968-7477aab808d2,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,191 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,191 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:bd959662-0c2b-415e-b9f6-7f1a1585f8fd,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,326 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,326 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:0b2e67ea-f80c-4b31-831b-92f05ebff92f,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3b7a5f17-45e7-4fe7-bd03-bfc55abb0542,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,555 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:54eaefea-6fd8-496f-aac3-d6d9b11aa08e,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,555 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,555 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,556 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,651 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:15c55a68-ad9e-409b-868d-7314fed33cd6,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.91|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d98f9f52-3c47-4d0b-b44f-afdc81ffe470,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,781 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,782 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,906 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:a486a0c0-e06e-4f38-9463-a3629e4816bb,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.29|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:600a3ac7-0793-497c-9202-a96797df80fc,timestamp:1622773579\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:19,979 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:76d4f958-3122-4b0a-8968-7477aab808d2,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,071 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,191 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,191 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:bd959662-0c2b-415e-b9f6-7f1a1585f8fd,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,192 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,326 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,326 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:0b2e67ea-f80c-4b31-831b-92f05ebff92f,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,327 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3b7a5f17-45e7-4fe7-bd03-bfc55abb0542,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,435 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,555 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:54eaefea-6fd8-496f-aac3-d6d9b11aa08e,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,555 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,555 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,556 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,556 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,556 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,556 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,556 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,655 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:181d6fbb-31c8-409c-8c40-91f9ca87760b,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,655 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9377a252-4fd9-414c-b79b-b7acaf4db898,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,723 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,723 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9ce2dd89-7cc2-432b-aab3-45796df6ac95,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,809 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,809 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,933 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f5ee8c50-9e08-4f19-8496-7c5b9e7dc1eb,timestamp:1622773580\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,933 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,933 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,934 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,934 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:20,934 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,025 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,025 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:c20512cd-61da-41ba-84e8-fd0ad1d82c64,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,103 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:26e4e085-75a9-4c92-b82e-1798c8545d93,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,103 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,175 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,175 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:6b49281f-bc3b-450c-a4b8-211bd1d766bf,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,655 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:181d6fbb-31c8-409c-8c40-91f9ca87760b,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,655 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,656 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9377a252-4fd9-414c-b79b-b7acaf4db898,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,722 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,723 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,723 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:9ce2dd89-7cc2-432b-aab3-45796df6ac95,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,808 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,809 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,809 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,933 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.56|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:f5ee8c50-9e08-4f19-8496-7c5b9e7dc1eb,timestamp:1622773580\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,933 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,933 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,934 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,934 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:20,934 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,025 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,025 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:c20512cd-61da-41ba-84e8-fd0ad1d82c64,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,026 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,103 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:26e4e085-75a9-4c92-b82e-1798c8545d93,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,103 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,104 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,175 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,175 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:6b49281f-bc3b-450c-a4b8-211bd1d766bf,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d0a777f8-47a0-4096-98db-fa1e95eed8ab,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,355 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4bbd2afa-f0c6-4f80-9755-32ad87075237,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,355 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:a1425d4c-3755-49a9-a7e7-398aa312a596,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,447 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,447 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:b307b445-4319-442d-867f-a619b80953a8,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,176 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d0a777f8-47a0-4096-98db-fa1e95eed8ab,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,267 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,355 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:4bbd2afa-f0c6-4f80-9755-32ad87075237,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,355 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,356 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:a1425d4c-3755-49a9-a7e7-398aa312a596,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,446 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,447 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,447 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:b307b445-4319-442d-867f-a619b80953a8,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,551 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:66ce5744-bc1d-49cc-a630-6346857aaf28,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,755 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,755 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,756 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,756 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,756 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:66ce5744-bc1d-49cc-a630-6346857aaf28,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,755 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,755 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,756 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,756 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,756 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,755 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:a49ea389-e689-4809-b654-7e47cb19b285,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,854 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,854 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3788112c-e7b1-406f-83da-b5e1e9f4b71f,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:21ccec25-7c1c-4c3e-a14a-ab510cb1cc03,timestamp:1622773581\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:21,928 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e8fb9b93-18aa-43aa-8700-7518a589dff6,timestamp:1622773582\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,026 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,026 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:83ccfc21-1e41-40c8-a6f4-3c7c67111466,timestamp:1622773582\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3cee8a41-66de-49ae-a8b0-9cd015e47080,timestamp:1622773582\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,198 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,198 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d7eef913-7998-40c0-8980-cb221bec9142,timestamp:1622773582\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,320 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,320 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:1d05d009-9c64-4bc3-adee-afa76f42442d,timestamp:1622773582\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[34m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,755 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:a49ea389-e689-4809-b654-7e47cb19b285,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,854 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,854 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3788112c-e7b1-406f-83da-b5e1e9f4b71f,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:21ccec25-7c1c-4c3e-a14a-ab510cb1cc03,timestamp:1622773581\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,927 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:21,928 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:e8fb9b93-18aa-43aa-8700-7518a589dff6,timestamp:1622773582\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,025 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,026 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,026 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:83ccfc21-1e41-40c8-a6f4-3c7c67111466,timestamp:1622773582\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:3cee8a41-66de-49ae-a8b0-9cd015e47080,timestamp:1622773582\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,197 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,198 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,198 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:d7eef913-7998-40c0-8980-cb221bec9142,timestamp:1622773582\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,319 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,320 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,320 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:36106 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:48befd686e86,requestID:1d05d009-9c64-4bc3-adee-afa76f42442d,timestamp:1622773582\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\u001b[35m2021-06-04 02:26:22,524 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:48befd686e86,timestamp:null\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=inference_inputs, data_type=\"S3Prefix\", content_type=\"application/x-image\", wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-documentary",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### input images by manifest file\n",
    "First, we generate a manifest file. Then we use the manifest file containing a list of object keys that you want to batch inference. Some key points:\n",
    "- content_type = 'application/x-image' (!!! here the content_type is for the actual object to be inference, not for the manifest file)\n",
    "- data_type = 'ManifestFile'\n",
    "- Manifest file format must follow the format as [this document](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html#SageMaker-Type-S3DataSource-S3DataType) pointed out. We create the manifest file by using jsonlines package.\n",
    "``` json\n",
    "[ {\"prefix\": \"s3://customer_bucket/some/prefix/\"},\n",
    "\"relative/path/to/custdata-1\",\n",
    "\"relative/path/custdata-2\",\n",
    "...\n",
    "\"relative/path/custdata-N\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "included-street",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "related-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_files\n",
      " ['78.png', '2.png', '21.png', '59.png', '85.png', '97.png', '37.png', '27.png', '20.png', '47.png', '48.png', '18.png', '68.png', '94.png', '46.png', '62.png', '43.png', '82.png', '33.png', '80.png', '57.png', '83.png', '70.png', '35.png', '10.png', '17.png', '52.png', '26.png', '92.png', '75.png', '56.png', '32.png', '79.png', '15.png', '7.png', '51.png', '9.png', '34.png', '74.png', '5.png', '72.png', '8.png', '93.png', '69.png', '31.png', '96.png', '11.png', '28.png', '24.png', '84.png', '55.png', '81.png', '64.png', '65.png', '39.png', '76.png', '67.png', '66.png', '1.png', '98.png', '77.png', '30.png', '58.png', '71.png', '73.png', '86.png', '89.png', '44.png', '91.png', '99.png', '13.png', '19.png', '14.png', '0.png', '60.png', '49.png', '61.png', '36.png', '38.png', '42.png', '3.png', '88.png', '53.png', '22.png', '63.png', '40.png', '54.png', '87.png', '95.png', '4.png', '25.png', '6.png', '90.png', '50.png', '12.png', '16.png', '23.png', '29.png', '41.png', '45.png']\n",
      "manifest_content\n",
      " [{'prefix': 's3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/images/'}, '78.png', '2.png', '21.png', '59.png', '85.png', '97.png', '37.png', '27.png', '20.png', '47.png', '48.png', '18.png', '68.png', '94.png', '46.png', '62.png', '43.png', '82.png', '33.png', '80.png', '57.png', '83.png', '70.png', '35.png', '10.png', '17.png', '52.png', '26.png', '92.png', '75.png', '56.png', '32.png', '79.png', '15.png', '7.png', '51.png', '9.png', '34.png', '74.png', '5.png', '72.png', '8.png', '93.png', '69.png', '31.png', '96.png', '11.png', '28.png', '24.png', '84.png', '55.png', '81.png', '64.png', '65.png', '39.png', '76.png', '67.png', '66.png', '1.png', '98.png', '77.png', '30.png', '58.png', '71.png', '73.png', '86.png', '89.png', '44.png', '91.png', '99.png', '13.png', '19.png', '14.png', '0.png', '60.png', '49.png', '61.png', '36.png', '38.png', '42.png', '3.png', '88.png', '53.png', '22.png', '63.png', '40.png', '54.png', '87.png', '95.png', '4.png', '25.png', '6.png', '90.png', '50.png', '12.png', '16.png', '23.png', '29.png', '41.png', '45.png']\n",
      "manifest_obj\n",
      " s3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "# build image list\n",
    "manifest_prefix = f\"s3://{bucket}/{prefix}/images/\"\n",
    "\n",
    "path = image_dir\n",
    "img_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "print('img_files\\n', img_files)\n",
    "\n",
    "manifest_content = [{\"prefix\": manifest_prefix}]\n",
    "manifest_content.extend(img_files)\n",
    "\n",
    "print('manifest_content\\n', manifest_content)\n",
    "\n",
    "# write jsonl file\n",
    "manifest_file = \"manifest.json\"\n",
    "with jsonlines.open(manifest_file, mode=\"w\") as writer:\n",
    "    writer.write(manifest_content)\n",
    "    \n",
    "# upload to S3\n",
    "manifest_obj = sagemaker_session.upload_data(path=manifest_file, key_prefix=prefix)\n",
    "\n",
    "print('manifest_obj\\n', manifest_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "common-summer",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch transform with manifest file\n",
    "transform_job = transformer.transform(\n",
    "    data=manifest_obj, data_type=\"ManifestFile\", content_type=\"application/x-image\", wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reserved-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest transform job \n",
      " pytorch-inference-2021-06-04-02-27-00-599\n"
     ]
    }
   ],
   "source": [
    "print('latest transform job \\n', transformer.latest_transform_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dangerous-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 6, 4, 2, 27, 0, 858000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2021-06-04-02-22-15-009',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '870',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Fri, 04 Jun 2021 02:27:00 GMT',\n",
      "                                      'x-amzn-requestid': '66a7c4b7-7c3d-4471-8399-431f35b7afde'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '66a7c4b7-7c3d-4471-8399-431f35b7afde',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'ManifestFile',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-688520471316/sagemaker/DEMO-pytorch-batch-inference-script/manifest.json'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-04-02-27-00-599',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-04-02-27-00-599',\n",
      " 'TransformJobStatus': 'InProgress',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-688520471316/pytorch-inference-2021-06-04-02-27-00-599'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.c5.xlarge'}}\n"
     ]
    }
   ],
   "source": [
    "# look at the status of the transform job\n",
    "import boto3\n",
    "import pprint as pp\n",
    "\n",
    "sm_cli = boto3.client('sagemaker')\n",
    "\n",
    "res = sm_cli.describe_transform_job(\n",
    "    TransformJobName=transformer.latest_transform_job.name\n",
    ")\n",
    "\n",
    "pp.pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-printer",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "###  Multiple instance\n",
    "We use `instance_count > 1` to create multiple inference instances. When a batch transform job starts, Amazon SageMaker initializes compute instances and distributes the inference or preprocessing workload between them. Batch Transform partitions the Amazon S3 objects in the input by key and maps Amazon S3 objects to instances. When you have multiples files, one instance might process input1.csv, and another instance might process the file named input2.csv.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intimate-picture",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_transformer = estimator.transformer(instance_count=2, instance_type=\"ml.c4.xlarge\")\n",
    "\n",
    "dist_transformer.transform(\n",
    "    data=inference_inputs, data_type=\"S3Prefix\", content_type=\"application/x-image\", wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-halifax",
   "metadata": {},
   "source": [
    "## Look at all transform jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "modular-egypt",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 6, 4, 2, 27, 4, 117000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 4, 2, 27, 4, 117000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-04-02-27-01-672',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-04-02-27-01-672',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 4, 2, 27, 0, 858000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 4, 2, 27, 3, 800000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-04-02-27-00-599',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-04-02-27-00-599',\n",
      " 'TransformJobStatus': 'InProgress'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 4, 2, 22, 15, 413000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 4, 2, 26, 24, 700000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 4, 2, 26, 24, 697000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-04-02-22-15-240',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-04-02-22-15-240',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 22, 2, 3, 90000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 22, 7, 28, 16000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 22, 7, 28, 13000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/sagemaker-scikit-learn-2021-06-03-22-02-02-816',\n",
      " 'TransformJobName': 'sagemaker-scikit-learn-2021-06-03-22-02-02-816',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 7, 32, 528000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 21, 12, 2, 962000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 12, 2, 959000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-21-07-31-593',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-21-07-31-593',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 5, 25, 664000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 21, 10, 38, 638000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 10, 38, 636000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-03-21-05-25-297',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-03-21-05-25-297',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 21, 5, 19, 888000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 21, 9, 47, 923000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 21, 9, 47, 920000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-21-05-19-449',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-21-05-19-449',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 23, 34, 835000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 28, 14, 566000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 28, 14, 563000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-20-23-34-620',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-20-23-34-620',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 23, 27, 979000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 28, 12, 860000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 28, 12, 857000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-inference-2021-06-03-20-23-27-273',\n",
      " 'TransformJobName': 'pytorch-inference-2021-06-03-20-23-27-273',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2021, 6, 3, 20, 22, 33, 696000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 6, 3, 20, 28, 22, 94000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 3, 20, 28, 22, 92000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-03-20-22-33-397',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-03-20-22-33-397',\n",
      " 'TransformJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "tjs = sm_cli.list_transform_jobs()['TransformJobSummaries']\n",
    "for tj in tjs:\n",
    "    pp.pprint(tj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "nasty-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2021, 6, 4, 2, 27, 4, 117000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'Environment': {},\n",
      " 'ModelName': 'pytorch-training-2021-06-04-02-27-00-982',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '908',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Fri, 04 Jun 2021 02:36:18 GMT',\n",
      "                                      'x-amzn-requestid': 'dfa5913b-85aa-444d-9cad-1882e8eac6cc'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'dfa5913b-85aa-444d-9cad-1882e8eac6cc',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2021, 6, 4, 2, 32, 15, 196000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-688520471316/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:688520471316:transform-job/pytorch-training-2021-06-04-02-27-01-672',\n",
      " 'TransformJobName': 'pytorch-training-2021-06-04-02-27-01-672',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-688520471316/pytorch-training-2021-06-04-02-27-01-672'},\n",
      " 'TransformResources': {'InstanceCount': 2, 'InstanceType': 'ml.c4.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2021, 6, 4, 2, 30, 34, 445000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "res = sm_cli.describe_transform_job(\n",
    "    TransformJobName=dist_transformer.latest_transform_job.name\n",
    ")\n",
    "\n",
    "pp.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "roman-wednesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-688520471316 pytorch-training-2021-06-04-02-27-01-672\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_bucket_and_prefix(s3_output_path):\n",
    "    trim = re.sub('s3://', '', s3_output_path)\n",
    "    bucket, prefix = trim.split('/')\n",
    "    return bucket, prefix\n",
    "\n",
    "local_path = 'output' # where to save the output locally\n",
    "\n",
    "bucket, output_prefix = get_bucket_and_prefix(res['TransformOutput']['S3OutputPath'])\n",
    "print(bucket, output_prefix)\n",
    "\n",
    "sagemaker_session.download_data(path=local_path, bucket=bucket, key_prefix=output_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reduced-marking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png.out   24.png.out\t4.png.out   55.png.out\t70.png.out  86.png.out\n",
      "1.png.out   25.png.out\t40.png.out  56.png.out\t71.png.out  87.png.out\n",
      "10.png.out  26.png.out\t41.png.out  57.png.out\t72.png.out  88.png.out\n",
      "11.png.out  27.png.out\t42.png.out  58.png.out\t73.png.out  89.png.out\n",
      "12.png.out  28.png.out\t43.png.out  59.png.out\t74.png.out  9.png.out\n",
      "13.png.out  29.png.out\t44.png.out  6.png.out\t75.png.out  90.png.out\n",
      "14.png.out  3.png.out\t45.png.out  60.png.out\t76.png.out  91.png.out\n",
      "15.png.out  30.png.out\t46.png.out  61.png.out\t77.png.out  92.png.out\n",
      "16.png.out  31.png.out\t47.png.out  62.png.out\t78.png.out  93.png.out\n",
      "17.png.out  32.png.out\t48.png.out  63.png.out\t79.png.out  94.png.out\n",
      "18.png.out  33.png.out\t49.png.out  64.png.out\t8.png.out   95.png.out\n",
      "19.png.out  34.png.out\t5.png.out   65.png.out\t80.png.out  96.png.out\n",
      "2.png.out   35.png.out\t50.png.out  66.png.out\t81.png.out  97.png.out\n",
      "20.png.out  36.png.out\t51.png.out  67.png.out\t82.png.out  98.png.out\n",
      "21.png.out  37.png.out\t52.png.out  68.png.out\t83.png.out  99.png.out\n",
      "22.png.out  38.png.out\t53.png.out  69.png.out\t84.png.out\n",
      "23.png.out  39.png.out\t54.png.out  7.png.out\t85.png.out\n"
     ]
    }
   ],
   "source": [
    "!ls {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "colonial-arabic",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 2}\n",
      "{'predictions': 0}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 9}\n",
      "{'predictions': 3}\n",
      "{'predictions': 6}\n",
      "{'predictions': 3}\n",
      "{'predictions': 7}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 9}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 9}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 7}\n",
      "{'predictions': 5}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 8}\n",
      "{'predictions': 0}\n",
      "{'predictions': 8}\n",
      "{'predictions': 1}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 8}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 6}\n",
      "{'predictions': 2}\n",
      "{'predictions': 9}\n",
      "{'predictions': 5}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 9}\n",
      "{'predictions': 6}\n",
      "{'predictions': 0}\n",
      "{'predictions': 8}\n",
      "{'predictions': 7}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 6}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 7}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 7}\n",
      "{'predictions': 1}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 5}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 3}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 8}\n",
      "{'predictions': 7}\n",
      "{'predictions': 8}\n",
      "{'predictions': 6}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 9}\n",
      "{'predictions': 4}\n",
      "{'predictions': 8}\n",
      "{'predictions': 6}\n",
      "{'predictions': 7}\n",
      "{'predictions': 4}\n",
      "{'predictions': 6}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, 'r') as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 333.854918,
   "end_time": "2021-06-03T00:15:43.072184",
   "environment_variables": {},
   "exception": true,
   "input_path": "pytorch-mnist-batch-transform.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch-mnist-batch-transform-2021-06-03-00-06-06.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-03T00:10:09.217266",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01005530a5b1473b9f4a024b19c04c0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_968ed82ad8f0453e8f81a839df4428db",
       "placeholder": "​",
       "style": "IPY_MODEL_e4f0965e53ee40adb1ae44da87428325",
       "value": "  0%"
      }
     },
     "0995f6633c0f4facabe6759837c606ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1410dcfcd117434889e9594cdde4e1b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "18caaab41d6146c1824859691f6cb435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d823500ff0dc4c2198b83cd231f8bffe",
       "placeholder": "​",
       "style": "IPY_MODEL_7dab31892241494e8d27d38ca98e5aa6",
       "value": " 0/28881 [00:00&lt;?, ?it/s]"
      }
     },
     "19ef65b0ecae45bdbca066cea679878d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ceacd43f28744eb9b7a12f8276b6016",
        "IPY_MODEL_e44ddce6c5704f0b9495ee662806f5f6",
        "IPY_MODEL_7717cc87ebcc4c0581ae32848b40982c"
       ],
       "layout": "IPY_MODEL_59d0678977a343abb8a02dc5c9699b89"
      }
     },
     "2126024805384bff9b0409b4dc91e60c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "216ba33f9f1b486ebac2a6fce0510246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f94b5a0d68c541e894e325a0e2f899d2",
       "placeholder": "​",
       "style": "IPY_MODEL_633cc1cdb94e43a6a07559483496c60d",
       "value": "  0%"
      }
     },
     "23445154eb524df985b5a755fcbddd32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_216ba33f9f1b486ebac2a6fce0510246",
        "IPY_MODEL_c4f4f4bfe979469c9bc59ab73bbf518f",
        "IPY_MODEL_fe83e178358040eaa07f6198ba693fc9"
       ],
       "layout": "IPY_MODEL_cf1f337300394948bce741af7bcd8b8c"
      }
     },
     "235ae38cf16e4aacb95c3d16d9749da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c2474d5a8144bf8930fa5cc02c73ccf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5495428879544d6da73e2ed7e70f0c96",
        "IPY_MODEL_6e2a4641cd944d9a8196f4a836e90590",
        "IPY_MODEL_9179e5f467c8450a988b988d7da06090"
       ],
       "layout": "IPY_MODEL_596f8cbad0884ec79cf6ee757cc9f38a"
      }
     },
     "2ceacd43f28744eb9b7a12f8276b6016": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a540362f86774590851c1d0892bea723",
       "placeholder": "​",
       "style": "IPY_MODEL_bb9ebd025f05499da7b847b8ef7a9ff5",
       "value": ""
      }
     },
     "495839f4239743669d9ee61cfbc33967": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d62b9fde9104c8081b545c3933a077e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51a28ca59cf9407ea0e02da868d79ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5495428879544d6da73e2ed7e70f0c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_235ae38cf16e4aacb95c3d16d9749da3",
       "placeholder": "​",
       "style": "IPY_MODEL_fe60ae53dd1646ca91018ba20934948b",
       "value": ""
      }
     },
     "596f8cbad0884ec79cf6ee757cc9f38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59d0678977a343abb8a02dc5c9699b89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "633cc1cdb94e43a6a07559483496c60d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63a57f663bfa4a1585c1ba36501b6b23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e2a4641cd944d9a8196f4a836e90590": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb8c653eeeb24799bcc9279389fdb523",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b513a456776d40b496f035c64360db90",
       "value": 1
      }
     },
     "7717cc87ebcc4c0581ae32848b40982c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b63360561b34257b171498e67902dda",
       "placeholder": "​",
       "style": "IPY_MODEL_f86487d9a78940a394503b2bea77d756",
       "value": " 9920512/? [04:50&lt;00:00, 36552.15it/s]"
      }
     },
     "7bceed60fb344aa182dccc3dcf0ee886": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_01005530a5b1473b9f4a024b19c04c0e",
        "IPY_MODEL_e82a5227430443d98d29555fd77b2bd3",
        "IPY_MODEL_18caaab41d6146c1824859691f6cb435"
       ],
       "layout": "IPY_MODEL_63a57f663bfa4a1585c1ba36501b6b23"
      }
     },
     "7dab31892241494e8d27d38ca98e5aa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8b5b76e77cb14ecf95a310ba46ed86f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "9179e5f467c8450a988b988d7da06090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94ef992b73d44d829b863815da70111f",
       "placeholder": "​",
       "style": "IPY_MODEL_1410dcfcd117434889e9594cdde4e1b0",
       "value": " 1654784/? [00:47&lt;00:00, 33514.08it/s]"
      }
     },
     "94ef992b73d44d829b863815da70111f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "968ed82ad8f0453e8f81a839df4428db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b63360561b34257b171498e67902dda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a540362f86774590851c1d0892bea723": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b513a456776d40b496f035c64360db90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb9ebd025f05499da7b847b8ef7a9ff5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c0b88a223b374693b6b0c74db9ffe346": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "c4f4f4bfe979469c9bc59ab73bbf518f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b5b76e77cb14ecf95a310ba46ed86f5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51a28ca59cf9407ea0e02da868d79ebd",
       "value": 0
      }
     },
     "cf1f337300394948bce741af7bcd8b8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d823500ff0dc4c2198b83cd231f8bffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e44ddce6c5704f0b9495ee662806f5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0995f6633c0f4facabe6759837c606ba",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d62b9fde9104c8081b545c3933a077e",
       "value": 1
      }
     },
     "e4f0965e53ee40adb1ae44da87428325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e82a5227430443d98d29555fd77b2bd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0b88a223b374693b6b0c74db9ffe346",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_495839f4239743669d9ee61cfbc33967",
       "value": 0
      }
     },
     "eb4c77cfe2c54976aef8efc0e3207140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f86487d9a78940a394503b2bea77d756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f94b5a0d68c541e894e325a0e2f899d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb8c653eeeb24799bcc9279389fdb523": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "fe60ae53dd1646ca91018ba20934948b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe83e178358040eaa07f6198ba693fc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2126024805384bff9b0409b4dc91e60c",
       "placeholder": "​",
       "style": "IPY_MODEL_eb4c77cfe2c54976aef8efc0e3207140",
       "value": " 0/4542 [00:00&lt;?, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
