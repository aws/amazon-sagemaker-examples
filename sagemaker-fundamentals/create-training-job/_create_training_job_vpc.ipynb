{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Job in Internet-free Mode\n",
    "\n",
    "If you want to isolate your training data and training container from the rest of the Internet, then you should create the training job in a private subnet. A private subnet is a subnet in your VPC without a route to Internet Gateway. This means, by default, no inbounding calls to your container from the Internet is possible and your container cannot make outbounding calls to the Internet. If you need the training container to access your S3 resource, you need to **explicitly** add a VPC endpoint and attach it to the route table of your private subnet to allow traffic to your data in S3 bucket. \n",
    "\n",
    "In this notebook, we will walk through an example of creating such a training job. We will\n",
    "\n",
    "- Build a simple training image\n",
    "- Set up a VPC\n",
    "- Set up a private subnet in the VPC\n",
    "- Set up a security group in the VPC\n",
    "- Create a training job in your private subnet && security group and watch it to fail (because it cannot access your S3 resource)\n",
    "- Add a VPC endpoint to allow traffic to S3\n",
    "- Create another training job in your private subnet and watch it to succeeed \n",
    "\n",
    "If you are not familiar with VPC security configuration, the following materials can help you\n",
    "- [Security in Amazon Virtual Private Cloud](https://docs.aws.amazon.com/vpc/latest/userguide/security.html)\n",
    "- [Training and Inference Containers in Internet-Free Mode](https://docs.aws.amazon.com/sagemaker/latest/dg/mkt-algo-model-internet-free.html)\n",
    "\n",
    "It's okay if you don't understand everything from the official docs above, the code samples you will see in this notebook will help you grasp those concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "import pprint\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "If you are running this notebook on an EC2 instance with an IAM user (you) as the default profile, then you will need policies to allow you to create VPC / Subnet / Secruity group / VPC endpoint.\n",
    "\n",
    "Likewise, if you are running this notebook on a SageMaker notebook instance or Studio, the service role needs to have those permission as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a training image\n",
    "\n",
    "We follow the same procedure for building a training image as in [this notebook](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create-training-job.ipynb). We will refer to this image as `example-image`. Please go through that notebook if you are not familiar with `CreateTrainingJob` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a repo in your ECR \n",
    "\n",
    "ecr = boto3.client('ecr')\n",
    "\n",
    "try:\n",
    "    # The repository might already exist\n",
    "    # in your ECR\n",
    "    cr_res = ecr.create_repository(\n",
    "        repositoryName='example-image')\n",
    "    pp.pprint(cr_res)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# build the image\n",
    "cd container/\n",
    "\n",
    "# tag it as example-image:latest\n",
    "docker build -t example-image:latest .\n",
    "    \n",
    "# test the container\n",
    "python local_test/test_container.py\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account | sed -e 's/^\"//' -e 's/\"$//')\n",
    "region=$(aws configure get region)\n",
    "ecr_account=${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "# Give docker your ECR login password\n",
    "aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $ecr_account\n",
    "\n",
    "# Fullname of the repo\n",
    "fullname=$ecr_account/example-image:latest\n",
    "\n",
    "# Tag the image with the fullname\n",
    "docker tag example-image:latest $fullname\n",
    "\n",
    "# Push to ECR\n",
    "docker push $fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a VPC\n",
    "\n",
    "You can think of Amazon VPC as the traditional network in a data center in the cloud. \n",
    "\n",
    "The following are the key concepts for VPCs: \n",
    "* Virtual private cloud (VPC) — A virtual network dedicated to your AWS account.\n",
    "* Subnet — A range of IP addresses in your VPC.\n",
    "* Route table — A set of rules, called routes, that are used to determine where network traffic is directed.\n",
    "* Internet gateway — A gateway that you attach to your VPC to enable communication between resources in your VPC and the internet.\n",
    "* VPC endpoint — Enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network. For more information, see AWS PrivateLink and VPC endpoints.\n",
    "* CIDR block —Classless Inter-Domain Routing. An internet protocol address allocation and route aggregation methodology. For more information, see [Classless Inter-Domain Routing](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation) in Wikipedia.\n",
    "\n",
    "All of these concepts are explained in the [official docs](https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VPC in your default region\n",
    "\n",
    "ec2 = boto3.client('ec2')\n",
    "\n",
    "vpc_res = ec2.create_vpc(\n",
    "    CidrBlock='10.0.0.0/20', # 2^(32 - 20) = 4906 private ipv4 addrs\n",
    "    AmazonProvidedIpv6CidrBlock=False,\n",
    "    DryRun=False,\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            'ResourceType': 'vpc', \n",
    "            'Tags':[\n",
    "                {\n",
    "                    'Key': 'Name',\n",
    "                    'Value': 'hello-world'\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(vpc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect this VPC in details\n",
    "\n",
    "vpc_des = ec2.describe_vpcs(\n",
    "    VpcIds=[vpc_res['Vpc']['VpcId']]\n",
    "    )\n",
    "pp.pprint(vpc_des['Vpcs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subnet and associate it with route table\n",
    "\n",
    "def get_first_availability_zone():\n",
    "    region_name = boto3.Session().region_name\n",
    "    avz_res = ec2.describe_availability_zones(\n",
    "        Filters=[\n",
    "            {\n",
    "                \"Name\": \"region-name\",\n",
    "                \"Values\": [region_name]\n",
    "            }\n",
    "        ],\n",
    "        AllAvailabilityZones=True,\n",
    "    )\n",
    "    \n",
    "    for az in avz_res['AvailabilityZones']:\n",
    "        if az['ZoneType']=='availability-zone':\n",
    "            return az\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def create_subnet(vpc_id, cidr_block, dry_run):\n",
    "    \"\"\"Create a subnet in the first availability zone in your current region\"\"\"\n",
    "    az = get_first_availability_zone()\n",
    "    if az is not None:\n",
    "        subnet_res = ec2.create_subnet(\n",
    "            AvailabilityZone = az['ZoneName'], #'us-west-2a',\n",
    "            VpcId = vpc_id,                    # vpc_res['Vpc']['VpcId'],\n",
    "            CidrBlock= cidr_block,             #'100.68.0.18/18',\n",
    "            DryRun=dry_run                     # True,\n",
    "        )\n",
    "        return subnet_res\n",
    "    else:\n",
    "        raise \"No availability zone\"\n",
    "        \n",
    "sn_res = create_subnet(\n",
    "    vpc_id=vpc_res['Vpc']['VpcId'],\n",
    "    cidr_block='10.0.0.0/28', # I want 2 ^ (32 - 28) private ipv4 in this subnet\n",
    "    dry_run=False)\n",
    "\n",
    "pp.pprint(sn_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a security group\n",
    "\n",
    "sg_res = ec2.create_security_group(\n",
    "    Description='security group for SageMaker instances',\n",
    "    GroupName='sagemaker-private',\n",
    "    VpcId=vpc_res['Vpc']['VpcId'],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": \"security-group\",\n",
    "            \"Tags\" : [\n",
    "                {   \n",
    "                    \"Key\": \"Service\", # Tag the sec gp by service, this can be used to filter sec gps\n",
    "                    \"Value\": \"SageMaker\" \n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "pp.pprint(sg_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the security group in detail\n",
    "\n",
    "ec2.describe_security_groups(\n",
    "    GroupIds=[\n",
    "        sg_res['GroupId']\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat a training job\n",
    "Now let's create a training job within your private subnet you just created. First, let's download some helper functions for creating service role for SageMaker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "file=$(ls . | grep iam_helpers.py)\n",
    "\n",
    "if [ -f \"$file\" ]\n",
    "then\n",
    "    rm $file\n",
    "fi\n",
    "\n",
    "wget https://raw.githubusercontent.com/hsl89/amazon-sagemaker-examples/sagemaker-fundamentals/sagemaker-fundamentals/execution-role/iam_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up service role for SageMaker\n",
    "\n",
    "sts = boto3.client('sts')\n",
    "caller = sts.get_caller_identity()\n",
    "\n",
    "if ':user/' in caller['Arn']: # as IAM user\n",
    "    # either paste in a role_arn with or create a new one and attach \n",
    "    # AmazonSageMakerFullAccess\n",
    "    role_name = 'example-sm'\n",
    "    role_arn = create_execution_role(role_name=role_name)['Role']['Arn']\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "    )\n",
    "elif 'assumed-role' in caller['Arn']: # on SageMaker infra\n",
    "    role_arn = caller['Arn']\n",
    "else:\n",
    "    print(\"I assume you are on an EC2 instance launched with an IAM role\")\n",
    "    role_arn = caller['Arn']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers\n",
    "def current_time():\n",
    "    ct = datetime.datetime.now() \n",
    "    return str(ct.now()).replace(\":\", \"-\").replace(\" \", \"-\")[:19]\n",
    "\n",
    "def account_id():\n",
    "    return boto3.client('sts').get_caller_identity()['Account']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this notebook self-contained, we will create a bucket and upload some data there to pass to training container as we did in the [basic create training job notebook](https://github.com/hsl89/amazon-sagemaker-examples/blob/sagemaker-fundamentals/sagemaker-fundamentals/create-training-job/create-training-job.ipynb). But you don't have to do so, if you already have a bucket that SageMaker service can access (i.e. a bucket with bucket name starts with `sagemaker`, see `AmazonSageMakerFullAccessPolicy`), then you can use \n",
    "that bucket as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bucket for SageMaker in your region if it does not exisit\n",
    "\n",
    "def create_bucket():\n",
    "    \"\"\"Create an S3 bucket that is intended to be used for short term\"\"\"\n",
    "    bucket = f\"sagemaker-{current_time()}\"\n",
    "    \n",
    "    region_name = boto3.Session().region_name\n",
    "    boto3.client('s3').create_bucket(\n",
    "        Bucket=bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': region_name\n",
    "        })\n",
    "    return bucket\n",
    "\n",
    "# replace it with your own SageMaker-accessible bucket \n",
    "# if you don't want to create a new one\n",
    "\n",
    "bucket = create_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload some mock data to your bucket\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "input_prefix = 'input_data'\n",
    "\n",
    "for fname in os.listdir('data'):\n",
    "    with open(os.path.join('data', fname), 'rb') as f:\n",
    "        key = input_prefix + fname\n",
    "        s3.upload_fileobj(f, bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_cli = boto3.client('sagemaker')\n",
    "\n",
    "\n",
    "# name training job\n",
    "training_job_name = 'example-training-job-{}'.format(current_time())\n",
    "\n",
    "data_path = \"s3://\" + bucket + '/' + input_prefix\n",
    "\n",
    "# location that SageMaker saves the model artifacts\n",
    "output_prefix = 'output/'\n",
    "output_path = \"s3://\" + bucket + '/' + output_prefix\n",
    "\n",
    "# ECR URI of your image\n",
    "region = boto3.Session().region_name\n",
    "account = account_id()\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/example-image:latest\".format(account, region)\n",
    "\n",
    "algorithm_specification = {\n",
    "    'TrainingImage': image_uri,\n",
    "    'TrainingInputMode': 'File',\n",
    "}\n",
    "\n",
    "\n",
    "input_data_config = [\n",
    "    {\n",
    "        'ChannelName': 'train',\n",
    "            'DataSource':{\n",
    "                'S3DataSource':{\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'S3Uri': data_path,\n",
    "                    'S3DataDistributionType': 'FullyReplicated',\n",
    "                }\n",
    "        }\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'ChannelName': 'test',\n",
    "        'DataSource':{\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': data_path,\n",
    "                'S3DataDistributionType': 'FullyReplicated',\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "    \n",
    "vpc_config = {\n",
    "    # security groups need to be configured to communicate \n",
    "    # with each other for distributed training job\n",
    "    'SecurityGroupIds' : [\n",
    "         sg_res['GroupId']\n",
    "    ],\n",
    "    'Subnets': [\n",
    "        sn_res['Subnet']['SubnetId']\n",
    "    ]\n",
    "}\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': output_path\n",
    "}\n",
    "\n",
    "resource_config = {\n",
    "    'InstanceType': 'ml.m5.large',\n",
    "    'InstanceCount':1,\n",
    "    'VolumeSizeInGB':5\n",
    "}\n",
    "\n",
    "stopping_condition={\n",
    "    'MaxRuntimeInSeconds':120,\n",
    "}\n",
    "\n",
    "enable_network_isolation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_res = sm_cli.create_training_job(\n",
    "    TrainingJobName=training_job_name,\n",
    "    AlgorithmSpecification=algorithm_specification,\n",
    "    RoleArn=role_arn,\n",
    "    InputDataConfig=input_data_config,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    VpcConfig=vpc_config,\n",
    "    ResourceConfig=resource_config,\n",
    "    StoppingCondition=stopping_condition,\n",
    "    EnableNetworkIsolation=enable_network_isolation,\n",
    "    EnableManagedSpotTraining=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the training job to fail\n",
    "stopped = False\n",
    "while not stopped:\n",
    "    tj_state = sm_cli.describe_training_job(TrainingJobName=training_job_name)\n",
    "    \n",
    "    if tj_state['TrainingJobStatus'] in ['Completed', 'Stopped', 'Failed']:\n",
    "        stopped=True\n",
    "    else:\n",
    "        print(\"Training in progress\")\n",
    "        time.sleep(30)\n",
    "\n",
    "if tj_state['TrainingJobStatus'] == 'Failed':\n",
    "    print(\"Training job failed \")\n",
    "    print(\"Failed Reason: {}\".format(tj_state['FailureReason']))\n",
    "else:\n",
    "    print(\"Training job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the failure message we expect to see. The subnet you created is isolated from the Internet and you have not created any mechanism for it to access your S3 resource. Therefore, SageMaker failed to download data from there. The error message also suggested ways to fix it: either add a route to S3 VPC endpoint or add a NAT device. We will explore the first option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a VPC endpoint\n",
    "\n",
    "A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. **Traffic between your VPC and the other service does not leave the Amazon network**. For more information, see [AWS PrivateLink and VPC endpoints](https://docs.aws.amazon.com/vpc/latest/userguide/endpoint-services-overview.html). \n",
    "\n",
    "There are three types of VPC endpoints at the time this notebook is published:\n",
    "\n",
    "A **gateway** endpoint serves as a target for a route in your route table for traffic destined for the AWS service. You can specify an endpoint policy to attach to the endpoint, which will control access to the service from your VPC. You can also specify the VPC route tables that use the endpoint.\n",
    "\n",
    "An **interface** endpoint is a network interface in your subnet that serves as an endpoint for communicating with the specified service. You can specify the subnets in which to create an endpoint, and the security groups to associate with the endpoint network interface.\n",
    "\n",
    "A **GatewayLoadBalancer** endpoint is a network interface in your subnet that serves an endpoint for communicating with a Gateway Load Balancer that you've configured as a VPC endpoint service.\n",
    "\n",
    "Both gateway and interface endpoint are viable options here. We will focus on interface endpoint here, because it saves us from additional configuration with route table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out service name for S3\n",
    "\n",
    "services = ec2.describe_vpc_endpoint_services()\n",
    "for s in services['ServiceNames']:\n",
    "    if 's3' in s:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a route table\n",
    "rt_res = ec2.create_route_table(\n",
    "    VpcId=vpc_res['Vpc']['VpcId'],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": 'route-table',\n",
    "            'Tags': [\n",
    "                {\n",
    "                    'Key': 'Service',\n",
    "                    'Value': 'SageMaker'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(rt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the route table with the subnet\n",
    "\n",
    "ass_rt_res = ec2.associate_route_table(\n",
    "    RouteTableId=rt_res['RouteTable']['RouteTableId'],\n",
    "    SubnetId=sn_res['Subnet']['SubnetId']\n",
    ")\n",
    "\n",
    "pp.pprint(ass_rt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gateway endpoint \n",
    "\n",
    "region_name = boto3.Session().region_name\n",
    "\n",
    "iep_res = ec2.create_vpc_endpoint(\n",
    "    VpcEndpointType='Gateway',\n",
    "    VpcId=vpc_res['Vpc']['VpcId'],\n",
    "    ServiceName=f'com.amazonaws.{region_name}.s3',\n",
    "    RouteTableIds=[rt_res['RouteTable']['RouteTableId']],\n",
    "    \n",
    "    # you don't need to add a tag, it is only\n",
    "    # used as a convenient way to filter through your \n",
    "    # endpoints in the future \n",
    "    TagSpecifications=[    \n",
    "        {\n",
    "            'ResourceType': 'vpc-endpoint',\n",
    "            'Tags' : [\n",
    "                {\n",
    "                    'Key' : 'Service',\n",
    "                    'Value': 'SageMaker'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "pp.pprint(iep_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have added a Gateway endpoint to the route table of the subnet. This endpoint allows the subnet to talk to your S3 bucket **privately**. The traffic between the subnet and your S3 bucket does not leave AWS network. Let's create another training job to verify that the training container can access the data in your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = 'example-training-job-{}'.format(current_time())\n",
    "\n",
    "ct_res = sm_cli.create_training_job(\n",
    "    TrainingJobName=training_job_name,\n",
    "    AlgorithmSpecification=algorithm_specification,\n",
    "    RoleArn=role_arn,\n",
    "    InputDataConfig=input_data_config,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    VpcConfig=vpc_config,\n",
    "    ResourceConfig=resource_config,\n",
    "    StoppingCondition=stopping_condition,\n",
    "    EnableNetworkIsolation=enable_network_isolation,\n",
    "    EnableManagedSpotTraining=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch to to succeed\n",
    "\n",
    "stopped = False\n",
    "while not stopped:\n",
    "    tj_state = sm_cli.describe_training_job(TrainingJobName=training_job_name)\n",
    "    \n",
    "    if tj_state['TrainingJobStatus'] in ['Completed', 'Stopped', 'Failed']:\n",
    "        stopped=True\n",
    "    else:\n",
    "        print(\"Training in progress\")\n",
    "        time.sleep(30)\n",
    "\n",
    "if tj_state['TrainingJobStatus'] == 'Failed':\n",
    "    print(\"Training job failed \")\n",
    "    print(\"Failed Reason: {}\".format(tj_state['FailureReason']))\n",
    "else:\n",
    "    print(\"Training job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review and clean up\n",
    "\n",
    "Let's review what you did in this notebook: you have created \n",
    "- a VPC\n",
    "- a subnet inside the VPC\n",
    "- a security group inside the VPC\n",
    "\n",
    "The VPC is isolated from the Internet, because you did not add an Internet Gateway to it. \n",
    "You created a training job in the subnet. The traffic in and out the SageMaker Instance running your training container is controled by the security group permissions. You verified that this training job failed, because SageMaker cannot download data from your S3 bucket. \n",
    "\n",
    "Next, you added \n",
    "- a route table to your subnet\n",
    "- an S3 Gateway Endpoint to the route table\n",
    "\n",
    "Then you verified that once you added the S3 Gateway Endpoint to your VPC, the same training job can go through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the entire VPC and its associated resources \n",
    "# adapted from https://gist.github.com/alberto-morales/b6d7719763f483185db27289d51f8ec5\n",
    "\n",
    "def vpc_cleanup(vpcid):\n",
    "    \"\"\"Remove VPC from AWS\n",
    "    Set your region/access-key/secret-key from env variables or boto config.\n",
    "    :param vpcid: id of vpc to delete\n",
    "    \"\"\"\n",
    "    if not vpcid:\n",
    "        return\n",
    "    print('Removing VPC ({}) from AWS'.format(vpcid))\n",
    "    ec2 = boto3.resource('ec2')\n",
    "    ec2client = ec2.meta.client\n",
    "    vpc = ec2.Vpc(vpcid)\n",
    "    # detach default dhcp_options if associated with the vpc\n",
    "    dhcp_options_default = ec2.DhcpOptions('default')\n",
    "    if dhcp_options_default:\n",
    "        dhcp_options_default.associate_with_vpc(\n",
    "            VpcId=vpc.id\n",
    "        )\n",
    "    # detach and delete all gateways associated with the vpc\n",
    "    for gw in vpc.internet_gateways.all():\n",
    "        vpc.detach_internet_gateway(InternetGatewayId=gw.id)\n",
    "        gw.delete()\n",
    "\n",
    "    # delete any instances\n",
    "    for subnet in vpc.subnets.all():\n",
    "        for instance in subnet.instances.all():\n",
    "            instance.terminate()\n",
    "    \n",
    "    # delte all subnets\n",
    "    for subnet in vpc.subnets.all():\n",
    "        for interface in subnet.network_interfaces.all():\n",
    "            interface.delete()\n",
    "        subnet.delete()\n",
    "    \n",
    "    # delete all route table associations\n",
    "    for rt in vpc.route_tables.all():\n",
    "        for rta in rt.associations:\n",
    "            if not rta.main:\n",
    "                rta.delete()\n",
    "            \n",
    "        try:\n",
    "            rt.delete()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    # delete our endpoints\n",
    "    for ep in ec2client.describe_vpc_endpoints(\n",
    "            Filters=[{\n",
    "                'Name': 'vpc-id',\n",
    "                'Values': [vpcid]\n",
    "            }])['VpcEndpoints']:\n",
    "        ec2client.delete_vpc_endpoints(VpcEndpointIds=[ep['VpcEndpointId']])\n",
    "    # delete our security groups\n",
    "    for sg in vpc.security_groups.all():\n",
    "        if sg.group_name != 'default':\n",
    "            sg.delete()\n",
    "    # delete any vpc peering connections\n",
    "    for vpcpeer in ec2client.describe_vpc_peering_connections(\n",
    "            Filters=[{\n",
    "                'Name': 'requester-vpc-info.vpc-id',\n",
    "                'Values': [vpcid]\n",
    "            }])['VpcPeeringConnections']:\n",
    "        ec2.VpcPeeringConnection(vpcpeer['VpcPeeringConnectionId']).delete()\n",
    "    # delete non-default network acls\n",
    "    for netacl in vpc.network_acls.all():\n",
    "        if not netacl.is_default:\n",
    "            netacl.delete()\n",
    "    # delete network interfaces\n",
    " \n",
    "    # finally, delete the vpc\n",
    "    ec2client.delete_vpc(VpcId=vpcid)\n",
    "    return\n",
    "\n",
    "vpc_cleanup(vpc_res[\"Vpc\"]['VpcId'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
