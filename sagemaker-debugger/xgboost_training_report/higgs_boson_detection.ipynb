{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Debugger XGBoost training report for Higgs Boson Detection Challenge\n",
    "This tutorial walks thorugh an example of training an XGBoost model using data from the [2014 ATLAS Higgs Boson Machine Learning Challenge](http://opendata.cern.ch/record/328). This example showcases some of the new features available in SageMaker Debugger, such as the deep profiling and the XGBoost training report.\n",
    "\n",
    "The [Debugger profiling report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html) displays hardware resource utilization metrics such as cpu, gpu, memory, and IO utilization. Debugger will help you identify any hardware bottlenecks and appropriately choose the right-sized instance for your training job.\n",
    "\n",
    "The [Debugger XGBoost training report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-training-xgboost-report.html) will provide a comprehensive evaluation of your model's performance to help you fine-tune and improve your model.\n",
    "\n",
    "The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) makes it easy to train XGBoost models accessing other AWS services, such as Amazon EC2, Amazon ECR, and Amazon S3. For more information about the XGBoost model and SageMaker, see the [XGBoost Algoritm Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) and the [SageMaker Python SDK documentation](https://github.com/aws/sagemaker-python-sdk).\n",
    "\n",
    "### Table of contents\n",
    "* [Setup and imports](#setup)\n",
    "* [Get and prepare data](#data)\n",
    "* [Create the SageMaker XGBoost Estimator](#estimator)\n",
    "* [Train XGBoost Model](#train)\n",
    "* [View post training reports](#reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup<a class=\"anchor\" id=\"setup\"></a>\n",
    "This notebook was created and tested on an `ml.t3.medium` notebook instance.\n",
    "\n",
    "After we've installed and imported the required packages, we'll need to specify a few variable that will be utilized throughout the example notebook:\n",
    "- `role`: The IAM role to run SageMaker training jobs. The default SageMaker role with the SageMaker full access policy will be used.\n",
    "- `sess`: The SageMaker session that interacts with different AWS services.\n",
    "- `bucket`: The S3 bucket where the model's input and output data will be stored. We will use the default S3 bucket automatically paired with the SageMaker session.\n",
    "- `key_prefix`: The directory in the S3 bucket where we'll store the input and output data.\n",
    "- `region`: The AWS region where we operate the SageMaker training job.\n",
    "- `s3`: the s3fs client to make it easier to read and write data from and to the S3 bucket.\n",
    "- `xgboost_container`: The URI for the XGBoost training container for our region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -Uqq sagemaker\n",
    "!pip install -Uqq s3fs==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "\n",
    "from IPython.display import FileLink, FileLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup sagemaker variables\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "key_prefix = \"higgs-boson\"\n",
    "region = sess._region_name\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "xgboost_container = image_uris.retrieve(\"xgboost\", region, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and prepare data <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "The data for this example notebook is provided by the European Organization for Nuclear Research (CERN). This data was utilized in a 2014 machine learning competition where participants had to develop an algorithm that improves the detection of Higgs boson signal events decaying into two tau particles from a sample of simulated ATLAS data. More background and details on this interesting data set can be found at Dataset from the [ATLAS Higgs Boson Machine Learning Challenge 2014](http://opendata.cern.ch/record/328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from CERN\n",
    "! aws s3 cp s3://sagemaker-sample-files/datasets/tabular/atlas_higgs_boson_2014/atlas-higgs-challenge-2014-v2.csv .\n",
    "df = pd.read_csv(\"atlas-higgs-challenge-2014-v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the columns we don't need and identify columns that will be used as features as well as the target\n",
    "non_feature_cols = [\"EventId\", \"Weight\", \"KaggleSet\", \"KaggleWeight\", \"Label\"]\n",
    "feature_cols = [col for col in df.columns if col not in non_feature_cols]\n",
    "label_col = \"Label\"\n",
    "df[\"Label\"] = df[\"Label\"].apply(lambda x: 1 if x == \"s\" else 0)\n",
    "\n",
    "# The original competition split the data out into training and validation sets. The data includes a column that identifies which sample falls into which set\n",
    "train_data = df.loc[df[\"KaggleSet\"] == \"t\", [label_col, *feature_cols]]\n",
    "test_data = df.loc[df[\"KaggleSet\"] == \"b\", [label_col, *feature_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the SageMaker session, we upload the data to S3\n",
    "for name, dataset in zip([\"train\", \"test\"], [train_data, test_data]):\n",
    "    sess.upload_string_as_file_body(\n",
    "        body=dataset.to_csv(index=False, header=False),\n",
    "        bucket=bucket,\n",
    "        key=f\"{key_prefix}/input/{name}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure data inputs for SageMaker training\n",
    "train_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/input/train.csv\", content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(\n",
    "    f\"s3://{bucket}/{key_prefix}/input/test.csv\", content_type=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create XGBoost Estimator <a class=\"anchor\" id=\"estimator\"></a>\n",
    "\n",
    "Here we create a SageMaker Estimator using the XGBoost image prepared by SageMaker. We attach the SageMaker Debugger built-in `create_xgboost_report()` rule to automatically generate an XGBoost training report after the training job is complete. SageMaker Debugger also turns on the [ProfilerReport](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html) rule and autogenerate a report regarding system resource utilization and bottleneck detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for the XGBoost model\n",
    "hyperparameters = {\"objective\": \"binary:logistic\", \"num_round\": \"100\", \"eval_metric\": \"error\"}\n",
    "\n",
    "# add a rule to generate the XGBoost Report\n",
    "rules = [Rule.sagemaker(rule_configs.create_xgboost_report())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker Estimator using the XGBoost image\n",
    "estimator = Estimator(\n",
    "    role=role,\n",
    "    image_uri=xgboost_container,\n",
    "    base_job_name=\"higgs-boson-model\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    rules=rules,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Model <a class=\"anchor\" id=\"train\"></a>\n",
    "Finally we launch a training job to train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\": train_input, \"validation\": validation_input}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download SageMaker Debugger Reports <a class=\"anchor\" id=\"reports\"></a>\n",
    "SageMaker Debugger generates profiling and training reports through a pair of processing jobs that run concurrent to the training job. The code below will download the outputs from the Debugger report output S3 URI to your current Jupyter working directory for easier viewing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "\n",
    "# get name of the xgboost training report\n",
    "xgb_profile_job_name = [\n",
    "    rule[\"RuleEvaluationJobArn\"].split(\"/\")[-1]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"CreateXgboostReport\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "\n",
    "base_output_path = os.path.dirname(estimator.latest_job_debugger_artifacts_path())\n",
    "rule_output_path = os.path.join(base_output_path, \"rule-output/\")\n",
    "xgb_report_path = os.path.join(rule_output_path, \"CreateXgboostReport\")\n",
    "profile_report_path = os.path.join(rule_output_path, profiler_report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    xgb_job_info = sess.sagemaker_client.describe_processing_job(\n",
    "        ProcessingJobName=xgb_profile_job_name\n",
    "    )\n",
    "\n",
    "    if xgb_job_info[\"ProcessingJobStatus\"] == \"Completed\":\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Job Status: {xgb_job_info['ProcessingJobStatus']}\")\n",
    "        time.sleep(30)\n",
    "\n",
    "s3.download(xgb_report_path, \"reports/xgb/\", recursive=True)\n",
    "s3.download(profile_report_path, \"reports/profiler/\", recursive=True)\n",
    "display(\n",
    "    \"Click link below to view the profiler report whcih will help you identify hardware bottlenecks.\",\n",
    "    FileLink(\"reports/profiler/profiler-output/profiler-report.html\"),\n",
    ")\n",
    "display(\n",
    "    \"Click link below to view the XGBoost Training reports which will help you imporve your model\",\n",
    "    FileLink(\"reports/xgb/xgboost_report.html\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Debugger Profiling report\n",
    "\n",
    "The following code opens the downloaded profiling report. For this training job, there is no bottleneck issues found as described in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=\"reports/profiler/profiler-output/profiler-report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Debugger XGBoost training report\n",
    "\n",
    "The following code displays the XGBoost training report. This shows how the training job made progress, such as loss values over time and statistics at `plot_step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=\"reports/xgb/xgboost_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
