{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb187715",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Multi-hop Lineage Queries\n",
    "\n",
    "Amazon SageMaker Lineage tracks events that happen within SageMaker allowing the relationships between them to be traced via a graph structure. SageMaker Lineage introduces a new API called `LineageQuery` that allows customers to query the lineage graph structure to discover relationship across their Machine Learning entities. \n",
    "\n",
    "Your machine learning workflows can generate deeply nested relationships, the lineage APIs allow you to answer questions about these relationships. For example find all Data Sets that trained the model deployed to a given Endpoint or find all Models trained by a Data Set.\n",
    "\n",
    "The lineage graph is created automatically by SageMaker and you can directly create or modify your own lineage.\n",
    "\n",
    "In addition to the `LineageQuery` API, the SageMaker SDK provides wrapper functions that make it easy to run queries that span across multiple hops of the entity relationship graph. These APIs and helper functions are described in this notebook.\n",
    "\n",
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 15 minutes to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Key Concepts](#Key-Concepts)\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "1. [Notebook Overview](#Notebook-Overview)\n",
    "1. [Create an Experiment and Trial for a training job](#Create-an-Experiment-and-Trial-for-a-training-job)\n",
    "1. [Training Data](#Training-Data)\n",
    "1. [Create a training job](#Create-a-training-job)\n",
    "1. [Create a Model Package Group for the trained model to be registered](#Create-a-Model-Package-Group-for-the-trained-model-to-be-registered)\n",
    "1. [Register the model in the Model Registry](#Register-the-model-in-the-Model-Registry)\n",
    "1. [Deploy the model to a SageMaker Endpoint](#Deploy-the-model-to-a-SageMaker-Endpoint)\n",
    "1. [SageMaker Lineage Queries](#SageMaker-Lineage-Queries)\n",
    "    1. [Using the LineageQuery API to find entity associations](#Using-the-LineageQuery-API-to-find-entity-associations)\n",
    "        1. [Find all datasets associated with an Endpoint](#Find-all-datasets-associated-with-an-Endpoint)\n",
    "        1. [Find the models associated with an Endpoint](#Find-the-models-associated-with-an-Endpoint)\n",
    "        1. [Find the trial components associated with an Endpoint](#Find-the-trial-components-associated-with-an-Endpoint)\n",
    "    1. [Change the focal point of lineage](#Change-the-focal-point-of-lineage)\n",
    "    1. [Use LineageQueryDirectionEnum.BOTH](#Use-LineageQueryDirectionEnum.BOTH)\n",
    "    1. [Directions in LineageQuery: Ascendants vs. Descendants](#Directions-in-LineageQuery:-Ascendants-vs.-Descendants)\n",
    "    1. [SDK helper functions](#SDK-helper-functions)\n",
    "    1. [Lineage Graph Visualization](#Lineage-Graph-Visualization)\n",
    "1. [Conclusion](#Conclusion)\n",
    "1. [Cleanup](#Cleanup)\n",
    "\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "* **Lineage Graph** - A connected graph tracing your machine learning workflow end to end. \n",
    "* **Artifacts** - Represents a URI addressable object or data.  Artifacts are typically inputs or outputs to Actions.  \n",
    "* **Actions**  - Represents an action taken such as a computation, transformation, or job.  \n",
    "* **Contexts** - Provides a method to logically group other entities.\n",
    "* **Associations** - A directed edge in the lineage graph that links two entities.\n",
    "* **Lineage Traversal** - Starting from an arbitrary point trace the lineage graph to discover and analyze relationships between steps in your workflow.\n",
    "* **Experiments** - Experiment entites (Experiments, Trials, and Trial Components) are also part of the lineage graph and can be associated wtih Artifacts, Actions, or Contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4a00f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "[`sagemaker-experiments`](https://github.com/aws/sagemaker-experiments) and [`pyvis`]((https://pyvis.readthedocs.io/en/latest/)) are two Python libraries that need to be installed as part of this notebook execution. `pyvis` is a library designed for interactive network visualization and `sagemaker-experiments` gives users the ability to use SageMaker's Experiment Tracking capabilities. \n",
    "\n",
    "This notebook should be run with `Python 3.9` using the SageMaker Studio `Python3 (Data Science)` kernel. The `sagemaker` sdk version required for this notebook is `>2.70.0`.\n",
    "\n",
    "If running in SageMaker Classic Notebooks, use the `conda_python3` kernel. \n",
    "\n",
    "The AWS account running this notebook should have access to provision two instances of type `ml.m5.xlarge`. These instances are used for training and deploying a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee7359",
   "metadata": {},
   "source": [
    "Let's start by installing the Python SDK, boto and AWS CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker botocore boto3 awscli --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69886125",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-experiments pyvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf2db5",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook demonstrates how to use SageMaker Lineage APIs to query multi-hop relationships across the lineage graph. Multi-hop relationships are those that span beyond single entity relationships, e.g. Model -> Endpoint, Training Job -> Model. Multi-hop queries allow users to search for distant relationships across the Lineage Graph such as Endpoint -> Data Set.\n",
    "\n",
    "To demonstrate these capabilities, in this notebook we create a training job, register a model to the Model Registry, and deploy the model to an Endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pprint\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 50, \"mode\": \"adaptive\"})\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm_client = sagemaker_session.sagemaker_client\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Helper function to print query outputs\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "s3_prefix = \"multihop-example\"\n",
    "\n",
    "unique_id = str(datetime.now().timestamp()).split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51f513",
   "metadata": {},
   "source": [
    "## Create an Experiment and Trial for a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "\n",
    "experiment_name = f\"MultihopQueryExperiment-{unique_id}\"\n",
    "exp = Experiment.create(experiment_name=experiment_name, sagemaker_boto_client=sm_client)\n",
    "\n",
    "trial = Trial.create(\n",
    "    experiment_name=exp.experiment_name,\n",
    "    trial_name=f\"MultihopQueryTrial-{unique_id}\",\n",
    "    sagemaker_boto_client=sm_client,\n",
    ")\n",
    "\n",
    "print(exp.experiment_name)\n",
    "print(trial.trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f088c",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "Creating a `data/` directory to store the preprocessed [UCI Abalone](https://archive.ics.uci.edu/ml/datasets/abalone) dataset. The preprocessing is done using the preprocessing script defined in the notebook [Orchestrating Jobs with Amazon SageMaker Model Building Pipelines](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-pipelines/tabular/abalone_build_train_deploy/sagemaker-pipelines-preprocess-train-evaluate-batch-transform.ipynb) notebook. Then training and validation data is uploaded to S3 so that it can be used in the training and inference job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d020ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bdc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./data/\"):\n",
    "    os.makedirs(\"./data/\")\n",
    "    print(\"Directory Created \")\n",
    "else:\n",
    "    print(\"Directory already exists\")\n",
    "\n",
    "# Download the processed abalone dataset files\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\",\n",
    "    \"datasets/tabular/uci_abalone/preprocessed/test.csv\",\n",
    "    \"./data/test.csv\",\n",
    ")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\",\n",
    "    \"datasets/tabular/uci_abalone/preprocessed/train.csv\",\n",
    "    \"./data/train.csv\",\n",
    ")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\",\n",
    "    \"datasets/tabular/uci_abalone/preprocessed/validation.csv\",\n",
    "    \"./data/validation.csv\",\n",
    ")\n",
    "\n",
    "# Upload the datasets to the SageMaker session default bucket\n",
    "boto3.Session().resource(\"s3\").Bucket(default_bucket).Object(\n",
    "    \"experiments-demo/train.csv\"\n",
    ").upload_file(\"data/train.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(default_bucket).Object(\n",
    "    \"experiments-demo/validation.csv\"\n",
    ").upload_file(\"data/validation.csv\")\n",
    "\n",
    "training_data = f\"s3://{default_bucket}/experiments-demo/train.csv\"\n",
    "validation_data = f\"s3://{default_bucket}/experiments-demo/validation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c9e25",
   "metadata": {},
   "source": [
    "## Create a training job\n",
    "\n",
    "We train a simple XGBoost model on the Abalone dataset. \n",
    "`sagemaker.image_uris.retrieve()` is used to get the sagemaker container for XGBoost so that it can be used in the Estimator. \n",
    "\n",
    "In the `.fit()` function, we pass in a training and validation dataset along with an `experiment_config`. The `experiment_config` ensures that the metrics, parameters, and artifats associated with this training job are logged to the experiment and trial created above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/{s3_prefix}/xgb_model\"\n",
    "training_instance_type = \"ml.m5.large\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:squarederror\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    verbosity=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=training_data,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=validation_data,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    experiment_config={\n",
    "        \"ExperimentName\": experiment_name,\n",
    "        \"TrialName\": trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"MultiHopQueryTrialComponent\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43b815",
   "metadata": {},
   "source": [
    "## Create a Model Package Group for the trained model to be registered\n",
    "\n",
    "Create a new Model Package Group or use an existing one to register the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = \"lineage-test-\" + unique_id\n",
    "mpg = sm_client.create_model_package_group(ModelPackageGroupName=model_package_group_name)\n",
    "mpg_arn = mpg[\"ModelPackageGroupArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d04c0",
   "metadata": {},
   "source": [
    "## Register the model in the Model Registry\n",
    "Once the model is registered, it appears in the Model Registry tab of the SageMaker Studio UI. The model is registered with the `approval_status` set to \"Approved\". By default, the model is registered with the `approval_status` set to \"PendingManualApproval\". Users can then navigate to the Model Registry to manually approve the model based on any criteria set for model evaluation or this can be done via API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "model_package = xgb_train.register(\n",
    "    model_package_group_name=mpg_arn,\n",
    "    inference_instances=[inference_instance_type],\n",
    "    transform_instances=[inference_instance_type],\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    approval_status=\"Approved\",\n",
    ")\n",
    "\n",
    "model_package_arn = model_package.model_package_arn\n",
    "print(\"Model Package ARN : \", model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f9d6c",
   "metadata": {},
   "source": [
    "## Deploy the model to a SageMaker Endpoint\n",
    "\n",
    "A SageMaker Endpoint is used to host a model that can be used for inference. The type of endpoint deployed in this notebook is a real time inference endpoint. This is ideal for inference workloads where you have real-time, interactive, low latency requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"lineage-test-endpoint-\" + unique_id\n",
    "model_package.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17178ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the endpoint ARN\n",
    "endpoint_arn = sm_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointArn\"]\n",
    "print(endpoint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73bd20",
   "metadata": {},
   "source": [
    "## SageMaker Lineage Queries\n",
    "\n",
    "We explore SageMaker's lineage capabilities to traverse the relationships between the entities created in this notebook - datasets, model, endpoint, and training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.lineage.context import Context, EndpointContext\n",
    "from sagemaker.lineage.action import Action\n",
    "from sagemaker.lineage.association import Association\n",
    "from sagemaker.lineage.artifact import Artifact, ModelArtifact, DatasetArtifact\n",
    "\n",
    "from sagemaker.lineage.query import (\n",
    "    LineageQuery,\n",
    "    LineageFilter,\n",
    "    LineageSourceEnum,\n",
    "    LineageEntityEnum,\n",
    "    LineageQueryDirectionEnum,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e985e",
   "metadata": {},
   "source": [
    "### Using the LineageQuery API to find entity associations\n",
    "\n",
    "In this section we use two APIs, `LineageQuery` and `LineageFilter` to construct queries to answer questions about the Lineage Graph and extract entity relationships. \n",
    "\n",
    "LineageQuery parameters:\n",
    "* `start_arns`: A list of ARNs that is used as the starting point for the query.\n",
    "* `direction`: The direction of the query.\n",
    "* `include_edges`: If true, return edges in addition to vertices.\n",
    "* `query_filter`: The query filter.\n",
    "\n",
    "LineageFilter paramters:\n",
    "* `entities`: A list of entity types (Artifact, Association, Action) to filter for when returning the results on LineageQuery\n",
    "* `sources`: A list of source types (Endpoint, Model, Dataset) to filter for when returning the results of LineageQuery\n",
    "\n",
    "A `Context` is automatically created when a SageMaker Endpoint is created, an `Artifact` is automatically created when a Model is created in SageMaker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the endpoint context and model artifact that should be used for the lineage queries.\n",
    "\n",
    "contexts = Context.list(source_uri=endpoint_arn)\n",
    "context_name = list(contexts)[0].context_name\n",
    "endpoint_context = EndpointContext.load(context_name=context_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963e76e",
   "metadata": {},
   "source": [
    "#### Find all datasets associated with an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LineageFilter to look for entities of type `ARTIFACT` and the source of type `DATASET`.\n",
    "\n",
    "query_filter = LineageFilter(\n",
    "    entities=[LineageEntityEnum.ARTIFACT], sources=[LineageSourceEnum.DATASET]\n",
    ")\n",
    "\n",
    "# Providing this `LineageFilter` to the `LineageQuery` constructs a query that traverses through the given context `endpoint_context`\n",
    "# and find all datasets.\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[endpoint_context.context_arn],\n",
    "    query_filter=query_filter,\n",
    "    direction=LineageQueryDirectionEnum.ASCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "# Parse through the query results to get the lineage objects corresponding to the datasets\n",
    "dataset_artifacts = []\n",
    "for vertex in query_result.vertices:\n",
    "    dataset_artifacts.append(vertex.to_lineage_object().source.source_uri)\n",
    "\n",
    "pp.pprint(dataset_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab1c4a",
   "metadata": {},
   "source": [
    "#### Find the models associated with an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LineageFilter to look for entities of type `ARTIFACT` and the source of type `MODEL`.\n",
    "\n",
    "query_filter = LineageFilter(\n",
    "    entities=[LineageEntityEnum.ARTIFACT], sources=[LineageSourceEnum.MODEL]\n",
    ")\n",
    "\n",
    "# Providing this `LineageFilter` to the `LineageQuery` constructs a query that traverses through the given context `endpoint_context`\n",
    "# and find all datasets.\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[endpoint_context.context_arn],\n",
    "    query_filter=query_filter,\n",
    "    direction=LineageQueryDirectionEnum.ASCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "# Parse through the query results to get the lineage objects corresponding to the model\n",
    "model_artifacts = []\n",
    "for vertex in query_result.vertices:\n",
    "    model_artifacts.append(vertex.to_lineage_object().source.source_uri)\n",
    "\n",
    "# The results of the `LineageQuery` API call return the ARN of the model deployed to the endpoint along with\n",
    "# the S3 URI to the model.tar.gz file associated with the model\n",
    "pp.pprint(model_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa79344",
   "metadata": {},
   "source": [
    "#### Find the trial components associated with an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LineageFilter to look for entities of type `TRIAL_COMPONENT` and the source of type `TRAINING_JOB`.\n",
    "\n",
    "query_filter = LineageFilter(\n",
    "    entities=[LineageEntityEnum.TRIAL_COMPONENT],\n",
    "    sources=[LineageSourceEnum.TRAINING_JOB],\n",
    ")\n",
    "\n",
    "# Providing this `LineageFilter` to the `LineageQuery` constructs a query that traverses through the given context `endpoint_context`\n",
    "# and find all datasets.\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[endpoint_context.context_arn],\n",
    "    query_filter=query_filter,\n",
    "    direction=LineageQueryDirectionEnum.ASCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "# Parse through the query results to get the ARNs of the training jobs associated with this Endpoint\n",
    "trial_components = []\n",
    "for vertex in query_result.vertices:\n",
    "    trial_components.append(vertex.arn)\n",
    "\n",
    "pp.pprint(trial_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954748f",
   "metadata": {},
   "source": [
    "#### Change the focal point of lineage\n",
    "\n",
    "The `LineageQuery` can be modified to have different `start_arns` which changes the focal point of lineage. In addition, the `LineageFilter` can take multiple sources and entities to expand the scope of the query. \n",
    "\n",
    "**Here we use the model as the lineage focal point and find the Endpoints and Datasets associated with it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ModelArtifact\n",
    "\n",
    "model_artifact_summary = list(Artifact.list(source_uri=model_package_arn))[0]\n",
    "model_artifact = ModelArtifact.load(artifact_arn=model_artifact_summary.artifact_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_filter = LineageFilter(\n",
    "    entities=[LineageEntityEnum.ARTIFACT],\n",
    "    sources=[LineageSourceEnum.ENDPOINT, LineageSourceEnum.DATASET],\n",
    ")\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[model_artifact.artifact_arn],  # Model is the starting artifact\n",
    "    query_filter=query_filter,\n",
    "    # Find all the entities that descend from the model, i.e. the endpoint\n",
    "    direction=LineageQueryDirectionEnum.DESCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "associations = []\n",
    "for vertex in query_result.vertices:\n",
    "    associations.append(vertex.to_lineage_object().source.source_uri)\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[model_artifact.artifact_arn],  # Model is the starting artifact\n",
    "    query_filter=query_filter,\n",
    "    # Find all the entities that ascend from the model, i.e. the datasets\n",
    "    direction=LineageQueryDirectionEnum.ASCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "for vertex in query_result.vertices:\n",
    "    associations.append(vertex.to_lineage_object().source.source_uri)\n",
    "\n",
    "pp.pprint(associations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa41ff9",
   "metadata": {},
   "source": [
    "#### Use LineageQueryDirectionEnum.BOTH\n",
    "\n",
    "When the direction is set to `BOTH`, when the query traverses the graph to find ascendant and descendant relationships, the traversal takes place not only from the starting node, but from each node that is visited. \n",
    "\n",
    "e.g. If the training job is run twice and both models generated by the training job are deployed to endpoints, this result of the query with direction set to `BOTH` shows both endpoints. This is because the same image is used for training and deploying the model. Since the image is common to the model (`start_arn`) and both the endpoints, it appears in the query result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bee658",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_filter = LineageFilter(\n",
    "    entities=[LineageEntityEnum.ARTIFACT],\n",
    "    sources=[LineageSourceEnum.ENDPOINT, LineageSourceEnum.DATASET],\n",
    ")\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[model_artifact.artifact_arn],  # Model is the starting artifact\n",
    "    query_filter=query_filter,\n",
    "    # This specifies that the query should look for associations both ascending and descending for the start\n",
    "    direction=LineageQueryDirectionEnum.BOTH,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "associations = []\n",
    "for vertex in query_result.vertices:\n",
    "    associations.append(vertex.to_lineage_object().source.source_uri)\n",
    "\n",
    "pp.pprint(associations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aff24",
   "metadata": {},
   "source": [
    "### Directions in LineageQuery: Ascendants vs. Descendants\n",
    "\n",
    "To understand the direction in the Lineage Graph, take the following entity relationship graph - \n",
    "Dataset -> Training Job -> Model -> Endpoint\n",
    "\n",
    "The endpoint is a **descendant** of the model, and the model is a **descendant** of the dataset. Similarly, the model is an **ascendant** of the endpoint The `direction` parameter can be used to specify whether the query should return entities that are descendants or ascendants of the entity in start_arns. If `start_arns` contains a model and the direction is `DESCENDANTS`, the query returns the endpoint. If the direction is `ASCENDANTS`, the query returns the dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we'll look at the impact of specifying the direction as ASCENDANT or DESCENDANT in a `LineageQuery`.\n",
    "\n",
    "query_filter = LineageFilter(\n",
    "    entities=[LineageEntityEnum.ARTIFACT],\n",
    "    sources=[\n",
    "        LineageSourceEnum.ENDPOINT,\n",
    "        LineageSourceEnum.MODEL,\n",
    "        LineageSourceEnum.DATASET,\n",
    "        LineageSourceEnum.TRAINING_JOB,\n",
    "    ],\n",
    ")\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[model_artifact.artifact_arn],\n",
    "    query_filter=query_filter,\n",
    "    direction=LineageQueryDirectionEnum.ASCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "ascendant_artifacts = []\n",
    "\n",
    "# The lineage entity returned for the Training Job is a TrialComponent which can't be converted to a\n",
    "# lineage object using the method `to_lineage_object()` so we extract the TrialComponent ARN.\n",
    "for vertex in query_result.vertices:\n",
    "    try:\n",
    "        ascendant_artifacts.append(vertex.to_lineage_object().source.source_uri)\n",
    "    except:\n",
    "        ascendant_artifacts.append(vertex.arn)\n",
    "\n",
    "print(\"Ascendant artifacts:\")\n",
    "pp.pprint(ascendant_artifacts)\n",
    "\n",
    "query_result = LineageQuery(sagemaker_session).query(\n",
    "    start_arns=[model_artifact.artifact_arn],\n",
    "    query_filter=query_filter,\n",
    "    direction=LineageQueryDirectionEnum.DESCENDANTS,\n",
    "    include_edges=False,\n",
    ")\n",
    "\n",
    "descendant_artifacts = []\n",
    "for vertex in query_result.vertices:\n",
    "    try:\n",
    "        descendant_artifacts.append(vertex.to_lineage_object().source.source_uri)\n",
    "    except:\n",
    "        # Handling TrialComponents.\n",
    "        descendant_artifacts.append(vertex.arn)\n",
    "\n",
    "print(\"Descendant artifacts:\")\n",
    "pp.pprint(descendant_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec9d14",
   "metadata": {},
   "source": [
    "### SDK helper functions\n",
    "\n",
    "The classes `EndpointContext`, `ModelArtifact`, and `DatasetArtifact`have helper functions that are wrappers over the `LineageQuery` API to make \n",
    "certain lineage queries easier to leverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the datasets associated with the endpoint\n",
    "\n",
    "datasets = []\n",
    "dataset_artifacts = endpoint_context.dataset_artifacts()\n",
    "for dataset in dataset_artifacts:\n",
    "    datasets.append(dataset.source.source_uri)\n",
    "print(\"Datasets : \", datasets)\n",
    "\n",
    "# Find the training jobs associated with the endpoint\n",
    "training_job_artifacts = endpoint_context.training_job_arns()\n",
    "training_jobs = []\n",
    "for training_job in training_job_artifacts:\n",
    "    training_jobs.append(training_job)\n",
    "print(\"Training Jobs : \", training_jobs)\n",
    "\n",
    "# Get the ARN for the pipeline execution associated with this endpoint (if any)\n",
    "pipeline_executions = endpoint_context.pipeline_execution_arn()\n",
    "if pipeline_executions:\n",
    "    for pipeline in pipelines_executions:\n",
    "        print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc055f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the `ModelArtifact` class to find all the datasets and endpoints associated with the model\n",
    "\n",
    "dataset_artifacts = model_artifact.dataset_artifacts()\n",
    "endpoint_contexts = model_artifact.endpoint_contexts()\n",
    "\n",
    "datasets = [dataset.source.source_uri for dataset in dataset_artifacts]\n",
    "endpoints = [endpoint.source.source_uri for endpoint in endpoint_contexts]\n",
    "\n",
    "print(\"Datasets associated with this model : \")\n",
    "pp.pprint(datasets)\n",
    "\n",
    "print(\"Endpoints associated with this model : \")\n",
    "pp.pprint(endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd69a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the `DatasetArtifact` class to find all the endpoints hosting models that were trained with a particular dataset\n",
    "# Find the artifact associated with the dataset\n",
    "\n",
    "dataset_artifact_arn = list(Artifact.list(source_uri=training_data))[0].artifact_arn\n",
    "dataset_artifact = DatasetArtifact.load(artifact_arn=dataset_artifact_arn)\n",
    "\n",
    "# Find the endpoints that used this training dataset\n",
    "endpoint_contexts = dataset_artifact.endpoint_contexts()\n",
    "endpoints = [endpoint.source.source_uri for endpoint in endpoint_contexts]\n",
    "\n",
    "print(\"Endpoints associated with the training dataset {}\".format(training_data))\n",
    "pp.pprint(endpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fdd40",
   "metadata": {},
   "source": [
    "### Lineage Graph Visualization\n",
    "\n",
    "A helper class `Visualizer()` is provided in `visualizer.py` to help plot the lineage graph. When the query response is rendered, a graph with the lineage relationships from the `StartArns` is displayed. From the `StartArns` the visualization shows the relationships with the other lineage entities returned in the `query_lineage` API call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph APIs\n",
    "# Here we use the boto3 `query_lineage` API to generate the query response to plot.\n",
    "\n",
    "from visualizer import Visualizer\n",
    "\n",
    "query_response = sm_client.query_lineage(\n",
    "    StartArns=[endpoint_context.context_arn], Direction=\"Ascendants\", IncludeEdges=True\n",
    ")\n",
    "\n",
    "viz = Visualizer()\n",
    "viz.render(query_response, \"Endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22436292",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = sm_client.query_lineage(\n",
    "    StartArns=[model_artifact.artifact_arn], Direction=\"Ascendants\", IncludeEdges=True\n",
    ")\n",
    "viz.render(query_response, \"Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393afa3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demostrated the capabilities of SageMaker Lineage that make it easy for users to keep track of their complex ML workflows. Users can construct their own lineage queries using the `LineageQuery` API and `LineageFilter` or they can use the functions provided on the `EndpointContext`, `ModelArtifact`, and `DatasetArtifact` classes. \n",
    "\n",
    "In addition, the responses from lineage queries can be plotting using the helper class `Visualizer()` to better understand the relationship between the lineage entities. \n",
    "\n",
    "When using SageMaker Pipelines as part of their ML workflows, users can find Pipeline execution ARNs using the lineage APIs described in this notebook.\n",
    "\n",
    "## Cleanup\n",
    "In this section we clean up the resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint\n",
    "\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# # Delete the model package\n",
    "sm_client.delete_model_package(ModelPackageName=model_package.model_package_arn)\n",
    "\n",
    "# Delete the model package group\n",
    "sm_client.delete_model_package_group(ModelPackageGroupName=model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the experiment and trial within it\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def delete_experiment(experiment):\n",
    "    for trial_summary in experiment.list_trials():\n",
    "        trial = Trial.load(trial_name=trial_summary.trial_name)\n",
    "        for trial_component_summary in trial.list_trial_components():\n",
    "            tc = TrialComponent.load(\n",
    "                trial_component_name=trial_component_summary.trial_component_name\n",
    "            )\n",
    "            trial.remove_trial_component(tc)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                tc.delete()\n",
    "            except:\n",
    "                # tc is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(0.5)\n",
    "        trial.delete()\n",
    "        experiment_name = experiment.experiment_name\n",
    "    experiment.delete()\n",
    "    print(f\"\\nExperiment {experiment_name} deleted\")\n",
    "\n",
    "\n",
    "# Delete the Experiment and Trials within it\n",
    "experiment = Experiment.load(experiment_name=exp.experiment_name)\n",
    "delete_experiment(experiment)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
