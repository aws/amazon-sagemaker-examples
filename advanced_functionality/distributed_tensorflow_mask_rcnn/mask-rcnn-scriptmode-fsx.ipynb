{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training of Mask-RCNN on Amazon SageMaker using FSx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is a step-by-step tutorial on distributed training of [Mask R-CNN]( https://arxiv.org/abs/1703.06870) implemented in [TensorFlow](https://www.tensorflow.org/) framework.\n",
    "\n",
    "Concretely, we will describe the steps for training [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) and [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) on [Amazon SageMaker](https://aws.amazon.com/sagemaker/) using [Amazon S3](https://aws.amazon.com/s3/)  and [Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/) file-system as data sources.\n",
    "\n",
    "The outline of steps is as follows:\n",
    "\n",
    "1. Stage COCO 2017 dataset on [Amazon S3](https://aws.amazon.com/s3/)\n",
    "2. Create Amazon FSx Lustre file-system and import data into the file-system from S3\n",
    "3. Build Docker training image and push it to [Amazon ECR](https://aws.amazon.com/ecr/)\n",
    "4. Configure data input channels\n",
    "5. Configure hyper-prarameters\n",
    "6. Define training metrics\n",
    "7. Define training job and start training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SageMaker Session\n",
    "\n",
    "First, let us specify the ```s3_bucket``` that we will use throughout the notebook. The ```s3_bucket``` must be located in the region of this notebook instance. If you do not specify S3 bucket name in `s3_bucket`, **default SageMaker bucket is used, if it exists**. We also initialize the SageMaker session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "\n",
    "s3_bucket  = None # your-s3-bucket-name\n",
    "\n",
    "role = get_execution_role() # you may provide a pre-existing role ARN here\n",
    "print(f\"SageMaker Execution Role: {role}\")\n",
    "\n",
    "session = boto3.session.Session()\n",
    "aws_region = session.region_name\n",
    "print(f\"AWS Region: {aws_region}\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=session)\n",
    "\n",
    "if s3_bucket is None:\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    \n",
    "print(f\"Using S3 bucket: {s3_bucket}\")\n",
    "\n",
    "try:\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.get_bucket_location(Bucket=s3_bucket)\n",
    "    bucket_region = response['LocationConstraint']\n",
    "    bucket_region = 'us-east-1' if bucket_region is None else bucket_region\n",
    "    \n",
    "    print(f\"Bucket region: {bucket_region}\")\n",
    "except:\n",
    "    print(f\"Access Error: Check if '{s3_bucket}' S3 bucket is in '{aws_region}' region\")\n",
    "    \n",
    "sts = boto3.client(\"sts\")\n",
    "aws_account_id = sts.get_caller_identity()[\"Account\"]\n",
    "\n",
    "print(f\"Account: {aws_account_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Attached FSx for Lustre File-system\n",
    "\n",
    "We check to see if an FSx for Lustre is attached, and if it is, we use the attached FSx for Lustre file-system for data input, otherwise, we use Amazon S3.\n",
    "\n",
    "**Note:**\n",
    "If you created this notebook instance using the [stack-sm.sh](stack-sm.sh) script, an FSx for Lustre file-system is automatically created and attached to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import socket\n",
    "\n",
    "def fsx_file_systems(fsx_client):\n",
    "    \"\"\"Generator for listing Fsx file systems\"\"\"\n",
    "\n",
    "    next_token = None\n",
    "    while True:\n",
    "        if next_token:\n",
    "            resp = fsx_client.describe_file_systems(NextToken=next_token)\n",
    "        else:\n",
    "            resp = fsx_client.describe_file_systems()\n",
    "            \n",
    "        file_systems = resp['FileSystems']\n",
    "        for fs in file_systems:\n",
    "            yield fs\n",
    "\n",
    "        try:\n",
    "            next_token = resp['NextToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "file_system_id = None\n",
    "\n",
    "notebook_attached_fsx = !df -kh | grep '@tcp:/' \\\n",
    "    | sed 's/\\([0-9a-zA-Z\\.]*\\)@tcp:\\/\\([a-zA-Z0-9]*\\).*/\\1 \\2/'\n",
    "fsx_mount_name = notebook_attached_fsx[0].split()[1]\n",
    "\n",
    "fsx_client = boto3.client(\"fsx\")\n",
    "\n",
    "for fsx_fs in fsx_file_systems(fsx_client):\n",
    "    mount_name = fsx_fs['LustreConfiguration']['MountName']\n",
    "    fs_id = fsx_fs['FileSystemId']\n",
    "    if mount_name == fsx_mount_name:\n",
    "        file_system_id = fs_id\n",
    "        break\n",
    "        \n",
    "if file_system_id:\n",
    "    print(f\"FSx for Lustre file-system is attached: {file_system_id}\")\n",
    "else:\n",
    "    print(f\"No FSx for Lustre file-system is attached\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage COCO 2017 dataset on Amazon S3\n",
    "\n",
    "We use [COCO 2017](http://cocodataset.org/#home) dataset. This step downloads COCO 2017 training and validation dataset to this notebook instance, extracts the files from the dataset, and uploads the extracted files to your Amazon S3 bucket. Expected time to execute this step is 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sys, os, subprocess\n",
    "\n",
    "key=\"mask-rcnn/sagemaker/input/train/pretrained-models/ImageNet-R50-AlignPadding.npz\"\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    response = s3_client.head_object(Bucket=s3_bucket, Key=key)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "file_size = response.get('ContentLength', 0) if response else 0\n",
    "\n",
    "if file_size == 0:\n",
    "    print(f\"Uploading data to s3://{s3_bucket}/mask-rcnn/sagemaker/input/train/\")\n",
    "    print(f\"Estimated time: 30 minutes\")\n",
    "    subprocess.check_call(['./prepare-s3-bucket.sh', s3_bucket], \n",
    "                          stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
    "    print(f\"Uploaded data to s3://{s3_bucket}/mask-rcnn/sagemaker/input/train/\")\n",
    "else:\n",
    "    print(\"Nothing to do: S3 bucket already has the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage COCO 2017 dataset on Amazon FSx for Lustre\n",
    "\n",
    "Next, we stage [COCO 2017](http://cocodataset.org/#home) dataset on Amazon FSx for Lustre file-system, if such a file-system is attached. The [prepare-efs.sh](prepare-efs.sh) script executes this step. The expected time to execute this step is 30 minutes, if the data isn't already imported from Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import sys, os, subprocess\n",
    "\n",
    "if file_system_id:\n",
    "    # Specify relative directory path for input data on the FSx for Lustre file system.\n",
    "    file_system_directory_path = \"mask-rcnn/sagemaker/input/train\"\n",
    "    print(f\"FSx for Lustre file-system data input path: {file_system_directory_path}\")\n",
    "    train_path = os.path.join(os.getenv('HOME'), 'fsx', file_system_directory_path)\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        print(f\"Staging data on fsx file-system: {train_path}\")\n",
    "        subprocess.check_call(['./prepare-fsx.sh', s3_bucket], \n",
    "                              stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
    "    else:\n",
    "        print(f\"Data already available in FSx for Lustre file-system: {train_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model Type\n",
    "\n",
    "We have a choice of two different models:\n",
    "\n",
    "1. [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) implementation supports a maximum per-GPU batch size of 1.\n",
    "\n",
    "2. [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) is an optimized implementation that supports a maximum per GPU batch size of 4, assuming per GPU memory of 32 GB.\n",
    "\n",
    "Below, set the `model_type` to `\"aws-samples-mask-rcnn\"`, or `\"tensorpack-mask-rcnn\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the model type you want to use\n",
    "model_type = \"aws-samples-mask-rcnn\" # \"tensorpack-mask-rcnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and push SageMaker Training Image to ECR\n",
    "\n",
    "Next, we build and push the training image to Amazon ECR, based on the selected model type. This may take several minutes on first-time build on this notebook. We also set the `training_script` based on the selected model type.\n",
    "\n",
    "**Note:**\n",
    "For this step, the [IAM Role](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) attached to this notebook instance needs full access to Amazon ECR service. If you created this notebook instance using the [stack-sm.sh](stack-sm.sh) script, the IAM Role attached to this notebook instance is already setup with full access to ECR service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import sys, os, subprocess\n",
    "\n",
    "with open(\"training-image-build.log\", \"w\") as logfile:\n",
    "    if \"tensorpack\" in model_type:\n",
    "        print(\"Building and pushing Tensorpack Faster-RCNN/Mask-RCNN docker image to ECR\")\n",
    "        subprocess.check_call(['./container-script-mode/build_tools/build_and_push.sh', \n",
    "                               aws_region], stdout=logfile, stderr=subprocess.STDOUT)\n",
    "        \n",
    "        image_tag = !cat ./container-script-mode/build_tools/set_env.sh \\\n",
    "            | grep 'IMAGE_TAG' | sed 's/.*IMAGE_TAG=\\(.*\\)/\\1/'\n",
    "        \n",
    "        image_name=\"mask-rcnn-tensorpack-sagemaker-script-mode\"\n",
    "        full_name=f\"{aws_account_id}.dkr.ecr.{aws_region}.amazonaws.com/{image_name}\"\n",
    "        tensorpack_image = f\"{full_name}:{image_tag[0]}\"\n",
    "        training_image = tensorpack_image\n",
    "        training_script= \"tensorpack-mask-rcnn.py\"\n",
    "\n",
    "    else:\n",
    "        print(\"Building and pushing AWS Samples Mask R-CNN docker image to ECR\")\n",
    "        subprocess.check_call(['./container-optimized-script-mode/build_tools/build_and_push.sh',\n",
    "                               aws_region], stdout=logfile, stderr=subprocess.STDOUT)\n",
    "        \n",
    "        image_tag = !cat ./container-optimized-script-mode/build_tools/set_env.sh \\\n",
    "            | grep 'IMAGE_TAG' | sed 's/.*IMAGE_TAG=\\(.*\\)/\\1/'\n",
    "        \n",
    "        image_name=\"mask-rcnn-tensorflow-sagemaker-script-mode\"\n",
    "        full_name=f\"{aws_account_id}.dkr.ecr.{aws_region}.amazonaws.com/{image_name}\"\n",
    "        aws_samples_image = f\"{full_name}:{image_tag[0]}\"\n",
    "       \n",
    "        training_image = aws_samples_image\n",
    "        training_script= \"aws-mask-rcnn.py\" \n",
    "\n",
    "print(f\"Training Image: {training_image}\")\n",
    "print(f\"Training Script: {training_script}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SageMaker Data Channels\n",
    "\n",
    "We define `train` data channels for Amazon S3, and Amazon FSx, if FSx Lustre file-system is available. \n",
    "\n",
    "For the training job, S3 data channel is used only if the FSx Lustre file-system is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define S3 Train Data Channel\n",
    "\n",
    "We first define S3 `train` data channel below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "prefix = \"mask-rcnn/sagemaker\"  # prefix in your S3 bucket\n",
    "\n",
    "s3train = f\"s3://{s3_bucket}/{prefix}/input/train\"\n",
    "train_input = TrainingInput(\n",
    "    s3_data=s3train, distribution=\"FullyReplicated\", s3_data_type=\"S3Prefix\", input_mode=\"File\"\n",
    ")\n",
    "\n",
    "s3_data_channels = {\"train\": train_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Amazon FSx Lustre Train Data Channel \n",
    "\n",
    "Next, we define the *train* data channel using FSx Lustre file-system, if Amazon FSx Lustre file-system is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "fsx_data_channels = None\n",
    "\n",
    "if file_system_id:\n",
    "    \n",
    "    # Specify directory path for input data on the file system. \n",
    "    # You need to provide normalized and absolute path below.\n",
    "    file_system_directory_path = 'mask-rcnn/sagemaker/input/train'\n",
    "    print(f'FSx file-system data input path: {file_system_directory_path}')\n",
    "\n",
    "    # Specify the access mode of the mount of the directory associated with the file system. \n",
    "    # Directory must be mounted 'ro'(read-only).\n",
    "    file_system_access_mode = 'ro'\n",
    "\n",
    "    # Specify your file system type.\n",
    "    file_system_type = 'FSxLustre'\n",
    "\n",
    "    train = FileSystemInput(file_system_id=file_system_id,\n",
    "                                        file_system_type=file_system_type,\n",
    "                                        directory_path=f\"/{fsx_mount_name}/{file_system_directory_path}\",\n",
    "                                        file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "    # Create log directory\n",
    "    file_system_directory_path = f'mask-rcnn/sagemaker/output/mask-rcnn-script-mode-{int(time.time())}'\n",
    "    print(f\"FSx for Lustre log directory:{file_system_directory_path}\")\n",
    "\n",
    "    # Create the log output directory. \n",
    "    # FSx for Lustre file-system is mounted on '$HOME/fsx' mount point for this notebook.\n",
    "    home_dir=os.environ['HOME']\n",
    "    local_fsx_path = os.path.join(home_dir,'fsx', file_system_directory_path)\n",
    "    print(f\"Creating log directory on FSx for Lustre: {local_fsx_path}\")\n",
    "\n",
    "    assert not os.path.isdir(local_fsx_path)\n",
    "    ! sudo mkdir -p -m a=rw {local_fsx_path}\n",
    "    assert os.path.isdir(local_fsx_path)\n",
    "        \n",
    "    # Specify the access mode of the mount of the directory associated with the file system. \n",
    "    # Directory must be mounted 'rw'(read-write).\n",
    "    file_system_access_mode = 'rw'\n",
    "\n",
    "    log = FileSystemInput(file_system_id=file_system_id,\n",
    "                           file_system_type=file_system_type,\n",
    "                           directory_path=f\"/{fsx_mount_name}/{file_system_directory_path}\",\n",
    "                           file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "    fsx_data_channels = {'train': train, 'log': log}\n",
    "else:\n",
    "    print(\"FSx for Lustre file-system is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Output Location\n",
    "\n",
    "Next, we define the model output location in S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"mask-rcnn/sagemaker\"  # prefix in your bucket\n",
    "s3_output_location = f\"s3://{s3_bucket}/{prefix}/output\"\n",
    "print(f\"Model output location: {s3_output_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Security Group and Subnets\n",
    "\n",
    "If an EFS file-system is attached to this notebook, we retrieve the security groups and subnets associated with the EFS file-system mount-targets, and use them in defining the training job.\n",
    "\n",
    "**Note:**\n",
    "For this step, the IAM Role attached to this notebook instance needs permission to describe EFS mount targets, and mount target security groups. If you created this notebook instance using the [stack-sm.sh](stack-sm.sh) script, the IAM Role attached to this notebook instance is already setup with required permissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "security_group_ids=None\n",
    "subnets=None\n",
    "\n",
    "if file_system_id:\n",
    "    fsx_client = boto3.client(\"fsx\")\n",
    "    ec2_client = boto3.client('ec2')\n",
    "    \n",
    "    response = fsx_client.describe_file_systems(FileSystemIds=[file_system_id])\n",
    "    file_system=response['FileSystems'][0]\n",
    "    subnets = file_system['SubnetIds']\n",
    "    network_interface_ids = file_system['NetworkInterfaceIds']\n",
    "         \n",
    "    response = ec2_client.describe_network_interfaces(\n",
    "        NetworkInterfaceIds=network_interface_ids)\n",
    "    network_interface = response['NetworkInterfaces'][0]\n",
    "    groups = network_interface['Groups']\n",
    "    security_group_ids = [ x['GroupId'] for x in groups ]\n",
    "   \n",
    "subnets = list(set(subnets)) if isinstance(subnets, list) else None\n",
    "security_group_ids = list(set(security_group_ids)) if isinstance(security_group_ids, list) \\\n",
    "                        else None\n",
    "\n",
    "print(f\"Subnets: {subnets}\")\n",
    "print(f\"Security groups: {security_group_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Hyper-parameters\n",
    "Next, we define the hyper-parameters. \n",
    "\n",
    "Note, some hyper-parameters are different between the two implementations. The batch size per GPU in TensorPack Faster-RCNN/Mask-RCNN is fixed at 1, but is configurable in AWS Samples Mask-RCNN. The learning rate schedule is specified in units of steps in TensorPack Faster-RCNN/Mask-RCNN, but in epochs in AWS Samples Mask-RCNN.\n",
    "\n",
    "The default learning rate schedule values shown below correspond to training for a total of 24 epochs, at 120,000 images per epoch.\n",
    "\n",
    "### TensorPack Faster-RCNN/Mask-RCNN Hyper-parameters\n",
    "\n",
    "| Hyper-parameter | Description | Default |\n",
    "|-----------|-------------|---------------|\n",
    "| backbone_weights | ResNet backbone pre-trained weights file | 'ImageNet-R50-AlignPadding.npz' |\n",
    "| batch_norm | Batch normalization option ('FreezeBN', 'SyncBN', 'GN', 'None') | 'FreezeBN' |\n",
    "| config: | Any hyper-parameter prefixed with **config:** is set as a model config parameter | - |\n",
    "| data_train | Training data | 'coco_train2017' |\n",
    "| data_val | Validation data | 'coco_val2017' |\n",
    "| eval_period | Number of epochs period for evaluation during training | 1 |\n",
    "| images_per_epoch | Images per epoch | 120000 |\n",
    "| load_model | Pre-trained model to load | - |\n",
    "| lr_schedule | Learning rate schedule in training steps | '[240000, 320000, 360000]' |\n",
    "| mode_fpn | Use Feature Pyramid Network (FPN) mode | True |\n",
    "| mode_mask | Compute masks | True |\n",
    "| resnet_arch | Must be 'resnet50' or 'resnet101' | 'resnet50' |\n",
    "\n",
    "\n",
    "### AWS Samples Mask-RCNN Hyper-parameters\n",
    "\n",
    "| Hyper-parameter | Description | Default |\n",
    "|-----------|-------------|---------------|\n",
    "| backbone_weights | ResNet backbone pre-trained weights file | 'ImageNet-R50-AlignPadding.npz' |\n",
    "| batch_norm | Batch normalization option ('FreezeBN', 'SyncBN', 'GN', 'None') | 'FreezeBN' |\n",
    "| batch_size_per_gpu | Batch size per gpu, 1 - 6 | 16 GB: 2, 32 GB: 4, > 32 GB : 6|\n",
    "| config: | Any hyper-parameter prefixed with **config:** is set as a model config parameter | - |\n",
    "| data_train | Training data | 'train2017' |\n",
    "| data_val | Validation data | 'val2017' |\n",
    "| eval_period | Number of epochs period for evaluation during training | 1 |\n",
    "| lr_schedule | Learning rate schedule in training steps | '[(16, 0.1), (20, 0.01), (24, None)]' |\n",
    "| images_per_epoch | Images per epoch | 120000 |\n",
    "| load_model | Pre-trained model to load | - |\n",
    "| mode_fpn | Use Feature Pyramid Network (FPN) mode. Must be True. | True |\n",
    "| mode_mask | Compute masks | True |\n",
    "| resnet_arch | Must be 'resnet50' or 'resnet101' | 'resnet50' |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"mode_fpn\": \"True\",\n",
    "    \"mode_mask\": \"True\",\n",
    "    \"eval_period\": 1,\n",
    "    \"batch_norm\": \"FreezeBN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Metrics\n",
    "Next, we define the regular expressions that SageMaker uses to extract algorithm metrics from training logs and send them to [AWS CloudWatch metrics](https://docs.aws.amazon.com/en_pv/AmazonCloudWatch/latest/monitoring/working_with_metrics.html). These algorithm metrics are visualized in SageMaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"fastrcnn_losses/box_loss\", \"Regex\": \".*fastrcnn_losses/box_loss:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"fastrcnn_losses/label_loss\", \"Regex\": \".*fastrcnn_losses/label_loss:\\\\s*(\\\\S+).*\"},\n",
    "    {\n",
    "        \"Name\": \"fastrcnn_losses/label_metrics/accuracy\",\n",
    "        \"Regex\": \".*fastrcnn_losses/label_metrics/accuracy:\\\\s*(\\\\S+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"fastrcnn_losses/label_metrics/false_negative\",\n",
    "        \"Regex\": \".*fastrcnn_losses/label_metrics/false_negative:\\\\s*(\\\\S+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"fastrcnn_losses/label_metrics/fg_accuracy\",\n",
    "        \"Regex\": \".*fastrcnn_losses/label_metrics/fg_accuracy:\\\\s*(\\\\S+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"fastrcnn_losses/num_fg_label\",\n",
    "        \"Regex\": \".*fastrcnn_losses/num_fg_label:\\\\s*(\\\\S+).*\",\n",
    "    },\n",
    "    {\"Name\": \"maskrcnn_loss/accuracy\", \"Regex\": \".*maskrcnn_loss/accuracy:\\\\s*(\\\\S+).*\"},\n",
    "    {\n",
    "        \"Name\": \"maskrcnn_loss/fg_pixel_ratio\",\n",
    "        \"Regex\": \".*maskrcnn_loss/fg_pixel_ratio:\\\\s*(\\\\S+).*\",\n",
    "    },\n",
    "    {\"Name\": \"maskrcnn_loss/maskrcnn_loss\", \"Regex\": \".*maskrcnn_loss/maskrcnn_loss:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"maskrcnn_loss/pos_accuracy\", \"Regex\": \".*maskrcnn_loss/pos_accuracy:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(bbox)/IoU=0.5\", \"Regex\": \".*mAP\\\\(bbox\\\\)/IoU=0\\\\.5:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(bbox)/IoU=0.5:0.95\", \"Regex\": \".*mAP\\\\(bbox\\\\)/IoU=0\\\\.5:0\\\\.95:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(bbox)/IoU=0.75\", \"Regex\": \".*mAP\\\\(bbox\\\\)/IoU=0\\\\.75:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(bbox)/large\", \"Regex\": \".*mAP\\\\(bbox\\\\)/large:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(bbox)/medium\", \"Regex\": \".*mAP\\\\(bbox\\\\)/medium:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(bbox)/small\", \"Regex\": \".*mAP\\\\(bbox\\\\)/small:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(segm)/IoU=0.5\", \"Regex\": \".*mAP\\\\(segm\\\\)/IoU=0\\\\.5:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(segm)/IoU=0.5:0.95\", \"Regex\": \".*mAP\\\\(segm\\\\)/IoU=0\\\\.5:0\\\\.95:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(segm)/IoU=0.75\", \"Regex\": \".*mAP\\\\(segm\\\\)/IoU=0\\\\.75:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(segm)/large\", \"Regex\": \".*mAP\\\\(segm\\\\)/large:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(segm)/medium\", \"Regex\": \".*mAP\\\\(segm\\\\)/medium:\\\\s*(\\\\S+).*\"},\n",
    "    {\"Name\": \"mAP(segm)/small\", \"Regex\": \".*mAP\\\\(segm\\\\)/small:\\\\s*(\\\\S+).*\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SageMaker Training Job\n",
    "\n",
    "Next, we use SageMaker [Estimator](https://sagemaker.readthedocs.io/en/stable/estimators.html) API to define a SageMaker Training Job. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training job\n",
    "\n",
    "We recommned using 16 GPUs for the training job, so we set ```instance_count=2```. We recommend using 100 GB [Amazon EBS](https://aws.amazon.com/ebs/) storage volume with each training instance, so we set ```volume_size = 100```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instance_type = 'ml.p3.16xlarge'  # You may optionally use 'ml.p3dn.24xlarge' or larger instance\n",
    "assert instance_type in ['ml.p3.16xlarge', 'ml.p3dn.24xlarge']\n",
    "\n",
    "if 'aws-samples' in model_type:\n",
    "    hyperparameters['batch_size_per_gpu'] = 2 if instance_type == 'ml.p3.16xlarge' else 4\n",
    "\n",
    "mpi_distribution = None\n",
    "instance_count = 2 # Between 1 - 4\n",
    "if instance_count > 1:\n",
    "    device_min_sys_mem_mb = 2560\n",
    "    custom_mpi_options = f\"--verbose --output-filename /opt/ml/model/logs \\\n",
    "        -x TF_DEVICE_MIN_SYS_MEMORY_IN_MB={device_min_sys_mem_mb}\"\n",
    "    mpi_distribution = {\"mpi\": { \"enabled\": True, \"custom_mpi_options\": custom_mpi_options } }   \n",
    "\n",
    "\n",
    "mask_rcnn_estimator = TensorFlow(image_uri=training_image,\n",
    "                                role=role, \n",
    "                                py_version='py3',\n",
    "                                instance_count=instance_count, \n",
    "                                instance_type=instance_type,\n",
    "                                distribution=mpi_distribution,\n",
    "                                entry_point=training_script,\n",
    "                                volume_size = 100,\n",
    "                                max_run = 400000,\n",
    "                                output_path=s3_output_location,\n",
    "                                sagemaker_session=sagemaker_session, \n",
    "                                hyperparameters = hyperparameters,\n",
    "                                metric_definitions = metric_definitions,\n",
    "                                subnets=subnets,\n",
    "                                security_group_ids=security_group_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Training Job\n",
    "\n",
    "Finally, we launch the SageMaker training job. See ```Training Jobs``` in SageMaker console to monitor the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "job_name = f\"mask-rcnn-fsx-scriptmode-{int(time.time())}\"\n",
    "print(f\"Launching Training Job: {job_name}\")\n",
    "\n",
    "data_channels = fsx_data_channels if fsx_data_channels else s3_data_channels\n",
    "\n",
    "# set wait=True below if you want to print logs in cell output\n",
    "mask_rcnn_estimator.fit(inputs=data_channels, job_name=job_name, logs=\"All\", wait=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/advanced_functionality|distributed_tensorflow_mask_rcnn|mask-rcnn-scriptmode-fsx.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
