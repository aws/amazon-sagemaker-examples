{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion XL Fine-Tuning with Kohya SS\n",
    "\n",
    "*This solution creates all the necessary components to get you started quickly with fine-tuning Stable Diffusion XL with a custom dataset, using a custom training container that leverages Kohya SS to do the fine-tuning. Stable Diffusion allows you to generate images from text prompts. The training is coordinated with an Amazon SageMaker pipeline and an Amazon SageMaker Training job. This solution automates many of the tedious tasks you must do to set up the necessary infrastructure to run your training. You will use this Notebook to set up the solution. For a general overview of the solution components, see the README file.*\n",
    "\n",
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One - Create the necessary resources through AWS CloudFormation\n",
    "\n",
    "This solution has been automated using an AWS CloudFormation template, located in this project directory. You may either run it through the AWS console, or by the CLI command below. In the template.yml file, you may update the \"KOHYA_SS_VERSION\" environment variable to use a specific version of Kohya SS, otherwise it will use v22.6.2.\n",
    "\n",
    "**Option 1: To run the AWS CloudFormation template via the AWS console, follow the steps below:**\n",
    "\n",
    "Note: Your user that is logged into the AWS Console must have the appropriate permissions to execute the stack. \n",
    "\n",
    "1. Navigate to the AWS CloudFormation console and click \"Create Stack\", then select \"With new resources (standard)\".\n",
    "2. Select \"Upload a template file\" and click \"Choose file\". Select the template.yml file located in this project directory and click \"Next\".\n",
    "3. Enter a stack name. Modify the resource name parameters if required, or leave the defaults. Click \"Next\". On the next page, click \"Next\" again.\n",
    "4. Scroll to the bottom of the page. In the \"Capabilities and transforms\" section, acknowledge the three checkbox items to confirm potential IAM updates.\n",
    "5. Click \"Submit\" to create the stack.\n",
    "\n",
    "**Option 2: To run the AWS CloudFormation template with all defaults via the AWS CLI v2, run the next command:**\n",
    "\n",
    "Note: Your SageMaker Execution role must have permissions to execute AWS CloudFormation commands, certain IAM permissions, S3 permissions, etc. If you are using the CLI and run into permission errors, you must update your Sagemaker Execution role and then continue the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!aws cloudformation create-stack --stack-name kohya-ss-fine-tuning-stack --template-body file://template.yml --capabilities \"CAPABILITY_IAM\" \"CAPABILITY_NAMED_IAM\" \"CAPABILITY_AUTO_EXPAND\" --parameters ParameterKey=TrainingS3BucketNamePrefix,ParameterValue=sagemaker-kohya-ss-fine-tuning ParameterKey=TrainingContainerRepositoryName,ParameterValue=kohya-ss-fine-tuning ParameterKey=TrainingContainerCodeRepositoryName,ParameterValue=kohya-ss-fine-tuning-container-image ParameterKey=TrainingContainerBuildProjectName,ParameterValue=kohya-ss-fine-tuning-build-container ParameterKey=TrainingPipelineName,ParameterValue=kohya-ss-fine-tuning-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the AWS CloudFormation stack to finish creating before moving on to the next step. You may check the status of the stack creation in the AWS CloudFormation console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two - Upload the fine-tuning configuration file, and your custom images to the S3 bucket\n",
    "\n",
    "The next step is to upload the following to the S3 Bucket that was created as part of Step One:\n",
    "\n",
    "**Kohya SS SDXL Configuration File: this .toml file is used to define the fine-tuning configuration parameters (instead of using the Kohya GUI)**\n",
    "\n",
    "**Custom Image Assets: You will need to provide a set of images for the fine-tuning process, which you will upload to the S3 Bucket**\n",
    "\n",
    "The structure of the S3 Bucket is intended to be the following:\n",
    "\n",
    "    bucket/0001-dataset/kohya-sdxl-config.toml\n",
    "    bucket/0001-dataset/<asset-folder-name>/        (images and caption files go here)\n",
    "    bucket/0002-dataset/kohya-sdxl-config.toml\n",
    "    bucket/0002-dataset/<asset-folder-name>/        (images and captions files go here)\n",
    "    ...\n",
    "\n",
    "The \"asset-folder-name\" must be named properly for the fine-tuning to be successful. This format will be described in the Asset Upload section below.\n",
    "Note that each \"xxxx-dataset\" prefix may contain separate datasets, with different config file contents.\n",
    "Do not change the \"kohya-sdxl-config.toml\" file name. If you change it, you will also have to change the file name in the \"train\" file.\n",
    "The config file and asset folder will be downloaded by the SageMaker Training job during the training process.\n",
    "\n",
    "**Keep in mind that whatever name you specify for \"xxxx-dataset\", will be the same parameter name you will specify when launching the SageMaker Pipeline, so it knows which files to pull.**\n",
    "\n",
    "**To upload the config file to the S3 Bucket, run the next command after you confirm the bucket name is correct:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the variables needed for the remaining steps. Update these only if you have made changes to this solution that would have changed these parameter values.\n",
    "\n",
    "# The base path of the local code that was cloned from the git repo in the README\n",
    "os.environ[\"LOCAL_CODE_BASE_PATH\"] = \"amazon-sagemaker-examples/use-cases/text-to-image-fine-tuning\"\n",
    "\n",
    "# The CodeCommit git repository name that contains the code to build the container image for training\n",
    "os.environ[\"CODECOMMIT_REPO_NAME\"] = \"kohya-ss-fine-tuning-container-image\"\n",
    "\n",
    "# The S3 bucket name that will contain the assets and config\n",
    "\n",
    "# ************** IMPORTANT NOTE: Make sure the S3 bucket below matches the S3 bucket name that was created in Step One **************\n",
    "# **************\n",
    "os.environ[\"S3_TRAINING_BUCKET\"] = f\"sagemaker-kohya-ss-fine-tuning-{os.environ['AWS_ACCOUNT_ID']}\"\n",
    "\n",
    "\n",
    "# Before uploading this config file, update your desired parameter values in \"kohya-sdxl-config.toml\".\n",
    "# Refer to the Appendix of this notebook for configuration notes. At a minimum, you will want to change the output_name parameter, which is the name of the output model.\n",
    "!aws s3 cp ~/$LOCAL_CODE_BASE_PATH/config/kohya-sdxl-config.toml \"s3://${S3_TRAINING_BUCKET}/0001-dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will upload your custom image assets to the same S3 Bucket. You will create an asset folder, and upload your images and caption files in that prefix in S3.\n",
    "\n",
    "The \"asset-folder-name\" must be named properly, according to the Kohya SS guidelines. This naming convention is what defines the number of repetitions and the trigger word for the prompt. \n",
    "\n",
    "For example, a folder name of \"60_dwjz\" signifies 60 repetitions with the trigger prompt word of \"dwjz\". Name this prefix in Amazon S3 properly according to your requirements, and manually upload your images to this prefix directory. You may change the number of repetitions, the trigger word, etc. It's a good idea to change the \"output_name\" parameter in the kohya-sdxl-config.toml file to contain your trigger word. At the end of your upload, your S3 structure should look like this:\n",
    "\n",
    "    bucket/0001-dataset/kohya-sdxl-config.toml\n",
    "    bucket/0001-dataset/60_dwjz/\n",
    "    bucket/0001-dataset/60_dwjz/1.jpg\n",
    "    bucket/0001-dataset/60_dwjz/1.caption\n",
    "    bucket/0001-dataset/60_dwjz/2.jpg\n",
    "    bucket/0001-dataset/60_dwjz/2.caption\n",
    "    ...\n",
    "\n",
    "The *.jpg files are your image assets. The *.caption files are your captions that help the model understand your prompts. The 1.caption file will contain a prompt that describes the image in 1.jpg, such as \"dwjz wearing a vest and sunglasses, serious facial expression, headshot view\".\n",
    "\n",
    "**You must upload your assets before continuing with the next steps. Caption files are optional, but encouraged.**\n",
    "\n",
    "To become more familiar with Kohya SS fine-tuning, visit the references here: https://github.com/bmaltais/kohya_ss. There are many variables to fine-tuning, and currently no accepted single pattern for generating great results. To ensure good results, ensure you have enough steps in the training, as well as good resolution assets, and make sure to have enough images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Three - Upload the necessary code to the AWS CodeCommit repository\n",
    "\n",
    "The code required for this solution is in the \"code\" directory of this project. In the next step, these files will be uploaded to the AWS CodeCommit repository that was created by the AWS CloudFormation template. This repository contains the code required to build the custom training container. Any updates to the code in this repository will trigger the container image to be built and pushed to ECR (i.e. through an EventBridge rule). Once you run the next steps, it will kick off the process that creates the training container image.\n",
    "\n",
    "- The \"buildspec.yml\" file creates the container image by leveraging the GitHub repository for Kohya SS, and pushes the training image to ECR\n",
    "- The \"Dockerfile\" file is used to override the Dockerfile in the Kohya SS project, enabling it for use with SageMaker Training\n",
    "- The \"train\" file calls the Kohya SS program to do the fine-tuning, and is invoked when the SageMaker Training job kicks off\n",
    "\n",
    "**To copy these files to the AWS CodeCommit repository, run the next commands:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Initial configuration for accessing CodeCommit. Reference: https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-git-remote-codecommit.html\n",
    "\n",
    "# Install latest pip version\n",
    "!curl -O https://bootstrap.pypa.io/get-pip.py\n",
    "!python3 get-pip.py --user\n",
    "\n",
    "# # Install git-remote-codecommit\n",
    "!pip install git-remote-codecommit\n",
    "\n",
    "# Clone the CodeCommit repository\n",
    "# ************** IMPORTANT NOTE: Make sure the region and the repository name below match the CodeCommit repository name that was created in Step One **************\n",
    "# **************\n",
    "!git clone codecommit::us-west-2://$CODECOMMIT_REPO_NAME /home/sagemaker-user/$CODECOMMIT_REPO_NAME\n",
    "\n",
    "# Change directories because this is where we cloned the repo in the step above\n",
    "# We will clone in a separate git directory because we don't want it to conflict with the amazon-sagemaker-examples repo that we cloned earlier\n",
    "os.chdir(f\"/home/sagemaker-user/{os.environ['CODECOMMIT_REPO_NAME']}\")\n",
    "\n",
    "# Copy the \"code\" directory files from the amazon-sagemaker-examples repository to the local git repository\n",
    "# We will commit the changes to this local git repository to the CodeCommit repository in our AWS account\n",
    "!cp -r ~/$LOCAL_CODE_BASE_PATH/code/* ~/$CODECOMMIT_REPO_NAME\n",
    "!git add .\n",
    "!git -c user.name=Author -c user.email=author@example.com commit -m \"initial commit\"\n",
    "!git push origin master:main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Four - Initiate the Amazon SageMaker Pipeline to start training\n",
    "\n",
    "Note: If you are running through this Notebook for the first time, you must ensure the previous step has finished uploading the container image to ECR before you continue. Every time you make a code change in the AWS CodeCommit repository, you must wait until the CodeBuild job completes so that it pushes the newest container image to ECR for use by this next step.\n",
    "\n",
    "To run a SageMaker pipeline, navigate to SageMaker Studio and follow the steps below:\n",
    "\n",
    "1. In the left navigation pane, click the Home button, and click \"Pipelines\".\n",
    "2. Navigate to the pipeline named \"kohya-ss-fine-tuning-pipeline\" and click it. If you changed the default name of the pipeline resource in Step One, select that one instead.\n",
    "3. Click \"Create execution\". Then enter a name for the execution.\n",
    "4. Update the parameter values if necessary, and click \"Start\" to execute the pipeline.\n",
    "5. As the pipeline is running, you may view the logs by clicking the step in the pipeline, and clicking the \"Logs\" button. You may also view related details in the SageMaker Training job console.\n",
    "6. Wait for the pipeline to complete.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "-InputS3DatasetLocation: the S3 prefix containing the training resources (e.g. sagemaker-kohya-ss-fine-tuning-\\<aws-account-id\\>/0001-dataset)\n",
    "\n",
    "-OutputS3ModelLocation: where the resulting model will be output (e.g. sagemaker-kohya-ss-fine-tuning-\\<aws-account-id\\>/model-outputs)\n",
    "\n",
    "-TrainingDockerImage: the latest ECR image tag\n",
    "\n",
    "-TrainingInstanceType: the instance type to run the training on\n",
    "\n",
    "-TrainingVolumeSizeInGB: the volume size of the training instance\n",
    "\n",
    "-MaxTrainingRuntimeInSeconds: the maximum time the training is allowed to run\n",
    "\n",
    "For training that will require many epochs/steps, also consider updating the MaxTrainingRuntimeInSeconds (currently set for 24 hours). The number of total steps is affected by the number of repetitions (ie the number in the asset folder name), the number of images, the number of epochs, and batch size. The more steps, the longer the training. You might also consider different instance types and volume sizes if your use case requires it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Five - Inference\n",
    "\n",
    "Once training is complete, the SageMaker Pipeline will show green for Status. Alternatively, you may also view job details in the SageMaker Training job console. By clicking on the SageMaker Pipeline step labeled \"TrainNewFineTunedModel\", you can view input/output details as well as logs. The Output tab shows where in S3 the output model has been uploaded to.\n",
    "\n",
    "In future iterations of this solution, a custom inference container may be created to run inference using this fine-tuned model. For now, we may use other tools to run inference. The [Automatic1111 Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) is a GUI that allows you to run inference on your models locally. \n",
    "\n",
    "1. Follow the directions to install the Stable Diffusion Web UI either locally, or on an EC2 instance.\n",
    "2. Download the model.tar.gz file from S3. This model contains your fine-tuned model.\n",
    "3. Unzip the contents of the model file, and copy the .safetensors file to the location \"\\<path to web ui installation\\>\\sd.webui\\webui\\models\\Lora\\\". \n",
    "4. Open the Stable Diffusion Web UI program. On Windows, this will be the program \"\\webui\\webui-user.bat\".\n",
    "5. In the web browser where your Web UI is running, click the button \"Show/hide extra networks\". Then navigate to the \"Lora\" tab. This is where all of your models in the Lora folder will show up. Click the model, and it will populate the prompt input box with \\<lora:model-name:1\\>.\n",
    "6. Append your prompt to that, and click \"Generate\" to run inference against your fine-tuned model. Note that you may decrease/increase the multiplier of your LoRA model by changing the \"1\" value. This adjusts the influence of your LoRA model accordingly.\n",
    "\n",
    "Note: This example demonstrates LoRA fine-tuning. We trained a LoRA model in the previous steps by specifying the LoRA network type in the configuration file.\n",
    "\n",
    "## Congratulations!\n",
    "#### You have successfully fine-tuned a custom SDXL model, and ran inference on it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "#### **The Kohya configuration .toml file**\n",
    "This file contains the config values that are fed into the Kohya program for training. If you change the config filename, you must also change it in the \"train\" file. This configuration is not specific to just Stable Diffusion XL. It's flexible to apply to other pre-trained models (however, if you modify the config file to apply to other models, also change the entrypoint file in the \"train\" file, as it currently points to \"sdxl_train_network.py\"). The configuration instance contained in this sample repository is one possible configuration for SDXL. This is the reason that some parameters are commented out - because they are either optional for SDXL, or don't apply to SDXL. There is currently no consensus for optimal parameter values. You will need to try different permutations of the configuration and compare your output model. This is a good starting point as to what the parameters mean: https://github.com/bmaltais/kohya_ss/wiki/LoRA-training-parameters\n",
    "\n",
    "To give you some initial direction, try modifying these hyperparameters first:\n",
    "- learning_rate\n",
    "- text_encoder_lr\n",
    "- unet_lr\n",
    "- optimizer_type\n",
    "- network_dim\n",
    "- the number of repetitions (you set this by the asset folder name prefix, e.g. the 60 in 60_dwjz_man signifies the number of repetitions)\n",
    "\n",
    "Please note that some config parameters rely on underlying hardware/GPU type (e.g. mixed_precision=bf16, xformers, etc). You must ensure that your training instance has the proper hardware configuration.\n",
    "\n",
    "\n",
    "#### **Solution enhancements**\n",
    "There are a few enhancements that may be made to the Kohya component, to allow for the following. These are currently not enabled.\n",
    "- Sampling. Support may be added for adding sampling, which outputs images regularly during the training process. This variable is specified by the \"sample_*\" parameters in the configuration file.\n",
    "- Regularization. Support may be added for adding regularization images in a specific directory. This variable is specified by the \"reg_data_dir\" parameter in the configuration file.\n",
    "- Captions. Support may be added for auto-generating caption files for the images before training. Currently, you must manually add caption files to the S3 directory.\n",
    "\n",
    "\n",
    "#### **Model output upload time**\n",
    "The resulting fine-tuned LoRA model is likely to be a few GB, which takes time to upload to S3 once the training has completed. Enhancements may be made to reduce this upload time in the future.\n",
    "\n",
    "\n",
    "#### **AWS CloudFormation template enhancements**\n",
    "PERMISSIONS: Consider restricting the permissions for the following Roles. Currently, these permissions use Administrator permissions, and are unrestricted.\n",
    "\n",
    "- SageMakerServiceRole\n",
    "- PipelineExecutionRole\n",
    "\n",
    "INFERENCE: This solution outputs a model to be used for inference, but does not automate the inference component. Enhancements may be made to build a custom inference container using this fine-tuned model.\n",
    "\n",
    "SAGEMAKER: Consider restricting internet access and instead using AWS PrivateLink, as well as using SageMaker inside a VPC.\n",
    "\n",
    "\n",
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/use-cases|text-to-image-fine-tuning|kohya-ss-fine-tuning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
