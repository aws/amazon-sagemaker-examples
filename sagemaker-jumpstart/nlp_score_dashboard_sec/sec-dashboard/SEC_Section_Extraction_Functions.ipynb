{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC SECTION EXTRACTOR and VISUALIZATION FUNCTIONS\n",
    "\n",
    "Helper functions needed for section extraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for extracting the \"Item\" sections from the forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "!pip install transformers==4.11.3 --ignore-installed ruamel-yaml\n",
    "!pip install torch==1.9.1 --no-cache-dir\n",
    "!pip install altair==4.1.0\n",
    "!pip install vega==3.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_items(part_header, part_text, form_type):\n",
    "    \"\"\"Extracts the item header and its corresponding text for every item within the plain text of a \"part\" of a form.\n",
    "\n",
    "    :type part_header: str\n",
    "    :param part_header: The header of a \"part\" of a form (e.g. Part III)\n",
    "\n",
    "    :type part_text: str\n",
    "    :param part_text: The plain text of a \"part\" of a form (e.g. Part III). In the case of 10-K and 8-K forms, the \"part\" is the whole form.\n",
    "\n",
    "    :type form_type: str\n",
    "    :param form_type: The form type (e.g. 10-K, 10-Q, 8-K)\n",
    "\n",
    "    :rtype: Iterator[(str, str, str)]\n",
    "    :returns: An iterator over tuples of the form (part_header, item_header, text)\n",
    "        where \"item_header\" is the item header and \"text\" is the corresponding text\n",
    "        for each item in the \"part\". part_header is included to differentiate\n",
    "        between portions of a filing that have the same item number but are in different parts.\n",
    "    \"\"\"\n",
    "    if form_type == \"10-K\" or form_type == \"10-Q\":\n",
    "        pattern = \"(?P<header>(\\n\\n(ITEM|Item) \\d+[A-Z]*.*?)\\n\\n)(?P<text>.*?)(?=(\\n\\n(ITEM|Item) \\d+[A-Z]*.*?)\\n\\n|$)\"\n",
    "    elif form_type == \"8-K\":\n",
    "        pattern = \"(?P<header>\\n\\n(ITEM|Item) \\d+\\.\\d+\\.*)(?P<text>.*?)(?=((\\n\\n(ITEM|Item) \\d+\\.\\d+.*?)\\n\\n|$))\"\n",
    "    return (\n",
    "        (part_header, _.group(\"header\").strip(), _.group(\"text\").strip())\n",
    "        for _ in re.finditer(pattern, part_text, re.DOTALL)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(form_text, form_type):\n",
    "    \"\"\"Extracts every part from form plain text, where a \"part\" is defined\n",
    "    specifically as a portion in the form starting with \"PART (some roman numeral)\".\n",
    "\n",
    "    :type form_text: str\n",
    "    :param form_text: The form plain text.\n",
    "\n",
    "    :type form_type: str\n",
    "    :param form_type: The form type (e.g. 10-K, 10-Q, 8-K)\n",
    "\n",
    "    :rtype: Iterator[(str, str)]\n",
    "    :returns: An iterator over the header and text for each part extracted from the form plain text.\n",
    "        (e.g. for 10-K forms, we iterate through Part I through Part IV)\n",
    "    \"\"\"\n",
    "    pattern = \"((^PART|^Part|\\n\\nPART|\\n\\nPart) [IVXLCDM]+).*?(\\n\\n.*?)(?=\\n\\n(PART|Part) [IVXLCDM]+.*?\\n\\n|$)\"\n",
    "    return ((_.group(1).strip(), _.group(3)) for _ in re.finditer(pattern, form_text, re.DOTALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_form_items(form_text, form_type):\n",
    "    \"\"\"Extracts the item header and its corresponding text for every item within a form's plaintext.\n",
    "\n",
    "    :type form_text: str\n",
    "    :param form_text: The form plain text.\n",
    "\n",
    "    :type form_type: str\n",
    "    :param form_type: The form type (e.g. 10-K, 10-Q, 8-K)\n",
    "\n",
    "    :rtype: Iterator[(str, str)]\n",
    "    :returns: An iterator over tuples of the form (header, text) where \"header\" is the item header and \"text\" is the corresponding text.\n",
    "    \"\"\"\n",
    "    if form_type == \"10-Q\":\n",
    "        for part_header, part_text in extract_parts(form_text, form_type):\n",
    "            items = extract_items(part_header, part_text, form_type)\n",
    "            yield from items\n",
    "    elif form_type == \"8-K\" or form_type == \"10-K\":\n",
    "        items = extract_items(\"\", form_text, form_type)\n",
    "        yield from items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for building a dataframe whose columns are the different \"Item\" sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_df_row(item_iter, columns, form_type):\n",
    "    \"\"\"Takes an iterator over tuples of the form (header, text) that is created from calling extract_items\n",
    "    and generates a row for a dataframe that has a column for each of the item types.\n",
    "\n",
    "    :type item_iter: Iterator[(str, str, str)]\n",
    "    :param item_iter: An iterator over tuples of the form (part_header, item_header, item_text).\n",
    "\n",
    "    :type columns: List[str]\n",
    "    :param columns: A list of column names for the dataframe we wish to generate a row for.\n",
    "\n",
    "    :type form_type: str\n",
    "    :param form_type: The form type. Currently supported types include 10-K, 10-Q, 8-K.\n",
    "\n",
    "    :rtype: List[str]\n",
    "    :returns: A row for the dataframe.\n",
    "    \"\"\"\n",
    "    mapping = {}  # mapping between processed column names and their corresponding row index\n",
    "    for idx, col_name in enumerate(columns):\n",
    "        processed_col_name = col_name.lower()\n",
    "        mapping[processed_col_name] = idx\n",
    "\n",
    "    returned_row = [\"\" for i in range(len(columns))]\n",
    "    for part_header, item_header, text in item_iter:\n",
    "        processed_header = (part_header.lower() + \" \" + item_header.lower()).strip()\n",
    "        if form_type == \"10-Q\":\n",
    "            processed_header = re.search(\"part [ivxlcdm]+ item \\d+[a-z]*\", processed_header).group(\n",
    "                0\n",
    "            )\n",
    "        elif form_type == \"10-K\":\n",
    "            processed_header = re.search(\"item \\d+[a-z]*\", processed_header).group(0)\n",
    "        elif form_type == \"8-K\":\n",
    "            if processed_header[-1] == \".\":\n",
    "                processed_header = processed_header[\n",
    "                    :-1\n",
    "                ]  # Some companies will include a period at the end of the header while others don't\n",
    "        if processed_header in mapping.keys():\n",
    "            row_index = mapping[processed_header]\n",
    "            returned_row[row_index] = text\n",
    "\n",
    "    return returned_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required hard-coded values for the different Item section header names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_10K = [\n",
    "    \"Item 1\",\n",
    "    \"Item 1A\",\n",
    "    \"Item 1B\",\n",
    "    \"Item 2\",\n",
    "    \"Item 3\",\n",
    "    \"Item 4\",\n",
    "    \"Item 5\",\n",
    "    \"Item 6\",\n",
    "    \"Item 7\",\n",
    "    \"Item 7A\",\n",
    "    \"Item 8\",\n",
    "    \"Item 9\",\n",
    "    \"Item 9A\",\n",
    "    \"Item 9B\",\n",
    "    \"Item 10\",\n",
    "    \"Item 11\",\n",
    "    \"Item 12\",\n",
    "    \"Item 13\",\n",
    "    \"Item 14\",\n",
    "    \"Item 15\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_10Q = [\n",
    "    \"Part I Item 1\",\n",
    "    \"Part I Item 2\",\n",
    "    \"Part I Item 3\",\n",
    "    \"Part I Item 4\",\n",
    "    \"Part II Item 1\",\n",
    "    \"Part II Item 1A\",\n",
    "    \"Part II Item 2\",\n",
    "    \"Part II Item 3\",\n",
    "    \"Part II Item 4\",\n",
    "    \"Part II Item 5\",\n",
    "    \"Part II Item 6\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_8K = [\n",
    "    \"Item 1.01\",\n",
    "    \"Item 1.02\",\n",
    "    \"Item 1.03\",\n",
    "    \"Item 1.04\",\n",
    "    \"Item 2.01\",\n",
    "    \"Item 2.02\",\n",
    "    \"Item 2.03\",\n",
    "    \"Item 2.04\",\n",
    "    \"Item 2.05\",\n",
    "    \"Item 2.06\",\n",
    "    \"Item 3.01\",\n",
    "    \"Item 3.02\",\n",
    "    \"Item 3.03\",\n",
    "    \"Item 4.01\",\n",
    "    \"Item 4.02\",\n",
    "    \"Item 5.01\",\n",
    "    \"Item 5.02\",\n",
    "    \"Item 5.03\",\n",
    "    \"Item 5.04\",\n",
    "    \"Item 5.05\",\n",
    "    \"Item 5.06\",\n",
    "    \"Item 5.07\",\n",
    "    \"Item 5.08\",\n",
    "    \"Item 6.01\",\n",
    "    \"Item 6.02\",\n",
    "    \"Item 6.03\",\n",
    "    \"Item 6.04\",\n",
    "    \"Item 6.05\",\n",
    "    \"Item 7.01\",\n",
    "    \"Item 8.01\",\n",
    "    \"Item 9.01\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_mappings_10K = {\n",
    "    \"Item 1\": \"Business\",\n",
    "    \"Item 1A\": \"Risk Factors\",\n",
    "    \"Item 1B\": \"Unresolved Staff Comments\",\n",
    "    \"Item 2\": \"Properties\",\n",
    "    \"Item 3\": \"Legal Proceedings\",\n",
    "    \"Item 4\": \"Mine Safety Disclosures\",\n",
    "    \"Item 5\": \"Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\",\n",
    "    \"Item 6\": \"Selected Financial Data\",\n",
    "    \"Item 7\": \"Management’s Discussion and Analysis of Financial Condition and Results of Operations\",\n",
    "    \"Item 7A\": \"Quantitative and Qualitative Disclosures about Market Risk\",\n",
    "    \"Item 8\": \"Financial Statements and Supplementary Data\",\n",
    "    \"Item 9\": \"Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\",\n",
    "    \"Item 9A\": \"Controls and Procedures\",\n",
    "    \"Item 9B\": \"Other Information\",\n",
    "    \"Item 10\": \"Directors, Executive Officers and Corporate Governance\",\n",
    "    \"Item 11\": \"Executive Compensation\",\n",
    "    \"Item 12\": \"Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\",\n",
    "    \"Item 13\": \"Certain Relationships and Related Transactions, and Director Independence\",\n",
    "    \"Item 14\": \"Principal Accountant Fees and Services\",\n",
    "    \"Item 15\": \"Exhibits, Financial Statement Schedules\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_mappings_10Q = {\n",
    "    \"Part I Item 1\": \"Financial Statements\",\n",
    "    \"Part I Item 2\": \"Management’s Discussion and Analysis of Financial Condition and Results of Operations\",\n",
    "    \"Part I Item 3\": \"Quantitative and Qualitative Disclosures About Market Risk\",\n",
    "    \"Part I Item 4\": \"Controls and Procedures\",\n",
    "    \"Part II Item 1\": \"Legal Proceedings\",\n",
    "    \"Part II Item 1A\": \"Risk Factors\",\n",
    "    \"Part II Item 2\": \"Unregistered Sales of Equity Securities and Use of Proceeds\",\n",
    "    \"Part II Item 3\": \"Defaults Upon Senior Securities\",\n",
    "    \"Part II Item 4\": \"Mine Safety Disclosures\",\n",
    "    \"Part II Item 5\": \"Other Information\",\n",
    "    \"Part II Item 6\": \"Exhibits\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_mappings_8K = {\n",
    "    \"Item 1.01\": \"Entry into a Material Definitive Agreement\",\n",
    "    \"Item 1.02\": \"Termination of a Material Definitive Agreement\",\n",
    "    \"Item 1.03\": \"Bankruptcy or Receivership\",\n",
    "    \"Item 1.04\": \"Mine Safety - Reporting of Shutdowns and Patterns of Violations\",\n",
    "    \"Item 2.01\": \"Completion of Acquisition or Disposition of Assets\",\n",
    "    \"Item 2.02\": \"Results of Operations and Financial Condition\",\n",
    "    \"Item 2.03\": \"Creation of a Direct Financial Obligation or an Obligation under an Off-Balance Sheet Arrangement of a Registrant\",\n",
    "    \"Item 2.04\": \"Triggering Events That Accelerate or Increase a Direct Financial Obligation or an Obligation under an Off-Balance Sheet Arrangement\",\n",
    "    \"Item 2.05\": \"Costs Associated with Exit or Disposal Activities\",\n",
    "    \"Item 2.06\": \"Material Impairments\",\n",
    "    \"Item 3.01\": \"Notice of Delisting or Failure to Satisfy a Continued Listing Rule or Standard; Transfer of Listing\",\n",
    "    \"Item 3.02\": \"Unregistered Sales of Equity Securities\",\n",
    "    \"Item 3.03\": \"Material Modification to Rights of Security Holders\",\n",
    "    \"Item 4.01\": \"Changes in Registrant's Certifying Accountant\",\n",
    "    \"Item 4.02\": \"Non-Reliance on Previously Issued Financial Statements or a Related Audit Report or Completed Interim Review\",\n",
    "    \"Item 5.01\": \"Changes in Control of Registrant\",\n",
    "    \"Item 5.02\": \"Departure of Directors or Certain Officers; Election of Directors; Appointment of Certain Officers; Compensatory Arrangements of Certain Officers\",\n",
    "    \"Item 5.03\": \"Amendments to Articles of Incorporation or Bylaws; Change in Fiscal Year\",\n",
    "    \"Item 5.04\": \"Temporary Suspension of Trading Under Registrant's Employee Benefit Plans\",\n",
    "    \"Item 5.05\": \"Amendment to Registrant's Code of Ethics, or Waiver of a Provision of the Code of Ethics\",\n",
    "    \"Item 5.06\": \"Change in Shell Company Status\",\n",
    "    \"Item 5.07\": \"Submission of Matters to a Vote of Security Holders\",\n",
    "    \"Item 5.08\": \"Shareholder Director Nominations\",\n",
    "    \"Item 6.01\": \"ABS Informational and Computational Material\",\n",
    "    \"Item 6.02\": \"Change of Servicer or Trustee\",\n",
    "    \"Item 6.03\": \"Change in Credit Enhancement or Other External Support\",\n",
    "    \"Item 6.04\": \"Failure to Make a Required Distribution\",\n",
    "    \"Item 6.05\": \"Securities Act Updating Disclosure\",\n",
    "    \"Item 7.01\": \"Regulation FD Disclosure\",\n",
    "    \"Item 8.01\": \"Other Events\",\n",
    "    \"Item 9.01\": \"Financial Statements and Exhibits\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarizer code\n",
    "summarizer = pipeline(\"summarization\")  # Uses the HF model\n",
    "\n",
    "# Set the max no of tokens (way less than 1000 because BERT does word-piece tokenization that splits words)\n",
    "# So to be safe, we keep it as below. https://paperswithcode.com/method/wordpiece\n",
    "max_seq_len = 500  # just less than 1024\n",
    "summary_pct = 0.10  # size of summary\n",
    "\n",
    "# Count the number of tokens from wordpiece tokenization\n",
    "def numtokens(txt):  # method to find how many tokens are in a passed string\n",
    "    x = summarizer.tokenizer(txt, return_length=True)\n",
    "    return x.length\n",
    "\n",
    "\n",
    "# Summarizer for long docs. Broken into two functions\n",
    "# partSummary takes the first set of paragraphs that are within max_seq_len and gives back summary and remaining paragraphs\n",
    "# fullSummary keeps calling partSummary until there are no paragraphs left. It joins all the part summaries to give a final summary\n",
    "def partSummary(txt):\n",
    "    numt = numtokens(txt)[0]  # number of tokens of the passed text\n",
    "    if numt < max_seq_len:  # if the passed text is already less than the max_seq_len, summarize it\n",
    "        summary = summarizer(\n",
    "            txt, min_length=int(numt * summary_pct / 2), max_length=int(numt * summary_pct)\n",
    "        )\n",
    "        txt = \"\"\n",
    "    else:\n",
    "        paragraph_list = txt.split(\"\\n\\n\")  # make separate paragraphs\n",
    "        lenp = [\n",
    "            numtokens(para)[0] for para in paragraph_list\n",
    "        ]  # get the number of tokens in each paragraph\n",
    "        if lenp[0] > max_seq_len:  # Special handling if first paragraph exceeds max_seq_len\n",
    "            sent_list = sent_tokenize(paragraph_list[0])  # split paragraph into sentences\n",
    "            lens = [\n",
    "                numtokens(sent)[0] for sent in sent_list\n",
    "            ]  # get the number of tokens in each sentence\n",
    "            if (\n",
    "                lens[0] > max_seq_len\n",
    "            ):  # special handling if the first \"sentence\" of the paragraph exceeds max_seq_len\n",
    "                paragraph_list.pop(0)  # skip summarizing this paragraph - summarize an empty string\n",
    "                summary = summarizer(\"\", min_length=0, max_length=2)\n",
    "                return summary, (\"\\n\\n\".join(paragraph_list))\n",
    "            else:  # split this larger paragraph into smaller paragraphs by adding the sentences\n",
    "                idx = where(cumsum(lens) > max_seq_len)[\n",
    "                    0\n",
    "                ].min()  # get the index where the sentences cross max_seq_len\n",
    "                x1 = \" \".join(\n",
    "                    sent_list[:idx]\n",
    "                )  # create the first paragraph, which is suitable for summarization\n",
    "                x2 = \" \".join(\n",
    "                    sent_list[idx:]\n",
    "                )  # create the second paragraph, using the rest of the original paragraph\n",
    "                paragraph_list[0] = x2  # insert these two paragraphs back into the paragraph list\n",
    "                paragraph_list.insert(0, x1)\n",
    "        lenp = [\n",
    "            numtokens(para)[0] for para in paragraph_list\n",
    "        ]  # get the number of tokens in each paragraph\n",
    "        idx = where(cumsum(lenp) > max_seq_len)[\n",
    "            0\n",
    "        ].min()  # get the index where it crosses max_seq_len\n",
    "        to_be_summ = \"\\n\\n\".join(paragraph_list[:idx])  # fast way to append the paras\n",
    "        numt = numtokens(to_be_summ)[0]\n",
    "        # print('[', numt, ']', end = '..')\n",
    "        summary = summarizer(\n",
    "            to_be_summ, min_length=int(numt * summary_pct / 2), max_length=int(numt * summary_pct)\n",
    "        )\n",
    "        txt = \"\\n\\n\".join(paragraph_list[idx:])  # return remaining paras to be summarized\n",
    "    return summary, txt\n",
    "\n",
    "\n",
    "def fullSummary(txt):\n",
    "    final_summary = \"\"\n",
    "    while len(txt) > 0:\n",
    "        # print ('lentext =', len(txt), end = '..')\n",
    "        summary, txt = partSummary(txt)\n",
    "        final_summary = final_summary + summary[0][\"summary_text\"]\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from vega import Vega\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrfunc(x, y, ax=None, **kws):\n",
    "    r, _ = pearsonr(x, y)\n",
    "    ax = ax or plt.gca()\n",
    "    ax.annotate(f\"p = {r:.2f}\", xy=(0.1, 0.9), xycoords=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorrelogram(df):\n",
    "    g = sns.pairplot(df, corner=True)\n",
    "    g.map_lower(corrfunc)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHeatmap(df):\n",
    "    sns.heatmap(df.corr(), annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vega RadarChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vega(spec):\n",
    "    bundle = {}\n",
    "    bundle[\"application/vnd.vega.v5+json\"] = spec\n",
    "    display(bundle, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max scaling done here\n",
    "def scaleScores(scores):\n",
    "    df = scores.copy()\n",
    "    cols = sorted(df.columns[1:-1])\n",
    "    df = df[cols]\n",
    "    scores_scaled = minmax_scale(df)  # scoring against other scores in the same NLP column\n",
    "    return scores_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncates a number\n",
    "def truncate(n, decimal):\n",
    "    multiplier = 10**decimal\n",
    "    return int(n * multiplier) / multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRadarChart(scores, tenk1_index, tenk2_index):\n",
    "    scores_scaled = scaleScores(scores)\n",
    "    radarchart = Vega(\n",
    "        {\n",
    "            \"$schema\": \"https://vega.github.io/schema/vega/v5.json\",\n",
    "            \"description\": \"A radar chart example, showing multiple dimensions in a radial layout.\",\n",
    "            \"width\": 400,\n",
    "            \"height\": 400,\n",
    "            \"padding\": 80,\n",
    "            \"autosize\": {\"type\": \"none\", \"contains\": \"padding\"},\n",
    "            \"signals\": [{\"name\": \"radius\", \"update\": \"width / 2\"}],\n",
    "            \"data\": [\n",
    "                {\n",
    "                    \"name\": \"table\",\n",
    "                    \"values\": [\n",
    "                        {\n",
    "                            \"key\": \"certainty\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][0], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"fraud\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][1], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"litigious\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][2], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"negative\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][3], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"polarity\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][4], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"positive\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][5], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"readability\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][6], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"risk\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][7], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"safe\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][8], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"sentiment\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][9], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"uncertainty\",\n",
    "                            \"value\": truncate(scores_scaled[tenk1_index][10], 2),\n",
    "                            \"category\": 1,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"certainty\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][0], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"fraud\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][1], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"litigious\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][2], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"negative\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][3], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"polarity\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][4], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"positive\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][5], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"readability\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][6], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"risk\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][7], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"safe\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][8], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"sentiment\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][9], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                        {\n",
    "                            \"key\": \"uncertainty\",\n",
    "                            \"value\": truncate(scores_scaled[tenk2_index][10], 2),\n",
    "                            \"category\": 2,\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"keys\",\n",
    "                    \"source\": \"table\",\n",
    "                    \"transform\": [{\"type\": \"aggregate\", \"groupby\": [\"key\"]}],\n",
    "                },\n",
    "            ],\n",
    "            \"scales\": [\n",
    "                {\n",
    "                    \"name\": \"angular\",\n",
    "                    \"type\": \"point\",\n",
    "                    \"range\": {\"signal\": \"[-PI, PI]\"},\n",
    "                    \"padding\": 0.5,\n",
    "                    \"domain\": {\"data\": \"table\", \"field\": \"key\"},\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"radial\",\n",
    "                    \"type\": \"linear\",\n",
    "                    \"range\": {\"signal\": \"[0, radius]\"},\n",
    "                    \"zero\": True,\n",
    "                    \"nice\": False,\n",
    "                    \"domain\": {\"data\": \"table\", \"field\": \"value\"},\n",
    "                    \"domainMin\": 0,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"color\",\n",
    "                    \"type\": \"ordinal\",\n",
    "                    \"domain\": {\"data\": \"table\", \"field\": \"category\"},\n",
    "                    \"range\": {\"scheme\": \"category10\"},\n",
    "                },\n",
    "            ],\n",
    "            \"encode\": {\"enter\": {\"x\": {\"signal\": \"radius\"}, \"y\": {\"signal\": \"radius\"}}},\n",
    "            \"marks\": [\n",
    "                {\n",
    "                    \"type\": \"group\",\n",
    "                    \"name\": \"categories\",\n",
    "                    \"zindex\": 1,\n",
    "                    \"from\": {\"facet\": {\"data\": \"table\", \"name\": \"facet\", \"groupby\": [\"category\"]}},\n",
    "                    \"marks\": [\n",
    "                        {\n",
    "                            \"type\": \"line\",\n",
    "                            \"name\": \"category-line\",\n",
    "                            \"from\": {\"data\": \"facet\"},\n",
    "                            \"encode\": {\n",
    "                                \"enter\": {\n",
    "                                    \"interpolate\": {\"value\": \"linear-closed\"},\n",
    "                                    \"x\": {\n",
    "                                        \"signal\": \"scale('radial', datum.value) * cos(scale('angular', datum.key))\"\n",
    "                                    },\n",
    "                                    \"y\": {\n",
    "                                        \"signal\": \"scale('radial', datum.value) * sin(scale('angular', datum.key))\"\n",
    "                                    },\n",
    "                                    \"stroke\": {\"scale\": \"color\", \"field\": \"category\"},\n",
    "                                    \"strokeWidth\": {\"value\": 1},\n",
    "                                    \"fill\": {\"scale\": \"color\", \"field\": \"category\"},\n",
    "                                    \"fillOpacity\": {\"value\": 0.1},\n",
    "                                }\n",
    "                            },\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"name\": \"value-text\",\n",
    "                            \"from\": {\"data\": \"category-line\"},\n",
    "                            \"encode\": {\n",
    "                                \"enter\": {\n",
    "                                    \"x\": {\"signal\": \"datum.x\"},\n",
    "                                    \"y\": {\"signal\": \"datum.y\"},\n",
    "                                    \"text\": {\"signal\": \"datum.datum.value\"},\n",
    "                                    \"align\": {\"value\": \"center\"},\n",
    "                                    \"baseline\": {\"value\": \"middle\"},\n",
    "                                    \"fill\": {\"value\": \"black\"},\n",
    "                                }\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"rule\",\n",
    "                    \"name\": \"radial-grid\",\n",
    "                    \"from\": {\"data\": \"keys\"},\n",
    "                    \"zindex\": 0,\n",
    "                    \"encode\": {\n",
    "                        \"enter\": {\n",
    "                            \"x\": {\"value\": 0},\n",
    "                            \"y\": {\"value\": 0},\n",
    "                            \"x2\": {\"signal\": \"radius * cos(scale('angular', datum.key))\"},\n",
    "                            \"y2\": {\"signal\": \"radius * sin(scale('angular', datum.key))\"},\n",
    "                            \"stroke\": {\"value\": \"lightgray\"},\n",
    "                            \"strokeWidth\": {\"value\": 1},\n",
    "                        }\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"name\": \"key-label\",\n",
    "                    \"from\": {\"data\": \"keys\"},\n",
    "                    \"zindex\": 1,\n",
    "                    \"encode\": {\n",
    "                        \"enter\": {\n",
    "                            \"x\": {\"signal\": \"(radius + 5) * cos(scale('angular', datum.key))\"},\n",
    "                            \"y\": {\"signal\": \"(radius + 5) * sin(scale('angular', datum.key))\"},\n",
    "                            \"text\": {\"field\": \"key\"},\n",
    "                            \"align\": [\n",
    "                                {\n",
    "                                    \"test\": \"abs(scale('angular', datum.key)) > PI / 2\",\n",
    "                                    \"value\": \"right\",\n",
    "                                },\n",
    "                                {\"value\": \"left\"},\n",
    "                            ],\n",
    "                            \"baseline\": [\n",
    "                                {\"test\": \"scale('angular', datum.key) > 0\", \"value\": \"top\"},\n",
    "                                {\"test\": \"scale('angular', datum.key) == 0\", \"value\": \"middle\"},\n",
    "                                {\"value\": \"bottom\"},\n",
    "                            ],\n",
    "                            \"fill\": {\"value\": \"black\"},\n",
    "                            \"fontWeight\": {\"value\": \"bold\"},\n",
    "                        }\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"line\",\n",
    "                    \"name\": \"outer-line\",\n",
    "                    \"from\": {\"data\": \"radial-grid\"},\n",
    "                    \"encode\": {\n",
    "                        \"enter\": {\n",
    "                            \"interpolate\": {\"value\": \"linear-closed\"},\n",
    "                            \"x\": {\"field\": \"x2\"},\n",
    "                            \"y\": {\"field\": \"y2\"},\n",
    "                            \"stroke\": {\"value\": \"lightgray\"},\n",
    "                            \"strokeWidth\": {\"value\": 1},\n",
    "                        }\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install R for creating an interactive screening table\n",
    "!apt-get update\n",
    "!apt-get -y install r-base r-base-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINISHED FUNCTION INSTALL.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "HUB_1P_IMAGE"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
