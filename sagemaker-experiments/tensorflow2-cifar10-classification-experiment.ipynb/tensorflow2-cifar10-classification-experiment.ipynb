{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baab172f",
   "metadata": {},
   "source": [
    "## CIFAR-10 Classification Experiment\n",
    "\n",
    "This demo shows how you can use SageMaker Experiment Management Python SDK to organize, track, compare, and evaluate your machine learning (ML) model training experiments.\n",
    "\n",
    "You can track artifacts for experiments, including data sets, algorithms, hyper-parameters, and metrics. Experiments executed on SageMaker such as SageMaker Autopilot jobs and training jobs will be automatically tracked. You can also track artifacts for additional steps within an ML workflow that come before/after model training e.g. data pre-processing or post-training model evaluation.\n",
    "\n",
    "The APIs also let you search and browse your current and past experiments, compare experiments, and identify best performing models.\n",
    "\n",
    "Now we will demonstrate these capabilities through an `CIFAR-10` handwritten digits classification example. The experiment will be organized as follows:\n",
    "\n",
    "1. Download and prepare the CIFAR-10 dataset.\n",
    "2. Train a ResNet-50 Convolutional Neural Network (CNN) Model. Tune the hyper parameter that configures the number of epochs and the optimizer in the model. Track the parameter configurations and resulting model accuracy using SageMaker Experiments Python SDK.\n",
    "3. Finally, use the search and analytics capabilities of Python SDK to search, compare, evaluate and visualize the performance of all model versions generated from model tuning in Step 2.\n",
    "\n",
    "Make sure you selected `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb162104",
   "metadata": {},
   "source": [
    "### Install Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker-experiments==0.1.31 matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bddaf",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f573dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f053d9",
   "metadata": {},
   "source": [
    "### Create a S3 bucket to hold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03901f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a s3 bucket to hold data, note that your account might already created a bucket with the same name\n",
    "account_id = sess.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "bucket = \"sagemaker-experiments-{}-{}\".format(sess.region_name, account_id)\n",
    "prefix = \"tf2-cifar10-experiment\"\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2234f6",
   "metadata": {},
   "source": [
    "### Download cifar10 dataset and upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96791708",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = cifar10.load_data()\n",
    "\n",
    "\n",
    "with open(\"./data/training/train_data.npy\", \"wb\") as f:\n",
    "    np.save(f, X_train)\n",
    "\n",
    "with open(\"./data/training/train_labels.npy\", \"wb\") as f:\n",
    "    np.save(f, y_train)\n",
    "\n",
    "with open(\"./data/validation/validation_data.npy\", \"wb\") as f:\n",
    "    np.save(f, X_valid)\n",
    "\n",
    "with open(\"./data/validation/validation_labels.npy\", \"wb\") as f:\n",
    "    np.save(f, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0516747",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_inputs_train = sagemaker.Session().upload_data(\n",
    "    path=\"data/training\", bucket=bucket, key_prefix=prefix + \"/training\"\n",
    ")\n",
    "s3_inputs_validation = sagemaker.Session().upload_data(\n",
    "    path=\"data/validation\", bucket=bucket, key_prefix=prefix + \"/validation\"\n",
    ")\n",
    "inputs = {\"training\": s3_inputs_train, \"validation\": s3_inputs_validation}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620e267",
   "metadata": {},
   "source": [
    "### Step 1 - Set up the Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : [1] a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or [2] a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or [3] a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f5651",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_experiment = Experiment.create(\n",
    "    experiment_name=f\"tf2-cifar10-classification-{int(time.time())}\",\n",
    "    description=\"Classification of CIFAR-10 dataset\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "print(cifar10_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dd68a",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment\n",
    "### Now create a Trial for each training run to track it's inputs, parameters, and metrics.\n",
    "While training the ResNet-50 CNN model on SageMaker, we will experiment with several values for the number of hidden channel in the model. We will create a Trial to track each training job run. We will also create a `TrialComponent` from the tracker we created before, and add to the Trial. This will enrich the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c42248",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_options = {\"optimizer\": [\"adam\", \"sgd\", \"rmsprop\"], \"epochs\": [5, 10]}\n",
    "\n",
    "hypnames, hypvalues = zip(*hyperparam_options.items())\n",
    "trial_hyperparameter_set = [dict(zip(hypnames, h)) for h in itertools.product(*hypvalues)]\n",
    "trial_hyperparameter_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03082be5",
   "metadata": {},
   "source": [
    "If you want to run the following training jobs asynchronously, you may need to increase your resource limit. Otherwise, you can run them sequentially.\n",
    "\n",
    "<b>Note the execution of the following code takes around an hour.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "run_number = 1\n",
    "for trial_hyp in trial_hyperparameter_set:\n",
    "    # Combine static hyperparameters and trial specific hyperparameters\n",
    "    hyperparams = trial_hyp\n",
    "\n",
    "    # Create unique job name with hyperparameter and time\n",
    "    time_append = int(time.time())\n",
    "    hyp_append = \"-\".join([str(elm) for elm in trial_hyp.values()])\n",
    "    training_job_name = f\"tf2-cifar10-training-{hyp_append}-{time_append}\"\n",
    "    trial_name = f\"trial-tf2-cifar10-training-{hyp_append}-{time_append}\"\n",
    "    trial_desc = f\"my-tensorflow2-cifar10-run-{run_number}\"\n",
    "\n",
    "    # Create a new Trial and associate Tracker to it\n",
    "    tf2_cifar10_trial = Trial.create(\n",
    "        trial_name=trial_name,\n",
    "        experiment_name=cifar10_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "        tags=[{\"Key\": \"trial-desc\", \"Value\": trial_desc}],\n",
    "    )\n",
    "\n",
    "    # Create an experiment config that associates training job to the Trial\n",
    "    experiment_config = {\n",
    "        \"ExperimentName\": cifar10_experiment.experiment_name,\n",
    "        \"TrialName\": tf2_cifar10_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": training_job_name,\n",
    "    }\n",
    "\n",
    "    metric_definitions = [\n",
    "        {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "    ]\n",
    "\n",
    "    # Create a TensorFlow Estimator with the Trial specific hyperparameters\n",
    "    cifar10_estimator = TensorFlow(\n",
    "        entry_point=\"cifar10_tf2.py\",\n",
    "        source_dir=\"source_dir\",\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.p3.2xlarge\",\n",
    "        framework_version=\"2.4.1\",\n",
    "        hyperparameters=hyperparams,\n",
    "        py_version=\"py37\",\n",
    "        metric_definitions=metric_definitions,\n",
    "        enable_sagemaker_metrics=True,\n",
    "        tags=[{\"Key\": \"trial-desc\", \"Value\": trial_desc}],\n",
    "    )\n",
    "\n",
    "    # Launch a training job\n",
    "    cifar10_estimator.fit(inputs, job_name=training_job_name, experiment_config=experiment_config)\n",
    "\n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)\n",
    "    run_number = run_number + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253a2f0",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now we will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30277e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "experiment_name = cifar10_experiment.experiment_name\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, experiment_name=experiment_name\n",
    ")\n",
    "trial_comp_ds_jobs = trial_component_analytics.dataframe()\n",
    "trial_comp_ds_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7d86a",
   "metadata": {},
   "source": [
    "Let's show the accuracy, epochs and optimizer.\n",
    "We will sort the results by accuracy descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_comp_ds_jobs = trial_comp_ds_jobs.sort_values(\"accuracy - Last\", ascending=False)\n",
    "trial_comp_ds_jobs[\"epochs\"] = trial_comp_ds_jobs[\"epochs\"].astype(\"Int64\").astype(\"str\")\n",
    "trial_comp_ds_jobs[[\"TrialComponentName\", \"accuracy - Last\", \"epochs\", \"optimizer\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffafe4f",
   "metadata": {},
   "source": [
    "### Visualize experiment\n",
    "\n",
    "Now we visualize the epochs/optimizer vs. accuracy in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trial_comp_ds_jobs[\"col_names\"] = (\n",
    "    trial_comp_ds_jobs[\"epochs\"] + \"-\" + trial_comp_ds_jobs[\"optimizer\"]\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches([15, 10])\n",
    "trial_comp_ds_jobs.plot.bar(\"col_names\", \"accuracy - Last\", ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac8abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}