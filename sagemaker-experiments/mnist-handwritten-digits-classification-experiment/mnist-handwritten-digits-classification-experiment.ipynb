{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a SageMaker Experiment with MNIST Handwritten Digits Classification\n",
    "\n",
    "This demo shows how you can use the [SageMaker Experiments Python SDK](https://sagemaker-experiments.readthedocs.io/en/latest/) to organize, track, compare, and evaluate your machine learning (ML) model training experiments.\n",
    "\n",
    "You can track artifacts for experiments, including data sets, algorithms, hyperparameters, and metrics. Experiments executed on SageMaker such as SageMaker Autopilot jobs and training jobs are automatically tracked. You can also track artifacts for additional steps within an ML workflow that come before or after model training, such as data pre-processing or post-training model evaluation.\n",
    "\n",
    "The APIs also let you search and browse your current and past experiments, compare experiments, and identify best-performing models.\n",
    "\n",
    "We demonstrate these capabilities through an MNIST handwritten digits classification example. The experiment is organized as follows:\n",
    "\n",
    "1. Download and prepare the MNIST dataset.\n",
    "2. Train a Convolutional Neural Network (CNN) Model. Tune the hyperparameter that configures the number of hidden channels in the model. Track the parameter configurations and resulting model accuracy using the SageMaker Experiments Python SDK.\n",
    "3. Finally use the search and analytics capabilities of the SDK to search, compare and evaluate the performance of all model versions generated from model tuning in Step 2.\n",
    "4. We also show an example of tracing the complete lineage of a model version: the collection of all the data pre-processing and training configurations and inputs that went into creating that model version.\n",
    "\n",
    "Make sure you select the `Python 3 (Data Science)` kernel in Studio, or `conda_pytorch_p36` in a notebook instance.\n",
    "\n",
    "## Runtime\n",
    "\n",
    "This notebook takes approximately 25 minutes to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Install modules](#Install-modules)\n",
    "1. [Setup](#Setup)\n",
    "1. [Download the dataset](#Download-the-dataset)\n",
    "1. [Step 1: Set up the Experiment](#Step-1:-Set-up-the-Experiment)\n",
    "1. [Step 2: Track Experiment](#Step-2:-Track-Experiment)\n",
    "1. [Deploy an endpoint for the best training job / trial component](#Deploy-an-endpoint-for-the-best-training-job-/-trial-component)\n",
    "1. [Cleanup](#Cleanup)\n",
    "1. [Contact](#Contact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the SageMaker Experiments Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install sagemaker-experiments==0.1.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch version needs to be the same in both the notebook instance and the training job container\n",
    "# https://github.com/pytorch/pytorch/issues/25214\n",
    "!{sys.executable} -m pip install torch==1.1.0\n",
    "!{sys.executable} -m pip install torchvision==0.2.2\n",
    "!{sys.executable} -m pip install pillow==6.2.2\n",
    "!{sys.executable} -m pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "set_matplotlib_formats(\"retina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sess = sagemaker.Session()\n",
    "sess = sm_sess.boto_session\n",
    "sm = sm_sess.sagemaker_client\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "We download the MNIST handwritten digits dataset, and then apply a transformation on each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sm_sess.default_bucket()\n",
    "prefix = \"DEMO-mnist\"\n",
    "print(\"Using S3 location: s3://\" + bucket + \"/\" + prefix + \"/\")\n",
    "\n",
    "datasets.MNIST.urls = [\n",
    "    \"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-images-idx3-ubyte.gz\",\n",
    "    \"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-labels-idx1-ubyte.gz\",\n",
    "    \"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-images-idx3-ubyte.gz\",\n",
    "    \"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-labels-idx1-ubyte.gz\",\n",
    "]\n",
    "\n",
    "# Download the dataset to the ./mnist folder, and load and transform (normalize) them\n",
    "train_set = datasets.MNIST(\n",
    "    \"mnist\",\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    \"mnist\",\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View an example image from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_set.data[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the images in the dataset, we upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker.Session().upload_data(path=\"mnist\", bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's track the parameters from the data pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    tracker.log_parameters(\n",
    "        {\n",
    "            \"normalization_mean\": 0.1307,\n",
    "            \"normalization_std\": 0.3081,\n",
    "        }\n",
    "    )\n",
    "    # We can log the S3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"mnist-dataset\", media_type=\"s3/uri\", value=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up the Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for: [1] a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or [2] a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or [3] a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=f\"mnist-hand-written-digits-classification-{int(time.time())}\",\n",
    "    description=\"Classification of mnist hand-written digits\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Track Experiment\n",
    "### Now create a Trial for each training run to track its inputs, parameters, and metrics.\n",
    "While training the CNN model on SageMaker, we experiment with several values for the number of hidden channel in the model. We create a Trial to track each training job run. We also create a TrialComponent from the tracker we created before, and add to the Trial. This enriches the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch, PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channel_trial_name_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run the following five training jobs in parallel, you may need to increase your resource limit. Here we run them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_trial_component = tracker.trial_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, num_hidden_channel in enumerate([2, 5, 10, 20, 32]):\n",
    "    # Create trial\n",
    "    trial_name = f\"cnn-training-job-{num_hidden_channel}-hidden-channels-{int(time.time())}\"\n",
    "    cnn_trial = Trial.create(\n",
    "        trial_name=trial_name,\n",
    "        experiment_name=mnist_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "    hidden_channel_trial_name_map[num_hidden_channel] = trial_name\n",
    "\n",
    "    # Associate the proprocessing trial component with the current trial\n",
    "    cnn_trial.add_trial_component(preprocessing_trial_component)\n",
    "\n",
    "    # All input configurations, parameters, and metrics specified in\n",
    "    # the estimator definition are automatically tracked\n",
    "    estimator = PyTorch(\n",
    "        py_version=\"py3\",\n",
    "        entry_point=\"./mnist.py\",\n",
    "        role=role,\n",
    "        sagemaker_session=sagemaker.Session(sagemaker_client=sm),\n",
    "        framework_version=\"1.1.0\",\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.c4.xlarge\",\n",
    "        hyperparameters={\n",
    "            \"epochs\": 2,\n",
    "            \"backend\": \"gloo\",\n",
    "            \"hidden_channels\": num_hidden_channel,\n",
    "            \"dropout\": 0.2,\n",
    "            \"kernel_size\": 5,\n",
    "            \"optimizer\": \"sgd\",\n",
    "        },\n",
    "        metric_definitions=[\n",
    "            {\"Name\": \"train:loss\", \"Regex\": \"Train Loss: (.*?);\"},\n",
    "            {\"Name\": \"test:loss\", \"Regex\": \"Test Average loss: (.*?),\"},\n",
    "            {\"Name\": \"test:accuracy\", \"Regex\": \"Test Accuracy: (.*?)%;\"},\n",
    "        ],\n",
    "        enable_sagemaker_metrics=True,\n",
    "    )\n",
    "\n",
    "    cnn_training_job_name = \"cnn-training-job-{}\".format(int(time.time()))\n",
    "\n",
    "    # Associate the estimator with the Experiment and Trial\n",
    "    estimator.fit(\n",
    "        inputs={\"training\": inputs},\n",
    "        job_name=cnn_training_job_name,\n",
    "        experiment_config={\n",
    "            \"TrialName\": cnn_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n",
    "\n",
    "    # Wait two seconds before dispatching the next training job\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now we use the analytics capabilities of the Experiments SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Simple Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\": [\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(sess, sm),\n",
    "    experiment_name=mnist_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=[\"test:accuracy\"],\n",
    "    parameter_names=[\"hidden_channels\", \"epochs\", \"dropout\", \"optimizer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To isolate and measure the impact of change in hidden channels on model accuracy, we vary the number of hidden channel and fix the value for other hyperparameters.\n",
    "\n",
    "Next let's look at an example of tracing the lineage of a model by accessing the data tracked by SageMaker Experiments for the `cnn-training-job-2-hidden-channels` trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(sess, sm),\n",
    "    search_expression={\n",
    "        \"Filters\": [\n",
    "            {\n",
    "                \"Name\": \"Parents.TrialName\",\n",
    "                \"Operator\": \"Equals\",\n",
    "                \"Value\": hidden_channel_trial_name_map[2],\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy an endpoint for the best training job / trial component\n",
    "\n",
    "Now we take the best model and deploy it to an endpoint so it is available to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling best based on sort in the analytics/dataframe, so first is best....\n",
    "best_trial_component_name = trial_component_analytics.dataframe().iloc[0][\"TrialComponentName\"]\n",
    "best_trial_component = TrialComponent.load(best_trial_component_name)\n",
    "\n",
    "model_data = best_trial_component.output_artifacts[\"SageMaker.ModelArtifact\"].value\n",
    "env = {\n",
    "    \"hidden_channels\": str(int(best_trial_component.parameters[\"hidden_channels\"])),\n",
    "    \"dropout\": str(best_trial_component.parameters[\"dropout\"]),\n",
    "    \"kernel_size\": str(int(best_trial_component.parameters[\"kernel_size\"])),\n",
    "}\n",
    "model = PyTorchModel(\n",
    "    model_data,\n",
    "    role,\n",
    "    \"./mnist.py\",\n",
    "    py_version=\"py3\",\n",
    "    env=env,\n",
    "    sagemaker_session=sagemaker.Session(sagemaker_client=sm),\n",
    "    framework_version=\"1.1.0\",\n",
    "    name=best_trial_component.trial_component_name,\n",
    ")\n",
    "\n",
    "predictor = model.deploy(instance_type=\"ml.m5.xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Once we're done, clean up the endpoint to prevent unnecessary billing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial components can exist independently of trials and experiments. You might want keep them if you plan on further exploration. If not, delete all experiment artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment.delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact\n",
    "Submit any questions or issues to https://github.com/aws/sagemaker-experiments/issues or mention @aws/sagemakerexperimentsadmin "
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
