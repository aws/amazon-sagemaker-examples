{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Boson Detection with XGBoost\n",
    "This tutorial will walk thorugh an example of training an XGBoost model using data from the [2014 ATLAS Higgs Boson Machine Learning Challenge](http://opendata.cern.ch/record/328). Additionally, this example will showcase some of the new features available in SageMaker Debugger such as the Profiler and the XGBoost training report. The profiler report display various hardware metrics such as cpu, gpu, memory, and IO utilization which will help you identify any hardware bottlenecks and appropriately choose the right size hardware for your training job. The XGBoost training report will provide a comprehensive evaluation of your model's perfomance to help you fine-tune and imporve your model.\n",
    "\n",
    "The [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) module  makes it easy to train XGBoost models. For more information about training XGBoost models on SageMaker, see the [XGBoost Algoritm Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) and the [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) repository.\n",
    "\n",
    "For more on XGBoost, please visit the XGBoost website: <https://xgboost.readthedocs.io/en/latest/>.\n",
    "\n",
    "### Table of contents\n",
    "* [Setup and imports](#setup)\n",
    "* [Get and prepare data](#data)\n",
    "* [Create the SageMaker XGBoost Estimator](#estimator)\n",
    "* [Train XGBoost Model](#train)\n",
    "* [View post training reports](#reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup<a class=\"anchor\" id=\"setup\"></a>\n",
    "This notebook was created and tested on an ml.t3.medium notebook instance.\n",
    "\n",
    "After we've installed and imported the required  packages, we'll need to specify a few variable that will be utilized throughout the example:\n",
    "- `role`: The IAM role that will be used to run our training job. The default SageMaker role will be used\n",
    "- `sess`: The SageMaker session that will be utilized to interact with different AWS services\n",
    "- `bucket`: The S3 bucket where the model's input and output data will be stored. Default SageMaker Bucket will be used\n",
    "- `key_prefix`: The directory in the S3 bucket where we'll store the input and output data\n",
    "- `region`: The AWS region where we'll be operating\n",
    "- `s3`: s3fs client to make it easier to read and write data to and from S3\n",
    "- `xgboost_container`: The URI for the XGBoost training container for our region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq sagemaker\n",
    "!pip install -Uqq s3fs==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import s3fs\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "\n",
    "from IPython.display import FileLink, FileLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup sagemaker variables\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "key_prefix = \"higgs-boson\"\n",
    "region = sess._region_name\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "xgboost_container = image_uris.retrieve(\"xgboost\", region, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and prepare data <a class=\"anchor\" id=\"data\"></a>\n",
    "\n",
    "The data that will be used for this example comes from the European Organization for Nuclear Research (CERN). This data was utilized in a 2014 machine learning competition where participants had to develop an algorithm that improves the detection of Higgs boson signal events decaying into two tau particles from a sample of simulated ATLAS data. More background and details on this interesting data set can be obtained [here](http://opendata.cern.ch/record/328)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from CERN and load it directly into memory\n",
    "data_url = \"http://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz\"\n",
    "gz_file = BytesIO(requests.get(data_url).content)\n",
    "gz_file.flush()\n",
    "df = pd.read_csv(gz_file, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the columns we don't need and identify columns that will be used as features as well as the target\n",
    "non_feature_cols = [\"EventId\", \"Weight\", \"KaggleSet\", \"KaggleWeight\", \"Label\"]\n",
    "feature_cols = [col for col in df.columns if col not in non_feature_cols]\n",
    "label_col = \"Label\"\n",
    "df[\"Label\"] = df[\"Label\"].apply(lambda x: 1 if x==\"s\" else 0)\n",
    "\n",
    "# The original competition split the data out into training and validation sets. The data includes a column that identifies which sample falls into which set\n",
    "train_data = df.loc[df[\"KaggleSet\"] == \"t\", [label_col, *feature_cols]]\n",
    "test_data = df.loc[df[\"KaggleSet\"] == \"b\", [label_col, *feature_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the SageMaker session, we upload the data to S3\n",
    "for name, dataset in zip([\"train\", \"test\"], [train_data, test_data]):\n",
    "    sess.upload_string_as_file_body(body=dataset.to_csv(index=False, header=False),\n",
    "                                   bucket=bucket,\n",
    "                                   key=f\"{key_prefix}/input/{name}.csv\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure data inputs for SageMaker training\n",
    "train_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/input/train.csv\", content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/input/test.csv\", content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create XGBoost Estimator <a class=\"anchor\" id=\"estimator\"></a>\n",
    "Here we will create a SageMaker Estimator using the XGBoost Image. We'll attach the SageMaker Debugger built-in `create_xgboost_report()` rule to automatically generate an XGBoost training report after the training job is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for the XGBoost model\n",
    "hyperparameters={\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "    \"eval_metric\": \"error\"\n",
    "}\n",
    "\n",
    "# add a rule to generate the XGBoost Report\n",
    "rules=[\n",
    "    Rule.sagemaker(rule_configs.create_xgboost_report())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker Estimator using the XGBoost image\n",
    "estimator=Estimator(\n",
    "    role=role,\n",
    "    image_uri=xgboost_container,\n",
    "    base_job_name=\"higgs-boson-model\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    rules=rules, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Model <a class=\"anchor\" id=\"train\"></a>\n",
    "Finally we launch a training job to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': train_input, 'validation': validation_input}, \n",
    "              wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View post Training Reports <a class=\"anchor\" id=\"reports\"></a>\n",
    "SageMaker generates the profiling and training reports though a pair of processing jobs that run concurrent to the training job. The code below will wait for the these two jobs to finish, an once they're done will download the outputs from S3 to jupyter for easier viewing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#get name of profiler report\n",
    "profiler_report_name = [rule[\"RuleConfigurationName\"] \n",
    "                        for rule in estimator.latest_training_job.rule_job_summary() \n",
    "                        if \"Profiler\" in rule[\"RuleConfigurationName\"]][0]\n",
    "\n",
    "#get name of the xgboost training report\n",
    "xgb_profile_job_name = [rule[\"RuleEvaluationJobArn\"].split(\"/\")[-1] \n",
    "                        for rule in estimator.latest_training_job.rule_job_summary() \n",
    "                        if \"CreateXgboostReport\" in rule[\"RuleConfigurationName\"]][0]\n",
    "\n",
    "base_output_path = os.path.dirname(estimator.latest_job_debugger_artifacts_path())\n",
    "rule_output_path = os.path.join(base_output_path, \"rule-output/\")\n",
    "xgb_report_path = os.path.join(rule_output_path, \"CreateXgboostReport\")\n",
    "profile_report_path = os.path.join(rule_output_path, profiler_report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    xgb_job_info = sess.sagemaker_client.describe_processing_job(ProcessingJobName=xgb_profile_job_name)\n",
    "\n",
    "    if xgb_job_info[\"ProcessingJobStatus\"] == \"Completed\":\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Job Status: {xgb_job_info['ProcessingJobStatus']}\")\n",
    "        time.sleep(30)\n",
    "\n",
    "s3.download(xgb_report_path, \"reports/xgb/\", recursive=True)\n",
    "s3.download(profile_report_path, \"reports/profiler/\", recursive=True)\n",
    "display(\"Click link below to view the profiler report whcih will help you identify hardware bottlenecks.\", FileLink(\"reports/profiler/profiler-output/profiler-report.html\"))\n",
    "display(\"Click link below to view the XGBoost Training reports which will help you imporve your model\", FileLink(\"reports/xgb/xgboost_report.html\"))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
